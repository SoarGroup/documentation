{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"What is Soar?","text":"<p>Soar is a general cognitive architecture for developing systems that exhibit intelligent behavior. Researchers all over the world, both from the fields of artificial intelligence and cognitive science, are using Soar for a variety of tasks. It has been in use since 1983, evolving through many different versions to where it is now Soar, Version 9.</p> <p>We intend ultimately to enable the Soar architecture to:</p> <ul> <li>work on the full range of tasks expected of an intelligent agent, from highly   routine to extremely difficult, open-ended problems</li> <li>represent and use appropriate forms of knowledge, such as procedural,   semantic, episodic, and iconic</li> <li>employ the full range of problem solving methods</li> <li>interact with the outside world, and</li> <li>learn about all aspects of the tasks and its performance on them.</li> </ul> <p>In other words, our intention is for Soar to support all the capabilities required of a general intelligent agent.</p> <p>The ultimate in intelligence would be complete rationality which would imply the ability to use all available knowledge for every task that the system encounters. Unfortunately, the complexity of retrieving relevant knowledge puts this goal out of reach as the body of knowledge increases, the tasks are made more diverse, and the requirements in system response time more stringent. The best that can be obtained currently is an approximation of complete rationality. The design of Soar can be seen as an investigation of one such approximation. Below is the primary principle which is the basis of Soar's design and which guides its attempt to approximate rational behavior.</p> <p>All decisions are made through the combination of relevant knowledge at run-time. In Soar, every decision is based on the current interpretation of sensory data, the contents of working memory created by prior problem solving, and any relevant knowledge retrieved from long-term memory. Decisions are never precompiled into uninterruptible sequences. For many years, a secondary principle has been that the number of distinct architectural mechanisms should be minimized. Through Soar 8, there has been a single framework for all tasks and subtasks (problem spaces), a single representation of permanent knowledge (productions), a single representation of temporary knowledge (objects with attributes and values), a single mechanism for generating goals (automatic subgoaling), and a single learning mechanism (chunking). We have revisited this assumption as we attempt to ensure that all available knowledge can be captured at runtime without disrupting task performance. This is leading to multiple learning mechanisms (chunking, reinforcement learning, episodic learning, and semantic learning), and multiple representations of long-term knowledge (productions for procedural knowledge, semantic memory, and episodic memory).</p> <p>Two additional principles that guide the design of Soar are functionality and performance. Functionality involves ensuring that Soar has all of the primitive capabilities necessary to realize the complete suite of cognitive capabilities used by humans, including, but not limited to reactive decision making, situational awareness, deliberate reasoning and comprehension, planning, and all forms of learning. Performance involves ensuring that there are computationally efficient algorithms for performing the primitive operations in Soar, from retrieving knowledge from long-term memories, to making decisions, to acquiring and storing new knowledge.</p> <p>For further background on Soar, we recommend Introduction to Soar at https://arxiv.org/abs/2205.03854 and The Soar Cognitive Architecture Laird, J.  E.(2012), The Soar Papers: Readings on Integrated Intelligence, Rosenbloom, Laird, and Newell (1993), and Unified Theories of Cognition, Newell (1990). Also available are Soar: A Functional Approach to General Intelligence and Soar: A comparison with Rule-Based Systems. There is also a full list of publications available. Entries on the Soar Knowledge Base and the older  Soar FAQ also provide answers to many common questions about Soar.</p> <p>We would like to extend a special thank you to DARPA, ONR and AFOSR for their continued support of Soar and projects related to Soar.</p>"},{"location":"explanations/","title":"Explanations","text":"<p>This section provides some explanations about the decisions behind Soar.</p> <ul> <li>Basic Kernel Terminology</li> <li>Design Dogma</li> <li>Threads in SML</li> <li>Timers</li> <li>Waterfall</li> </ul>"},{"location":"explanations/BasicKernelTerminology/","title":"Basic Kernel Terminology","text":"<p>This is a document that defines some of the basic data structures, files and terminology used in the Soar kernel code. It is very incomplete but a good starting point for understanding the kernel.</p> <p>\"But where can I start?\"</p> <p>In a nutshell: The Soar Kernel is a very object-oriented, structured set of code. If you don't understand the basic Soar execution cycle and its phases, the source code won't help you. You should start by reading the introductory material in the Soar Tutorials that are bundled with the releases (in the Documents directory). Then read the first four chapters of the Soar Manual, \"Introduction\" thru \"Learning\" Basic code execution</p>","tags":["kernel programming"]},{"location":"explanations/BasicKernelTerminology/#data-structures","title":"Data Structures","text":"<p>All of the structures are well-commented in the header files. In earlier versions of Soar (up thru 8.3.5), the single header file \"soarkernel.h\" defined all the common structures used throughout the code. I still find it the easiest place to search for information even though it's a very large file as code goes. In 8.6. and later, the header file was separated by function into many smaller files which can be found in \"Core/SoarKernel/include\".</p> <p>The <code>agent_struct</code> defined in agent.h includes all the system parameters, counters, variables, and pointers to all the other structures used by an agent (WMEs, productions, hash tables, memory_pools, formats, etc etc). It's a BIG structure, tough to read, and includes a lot of detailed comments. But if it isn't defined or allocated here, the agent doesn't know about it.</p> <p>Chances are you will never modify any structures in the rete, lexer, hash tables, or backtracing facilities, but you should know that they exist. If you do start to muck with these structures, you better know what you are doing. Changes here can greatly impact performance and even whether or not Soar will run properly. Several structures require their members to be defined in specific order and are commented appropriately.</p> <p>Structures that you should familiarize yourself with are symbols (a typedef'd union!!), wmes, productions, instantiations, preferences, and (eventually) memory pools. </p> <ul> <li>symbol_struct is in symtab.h, everything in soar boils down to     some kind of symbol. See Development/ Symbol for details. </li> <li>wme_struct is in wmem.h, defines the working memory elements of an agent </li> <li>production_struct is in production.h, these are the productions as loaded into     Soar and stored in the rete. instantiations are in instantiation.h, these store     the bindings of productions as they are matched in the rete. Instantiations     whose conditions all</li> <li>match are fired during specific phases - meaning their actions are executed:     preferences are asserted to create wmes, and/or RHS actions are executed.</li> <li>preference_struct is defined in gdatastructs.h store a pointer to the     instantiation that created them, and when the instantiation no longer matches,     the preference is retracted. </li> </ul>","tags":["kernel programming"]},{"location":"explanations/BasicKernelTerminology/#i-want-to-add-a-new-link","title":"I want to add a new link!","text":"<p>Existing links include input/output and reward links. Instructions on how to make your own are HowTo: IO and reward links.</p>","tags":["kernel programming"]},{"location":"explanations/BasicKernelTerminology/#things-to-add","title":"Things to add","text":"<p>A lot of topics are in the Soar FAQ</p> <ul> <li>Basic structure of how critical code works (e.g. decision procedure is a big     switch statement, how printing/XML generation works)</li> <li>Locations of critical code (e.g. decision procedure, preference procedure, scheduler)</li> <li>Union basics (most people don't know what unions are)<ul> <li>see Kernigan and Ritchie</li> <li>Unions are a data structure that can have multiple data-dependent ways of     storing and accessing information, much like (but better than) overloading     methods in C++.</li> </ul> </li> <li>Explain how sysparams work (e.g. how they are set/used, how to add a new one)</li> <li>sysparams are just an array of agent parameters that store settings for     runtime switches. Most of the sysparams are either True/False, or can take on     some enum value. Setting a sysparam is easy, cf. init_soar.c for     initializing and setting values. Search the code for \"set_sysparams\" to see     examples.</li> <li>To add a sysparam, see gsysparams.h (although that file MUST be renamed or     folded into another header when gSKI removed). The code depends on looping over     HIGHEST_SYSPARAM, so make sure it's always equal to the last one in the set of     definitions.</li> <li>When is it a sysparam, and when is it part of the agent struct? Depends what     you are using it for, and whether it needs to be exposed for the user interface.     If its a user-controlled setting, it should definitely be a sysparam.</li> <li>What is a slot</li> </ul> <p>From John:</p> <p>\"We used to select more than just the operator (state, problem space, and goal) and all together this was the context. Slots were for things that can be selected, so there was a slot for each of those. Now there is just a slot for the operator and although some of that language might have bled over to selection of values for non-operator attributes. In general they are an out of date terminology.\"</p> <ul> <li>Basics of how wme changes are done in parallel (i.e. explain do_buffered_wm_and_ownership_changes)</li> <li>Difference between wme and input_wme (and any other wmes there might be)</li> <li>Where/how to add new links (e.g. ep-mem link, RL link, etc)</li> <li> <p>Explain memory pool basics</p> </li> <li> <p>Basics of bit manipulations that are used (unless this is rete-only, in which     case don't bother)</p> <ul> <li>I think the rete is the only place bit manipulations occur. Bit     manipulations are extremely fast. If you can guarantee your raw data     structure, you can shift registers instead of calling complex instructions     to go very fast. Compilers hide this from you, but don't always know when     they can optimize.</li> </ul> </li> <li>Explain transitive closure and tc_num</li> <li>What all the Soar kernel STL-like data structures are (e.g. lists, hash tables, growable strings, others?) and how to use them. Ref counting (link to Tracking down memory leaks)</li> </ul>","tags":["kernel programming"]},{"location":"explanations/BasicKernelTerminology/#some-definitions","title":"Some Definitions","text":"","tags":["kernel programming"]},{"location":"explanations/BasicKernelTerminology/#slot","title":"slot","text":"<p>From John Laird:</p> <p>We used to select more than just the operator (state, problem space, and goal) all together this was the context. Slots were for things that can be selected, so there was a slot for each of those. Now there is just a slot for the operator, although some of that language might have bled over to selection of values for non-operator attributes. In general they are an out of date terminology.</p> <p>Slots are contained by identifiers, and hold all the preferences associated with the identifier, including acceptable wme preferences. Each identifier can have multiple slots, which can be accessed via the prev and next fields in the slot structure. Operator preferences are held incontext slots, which are identified by the isa_context_slot flag.</p>","tags":["kernel programming"]},{"location":"explanations/BasicKernelTerminology/#tc","title":"tc","text":"<p>transitive closure</p>","tags":["kernel programming"]},{"location":"explanations/BasicKernelTerminology/#match-goal","title":"match goal","text":"<p>The lowest goal (biggest number after the \"S\") that an instantiation of the LHS of a production matches on. Part of the instantiation structure.</p>","tags":["kernel programming"]},{"location":"explanations/BasicKernelTerminology/#potential","title":"potential","text":"<p>Also referred to as backtracing.</p> <p>condition whose id is instantiated on a symbol linked from both the current goal and a higher goal, and is tested for in the production's LHS using a path from the current goal.</p> <p>For example, if the following wmes are in working memory</p> <pre><code>(S1 ^foo F1)\n(S2 ^bar F1)\n(F1 ^baz B1)\n(S2 ^superstate S1)\n\nand this production was backtraced through\nCode:\nsp {example\n   (&lt;s&gt; ^bar &lt;b&gt;)\n   (&lt;b&gt; ^baz &lt;z&gt;)\n--&gt;\n   ...}\n</code></pre> <p>then <code>(&lt;b&gt; ^baz &lt;z&gt;)</code> would be a potential condition.</p>","tags":["kernel programming"]},{"location":"explanations/BasicKernelTerminology/#potential-life","title":"potential (life)","text":"<p>abstract invented concept that actually has no real meaning.</p>","tags":["kernel programming"]},{"location":"explanations/BasicKernelTerminology/#tm","title":"tm","text":"<p>temporary memory. I believe that any preference that is currently valid in Soar (either they are o-supported or the instantiation that generated them still matches) is in temporary memory. Once a preference is no longer valid, it is taken out of temporary memory (which involves setting the in_tm flag to false, and taking them off the preferences array and all_preferences lists on the slot they're on). |</p>","tags":["kernel programming"]},{"location":"explanations/BasicKernelTerminology/#clone-preference","title":"clone (preference)","text":"<p>a copy of a preference that is the result of a subgoal. While the inst pointer of the original preference points to the instantiation of the rule that fired in the subgoal to create the result, the inst pointer of the clone points to the newly created chunk or justification. Therefore, the preference and its clone exist on different match goals, and hence different match goal levels. |</p>","tags":["kernel programming"]},{"location":"explanations/BasicKernelTerminology/#instantiation","title":"instantiation","text":"<p>a particular match of a production in working memory, and the preferences generated |</p>","tags":["kernel programming"]},{"location":"explanations/BasicKernelTerminology/#debug_memory","title":"DEBUG_MEMORY","text":"<p>if this flag is defined, the contents of freed memory locations in the memory pools are memset to <code>0xBB</code></p>","tags":["kernel programming"]},{"location":"explanations/DesignDogma/","title":"Soar Design Dogma","text":"","tags":["agent debugging"]},{"location":"explanations/DesignDogma/#introduction","title":"Introduction","text":"<p>This document contains a collection of Soar wisdom gathered during a series of conversations between John Laird and myself as I mounted the Soar learning curve over the course of my first year as a graduate student at the University of Michigan. My hope was that by writing these guidelines down I might ease the curve for future Soar users. To get the most value from this document, I recommend you read it once at the beginning of your Soar experience and then read it again once you've started using Soar in earnest.</p>","tags":["agent debugging"]},{"location":"explanations/DesignDogma/#golden-rule-beware-the-devil-of-character-efficiency","title":"Golden Rule: Beware the Devil of Character Efficiency","text":"<p>Focus on creating short productions with only a few conditions and actions. As a rule of thumb, a production should have less than a handful (i.e., five) of each. If you have a production that's too big, it's a sign that you should examine that production and see if it should be broken up into multiple smaller productions.</p> <p>A production with too many conditions often has a subset of conditions that define a separate \"concept\" that should be identified with a separate elaboration. When counting conditions, you should only count those that actually test a WME for its value not to reach other WMEs. For example, the condition <code>(&lt;s&gt; ^io.input-link &lt;il&gt;)</code> likely doesn't count because it's probably being used to reach and test another WME on the input link.</p> <p>If a rule has too many actions usually some of those actions are not truly related. Consider separating it into multiple productions with the same or similar conditions. When counting actions, you should only count those that actually add or remove a WME in working memory. Exception: Initialization rules can often have a very large number of actions and this is ok.</p> <p>Example</p> <p>The rule shown at left (below) was taken from TankSoar. It has a total of six conditions. This is not necessarily too big. However, if you study this production (and you are familiar with TankSoar), you'll see that it is really testing three high level conditions:</p> <ul> <li>Am I in the state <code>tankSoar</code>?</li> <li>Am I low on health (less than 300)?</li> <li>Am I in danger?</li> </ul> <p>Adding an elaboration to detect \"in-danger\" not only makes the rule easier to read but also provides a potentially useful WME for use by other productions. The revised production and its companion elaboration are shown in the second example.</p> <pre><code>sp {propose*recharge*health-BAD\n   (state &lt;s&gt; ^name tanksoar\n              ^io.input-link &lt;il&gt;)\n   (&lt;il&gt; ^radar.tank.distance &gt; 0\n         ^health &lt; 300\n        -^smell.distance &lt; 4\n        -^sound\n        -^incoming)\n--&gt;\n   (&lt;s&gt; ^operator &lt;o&gt; +)\n   (&lt;o&gt; ^name recharge-health)\n}\n</code></pre> <pre><code>sp {elaborate*in-danger\n   (state &lt;s&gt; ^name tanksoar\n              ^io.input-link &lt;il&gt;)\n   (&lt;il&gt; ^radar.tank.distance &gt; 0\n        -^smell.distance &lt; 4\n        -^sound\n        -^incoming)\n--&gt;\n   (&lt;s&gt; ^in-danger yes)\n}\n\nsp {propose*recharge*health\n   (state &lt;s&gt; ^name tanksoar\n              ^in-danger yes\n              ^io.input-link &lt;il&gt;)\n   (&lt;il&gt; ^health &lt; 300)\n--&gt;\n   (&lt;s&gt; ^operator &lt;o&gt; +)\n   (&lt;o&gt; ^name recharge-health)\n}\n</code></pre> <p>Justification</p> <p>Smaller productions are easier to re-use and easier to understand when you return to them later. Smaller rules also lead to more general chunks. Instead of watching for a specific combination of data, the chunk will learn to watch for only one matching augmentation on the state. Productions with lots of conditions often produce many partial matches on the RETE network (see the memories command in the Soar Manual) that will noticeably slow down performance. Productions with lots of actions can lead to unwanted or unexpected side effects as the program evolves.</p>","tags":["agent debugging"]},{"location":"explanations/DesignDogma/#only-include-the-conditions-you-need","title":"Only include the conditions you need","text":"<p>When proposing an operator, don't compute information that won't be needed until application. Exception: It's ok to attach matched values that were already required for the conditions of the proposal rule.</p> <p>Example</p> <p>Your TankSoar tank needs to turn on its radar whenever it turns. You've cleverly decided to set the range of the radar based upon the tank's distance from the wall it is facing in order to save energy. Rather than calculate this range in the proposal rule, use a separate elaboration to add the range data once the operator has been selected.</p> <p>Justification</p> <p>Clearly this practice reduces rule size and provides a small savings in execution time. It also prevents operators from being rejected and re-proposed when the extraneous data changes.</p>","tags":["agent debugging"]},{"location":"explanations/DesignDogma/#consider-all-your-options","title":"Consider all your options","text":"<p>Operator proposal rules should fire whenever an operator is legitimate, not just when it is appropriate. Exception: If limiting the agent's options will significantly improve its performance you may consider violating this guideline.</p> <p>Example</p> <p>You decide to modify your Eater so that it never moves back to the square it just came from. Rather than only proposing moves to new squares, propose moves to all adjacent squares and use selection operators to assign a less or least preference to the undesired direction.</p> <p>Justification</p> <p>You never know when your worst option is also your best. Deciding what to do is the job of operator preference rules. You should not short-circuit this mechanism without good reason. Also, as stated above, additional conditions for operator proposal may cause unnecessary operator retraction and re-proposal.</p>","tags":["agent debugging"]},{"location":"explanations/DesignDogma/#one-action-per-operator","title":"One action per operator","text":"<p>The name of the operator should indicate specifically what actions you are taking. In particular, avoid \"multi-use\" operators that perform similar actions for significantly different reasons depending upon what augmentations they have.</p> <p>Example</p> <p>Your agent needs to be able to navigate to a waypoint or a given <code>x, y, z</code> position. The move-to-waypoint operators could be implemented as a special case of the move-to-xyz operator. However, this is probably poor practice.</p> <p>Justification</p> <p>When an operator is vaguely named or has multiple behaviors your Soar program will be difficult to debug because you aren't certain what the agent is doing. You can get the same effect by having additional augmentations on the operator that trigger the general actions. For example, you could have <code>^type</code> move on the above operators and there can be selection and application rules that test for the type (but not the name).</p>","tags":["agent debugging"]},{"location":"explanations/DesignDogma/#dont-force-operator-proposals","title":"Don't force operator proposals","text":"<p>If you find yourself adding operators that put o-supported data on the top state for the sole purpose of causing another rule to fire and not be retracted when the original data changes you're probably doing something wrong.</p> <p>Example</p> <p>In a real time system, you want the agent to turn toward an object. First, you write your proposal operator to match the heading (angle off) to the object and then turn to it. Unfortunately, since you must turn to reach the new heading, the angle off to the object changes and the operator retracts before you complete. You decide to have on operator record the angle off on the top state and a second operator turn to that angle off as recorded.</p> <p>A better solution: Create an I-supported augmentation that records that the object is to the agent's right, left or directly in front. Have your agent turn in the specified direction until the object is in front of the agent.</p> <p>Justification</p> <p>Having operators depend on transient, yet o-supported top state augmentations can cause problems if the operator that removes that augmentation is interrupted.</p>","tags":["agent debugging"]},{"location":"explanations/DesignDogma/#avoid-assumptions","title":"Avoid assumptions","text":"<p>Whenever you remove a WME in the actions of a rule, test that WME exists in the conditions of a rule.</p> <p>Example</p> <pre><code>sp {apply*remove-foo\n   (state &lt;s&gt; ^name my-state\n              ^operator &lt;o&gt;)\n   (&lt;o&gt; ^name remove-foo)\n--&gt;\n   (&lt;s&gt; ^foo bar -)           # BAD!\n}\n</code></pre> <pre><code>sp {apply*remove-foo\n   (state &lt;s&gt; ^name my-state\n              ^operator &lt;o&gt;\n              ^foo bar)       # Correct\n   (&lt;o&gt; ^name remove-foo)\n--&gt;\n   (&lt;s&gt; ^foo bar -)\n}\n</code></pre> <p>Justification</p> <p>The purpose of a rule is to minimize implicit assumptions.</p>","tags":["agent debugging"]},{"location":"explanations/DesignDogma/#establish-a-proper-context-for-o-support","title":"Establish a Proper Context for O-Support","text":"<p>When the operator application rule of a substate modifies a superstate, the rule should always include an attribute of that superstate in its conditions. The best way to do this is to reference the state(s) that will be modified by name if possible. (See the next section.)</p> <p>Example</p> <p>You create a generic rule that adds a \"last-action\" WME to the top state (i.e., the last action taken by the agent). To create this generic rule you only match on actions on the output-link.</p> <p>Justification</p> <p>O-support means \"permanent\" only in the context of the state(s) that were tested to create it. Once those state(s) cease to exist, the o-supported WMEs are removed even if they are used to augment a state that has not been removed. Specifically, Soar establishes the context of an o-supported attribute by examining the states that are tested in the operator proposal rule for the operator that created the attribute. Therefore, if an operator proposal rule does not test any part of the state it intends to modify, then o-supported attributes that are created by applying that operator will vanish as soon as you leave the current state.</p>","tags":["agent debugging"]},{"location":"explanations/DesignDogma/#use-state-names","title":"Use State Names","text":"<p>If possible, refer to a state or states by name in the LHS of operator proposal rules.</p> <p>Example</p> <pre><code>sp {my-rule\n   (state &lt;s&gt; ^name mystate)\n# etc...\n</code></pre> <p>Justification</p> <p>By being specific about the context of a rule, you prevent it from firing when least expected! This also often prevents more subtle problems like vanishing o-supported WMEs (see previous section).</p>","tags":["agent debugging"]},{"location":"explanations/DesignDogma/#an-agent-has-only-one-state","title":"An Agent has only one State","text":"<p>When possible, avoid rules that test multiple states.</p> <p>Example</p> <pre><code>sp {my-rule\n   (state &lt;s&gt; ^name state1)\n   (state &lt;s&gt; ^name state2)\n# etc...\n</code></pre> <p>Justification</p> <p>This creates multiple matches on the RETE and may, as a result, create performance bottlenecks.</p>","tags":["agent debugging"]},{"location":"explanations/DesignDogma/#use-an-ide-like-visualsoar","title":"Use an IDE like VisualSoar","text":"<p>Write your Soar code using VisualSoar. If so, maintain and use your VisualSoar data map!</p> <p>Example</p> <p>N/A</p> <p>Justification</p> <p>Much like comments on code, VisualSoar's enforced structure and data map is exceptionally helpful for people who are examining code they have not themselves written. VisualSoar provides helpful functionality like syntax highlighting and identifier completion. It also helps you catch bugs in your code by watching for rules that match unspecified WMEs. Such bugs (particularly typos involving nearly identical letters like l and 1) can sometimes require significant effort to discover.</p>","tags":["agent debugging"]},{"location":"explanations/DesignDogma/#dont-sacrifice-semantics-for-syntax","title":"Don't Sacrifice Semantics for Syntax","text":"<p>Only write rules that perform standard problem space functions: state elaboration, operator proposal, operator comparison, operator elaboration, and operator application. Do not write rules that:</p> <ul> <li>Test a selected operator in a rule that creates a preference for another operator.</li> <li>Test a for a currently proposed operator in the condition of another operator proposal rule.</li> <li>Test a proposed operator in the conditions of a rule that modify a state (outside of     the operator).</li> </ul> <p>Example</p> <pre><code>sp {xxyyzz\n   (state &lt;s&gt; ^att &lt;v&gt;\n              ^operator &lt;o&gt;)\n   (&lt;o&gt; ^name xxyyzz\n--&gt;\n   (&lt;s&gt; ^operator &lt;o&gt; +)\n   (&lt;o&gt; ^name dance)\n}\n</code></pre> <p>Justification</p> <p>By violating the intent of the Soar language you will likely achieve undesirable results. There is almost certainly a better way of doing what you are trying to do.</p>","tags":["agent debugging"]},{"location":"explanations/DesignDogma/#one-thing-at-a-time","title":"One Thing at a Time","text":"<p>Don't mix different problem space functions in the same rule except operator proposal and selection. It is ok to propose an operator and create a unary preference at the same time.</p> <p>Example</p> <pre><code>sp {xxyyzz\n   (state &lt;s&gt; ^att &lt;v&gt;\n              ^operator &lt;o&gt;)\n   (&lt;o&gt; ^name xxyyzz\n--&gt;\n   (&lt;s&gt; ^operator &lt;o&gt; +\n        ^att &lt;v&gt; -)\n   (&lt;o&gt; ^name dance)\n}\n</code></pre> <p>Justification</p> <p>By violating the intent of the Soar language you will likely achieve undesirable results. There is almost certainly a better way of doing what you are trying to do.</p>","tags":["agent debugging"]},{"location":"explanations/ThreadsInSML/","title":"Threads in SML","text":"<p>This document is intended to explain how threads are used in Soar 8.6 and later (this document is being written against 8.6.3). It assumes you already have a passing familiarity with both Soar and the SML interface language. This is advanced reading, for those who want to understand everything that's going on \"under the hood\".</p>","tags":["sml","threads"]},{"location":"explanations/ThreadsInSML/#what-threads-exist","title":"What Threads Exist","text":"<p>As with all things related to SML, we need to divide up the world into client-side threading and kernel-side threading. The kernel side threading is relatively simple. The kernel is either run in the client's thread or in its own separate thread. This choice is made by the client when it initializes the Soar kernel by calling either <code>Kernel::CreateKernelInCurrentThread()</code> or <code>Kernel::CreateKernelInNewThread()</code>. A remote connection (<code>Kernel::CreateRemoteConnection()</code>) doesn't affect the way the kernel is run, this is determined by the local client that created the kernel initially. If the kernel is running in its own thread, I will name this thread the KernelThread.</p> <p>The client side is potentially more complex. First, the client application may inherently be multi-threaded, such as a Java GUI app or it may be a simple single-threaded C++ program (e.g. a command line utility). Second, the calls to start Soar running (e.g. <code>RunAllAgentsForever</code>) block, so many clients will choose to execute this call in a separate thread in order to keep the rest of the application responsive. I'll call this the RunThread, which means the thread where the run call is initiated. Finally, SML itself starts up (by default) a thread called the EventThread. This thread is intended to keep the client responsive without a lot of work by the application developer.</p> <p>This gives us a picture of the overall set of threads:</p> Runs in Description KernelThread Kernel Keeps the kernel responsive to external commands (i.e. ones coming in over a socket connection). EventThread Client SML Used to service incoming events sent by the kernel if Soar is not running (i.e. productions are not firing). This thread is optional but is created by default. RunThread Client Point that run commands are executed. This thread is created by the client, either explicitly with a new thread or implicitly by calling run from the client's main thread. Client Threads Client Other threads that the client application may have for its own use. Typical examples are window manager threads in GUI apps.","tags":["sml","threads"]},{"location":"explanations/ThreadsInSML/#why-have-multiple-threads-at-all","title":"Why Have Multiple Threads At All?","text":"<p>As we're about to dive into the complexity of the threading in SML, one obvious question is why not just have a single thread and make everyone's life easier. Well, the answer is that would make the SML/ kernel developer's life easier but at the cost of making the client/ application developer's life harder. Let me explain why that is more fully.</p>","tags":["sml","threads"]},{"location":"explanations/ThreadsInSML/#why-have-a-kernel-thread","title":"Why Have a Kernel Thread?","text":"<p>With Soar 8.6 a single Soar kernel can have multiple clients connected to it at once. A common situation is an environment in Java that has a local connection to the kernel itself. A debugger is connected remotely to the kernel and a logging application is also remotely connected. Commands can be sent to the kernel over a socket. The question is, how and when should the kernel check this socket for new commands?</p> <p>In the single-threaded model, the kernel is running in the same thread as the client that created it (in our example, the Java environment). In this case, the client is required to poll the socket periodically to see if new commands have arrived. This is exactly what the method <code>Kernel::CheckForIncomingCommands()</code> does and clients that call <code>CreateKernelInCurrentThread()</code> are required to call this periodically. But making such periodic calls is often difficult for a client. In the case of the Java app the user would need to start some sort of timer and poll across to the kernel whenever it went off. If they fail to realize that this must be done, then the debugger would fail to function at all, leading to a lot of \"why doesn't the debugger respond\" problems. In other clients, making periodic calls may be really complicated. Simple command line utilities tend to take the form: get command from the user, do some work, print some results, get another command. Writing these would be much more challenging if the client is not allowed to block while getting input from the keyboard.</p> <p>So the result is that we recommend running the kernel in its own thread in most cases. That separate thread checks for new commands coming in from either the socket or the local client. In this model, commands are always run in the kernel's thread. That means if the local client calls \"run\" what actually happens is that command is placed on a message queue and the kernel thread then pulls the command from that queue and executes it. That's important to understand if you're trying to debug a problem at the kernel level as the client's function call just adds a message to a queue and you usually need to break the execution at the point that the kernel's thread has picked up the message (e.g. in <code>KernelSML::ProcessCommand()</code>). You won't see the client's triggering call higher up in the call stack at that point as it's in a different thread.</p>","tags":["sml","threads"]},{"location":"explanations/ThreadsInSML/#why-have-an-event-thread","title":"Why Have an Event Thread?","text":"<p>When Soar is running, it is constantly generating a stream of events. These events are posted to each client, allowing the client to know what's going on during the course of a run. The EventThread exists to help clients remain responsive to these incoming events. The first thing to understand about Soar events is that they are synchronous calls. That is to say, the kernel blocks during the call to send each client a message that a particular event has occurred. The kernel only continues executing once that call completes. It may not be immediately obvious that events need to be synchronous (indeed early on we thought they might not be) but in turns out to be useful they must be. For example, consider an agent that wishes to take some action when a new phase starts so it registers for the start phase event. If the call is not synchronous, then by the time the event arrives the kernel may now be at a much later execution point. This would limit clients to knowing what had happened, but not doing things at particular times (and this turns out to be 95% of the actual usage).</p> <p>So given that event calls are synchronous and the kernel blocks waiting for them to complete, how do we ensure that clients are responsive?</p> <ul> <li> <p>In the case where the kernel and the client are running in the same thread   there is really no problem. The event call is just a function callback and the   callback executes in the kernel's thread.</p> </li> <li> <p>When the kernel and client are running in separate processes connected   by a socket, the client needs to check for new messages arriving on the socket.</p> <ul> <li> <p>As with the kernel thread, this could be done by requiring the client to   periodically poll for new events coming in on the socket (and again this   mode is supported by having clients call   <code>Kernel::CheckForIncomingEvents()</code>). But this periodic polling can be   complicated as explained earlier. In fact, the situation is even worse for   the client as it needs to be as fast as possible responding to incoming   events or the entire system's performance will degrade.</p> </li> <li> <p>This is where the EventThread comes in. Its job is to check the socket for   new events and make the appropriate callback to the client code. This keeps the   client responsive and most people will never stop to wonder how a callback   inside one process is being triggered by a kernel running in another process   without their doing anything.</p> </li> </ul> </li> </ul> <p>There is however a wrinkle in this behavior. When a run call is made by a client (on what we're calling the RunThread) that call blocks. While it is blocked it is checking for incoming messages and dispatching them, while it waits for the message to indicate that the run has completed to come through. This means that when a run is triggered by a client, callbacks will occur on the RunThread. When that client did not initiate the run (e.g. somebody typed run in the debugger) or when Soar is not running (e.g. during an init-soar event), events are handled by the EventThread. This means that callbacks can be called on different threads at different times.</p>","tags":["sml","threads"]},{"location":"explanations/ThreadsInSML/#callback-threading-and-blocking-on-run","title":"Callback Threading and Blocking on Run","text":"<p>Let's discuss that a little more. First of all, having the calls come back on different threads isn't ideal. It means a client developer could have different bugs that occur when Soar is run from the client or when Soar is run remotely because the threading is different. In practice, this hasn't really been an issue. On a larger front though it suggests maybe the run calls should not in fact block. If the run calls did not block, the client's life would be easier (they wouldn't need to create a thread when they started a run) and all callbacks would come in on the event thread. The fact that run does block is largely an artifact of how we used to design environments. The main run loop used to look something like:</p> <pre><code>while (!stopped)\n{\nRun-agents-1-step()\nUpdate-world()\n}\n</code></pre> <p>With this model we really want the run call to block so that each single step was a single call (writing this where <code>Run-agents-1-step</code> is non-blocking would be much harder). But over the development of 8.6 we learned that we really didn't want this model and instead we now have a model more like this:</p> <pre><code>RegisterCallback(update-after-output-event, updateWorld)\nWhile (!stopped)\n{\nRun-agents-forever()\n}\n</code></pre> <p>This new event driven model means that having <code>run-agents-forever</code> be a non-blocking call would be a possibility after all. In fact it would probably simplify matters for the client side developer. However, it's a very significant adjustment (breaking lots of existing code) and so far we haven't actively considered making the <code>run-agents-forver</code> call non-blocking.</p>","tags":["sml","threads"]},{"location":"explanations/ThreadsInSML/#locking-and-thread-safety","title":"Locking and Thread-Safety","text":"<p>Given that there are these multiple threads in the system you may need to understand how locking is implemented, to ensure thread safety across the system. The approach we've taken is to assume that the kernel is itself not thread-safe at all. E.g., we'll assume it's not safe to remove a production at the same time a preference is being created as the result of another production firing. Therefore, the approach is to only allow a single command to execute in the kernel at a time.</p> <p>In practical terms, this means even if multiple clients are connected through remote connections their commands are queued up, together with the commands that come from the local connection and executed one at a time. The code for this is in ReceiverThread.cpp. This ensures that the kernel side only executes one command at a time.</p> <p>We also assume that the messaging code is not necessarily thread safe, so we have the client block from sending two messages at the same time. This is achieved with the <code>m_ClientMutex</code> mutex object defined in the Connection class. This decision has a couple of implications.</p> <p>First, it allows the EventThread and the RunThread in the client to live in harmony. A run call will wait for the current event to be processed before it starts and once the run has begun, this lock forces the EventThread to wait for the run to complete. As a result, all events during a run (started by that client) come back on the RunThread and all events outside of a run come back on the EventThread.</p> <p>Second, the presence of a lock on the client makes interruption a bit tricky. If a client issues a stop command from a different thread than the RunThread, it will block, waiting for the run to complete. This is not very helpful. The solution is to have the client issue the stop in an event handler callback, as that callback will always occur on the RunThread if the client is currently running Soar. (If you really want to follow the different cases, the callback might be called by the EventThread but only if the client has not called run, in which case the stop call will go through because the RunThread will not be holding the lock or at least not holding it for a long time).</p> <p>You might wonder, given this model how does the debugger print out state information during a run (e.g. after every 5 decisions). The answer is that it does the work in a callback so the print commands execute on the same thread as the original run command.</p> <p>So while we do not support multiple commands being executed simultaneously (where a second command starts up at an arbitrary time during the first command), we do support multiple commands being executed in a stack (or with reentrancy) where one command is partially complete (such as a run) and another command is executed in the middle of the first command. The keys to this are that the run is paused while this happens (it's in an event handler to be more precise) and the second command executes at a known time (inside an event handler) so the state of the system is well defined. We often end up with large sequences of calls going back and forth inside an initial trigger (init-soar is famous for this) as one action triggers an event, which triggers another action and so on. But it's all within a single logical stack of commands, rather than having multiple simultaneous threads of execution.</p>","tags":["sml","threads"]},{"location":"explanations/ThreadsInSML/#best-practices","title":"Best Practices","text":"<p>From the constraints of the threading model we have arrived at these \"best practices\" which will help clients behave well:</p> Description Call <code>RunAllAgentsForever</code> in a new thread If you don't want your application to block waiting for the run call to complete, you should make that call in a new thread. Call stop from an event handler In order to interrupt a run you need to be on the same thread as the original run call (if your client issues the run). This can be ensured by issuing the stop from an event handler's callback. This is also good advice for any other SML call that you wish to make while the kernel is running (e.g. printing out current state information in the middle of a run). Don't make assumptions about the thread an event handler is called on The event handler may be called from the RunThread or from the EventThread depending on the situation. <p>If you have any concerns about how to follow these guidelines please take a look at the sample environments that we include with the distributions. E.g. search for <code>RunAllAgentsForever</code> and <code>Stop</code> to see examples of those behaviors.</p>","tags":["sml","threads"]},{"location":"explanations/Timers/","title":"Timers","text":"<p>This document describes how Soar's internal timers work.</p>","tags":["kernel programming"]},{"location":"explanations/Timers/#preprocessor-symbols","title":"Preprocessor Symbols","text":"<p>Core/SoarKernel/src/kernel.h contains a few relevant preprocessor symbols:</p> <ul> <li><code>NO_TIMING_STUFF</code>: Defining this symbol removes most timer code from the kernel.     The stats command output will be much shorter as well, as it will not include     timing statistics.</li> <li><code>DETAILED_TIMING_STATS</code>: Only valid when <code>NO_TIMING_STUFF</code>     is not defined. Defining this turns on more timers for more detailed stats for     things like chunking and GDS. Compiling out timer code can result in much     faster runs. Timers are compiled-in by default, but not detailed timing stats.</li> </ul>","tags":["kernel programming"]},{"location":"explanations/Timers/#stats-output","title":"Stats Output","text":"<p>Some more information regarding the stats command.</p> stats Output agent struct Detailed Description Total CPU Time timers_total_cpu_time No Most encompassing, includes some scheduling code and all callbacks. Kernel CPU Time timers_total_kernel_time No Total CPU minus callbacks and a few other smaller things. Kernel / Phase (table) timers_decision_cycle_phase[NUM_PHASE_TYPES] No Time spent in each phase but not in callbacks. Callbcks / Phase (table) timers_monitors_cpu_time[NUM_PHASE_TYPES] No Time spent in callbacks for each phase, but notINPUT_PHASE_CALLBACK or output functions. Input fn (table) timers_input_function_cpu_time No Time spent in INPUT_PHASE_CALLBACK. Outpt fn (table) timers_output_function_cpu_time No Time spent in output functions. stats --max timers_decision_cycle, max_dc_time_msec No Used to collect max per-cycle statistics. Essentially a sum of timers_decision_cycle_phase sml_Names::kParamStatsOwnershipTime...(XML only) timers_ownership_cpu_time Yes Time spent in do_buffered_link_changes. Included in the decision cycle phase timers. sml_Names::kParamStatsChunkingTime...(XML only) timers_chunking_cpu_time Yes Time spent chunking. Included in decision cycle phase timers. sml_Names::kParamStatsMatchTime...(XML only) timers_match_cpu_time Yes Time spent adding/removing WMEs to/from rete. Included in decision cycle phase timers. sml_Names::kParamStatsGDSTime... (XML only) timers_gds_cpu_time Yes Time spent in the GDS code. Included in the decision cycle phase timers.","tags":["kernel programming"]},{"location":"explanations/Timers/#timers-command","title":"Timers Command","text":"<p>There is a timers command to enable/disable timers at run-time. This should result in a performance improvement but not as much as compiling out the timers completely by defining <code>NO_TIMING_STUFF</code> in kernel.h.</p>","tags":["kernel programming"]},{"location":"explanations/Timers/#timer-implementation","title":"Timer Implementation","text":"<p>The timers are currently implemented using the STLSoft library. The STLSoft code is wrapped in another layer in Core/shared/misc.h which define <code>soar_wallclock_timer</code> and <code>soar_process_timer</code>. Here are the comments from that file:</p> <p>Code:</p> <pre><code>// Instantiate soar_wallclock_timer or soar_process_timer objects to measure\n// \"wall\" (real) time or process (cpu) time. Call reset if you are unsure of\n// the timer's state and want to make sure it is stopped. Call start and then\n// stop to deliniate a timed period, and then call get_usec to get the value\n// of that period's length, in microseconds. It is OK to call get_usec after\n// calling start again. Resolution varies by platform, and may be in the\n// millisecond range on some.\n//\n// Use soar_timer_accumulator to rack up multiple timer periods. Instead of\n// calling get_usec on the timer, simply pass the timer to a\n// soar_timer_accumulator instance with it's update call. Use reset to clear\n// the accumulated time.\n// Platform-specific inclusions and typedefs\n//\n// The STLSoft timers used in the kernel have platform-specific namespaces\n// even though they share very similar interfaces. The typedefs here\n// simplify the classes below by removing those namespaces.\n//\n// We are using two different types of timers from STLSoft,\n// performance_counter and processtimes_counter. The performance timer is\n// a high-performance wall-clock timer. The processtimes_counter is a cpu-\n// time timer. Keep in mind that as of 11/2010 the resolution of process-time\n// counters on windows is 16 milliseconds.\n</code></pre>","tags":["kernel programming"]},{"location":"explanations/Timers/#simple-usage","title":"Simple Usage","text":"<pre><code>soar_process_timer timer;\nsoar_timer_accumulator stat;\n...\ntimer.reset(); // initialize/reset\nstat.reset();  // initialize/reset\n...\ntimer.start();\n// do stuff that takes time\ntimer.stop();\nstat.update(timer); // read the timer, add elapsed to stat\n...\nstat.get_sec(); // total time accumulated with update();\n</code></pre>","tags":["kernel programming"]},{"location":"explanations/Timers/#increasing-resolution","title":"Increasing Resolution","text":"<p>By default, the<code>soar_process_timer</code> uses an STLSoft interface called <code>processtimes_counter</code>. This is fine on most systems, but has a somewhat unacceptable 16 millisecond resolution on Windows platforms. The other kind of timer available is performance_counter which is used by the <code>soar_wall</code> <code>clock_timer</code>. This counter has higher resolution but the timer itself takes more time to execute (on most systems). To increase resolution on Windows system, uncomment the symbol <code>USE_PERFORMANCE_FOR_BOTH</code> in Core/shared/misc.h so that<code>soar_process_timer</code> uses the performance_counter. Note that this higher-resolution timer is measuring things in different way than the process times_counter and the results should probably not be compared.</p>","tags":["kernel programming"]},{"location":"explanations/Timers/#old-stats-comments-in-kernel","title":"Old Stats Comments in Kernel","text":"<pre><code>/*\nFor Soar 7, the timing code has been completely revamped.  When the compile\nflag NO_TIMING_STUFF is not set, statistics will be now be collected on the\ntotal cpu time, total kernel time, time spent in the individual phases of a\ndecision cycle, time spent executing the input and output functions, and time\nspent executing callbacks (or monitors).  When the DETAILED_TIMING_STATS flag\nis set, additional statistics will be collected for ownership, match, and\nchunking computations according to the phase in which they occur. (Notice\nthat DETAILED_TIMING_STATS can only be collected when NO_TIMING_STUFF is not\ntrue.)\nThe total_cpu_time is turned on when one of the run_&lt;x&gt; functions is\ninitiated.  This timer is not turned off while the do_one_top_level_phase()\nfunction is executing.  The total_kernel_time timer is turned on just after\nthe total_cpu_time timer and turned off just before the other is turned off.\nThis guarantees that the total kernel time -- including the time it takes to\nturn on and off the kernel timer -- is a part of the total cpu time.  The\ntotal_kernel_time is also turned off whenever a callback is initiated or when\nthe input and output functions are executing.\nThe decision_cycle_phase_timers measure the kernel time for each phase of the\ndecision cycle (ie, INPUT_PHASE, PREFERENCE_PHASE, WM_PHASE, OUTPUT_PHASE,\nand DECISION_PHASE).  Each is turned on at the beginning of its corresponding\nphase in do_one_top_level_phase and turned off at the end of that phase.\nThese timers are also turned off for callbacks and during the execution of\nthe input and output functions.\nThe monitors_cpu_time timers are also indexed by the current phase.  Whenever\na callback is initiated, both the total_kernel_time and\ndecision_cycle_phase_timer for the current phase are turned off and the\nmonitors_cpu_time turned on.  After the callback has terminated, the kernel\ntimers are turned back on.  Notice that the same relationship holds here as\nit did between the total_cpu_time and total_kernel_time timers.  The\ntotal_kernel_time is always turned off last and turned on first, in\ncomparison to the decision_cycle_phase_timer.  This means that turning the\ndecision_cycle_phase_timers on and off is included as part of the kernel time\nand helps ensure that the total_kernel_time is always greater than the sum of\nthe decision_cycle_timers.\nThe input_function_cpu_time and output_function_cpu_time timers measure the\ntime it takes to execute the input and output functions respectively.  Both\nthe total_kernel_time and decision_cycle_phase_timers are turned off when\nthese timers are turned on (with the same ordering as discussed previously).\nThe input function is a little tricky.  Because add-wme can be called by the\ninput routine, which then calls do_buffered_wm_and_ownership_changes, we\ncan't just turn off the kernel timers for input and expect to get numbers for\nboth match_time (see next para) and kernel time.  The solution implemented in\nthe 28.07.96 changes is to not turn off the kernel timers until the actual\nINPUT_PHASE_CALLBACK is initiated.  This takes care of all but direct\nadditions and removals of WMEs.  Since these are done through the add-wme and\nremove-wme commands, the input_timer is turned off there was well, and the\nkernel timers turned back on (for the buffered wm changes).  However, this is\na hack and may introduce problems when add-wme and remove-wme are used at the\ncommand line or someplace in the decision cycle other than input (probably\nrare but possible).\nThe DETAILED_TIMING_STATS flag enables collection of statistics on match,\nownership and chunking calculations performed in each part of the decision\ncycle.  An 'other' value is reported which is simply the difference between\nthe sum of the detailed timers and the kernel timer for some phase.  The other\nvalue should always be greater than or equal to zero.\nThe \"stats\" command (in soarCommandUtils) has been updated to report these\nnew timing values.  The output is provided in a spreadsheet-style format to\ndisplay the information in a succinct form.  There are also some derived\ntotals in that report.  The derived totals in the right column are simply the\nsum of the all the other columns in a particular row; for example, the\nderived total for the first row, kernel time, is just the sum of all the\ndecision_cycle_phase_timers.  The derived totals in the bottom row are the\nsum of all the basic timers in that row (i.e., no DETAILED statistics are\nincluded in the sum).  For example, the derived total under input is equal to\nthe sum of decision_cycle_phase_timer and the monitors_time for the\nINPUT_PHASE, and the input_function_cpu_time and represents the total time\nspent in the input phase for the current run.  The number in the lower\nright-hand corner is the sum of the derived totals above it in that right\ncolumn (and should always be equal to the numbers to the left of it in that\nrow).\nAlso reported with the stats command are the values of total_cpu_time and\ntotal_kernel_time.  If the ordering discussed above is strictly enforced,\ntotal_kernel_time should always be slightly greater than the derived total\nkernel time and total_cpu_time greater than the derived total CPU time. REW */\n</code></pre>","tags":["kernel programming"]},{"location":"explanations/Waterfall/","title":"Waterfall","text":"<p>This document describes the \"Waterfall\" modifications made to to Soar.</p> <p>As described by Bob Marinier...</p> <p>\"Suppose I have a blocks world agent that is trying to accomplish \"put A on B\". Several moves might be required to do this, and the agent doesn't know what they are, so it goes into a subgoal and starts randomly moving blocks around. What we want is for the agent to get a positive reward on the substate's reward link when it succeeds. So we can have a rule that detects that A is on B and creates a reward when that happens. However, when A is on B, the subgoal's supporting operator proposal will retract. Even though this retraction could, in principle, occur in parallel with the reward rule firing, the, waterfall will cause the retraction to occur first, and thus the substate will go away before the reward rule gets to fire, so the agent won't get the reward. In our proposed modification, the reward rule and retraction would occur in parallel, and thus the agent would get the reward.\"</p>","tags":["kernel programming","substate"]},{"location":"explanations/Waterfall/#brief-description-in-manual","title":"Brief description in manual","text":"<p>Note: This mechanism is not referred to by any name in the manual, including waterfall. See the last paragraph of chapter 2.6.5:</p> <p>The second change when there are multiple substates is that at each phase, Soar goes through the substates, from oldest (highest) to newest (lowest), completing any necessary processing at that level for that phase before doing any processing in the next substate. When firing productions for the proposal or application phases, Soar processes the firing (and retraction) of rules, starting from those matching the oldest substate to the newest. Whenever a production fires or retracts, changes are made to working memory and preference memory, possibly changing which productions will match at the lower levels (productions firing within a given level are fired in parallel \u2013 simulated). Productions firings at higher levels can resolve impasses and thus eliminate lower states before the productions at the lower level ever fire. Thus, whenever a level in the state stack is reached, all production activity is guaranteed to be consistent with any processing that has occurred at higher levels.</p>","tags":["kernel programming","substate"]},{"location":"explanations/Waterfall/#definitions","title":"Definitions","text":"<p>Minor quiescence: no more i-assertions (or any retractions) ready to fire in the current goal</p> <p>Consistency check: making sure that the currently selected operator is still legal (e.g., it's still acceptable, it shouldn't be replaced by a better operator or an impasse)</p> <p>Available compile flags (in kernel.h)</p> <pre><code>/* For information on the consistency check routines */\n/* #define DEBUG_CONSISTENCY_CHECK */\n/* For information on aspects of determining the active level */\n/* #define DEBUG_DETERMINE_LEVEL_PHASE */\n</code></pre>","tags":["kernel programming","substate"]},{"location":"explanations/Waterfall/#available-kernel-functions","title":"Available kernel functions","text":"<p>highest_active_goal_propose: Find the highest goal of activity among the current i-assertions and retractions</p> <p>highest_active_goal_apply: Find the highest goal of activity among the current i-assertions, o-assertions and retractions</p> <p>active_production_type_at_goal: Returns IE_PRODS if i-assertions active, otherwise PE_PRODS</p> <p>initialize_consistency_calculations_for_new_decision: call before functions below?</p> <p>determine_highest_active_production_level_in_stack_apply: implements waterfall for apply phase (DETERMINE_LEVEL_PHASE)</p> <ul> <li>calls itself recursively</li> <li>called in do_one_top_level_phase (APPLY_PHASE, twice)</li> <li>if the next active goal     is lower in the stack than the previous one, but the stack is no longer     consistent up to the previous goal, then proceed to output</li> </ul> <p>determine_highest_active_production_level_in_stack_propose: implements waterfall for propose phase</p> <ul> <li>called in do_one_top_level_phase (PROPOSE_PHASE, twice)</li> </ul> <p>get_next_assertion (rete.cpp): gets next production/token/wme associated with the current goal (as determined by above) do_working_memory_phase: \"commits\" the changes at the end of a phase</p>","tags":["kernel programming","substate"]},{"location":"explanations/Waterfall/#implementation-thoughts","title":"Implementation thoughts","text":"<p>In do_one_top_level_phase, currently do this:</p> <ol> <li>determine highest active goal</li> <li>fire rules at that goal</li> <li>commit changes</li> <li>proceed to next phase</li> </ol> <p>Could change it to do this:</p> <ol> <li>determine highest active goal</li> <li>fire rules at that goal, tracking the highest goal with a change</li> <li>determine highest active goal below highest changed goal</li> <li>goto 2 until past bottom goal</li> <li>commit changes</li> <li>proceed to next phase</li> </ol>","tags":["kernel programming","substate"]},{"location":"explanations/Waterfall/#test-case","title":"Test Case","text":"<pre><code># Test case for revised waterfall model\n#\n# In Soar8/9.0.0 waterfall model, the change*substate rule will never fire. This is because the\n# change*top-state rule will fire first, which will cause the proposal to unmatch and thus the\n# substate will retract\n#\n# In the revised waterfall model, change*substate will fire in parallel with change*top-state, since\n# the effects cannot possibly conflict.\n\nlearn --off\n\nsp {propose*test\n(state  ^superstate nil\n          -^result true)\n--&gt;\n( ^operator  +)\n( ^name test)\n}\n\nsp {change*top-state\n(state  ^superstate )\n( ^operator.name test)\n--&gt;\n( ^result true)\n(write (crlf) |Changed top-state|)\n}\n\nsp {change*substate\n(state  ^superstate )\n( ^operator.name test\n      ^result true)\n--&gt;\n( ^substate changed)\n(write (crlf) |Changed substate|)\n}\n</code></pre>","tags":["kernel programming","substate"]},{"location":"explanations/Waterfall/#test-case-in-jsoar","title":"Test case in jSoar","text":"<p>The file <code>/jsoar/test/org/jsoar/kernel/FunctionalTests_testWaterJugLookAhead.soar</code> in the jSoar project contains the above code plus a (succeeded) rhs call that works with JUnit so that the test can succeed once the changes to the waterfall model work.</p>","tags":["kernel programming","substate"]},{"location":"explanations/Waterfall/#notes","title":"Notes","text":"<ul> <li>preference phase: the inner loop that processes assertions and retractions at     the active level and possibly below with new waterfall model</li> <li>matches: assertion/retraction, matches AND unmatches coming from the rete</li> <li>active_level: the highest level at which matches are waiting to be processed</li> <li>previous_active_level: the active_level at the start of the previous outer     preference loop</li> <li>change_level: lowest level affected by matches fired during previous iteration     of inner preference loop, always equal to or higher than active_level, matches     firing in next iteration cannot change this level or higher.</li> <li>next_change_level: lowest level affected by matches fired during this     iteration of inner preference loop, becomes change_level for next iteration</li> <li>high_match_change_level: highest level affected by a match's changes, compares     to change_level</li> <li>low_match_change_level: lowest level affected by a match's changes, sets     next_change_level</li> </ul>","tags":["kernel programming","substate"]},{"location":"explanations/Waterfall/#algorithm","title":"Algorithm","text":"<p>This describes one outer preference loop.</p> <ol> <li>Reset '''active_level'''=0, '''next_change_level'''=0.</li> <li>Set '''active_level'''.</li> <li>Set '''previous_active_level''' = '''active_level'''</li> <li> <p>Inner preference loop start:</p> <ol> <li>If '''active_level''' is invalid, break out of loop.</li> <li>Set '''change_level''' = '''next_change_level'''.</li> <li> <p>For each match at the '''active_level''':</p> <ol> <li>Determine '''high_match_change_level''' and '''low_match_change_level''' (see execute_action).</li> <li> <p>If the '''high_match_change_level''' &lt; '''change_level''':</p> <ol> <li>Fire the match (and be sure match is removed from match lists).</li> <li>Set '''next_change_level''' = min('''next_change_level''', '''low_match_change_level''')</li> </ol> </li> <li> <p>Else if '''high_match_change_level''' &gt;= '''change_level''':</p> <ol> <li>Do not fire the match (and be sure match is retained in match lists).</li> </ol> </li> </ol> </li> <li> <p>Set '''active_level''' to next lowest level that has activity (matches) below the current '''active_level'''.</p> </li> <li>Go to inner preference loop start.</li> </ol> </li> <li> <p>Set '''active_level''' = '''previous_active_level'''</p> </li> <li>Commit changes (do_working_memory_phase)</li> </ol>","tags":["kernel programming","substate"]},{"location":"explanations/Waterfall/#implementation-notes","title":"Implementation Notes","text":"<ul> <li>done in initialize_consistency_calculations_for_new_decision</li> <li>done in determine_highest_active_production_level_in_stack _apply/propose</li> <li>local variable in doApplyPhase, not yet implemented for propose</li> <li>current handling of this (in the apply phase) is to set current_phase to     Phase.OUTPUT. May need to actually check this though because we probably won't     be changing current_phase in 4.4.</li> </ul> <p>find out what level a match will change possibly out of date</p> <ol> <li>Call create_instantiation on the assertion</li> <li>Determine the highest level of any action (as reported by execute_action) (see solution above)</li> <li>If any action's level is higher than the safe active level<ol> <li>Don't create the instantiation (see below)</li> <li>Put the assertion back on the assertions list where we got it from (the    pointers should still be in the right places)</li> </ol> </li> <li>For each retraction at this goal, do something similar to above</li> </ol>","tags":["kernel programming","substate"]},{"location":"explanations/Waterfall/#notes-on-only-firing-the-assertion","title":"Notes on only firing the assertion","text":"<p>create_instantiation is going to go through all of the actions, if we find midway through that an action is bad, we throw out the entire instantiation. This means execute_action needs to return this sort of failure code so that the effects of get_next_assertion on the rete listener can be undone, which is something like pushing the assertion back on to the list for the active goal. There are multiple lists of assertions for each goal, we need to put it back on the correct one.</p>","tags":["kernel programming","substate"]},{"location":"how_to/","title":"How-To Guides","text":""},{"location":"how_to/BuildingSoarRos/","title":"Build Soar with ROS","text":"","tags":["ROS","compile"]},{"location":"how_to/BuildingSoarRos/#requirements","title":"Requirements:","text":"<ul> <li>Ubuntu 18.04.4 LTS Bionic THIS IS NOT OPTIONAL. NO OTHER LINUX DISTRO WORKS</li> <li>Relatively recent GPU YOUR COMPUTER MUST HAVE A DISPLAY</li> <li>ROS Melodic ONLY MELODIC WILL WORK</li> <li>Gazebo 9 MUST BE 9</li> <li>Point Cloud Library version 1.8.1 Must be 1.8.1</li> </ul> <p>ROS Installation (from http://wiki.ros.org/melodic/Installation/Ubuntu):</p> <pre><code>sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" &gt; /etc/apt/sources.list.d/ros-latest.list'\nsudo apt-key adv --keyserver 'hkp://keyserver.ubuntu.com:80' --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654\nsudo apt update\nsudo apt install ros-melodic-desktop-full\necho \"source /opt/ros/melodic/setup.bash\" &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> <p>Point Cloud Library should also be installed. Run sudo apt install libpcl-dev to make sure.</p>","tags":["ROS","compile"]},{"location":"how_to/BuildingSoarRos/#download-and-build-soar","title":"Download and Build Soar","text":"<pre><code>git clone https://github.com/SoarGroup/Soar.git -b svs_overhaul\nsudo apt install build-essential swig openjdk-8-jdk python-all-dev\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$SOAR_HOME:/opt/ros/melodic/lib/\nexport CPATH=$CPATH:/usr/include/pcl-1.8/:/opt/ros/melodic/include/\ncd Soar\npython2 scons/scons.py all --use-ros\n</code></pre> <p>If you want Python 3 support, replace step 4 with:</p> <pre><code>which python3\n</code></pre> <p>Copy the file path returned <pre><code>python2 scons/scons.py all --use-ros --python=&lt;insert/path/copied/above&gt;\n</code></pre></p> <p>Recommended: If you want to use Lizzie's svs_utils ROS package to make a world with a Fetch robot, follow these steps: Install the Fetch ROS and Gazebo packages: sudo apt install ros-melodic-fetch-ros ros-melodic-fetch-gazebo Create a catkin workspace: mkdir ~/svs_utils_ws/src</p> <pre><code>cd ~/svs_utils_ws\ncatkin_make\ncd src\ngit clone https://[your_username]@bitbucket.org/emgoeddel/svs_util.git (Ask Lizzie for access to the Bitbucket)\ncd ..\ncatkin_make\necho \"source ~/svs_util_ws/devel/setup.bash\" &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>","tags":["ROS","compile"]},{"location":"how_to/CLIParsingCode/","title":"Command Line Interface Parsing Code","text":"","tags":["kernel programming"]},{"location":"how_to/CLIParsingCode/#overview","title":"Overview","text":"<p>The command line interface (CLI) described in this document has no relation to the lexer/parser inside the Soar kernel. CLI often refers to the actual object instance (a member of KernelSML) but sometimes can refer to the whole component.</p> <p>The CLI takes an arbitrary string and transforms it into method calls providing a general interface to Soar as described by the help document on the Soar wiki (on Google Code).</p> <p>A command line in this context can actually be many commands, or an entire file. In this document it will be called a command line. The syntax of what is legal closely follows the Tcl language and is spelled out in the Doxygen help in Core/shared/tokenizer.h. These rules are reprinted below.</p> <p>The command line enters the CLI at CommandLineInterface:: DoCommand. Some quick state is updated but then it is passed to Source (defined in cli_source.cpp), a same function used by the source command in Soar. This is why command lines and files are interchangeable.</p> <p>Source then uses the tokenizer utility to split out the command name and its arguments. The critical piece used by tokenizer to do this is the parser instance (cli::Parser, cli_Parser.h, a member of CLI) which knows what all the commands and aliases are.</p> <p>The parser expands aliases, performs a partial match if necessary and then, if there is no ambiguity, calls the appropriate command's Parse function with a vector of the tokens used for the command. Sometimes this vector is only of length 1 (the command name). Again, Tcl rules are used to tokenize each command (and to split commands).</p> <p>These commands' parse methods are defined in cli_Commands.h and registered with the parser with the CLI is first created. The parser is also aware of aliases, which are initially defined in the Aliases constructor executed when the parser is first created. Aliases can change down the road when commands access the parser's aliases member.</p> <p>The purpose of the parse function is to process the command's options (if any) and report syntax errors as necessary. Some input checking is done here but most is saved for the next step (below). Few commands (such as dirs) have no parsing--most have plenty of stuff to do in this phase. No actual processing should happen here, the functions called as a result of parsing should be able to be called directly elsewhere for the same effect without parsing. Example of a command that takes no arguments:</p> <pre><code>dirs\n</code></pre> <p>Some commands just need to test for the presence of and get an argument or two off of the command line before proceeding. An example of this is the max-elaborations command. These commands are simple - the vector of tokens can be inspected and used directly.</p> <p>Example of command that has arguments:</p> <pre><code>max-elaborations 15\nNon-option argument: 15\n</code></pre> <p>Other commands have options which are handled using the option utilities on the Parser instance, sometimes in addition to other, non-option arguments.</p> <p>More common commands (with options):</p> <ul> <li>echo-commands -y</li> <li>Option (short): y</li> <li>learn --off</li> <li>Option (long): off</li> <li>echo -n Hello world!</li> <li>Option (short): n</li> <li>Arguments: Hello, world!</li> <li>watch --chunks -L print</li> <li>Option (long): chunks</li> <li>Option (short) with argument: L, print</li> <li>Options always have both long and short forms, and a required argument,   optional argument, or no argument setting expected. These are all defined in the   top of the Parse function before the option handling code is called.</li> </ul> <p>Once the command and options are parsed, a function call is made to actually process the command. These are all declared initially on the Cli-interface defined in cli_Cli.h. This interface exists to facilitate context-free testing of the command parsing. By convention, these processing functions all start with Do so they are easily spotted on the CLI.</p> <p>The CLI implements this interface, and defines the functions and their related helper functions in their own files. DoSource, for example, is defined in cli_source.cpp.</p> <p>The meat of the command happens in these Do functions. The function signatures vary depending on what the commands need. Enumerations are used to pass modes from the parsing step to the Do step. Null pointers are used often when some parameter is optional, to indicate that it was omitted. Bit vectors are often used to pass a number of flags from the parsing step to the processing step.</p> <p>The motivation behind splitting the parsing from the processing in the commands is both for testing and so that other parts of Soar/SML can call-these interface functions directly without having to render command lines.</p> <p>When commands complete, they return text to be printed after they execute. Traditionally, little or nothing is printed when there is success.</p> <p>There is support for more structured output for commands so that callers can pull specific values out of command results (instead of parsing the stringified results). This mode is optional (skip doing this until you know you need it) and is tested by checking the m_RawOutput member on the CLI. Structured output is built up using a form of XML.</p>","tags":["kernel programming"]},{"location":"how_to/CLIParsingCode/#tokenizing-rules","title":"Tokenizing Rules","text":"<p>The tokenizer used by the CLI follows most of the rules of Tcl. Here they are, copied from the tokenizer header (Core/shared/tokenizer.h):</p> <p>[1] A Tcl script is a string containing one or more commands. Semi-colons and newlines are command separators unless quoted as described below. Close brackets are command terminators during command substitution (see below) unless quoted. [Square brackets have no special meaning in this parser.]</p> <p>[2] A command is evaluated in two steps. First, the Tcl interpreter breaks the command into words and performs substitutions as described below. These substitutions are performed in the same way for all commands. [The first word of the command has no special meaning in this parser.] All of the words of the command are passed to the command procedure [via a callback interface]. The command procedure is free to interpret each of its words in any way it likes, such as an integer, variable name, list, or Tcl script. Different commands interpret their words differently.</p> <p>[3] Words of a command are separated by white space (except for newlines, which are command separators).</p> <p>[4] If the first character of a word is double-quote (\") then the word is terminated by the next double-quote character. If semi-colons, close brackets, or white space characters (including newlines) appear between the quotes then they are treated as ordinary characters and included in the word. Backslash substitution [but not command substitution or variable substitution] is performed on the characters between the quotes as described below. The double-quotes are not retained as part of the word.</p> <p>[5] If the first character of a word is an open brace ({) then the word is terminated by the matching close brace (}). Braces nest within the word: for each additional open brace there must be an additional close brace (however, if an open brace or close brace within the word is quoted with a backslash then it is not counted in locating the matching close brace). No substitutions are performed on the characters between the braces except for backslash-newline substitutions described below, nor do semi-colons, newlines, close brackets, or white space receive any special interpretation. The word will consist of exactly the characters between the outer braces, not including the braces themselves.</p> <p>[6] [Square brackets are not special in this parser. No command substitution.]</p> <p>[7] [Dollar signs are not special in this parser. No variable substitution.]</p> <p>[8] If a backslash <code>\\</code> appears within a word then backslash substitution occurs. In all cases but those described below the backslash is dropped and the following character is treated as an ordinary character and included in the word. This allows characters such as double quotes, and close brackets [and dollar signs but they aren't special characters in this parser] to be included in words without triggering special processing. The following table lists the backslash sequences that are handled specially, along with the value that replaces each sequence.</p> <pre><code>\\a Audible alert (bell) (0x7).\n\\b Backspace (0x8).\n\\f Form feed (0xc).\n\\n Newline (0xa).\n\\r Carriage-return (0xd).\n\\t Tab (0x9).\n\\v Vertical tab (0xb).\n\\&lt;newline&gt;whiteSpace\n</code></pre> <p>A single space character replaces the backslash, newline, and all spaces and tabs after the newline. This backslash sequence is unique in that [...] it will be replaced even when it occurs between braces, and the resulting space will be treated as a word separator if it isn't in braces or quotes. \\ Backslash (``\\''). [Not implemented: \\ooo The digits ooo (one, two, or three of them) give the octal value of the character.] [Not implemented: \\xhh The hexadecimal digits hh give the hexadecimal value of the character. Any number of digits may be present.]</p> <p>Backslash substitution is not performed on words enclosed in braces, except for backslash-newline as described above.</p> <p>[9] If a hash character (#) appears at a point where Tcl is expecting the first character of the first word of a command, then the hash character and the characters that follow it, up through the next newline, are treated as a comment and ignored. The comment character only has significance when it appears at the beginning of a command.</p> <p>[10] [Talks about details regarding substitution and generally does not apply to this parser.]</p> <p>[11] [Talks about details regarding substitution and generally does not apply to this parser.]</p>","tags":["kernel programming"]},{"location":"how_to/CLIParsingCode/#parsing","title":"Parsing","text":"<p>The first token of a command is used to find its parser implementation. The command parsers are defined in cli_Commands.h and implementParserCommand. The rest of the tokens are either options, option arguments, or non-option arguments. Options</p> <p>Options start with dashes. One dash followed by one or more letters is interpreted as one or more short options.</p> <pre><code>-f: Option f\n-for: Options f o r\n</code></pre> <p>Two dashes are followed by one long option</p> <pre><code>--foo: Option foo\n</code></pre> <p>All options have a short form and a long form.</p> <p><code>--level</code> and <code>-l</code> both represent the \"level\" option in the watch command.</p> <p>Options can have arguments associated with them. The argument, if it accepts one, can be required or optional. This is specified when the option is defined in its parse function:</p> <pre><code>// Short option, long option, one of none, optional, required\n{'f', \"fullwmes\", OPTARG_NONE},\n{'b', \"backtracing\", OPTARG_OPTIONAL},\n{'l', \"level\", OPTARG_REQUIRED},\n</code></pre> <p>Options with arguments generally accept whatever comes after them as its argument. Optional arguments are trickier, refer to cli_Options.h for details.</p> <pre><code>--level 4: level takes a required argument, 4 is consumed as its argument.\n</code></pre> <p>Options can occur anywhere in the command line, except after special option - which forces an end to option parsing. Options and any of their arguments are moved to the beginning of the token vector, keeping their same relative order. The number of options remaining can be obtained with <code>GetNonOptionArguments()</code> and the actual options starting with the length of the token vector.</p> <pre><code>cli::Options opt; // Option parsing utility instance\n// ... define options, parse options\nint remain = opt.GetNonOptionArguments(); // Number of non-option arguments remaining\n// ... assuming remain &gt; 0\nint i = argv.size() - remain; // Index of first non-option argument\nargv[i];\n</code></pre> <p>Processing options and their arguments has a lot of boiler plate code, something that could totally be improved. Write tests first.</p> <pre><code>cli::Options opt; // Option parsing utility instance\nOptionsData optionsData[] =\n{\n// Options definitions\n{'f', \"fullwmes\", OPTARG_NONE}\n{'f', \"full-wmes\", OPTARG_NONE}, // multiple long options OK\n{'b', \"backtracing\", OPTARG_OPTIONAL},\n{'l', \"level\", OPTARG_REQUIRED},\n{0, 0, OPTARG_NONE} // terminate with this, sorry\n};\nfor (;;) // most compilers won't complain about this kind of forever\n{\n// this returns false only on major error\nif (!opt.ProcessOptions(argv, optionsData)) return false;\n// this will be -1 if option parsing is complete\nif (opt.GetOption() == -1) break;\nswitch (opt.GetOption())\n{\ncase 'f':\n// remember this flag is flipped\nbreak;\ncase 'b':\n// remember this flag is flipped\nif (!opt.GetOptionArgument.empty())\nopt.GetOptionArgument(); // Here's the optional argument\nbreak;\ncase 'l':\n// remember this flag is flipped\nopt.GetOptionArgument(); // Here's the argument\nbreak;\n}\n}\nif (opt.GetNonOptionArguments())\nint i = argv.size() - opt.GetNonOptionArguments(); // index to argument\n</code></pre> <p>Non-options are often tested for existance, count, there's a utility function for that:</p> <pre><code>// returns true if there is one or no non-option argument\nopt.CheckNumNonOptArgs(0, 1); // min, max\n// returns true if there are three non-option arguments\nopt.CheckNumNonOptArgs(3, 3);\n</code></pre>","tags":["kernel programming"]},{"location":"how_to/CLIParsingCode/#executing","title":"Executing","text":"<p>Once a command and its options are parsed, a function is called to Do the work. Looking at the excise command definition (cli_Cli.h):</p> <pre><code>// parsing distills the command line options down to this list\nenum eExciseOptions\n{\nEXCISE_ALL,\nEXCISE_CHUNKS,\nEXCISE_DEFAULT,\nEXCISE_RL,\nEXCISE_TASK,\nEXCISE_TEMPLATE,\nEXCISE_USER,\nEXCISE_NUM_OPTIONS, // must be last\n};\n// and stores them in this type\ntypedef std::bitset&lt;EXCISE_NUM_OPTIONS&gt; ExciseBitset;\n/\\*\\*\n- @brief excise command\n- @param options The various options set on the command line\n- @param pProduction A production to excise, optional\n_/ virtual bool DoExcise(const ExciseBitset&amp; options, const std::string_ pProduction = 0) = 0;\n</code></pre> <p>This excise function takes a bitset of option flags parsed from the command line, and optionally a pointer to a string of a specific production to excise. A pointer is used because it is optional, and null can be passed when all of the command's state is contained in the options set.</p>","tags":["kernel programming"]},{"location":"how_to/CLIParsingCode/#errors","title":"Errors","text":"<p>Command implementations should return true if the command is successful, false if there is an error condition. Before returning false, error state should be set so that the user can try and figure out what went wrong. Call SetError() on the cli::Cli instance to set the error text. Return false. SetError() always returns false so you can just return that.</p> <pre><code>// during parsing, you should have a reference to cli\nif (argv.size() &gt; 2)\nreturn cli.SetError(\"Only one argument (a directory) is allowed. Paths with spaces should be enclosed in quotes.\");\n// during execution, you are the cli\nif (!pScheduler-&gt;VerifyStepSizeForRunType(forever, runType, interleave))\nreturn SetError(\"Run type and interleave setting incompatible.\");\n</code></pre>","tags":["kernel programming"]},{"location":"how_to/CLIParsingCode/#implementing-new-command-checklist","title":"Implementing New Command Checklist","text":"<p>Open cli_Cli.h and define your command's functional interface. Open cli_Commands.h and create a new cli::ParserCommand instance for your command. Find a similar command and copy and paste it, changing what you need, or use a template:</p> <pre><code>// no option parsing\nclass TheCommand : public cli::ParserCommand\n{\npublic:\nTheCommand(cli::Cli&amp; cli) : cli(cli), ParserCommand() {}\n// always virtual destructor\nvirtual ~TheCommand() {}\n// the token that chooses this command\nvirtual const char* GetString() const { return \"the\"; }\n// help string look at other commands for examples\nvirtual const char* GetSyntax() const\n{\nreturn \"Syntax: the [syntax]\";\n}\n// the meat\nvirtual bool Parse(std::vector&lt; std::string &gt;&amp;argv)\n{\n// possibly do something with argv\n// call the function declared in Cli\nreturn cli.DoThe();\n}\nprivate:\ncli::Cli&amp; cli;\n// no copy\nTheCommand&amp; operator=(const TheCommand&amp;);\n};\n// option parsing\nclass TheCommand : public cli::ParserCommand\n{\npublic:\nTheCommand(cli::Cli&amp; cli) : cli(cli), ParserCommand() {}\n// always virtual destructor\nvirtual ~TheCommand() {}\n// the token that chooses this command\nvirtual const char* GetString() const { return \"the\"; }\n// help string look at other commands for examples\nvirtual const char* GetSyntax() const\n{\nreturn \"Syntax: the [syntax]\";\n}\n// the meat\nvirtual bool Parse(std::vector&lt; std::string &gt;&amp;argv)\n{\ncli::Options opt;\n// define options\nOptionsData optionsData[] =\n{\n//{'a', \"alpha\", OPTARG_NONE},\n//{'b', \"bravo\", OPTARG_OPTIONAL},\n//{'c', \"charlie\", OPTARG_REQUIRED},\n{0, 0, OPTARG_NONE}\n};\n// declare state here to save during parsing\n// loop through args\nfor (;;)\n{\nif (!opt.ProcessOptions(argv, optionsData))\nreturn cli.SetError(opt.GetError());\nif (opt.GetOption() == -1) break;\nswitch (opt.GetOption())\n{\ncase 'a':\nbreak;\ncase 'b':\nif (!opt.GetOptionArgument.empty())\nopt.GetOptionArgument(); // Here's the optional argument\nbreak;\ncase 'c':\nopt.GetOptionArgument(); // Here's the argument\nbreak;\n}\n}\n// call the function declared in Cli\nreturn cli.DoThe();\n}\nprivate:\ncli::Cli&amp; cli;\n// no copy\nTheCommand&amp; operator=(const TheCommand&amp;);\n};\n</code></pre> <p>Open up cli_CommandLineInterface.cpp and add your command in the constructor. Create cli_the.cpp for your command and implement the command execution.</p>","tags":["kernel programming"]},{"location":"how_to/HowToCompileSmlClients/","title":"How to compile SML Clients","text":"","tags":["compile"]},{"location":"how_to/HowToCompileSmlClients/#introduction","title":"Introduction","text":"<p>The SML API is the standard method to get Soar agents to communicate with external environments, such as simulations or games. The API was written natively in C++, but has Java, Python, and Tcl bindings generated via SWIG. This page lays out the steps required to compile C++, Java, and Python SML client programs successfully on Linux/OSX/Windows. These instructions are for the 9.3.2 and later releases. Previous releases required a slightly more complex compilation process.</p> <p>Building a program to call the SML API is conceptually straightforward in any language. Usually, only one or two dependencies must be specified. In practice, this can still be painful because the operating system must be told where to look for the dependencies. All dependencies are located in a single directory or one of its subdirectories. This will be SoarSuite/bin if you are using a pre-built release distribution of Soar, or (by default) SoarSuite/out if you built Soar yourself.</p> <p>For all languages, compilers and operating systems, please make sure that you link 32-bit programs to the 32-bit version of Soar, and likewise for the 64-bit version. The error messages compilers produce for mismatched instruction sets tend to be cryptic, and you probably won't realize what the problem is from reading them.</p>","tags":["compile"]},{"location":"how_to/HowToCompileSmlClients/#c","title":"C++","text":"<p>To use the SML API in a C++ program, you must include the header file \"smlClient.h\" and link to the Soar shared library. If you are using the pre-built release package, the Soar shared library will be in SoarSuite/bin, named _libSoar.so (Linux), libSoar.dylib (OSX), or Soar.dll (Windows). The header will be in SoarSuite/bin/include. If you are building Soar from source, by default the build script will put the shared library in SoarSuite/out, and the headers in SoarSuite/out/include. Also note that when building from source, you need to build the \"kernel\" target (built by default) to get the shared library, and the \"headers\" target (not built by default) to produce the include directory. See the BuildSconsScript for more information. For the rest of this section, we will assume the reader is using the pre-built release package.</p> <p>For convenience, here's a Hello World program that you can use to test your compilation process:</p> <pre><code>#include &lt;iostream&gt;\n#include \"sml_Client.h\"\nusing namespace std;\nusing namespace sml;\nint main(int argc, char *argv[]) {\nKernel *k = Kernel::CreateKernelInNewThread();\nAgent *a = k-&gt;CreateAgent(\"soar\");\ncout &lt;&lt; a-&gt;ExecuteCommandLine(\"echo Hello World\") &lt;&lt; endl;\nstring dummy;\ncin &gt;&gt; dummy;\nreturn 0;\n}\n</code></pre>","tags":["compile"]},{"location":"how_to/HowToCompileSmlClients/#linux-mac-os-x","title":"Linux / Mac OS X","text":"<p>It's fairly straightforward to compile an SML client program from a shell using g++ or clang++. Both compilers take the same arguments. Supposing you unpacked the release into /home/user/SoarSuite, the compilation command should be:</p> <pre><code>g++ -L/home/user/SoarSuite/bin -I/home/user/SoarSuite/bin/include your_program.cpp -lSoar\n</code></pre> <p><code>-L</code> specifies additional library search directories, <code>-I</code> specifies additional include search directories, and <code>-l</code> specifies libraries to link to. The linker automatically figures out that -lSoar refers to the file libSoar.so on Linux or libSoar.dylib on OSX. Note that even though the linker can find the Soar shared library at link-time, the OS will still not know where it is at run-time (unless you use the RPATH feature). Therefore, you still need to set the environment variables <code>LD_LIBRARY_PATH</code> on Linux and <code>DYLD_LIBRARY_PATH</code> on OSX to <code>/home/user/SoarSuite/bin</code> when running your compiled program. More details can be found in BuildLibrarySearchPaths.</p>","tags":["compile"]},{"location":"how_to/HowToCompileSmlClients/#windows-with-visual-studio","title":"Windows with Visual Studio","text":"<p>Compiling an SML program using Visual Studio is a little more tedious because you have to navigate its cryptic configuration GUI. Here we present step-by-step instructions for setting up a new C++ project. These steps were tested using MSVC++ 2010 Express, but should be very similar or identical for other versions of Visual Studio. We assume you extracted the release into C:\\SoarSuite.</p> <ol> <li>In the menu, select File/New/Project...</li> <li>Choose the \"Empty Project\" template. Enter a name for the project.</li> <li>In the Solution Explorer, under the newly created project, there should be a \"Source Files\" folder. Right click it, choose Add/New Item... Choose \"C++ File\" in the template selection window that pops up, and give the file a name. You need to do this now so that the Properties window will show options for compiling C++ programs. I also copied the contents of the above Hello World program into the new file, but you don't have to.</li> <li>Right click on the new project (NOT the solution) in the Solution Explorer, choose Properties.</li> <li>Click on \"Configuration Manager\" in the upper right corner of the Properties window. Make sure that your project's Platform matches the version of Soar you downloaded/compiled. That means if you have a 32-bit version of Soar.dll, you need to use the \"Win32\" platform, and if you have a 64-bit version, you need to use the \"x64\" platform. VC++ Express doesn't include a 64-bit compiler, so if you are using it, you must use the 32-bit Soar. When you are done, close the Configuration Manager.</li> <li>In the \"Configuration\" drop-down box in the top left corner of the properties window, select \"All Configurations\" so that the changes you make apply to both debug and release configurations.</li> <li>Under Configuration Properties / Debugging / Environment, enter PATH=C:\\SoarSuite\\out. This will set the PATH environment variable to find Soar.dll when you run your program from within the IDE.</li> <li>Under Configuration Properties / C/C++ / General / Additional Include Directories, add the entry C:\\SoarSuite\\bin\\include.</li> <li>Under Configuration Properties / Linker / General / Additional Library Directories, add the entry C:\\SoarSuite\\bin.</li> <li>Under Configuration Properties / Linker / Input / Additional Dependencies, add Soar.lib.</li> <li>Click \"Okay\" in the Properties window to save the changes.</li> </ol> <p>Now you should be able to build and run your project. Remember that if you want to run the program outside of the Visual Studio IDE, you need to add C:\\SoarSuite\\bin to your PATH environment variable, discussed in more detail in BuildLibrarySearchPaths.</p>","tags":["compile"]},{"location":"how_to/HowToCompileSmlClients/#static-linking","title":"Static Linking","text":"<p>You can compile Soar as a static library, as described in BuildSconsScript. To link your program to a static Soar library, the only change you have to make is to define the macro <code>STATIC_LINKED</code> before you include sml_Client.h. There are macros in the Soar headers that will expand to different values depending on whether <code>STATIC_LINKED</code> is defined. Specifically, the prefix declspec (dllimport) is prepended to all SML API functions when compiling with MSVC++. More information is available here, but you don't need to understand it to compile successfully.</p> <ul> <li>With g++ and clang++, the easiest way to do this is to pass in the flag <code>-DSTATIC_LINKED</code>.</li> <li>In Windows/VC++, go to the Properties window for the project. Under   Configuration Properties / C/C++ / Preprocessor / Preprocessor Definitions, add   the text <code>STATIC_LINKED</code>. Click \"Apply\", then look under Configuration Properties   / C/C++ / Command Line. You should see/D \"STATIC_LINKED\" somewhere in the   command.</li> </ul>","tags":["compile"]},{"location":"how_to/HowToCompileSmlClients/#java","title":"Java","text":"<p>The only requirement for compiling a Java SML client is that the file sml.jar be in your class path. This file should be located inSoarSuite/bin/java in the release, and SoarSuite/out/java if you built Soar yourself and included the target sml_java (built by default).</p> <p>In the following, I assume you're compiling a source file HelloWorld.java with the following contents:</p> <pre><code>import sml.Kernel;\nimport sml.Agent;\npublic class HelloWorld {\npublic static void main(String[] args) {\nKernel k = Kernel.CreateKernelInNewThread();\nAgent a = k.CreateAgent(\"soar\");\nSystem.out.println(a.ExecuteCommandLine(\"echo Hello World\"));\n}\n}\n</code></pre> <p>To compile your program using javac directly from the command line, add sml.jar to the class path using the -cp flag. The command is essentially the same for all operating systems:</p> <pre><code>javac -cp /home/user/SoarSuite/bin/java/sml.jar HelloWorld.java (for Linux/OSX)\njavac -cp C:\\SoarSuite\\bin\\java\\sml.jar HelloWorld.java (for Windows)\n</code></pre> <p>This should produce a file HelloWorld.class.</p> <p>Oddly enough, running a Java SML client program is trickier than compiling it. The classes in sml.jar use JNI to call the C++ API under the hood. The JNI functions are compiled into a native shared library named libJava_sml_ClientInterface.so (Linux),libJava_sml_ClientInterface.dylib (OSX), or Java_sml_ClientInterface.dll (Windows). This file should be in SoarSuite/bin orSoarSuite/out. When you run your program, you have to make sure the Java virtual machine can locate this library as well as the Soar shared library. This is explained in BuildLibrarySearchPaths.</p> <p>After you set the library path correctly, you can run HelloWorld.class using the JVM. When you run the program, sml.jar should also be in the class path. Assuming HelloWorld.class is in the current directory, the command to run the program is:</p> <pre><code>java -cp /home/user/SoarSuite/bin/java/sml.jar:. HelloWorld (for Linux/OSX)\njava -cp C:\\SoarSuite\\bin\\java\\sml.jar;. HelloWorld (for Windows)\n</code></pre> <p>You should see \"Hello World\" printed to the console. If you didn't set the library search path correctly, running your program will produce an error that looks something like this:</p> <pre><code>java.lang.UnsatisfiedLinkError: no Java_sml_ClientInterface in java.library.path\nException in thread \"main\" java.lang.UnsatisfiedLinkError: no Java_sml_ClientInterface in java.library.path\nat java.lang.ClassLoader.loadLibrary(ClassLoader.java:1856)\nat java.lang.Runtime.loadLibrary0(Runtime.java:845)\nat java.lang.System.loadLibrary(System.java:1084)\nat sml.smlJNI.&lt;clinit&gt;(smlJNI.java:15)\nat sml.Kernel.CreateKernelInNewThread(Kernel.java:133)\nat HelloWorld.main(HelloWorld.java:6)\n</code></pre>","tags":["compile"]},{"location":"how_to/HowToCompileSmlClients/#eclipse","title":"Eclipse","text":"<p>Many Java programmers use the Eclipse IDE. Here are the steps to create an SML project in Eclipse. Note that Eclipse is a general purpose IDE and comes in many different variations. These instructions were written for \"Eclipse IDE for Java Developers\". Remember that all we are doing here is getting Eclipse to find sml.jar at compile time and the JNI shared libraries at run time.</p> <ol> <li> <p>In the main menu bar, choose File / New / Java Project. Give the project a    name, then click Next.</p> </li> <li> <p>Choose the Libraries tab, then click \"Add External JARs\". Choose    SoarSuite/bin/java/sml.jar in the file selection dialog. Click Finish.</p> </li> <li> <p>In the \"Package Explorer\", right click on the \"src\" folder under your project    and choose New / Class, and create a class with a main function. For example,    you can create a HelloWorld class and paste in the contents of the Hello World    program above.</p> </li> <li> <p>Again in the \"Package Explorer\", right click on your project, choose    Properties. Then choose \"Run/Debug Settings\", and click the \"New...\" button on    the right. Choose \"Java Application\" in the pop-up window. In the configuration    properties window that comes up, click \"Search...\" and choose the class you    created with the main function.</p> </li> <li> <p>In the same window, select the \"Environment\" tab, click \"New...\" to add a new    environment variable. For the Name field in the pop-up, enter <code>LD_LIBRARY_PATH</code> if    you're in Linux, <code>DYLD_LIBRARY_PATH</code> if in OSX, or PATH if in Windows. For the    Value, enter the full path to your SoarSuite/bin directory. This will help the    JVM find the JNI shared library when you run your project.</p> </li> <li> <p>Click OK, then OK again to close the configuration properties window.</p> </li> </ol> <p>Now you should be able to run your project by choosing Run / Run in the main menu bar.</p>","tags":["compile"]},{"location":"how_to/HowToCompileSmlClients/#python","title":"Python","text":"<p>To call SML via Python, you need to import the module <code>Python_sml_ClientInterface</code>, defined in the file <code>Python_sml_ClientInterface.py</code>. This file should be in SoarSuite/bin in the release, and SoarSuite/out in your own build, if you built the target sml_python. Like the Java SML bindings, the Python bindings also depend on a native library, called <code>_Python_sml_ClientInterface.so</code> (Linux), <code>_Python_sml_ClientInterface.dylib</code> (OSX), or <code>_Python_sml_ClientInterface.dll</code> (Windows). Note the leading underscore in all versions. This file should also be in SoarSuite/bin in the release or SoarSuite/out in your own build. We will assume the reader is using the pre-built release package and both files are in SoarSuite/bin. There are two ways to make the Python interpreter locate these files.</p> <ol> <li>Set the environment variable <code>PYTHONPATH</code> to include SoarSuite/bin. The    Python interpreter will search SoarSuite/bin for modules for any program you    run.</li> <li>Append SoarSuite/bin to the variable <code>sys.path</code> in the script itself    before <code>importing Python_sml_ClientInterface</code>. This method is local to the script    you applied it to, and is recommended if you have multiple versions of Soar on    your computer.</li> </ol> <p>Here is the Hello World program in Python, using the second method:</p> <pre><code>import sys\nsys.path.append('/home/user/SoarSuite/bin')\nimport Python_sml_ClientInterface as sml\nk = sml.Kernel.CreateKernelInNewThread()\na = k.CreateAgent('soar')\nprint a.ExecuteCommandLine('echo hello world')\n</code></pre> <p>If you use the first method to modify the search path, the first two lines of the script are not needed. In any case, you should be able to run the script like a normal Python program:</p> <pre><code>$ python helloworld.py\nhello world\n</code></pre>","tags":["compile"]},{"location":"how_to/IOAndRewardLinks/","title":"I/O and Reward Links","text":"","tags":["kernel programming"]},{"location":"how_to/IOAndRewardLinks/#introduction","title":"Introduction","text":"<p>Soar provides several links on various states: the io, input-link, and output-link exist on the top state, whereas a reward-link exists on every state. This page will describe how to add your own link, using the emotion link as an example (since that's what I'm working on at the moment). Note that this is actually a couple links (like io has a couple links) and it's only on the top state. If you only want a single link and/or you want links on all states, just search the code for reward-link to see how that's different (most of the differences for reward-link are because it is on every state).</p> <p>When adding a new link, there are several things you need to deal with:</p> <ul> <li>adding the link on agent creation</li> <li>removing the link on agent destruction</li> <li>recreating the link during an init-soar</li> </ul> <p>Depending on what the link is for, you may also need to deal with:</p> <ul> <li>reading things off of the link</li> <li>putting things on the link</li> </ul>","tags":["kernel programming"]},{"location":"how_to/IOAndRewardLinks/#adding-the-link-on-agent-creation","title":"Adding the link on agent creation","text":"<p>Adding a new link involves several steps:</p> <ul> <li>Creating and saving the link symbols and WMEs</li> </ul>","tags":["kernel programming"]},{"location":"how_to/IOAndRewardLinks/#creating-and-saving-the-link-symbols-and-wmes","title":"Creating and saving the link symbols and WMEs","text":"<p>Commonly-used symbols are often created once and stored on the agent structure. This includes link names (the attribute of the link wme). Let's suppose I want the following link structure (I'm using concrete identifiers for clarity; the actual identifiers that get created may be different):</p> <pre><code>S1 [COLOR=#666600]^[/COLOR]emotion E1 E1 [COLOR=#666600]^[/COLOR]appraisal[COLOR=#666600]-[/COLOR]link A1 [COLOR=#666600]^[/COLOR]feeling[COLOR=#666600]-[/COLOR]link F1\n</code></pre> <p>I need to create and save symbols for \"emotion\", \"appraisal-link\" and \"feeling-link\", and the WMEs that contain those symbols. To do this, go to the agent structure (agent.h) and find the section labeled \"Predefined Symbols\". At the end of this section, add a Symbol pointer for each new symbol:</p> <pre><code>[COLOR=#660066]Symbol[/COLOR] [COLOR=#666600]*[/COLOR] emotion_symbol[COLOR=#666600];[/COLOR]\n[COLOR=#660066]Symbol[/COLOR] [COLOR=#666600]*[/COLOR] appraisal_link_symbol[COLOR=#666600];[/COLOR]\n[COLOR=#660066]Symbol[/COLOR] [COLOR=#666600]*[/COLOR] feeling_link_symbol[COLOR=#666600];[/COLOR]\n</code></pre> <p>Now find the part of the agent structure labeled \"I/O stuff\" and add the Symbols corresponding to the identifier values of the WMEs and the wme structures themselves (generally speaking, you only need to save the WMEs that you plan on directly manipulating in other code):</p> <pre><code>Symbol            * emotion_header;\nwme               * emotion_header_link;\n\nSymbol            * emotion_header_appraisal;\nSymbol            * emotion_header_feeling;\n</code></pre> <p>Now go to the <code>create_predefined_symbols</code> function (in symtab.cpp) and create your symbols at the end:</p> <pre><code>thisAgent-&gt;emotion_symbol = make_sym_constant (thisAgent, \"emotion\");\nthisAgent-&gt;appraisal_link_symbol = make_sym_constant( thisAgent, \"appraisal-link\" );\nthisAgent-&gt;feeling_link_symbol = make_sym_constant( thisAgent, \"feeling-link\" );\n</code></pre> <p>Finally, go to the init_agent_memory function in init_soar.cpp and create the identifier values and WMEs corresponding to the desired structure:</p> <pre><code>thisAgent-&gt;emotion_header = get_new_io_identifier (thisAgent, 'E'); // E1\nthisAgent-&gt;emotion_header_appraisal = get_new_io_identifier (thisAgent, 'A');  // A1\nthisAgent-&gt;emotion_header_feeling = get_new_io_identifier (thisAgent, 'F'); // F1\n// (S1 ^emotion E1)\nthisAgent-&gt;emotion_header_link = add_input_wme (thisAgent,\nthisAgent-&gt;top_state,\nthisAgent-&gt;emotion_symbol,\nthisAgent-&gt;emotion_header);\n// (E1 ^appraisal-link A1)\nadd_input_wme (thisAgent, thisAgent-&gt;emotion_header,\nthisAgent-&gt;appraisal_link_symbol,\nthisAgent-&gt;emotion_header_appraisal);\n// (E1 ^feeling-link F1)\nadd_input_wme (thisAgent, thisAgent-&gt;emotion_header,\nthisAgent-&gt;feeling_link_symbol,\nthisAgent-&gt;emotion_header_feeling);\n</code></pre>","tags":["kernel programming"]},{"location":"how_to/IOAndRewardLinks/#removing-the-link-on-agent-destruction","title":"Removing the link on agent destruction","text":"<p>On agent destruction, we need to remove all of those symbols we saved on the agent structure. To do this, go to the release_predefined_symbols function (in symtab.cpp) and add the following to the end:</p> <pre><code>release_helper( thisAgent, &amp;( thisAgent-&gt;emotion_symbol ) );\nrelease_helper( thisAgent, &amp;( thisAgent-&gt;appraisal_link_symbol ) );\nrelease_helper( thisAgent, &amp;( thisAgent-&gt;feeling_link_symbol ) );\n</code></pre> <p>Note that this function is called from destroy_soar_agent in agent.cpp.</p> <p>In general, you do not need to explicitly release the WMEs, since those will automatically be cleaned up when the wme memory pool is cleaned up during agent destruction.</p>","tags":["kernel programming"]},{"location":"how_to/IOAndRewardLinks/#recreating-the-link-during-an-init-soar","title":"Recreating the link during an init-soar","text":"<p>Perhaps counter-intuitively, link recreation is handled in the do_input_cycle function in io.cpp. (Historically, initial link creation was handled here as well). Basically, the reinitialize_soar function calls clear_goal_stack which destroys the entire state and then calls do_input_cycle to recreate the top state. Find the part of do_input_cycle inside the if clause labeled \"top state was just removed\" and release the identifier values we created and set the corresponding pointers (including to WMEs) on the agent structure to NIL:</p> <pre><code>release_io_symbol (thisAgent, thisAgent-&gt;emotion_header);\nrelease_io_symbol (thisAgent, thisAgent-&gt;emotion_header_appraisal);\nrelease_io_symbol (thisAgent, thisAgent-&gt;emotion_header_feeling);\nthisAgent-&gt;emotion_header = NIL;\nthisAgent-&gt;emotion_header_appraisal = NIL;\nthisAgent-&gt;emotion_header_feeling = NIL;\nthisAgent-&gt;emotion_header_link = NIL;\n</code></pre> <p>Failure to do this properly will result in memory leak warnings when you do an init-soar.</p>","tags":["kernel programming"]},{"location":"how_to/IOAndRewardLinks/#reading-things-off-of-the-link","title":"Reading things off of the link","text":"<p>To read things off the link, you need to loop over any WMEs that might be on the link. In our example, suppose the following structure exists:</p> <pre><code>S1 ^emotion E1\nE1 ^appraisal-link A1\nA1 ^frame F1\nF1 ^conduciveness 1.0\n</code></pre> <p>We have a pointer to the appraisal-link on the agent structure already, so we can start there. First, make sure it exists (depending on when you call this function, it might not):</p> <pre><code>void get_appraisals(agent* thisAgent)\n{\nif(!thisAgent-&gt;emotion_header_appraisal) return;\n</code></pre> <p>Next, we have to loop over the slots. Slots are simply a list of WMEs that have the same id and attribute - that is, they support multi-valued attributes. If you don't have any multi-valued attributes, then each slot will only have one wme.</p> <pre><code>slot* frame_slot = thisAgent-&gt;emotion_header_appraisal-&gt;id.slots;\nslot* appraisal_slot;\nwme *frame, *appraisal;\nif ( frame_slot )\n{\nfor ( ; frame_slot; frame_slot = frame_slot-&gt;next )\n{\n</code></pre> <p>Each slot has an id, attr, and list of WMEs. In this case, we are looking for the \"frame\" slot. We will skip any other slots we see:</p> <p>Code:</p> <pre><code>if(frame_slot-&gt;attr-&gt;sc.common_symbol_info.symbol_type == SYM_CONSTANT_SYMBOL_TYPE\n&amp;&amp; !strcmp(frame_slot-&gt;attr-&gt;sc.name, \"frame\")) /* BADBAD: should store \"frame\" symbol in common symbols so can do direct comparison */\n{\n</code></pre> <p>When we find a \"frame\" slot, we will loop over its WMEs (each of which have the same id and the \"frame\" attribute). For the structure above, the only wme on this list will be A1 ^frame F1. For each wme that has an id value (just one in this case), we will loop over its slots and WMEs:</p> <pre><code>for ( frame = frame_slot-&gt;wmes ; frame; frame = frame-&gt;next)\n{\nif (frame-&gt;value-&gt;common.symbol_type == IDENTIFIER_SYMBOL_TYPE)\n{\nfor ( appraisal_slot = frame-&gt;value-&gt;id.slots; appraisal_slot; appraisal_slot = appraisal_slot-&gt;next )\n{\nfor ( appraisal = appraisal_slot-&gt;wmes; appraisal; appraisal = appraisal-&gt;next )\n{\n// do stuff with the WMEs; in this example, will get the F1 ^conduciveness 1.0 wme here\n}\n</code></pre> <p>Here's the complete example:</p> <pre><code>void get_appraisals(agent* thisAgent)\n{\nif(!thisAgent-&gt;emotion_header_appraisal) return;\nslot* frame_slot = thisAgent-&gt;emotion_header_appraisal-&gt;id.slots;\nslot* appraisal_slot;\nwme *frame, *appraisal;\nif ( frame_slot )\n{\nfor ( ; frame_slot; frame_slot = frame_slot-&gt;next )\n{\nif(    frame_slot-&gt;attr-&gt;sc.common_symbol_info.symbol_type == SYM_CONSTANT_SYMBOL_TYPE\n&amp;&amp; !strcmp(frame_slot-&gt;attr-&gt;sc.name, \"frame\")) /* BADBAD: should store \"frame\" symbol in common symbols so can do direct comparison */\n{\nfor ( frame = frame_slot-&gt;wmes ; frame; frame = frame-&gt;next)\n{\nif (frame-&gt;value-&gt;common.symbol_type == IDENTIFIER_SYMBOL_TYPE)\n{\nfor ( appraisal_slot = frame-&gt;value-&gt;id.slots; appraisal_slot; appraisal_slot = appraisal_slot-&gt;next )\n{\nfor ( appraisal = appraisal_slot-&gt;wmes; appraisal; appraisal = appraisal-&gt;next )\n{\n// do stuff with the WMEs; in this example, will get the F1 ^conduciveness 1.0 wme here\n}\n}\n}\n}\n}\n}\n}\n}\n</code></pre> <p>Of course, we need to call this function from somewhere. In this example, we'll read this link during the input phase, so we'll call it from do_input_cycle (in io.cpp), in the block of code marked \"if there is a top state, do the normal input cycle\":</p> <pre><code>/* --- if there is a top state, do the normal input cycle --- */\nif (thisAgent-&gt;top_state) {\nsoar_invoke_callbacks(thisAgent, INPUT_PHASE_CALLBACK, (soar_call_data) NORMAL_INPUT_CYCLE);\nget_appraisals(thisAgent);  // added this line\n}\n</code></pre>","tags":["kernel programming"]},{"location":"how_to/IOAndRewardLinks/#putting-things-on-the-link","title":"Putting things on the link","text":"<p>To put things on the link, you'll want to use these two functions: add_input_wme and remove_input_wme. In my example, I want to replace a wme that may exist on the feeling-link:</p> <pre><code>S1 ^emotion E1\nE1 ^feeling-link F1\nF1 ^frame F2  &lt;-- I want to blink this\n</code></pre> <p>First, let's suppose I already have a pointer to this wme saved on the agent structure:</p> <pre><code>wme * feeling_frame;\n</code></pre> <p>And also assume that I initialized this to 0 in init_agent_memory:</p> <pre><code>thisAgent-&gt;feeling_frame = 0;\n</code></pre> <p>Now I can update it like this:</p> <pre><code>void generate_feeling_frame(agent* thisAgent)\n{\n// clear previous feeling frame (stored on agent structure)\nif(thisAgent-&gt;feeling_frame) { remove_input_wme(thisAgent, thisAgent-&gt;feeling_frame); }\n// generate new frame\nthisAgent-&gt;feeling_frame = add_input_wme(thisAgent, thisAgent-&gt;emotion_header_feeling, make_sym_constant(thisAgent, \"frame\"), make_new_identifier(thisAgent, 'F', TOP_GOAL_LEVEL));\n}\n</code></pre> <p>Actually, that's not quite right - this will result in a memory leak (which will cause init-soar to fail, among other things). What will happen here is the call to make_sym_constant will create a new Symbol with a reference count of 1, and then add_input_wme will add another ref count to it. When this function is called later, remove_input_wme will decrement the ref count by 1, still leaving it with a non-zero ref count. The way to fix this is to decrement the ref count after we pass the Symbol off to add_input_wme (in effect, we are relinquishing control of the Symbol to the wme):</p> <pre><code>void generate_feeling_frame(agent* thisAgent)\n{\n// clear previous feeling frame (stored on agent structure)\nif(thisAgent-&gt;feeling_frame) { remove_input_wme(thisAgent, thisAgent-&gt;feeling_frame); }\n// generate new frame\nSymbol* frame_att = make_sym_constant(thisAgent, \"frame\");\nthisAgent-&gt;feeling_frame = add_input_wme(thisAgent, thisAgent-&gt;emotion_header_feeling, frame_att, make_new_identifier(thisAgent, 'F', TOP_GOAL_LEVEL));\nsymbol_remove_ref(thisAgent, frame_att);\n}\n</code></pre> <p>Of course, we need to call this function from somewhere. In this example, we want to generate a new frame right after we read in the appraisals, so we call the function from the same block of code as above (in do_input_phase in io.cpp):</p> <pre><code>/* --- if there is a top state, do the normal input cycle --- */\nif (thisAgent-&gt;top_state) {\nsoar_invoke_callbacks(thisAgent, INPUT_PHASE_CALLBACK, (soar_call_data) NORMAL_INPUT_CYCLE);\nget_appraisals(thisAgent);  // added this line above\ngenerate_feeling_frame(thisAgent); // added this line\n}\n</code></pre>","tags":["kernel programming"]},{"location":"how_to/MemoryLeakDebuggingWithVisualStudio/","title":"Memory Leak Debugging with Visual Studio","text":"<p>This document summarizes one technique for fixing memory leaks in the Soar kernel using Visual Studio's Leak Detection tools.</p> <p>First, choose a program you will use for testing. I recommend TestCLI or TestClientSML or some other program that can repeatably cause leaks.</p> <p>At the top of the file containing main.cpp, add this:</p> <pre><code>#ifdef _MSC_VER\n// Use Visual C++'s memory checking functionality\n#define _CRTDBG_MAP_ALLOC\n#include &lt;crtdbg.h&gt;\n#endif // _MSC_VER\n</code></pre> <p>This enables the leak-detection versions of the memory allocation and de-allocation functions.</p> <p>At the beginning of the main function, add this code:</p> <pre><code>#ifdef _MSC_VER\n//_crtBreakAlloc = 1828;\n_CrtSetDbgFlag ( _CRTDBG_ALLOC_MEM_DF | _CRTDBG_LEAK_CHECK_DF );\n#endif // _MSC_VER\n</code></pre> <p>The #ifdef's make sure that we don't try this with any other compiler. The CrtSetDbgFlag line says \"report detected leaks when the program exits.\" This is the preferred method -- it is possible to put a similar line at the end of main that says \"report detected leaks now\", but this is subtly different -- objects allocated in the main function may not be deallocated yet, and dlls are not yet unloaded. This can lead to false leak reports. So do it the way I have shown.</p> <p>I will describe the purpose of the commented line in a moment.</p> <p>This is enough to get your test program to report any leaks. The program (and any code you're testing) needs to be compiled in Debug mode for this to work. A leak report will look something like this:</p> <pre><code>Detected memory leaks!\nDumping objects -&gt;\n{19907} normal block at 0x00B24688, 11 bytes long.\nData: &lt;    &lt;#d*1&gt; &gt; 0B 00 00 00 3C 23 64 2A 31 3E 00\n{19906} normal block at 0x00B60360, 104 bytes long.\n Data: &lt;                &gt; 00 00 00 00 01 00 00 00 00 CD CD CD CD CD CD CD\n{3840} normal block at 0x00B2B240, 12 bytes long.\n Data: &lt;    desired &gt; 0C 00 00 00 64 65 73 69 72 65 64 00\n{3839} normal block at 0x00B2B198, 104 bytes long.\n Data: &lt;                &gt; 00 00 00 00 01 00 00 00 02 CD CD CD CD CD CD CD\n{1828} normal block at 0x00AE4BC8, 8 bytes long.\n Data: &lt;H       &gt; 48 02 AF 00 00 00 00 00\n{1699} normal block at 0x00B195C0, 56 bytes long.\n Data: &lt;                &gt; 00 00 00 00 CD CD CD CD CD CD CD CD CD CD CD CD\n{1698} normal block at 0x00B19550, 48 bytes long.\n Data: &lt;@               &gt; 40 CD CD CD CD CD CD CD 00 00 00 00 00 00 00 00\nObject dump complete.\n</code></pre> <p>What this means is that there were 7 leaks in this run. The number in {} is the allocation number of the leaked memory (e.g. {1698} means the 1698th malloc wasn't freed). The leaks are reported in reverse order for some reason. The Data line can sometimes give you a clue as to what is leaking. But the key is the number in the {}. In the code you added at the beginning of main, change the number in the commented line to one of the leak numbers (e.g. 1698 in the above report) and uncomment the line. I recommend doing this in the order in which the leaks occur (i.e. start at the bottom of the list), because some leaks can cause others or appear many times, so if you fix them in order some of the later ones may go away.</p> <p>Now run the program again. The code will break on the allocation number you specified (I recommend running the code from within Visual Studio as this will make bringing up the line of code easier). It is very important that this run be exactly like the previous run so that the same allocations occur in the same order. Otherwise the code will break on some irrelevant allocation. This means removing any randomness in the code execution. For multithreaded code this can be a pain, so I recommend coming up with the simplest possible test case that reproduces the leak you're working on. Sometimes the leak number will change over time because of threading issues, but will remain the same for a while. So it's important to regenerate the report periodically to make sure the allocation number you're working with is still accurate.</p> <p>When the code breaks, it will probably dump you in a low-level system file like dgbheap.c where the actual malloc is taking place. This is probably not interesting to you. You want to look at your callstack and find the relevant place in your code that you can actually do something about.</p>","tags":["kernel programming"]},{"location":"how_to/MemoryLeakDebuggingWithVisualStudio/#soar-kernel-gotchas","title":"Soar Kernel Gotchas","text":"<p>Most leaks reported in the kernel will be in the allocate_memory function. You will need to look higher up in the callstack to find the real source of the problem. This will often be in a call to a function like get_new_io_identifier or add_input_wme. Often, these functions return a pointer that is not saved, and thus cannot be released when it goes away or the agent is destroyed (much of the memory cleanup occurs in destroy_soar_agent).</p> <p>When working with Soar kernel code, some of the leak locations can be confusing. For example, if a hashtable is leaking, the reported leak may not occur where the hashtable was originally allocated, but rather where the hashtable was last resized. This kind of leak can appear to move around depending on what Soar code is run, because some code will require more allocations than others, but only the last one leaks. A similar thing can happen with memory pools (BTW, I believe all hashtable and memory pool leaks have been fixed now).</p> <p>It's also very common for symbols to leak. This is usually because the ref counts have not gone to zero for some reason, but it can also be because a pointer to the symbol was not saved so that it could be released. Most \"built-in\" symbols are released in the release_predefined_symbols function.</p>","tags":["kernel programming"]},{"location":"how_to/MemoryLeakDebuggingWithVisualStudio/#finding-leaks-to-the-memory-pools","title":"Finding Leaks to the Memory Pools","text":"<p>Soar uses memory pools for efficiency. These pools are deallocated when the agent is destroyed. Thus, if code takes memory from the pool without returning it, the leak detection will not see this because all of the pool memory is returned to the OS at the end. These kinds of leaks can cause memory usage to climb while Soar is running, however.</p> <p>In order to find these leaks, the memory pools must be disabled. This will hurt performance, but it will allow the leaks to be detected.</p> <p>To disable the memory pools, find the functions allocate_with_pool and free_with_pool in mem.h. Comment out everything in those functions, and uncomment the last line. Now, calls to get memory from a pool and to release memory back to the pool will just do a standard malloc and free.</p> <p>It should be noted that this can sometimes uncover bad pointer bugs. When the pool is in use, memory returned to the pool is probably not overwritten immediately. So if a pointer to that released memory is accessed, there is a good chance that it will work. When the pools are disabled, though, that memory is overwritten (in a DEBUG build, at least), and so such accesses will fail. Thus, you should periodically disable the pools even if you aren't looking for leaks to check your code in this way.</p>","tags":["kernel programming"]},{"location":"how_to/MemoryLeakDebuggingWithVisualStudio/#finding-leaks-in-dlls-and-modules-for-other-languages","title":"Finding leaks in DLLs and modules for other languages","text":"<p>If the .exe you are using has the memory leak detection code as described above and you are using Multithreaded Debug DLL code generation setting, then leaks in DLLs used by that .exe will also be reported.</p> <p>If the above conditions are not met and you want to check for leaks in a DLL, you need to add some special code to the DLL:</p> <pre><code>// Check for memory leaks\n#if defined(_DEBUG) &amp;&amp; defined(_WIN32)\n#define _CRTDBG_MAP_ALLOC\n#include &lt;stdlib.h&gt;\n#include &lt;crtdbg.h&gt;\n\nbool __stdcall DllMain( void _ hModule,\nunsigned long ul_reason_for_call,\nvoid _ lpReserved)\n{\n//_crtBreakAlloc = 1397;\n_CrtSetDbgFlag ( _CRTDBG_ALLOC_MEM_DF | _CRTDBG_LEAK_CHECK_DF );\nreturn 1;\n}\n#endif\n</code></pre> <p>This will report leaks for the DLL just as the .exe did before. Note that if you have the leak detection in both places, then the DLL leaks will get reported twice.</p> <p>For detecting leaks in programs written in other languages (e.g. Java), this code needs to be in the SWIG-generated DLL. We've already put it in there for you, so all you need is a debug build to see it (be sure to run from the command line so you can see this output at the end). The reported leaks should not be in the languages themselves, but rather in the SWIG or SML DLLs. Note that the Tcl and Python modules report lots of leaks (the SWIG people tell me this is because of the nature of memory management in those languages), so it may be difficult to pick out the leaks you are interested in for those languages.</p>","tags":["kernel programming"]},{"location":"how_to/SMLOutputLinkGuide/","title":"SML Output Link Guide","text":"<p>General Advice: Read the output link after the agent's output phase but before the next decision cycle's input phase.</p> <p>This is usually accomplished by registering for an event that fires in this range and reading the output link in there.</p> <p>Exercise care if you save commands (or other working memory elements on the output-link) to use later and return control back to Soar.</p> <p>Working memory elements can be removed by the Soar agent and freed by SML. Referring to them (to add, say ^status complete) will cause a segmentation fault.</p> <p>Be careful not to dereference working memory elements you have disconnected with <code>DestroyWME</code>.</p> <p>Destroyed pointers are freed by SML and will cause a segmentation fault if used.</p>","tags":["io","event","sml"]},{"location":"how_to/SMLOutputLinkGuide/#events-during-which-output-may-be-read","title":"Events During Which Output May Be Read","text":"<p>Recommended: Register for the Update event <code>smlEVENT_AFTER_ALL_OUTPUT_PHASES</code>.</p> <p>Run Events (agent-specific):</p> <pre><code># Register using Agent::RegisterForRunEvent\nsmlEVENT_AFTER_OUTPUT_PHASE   # All three of these are essentially equivalent\nsmlEVENT_AFTER_DECISION_PHASE\nsmlEVENT_AFTER_DECISION_CYCLE\n</code></pre> <p>Update Events:</p> <pre><code># Register using Kernel::RegisterForUpdateEvent\nsmlEVENT_AFTER_ALL_OUTPUT_PHASES    # Fires after all agents' output phases are done\nsmlEVENT_AFTER_ALL_GENERATED_OUTPUT # Fires as above but only after all agents also have output or reached max-nil-output-cycles\n</code></pre>","tags":["io","event","sml"]},{"location":"how_to/SMLOutputLinkGuide/#reading-the-output-link","title":"Reading the Output Link","text":"<p>There are a number of different ways to read information from the output link, each with pros and cons. Choose whichever method seems easiest to you.</p> <p>Examine In Detail</p> <ul> <li>Use <code>GetOutputLink</code>, <code>GetNumberChildren</code>, <code>GetChild</code>, and other similar   methods to examine working memory in its raw state.</li> <li>Can't use <code>IsJustAdded</code> and <code>AreChildrenModified</code> - these require   <code>SetTrackOutputLinkChanges</code> true</li> </ul> <p>Advantages:</p> <ul> <li>Most flexible.</li> <li>Can disable change tracking <code>Agent::SetTrackOutputLinkChanges(false)</code></li> </ul> <p>Disadvantages:</p> <ul> <li>Most verbose.</li> </ul>","tags":["io","event","sml"]},{"location":"how_to/SMLOutputLinkGuide/#command-interface","title":"Command Interface","text":"<p>Use Commands, <code>GetCommand</code>, and <code>GetParamValue</code> to get top level WMEs that have been added since the last cycle.</p> <p>This method is closest to the original SGIO and should be sufficient for most cases. \"Commands\" used in this context refer to identifier WMEs on the top-level of the output link. \"Parameters\" refer to valued attributes that are children of a top-level command (identifier).</p> <p>Advantages:</p> <ul> <li>Easiest.</li> </ul> <p>Disadvantages:</p> <ul> <li>Do not save identifiers and return control back to Soar - they could be deleted.</li> <li>Not good for commands that span multiple decision cycles, retained so that   <code>^status</code> complete can be added.</li> <li>Must follow \"command\" format: top level identifier.</li> </ul> <pre><code># \"Command\" format\n&lt;s&gt; ^io.output-link &lt;ol&gt;\n&lt;ol&gt; ^move &lt;c&gt;            # Command name \"move\"\n&lt;c&gt; ^direction north      # Parameter \"direction\"\n\n# Not \"Command\" format\n&lt;s&gt; ^io.output-link &lt;ol&gt;\n&lt;ol&gt; ^move north\n</code></pre>","tags":["io","event","sml"]},{"location":"how_to/SMLOutputLinkGuide/#changes-interface","title":"Changes Interface","text":"<p>Use <code>GetNumberOutputLinkChanges</code>, <code>GetOutputLinkChange</code>, and <code>IsOutputLinkChangeAdd</code> to get the list of all WMEs added and removed since the last decision cycle.</p> <p>All WMEs count as an output link change.</p> <p>Advantages:</p> <ul> <li>Full access to output link.</li> <li>Output link removals can be detected using <code>IsOutputLinkChangeAdd() == false</code></li> <li>Great for commands that can span multiple decision cycles because of removal   notification.</li> </ul> <p>Disadvantages:</p> <ul> <li>Need to parse changes to figure out what's attached to what.</li> </ul> <pre><code># This structure:\n&lt;s&gt; ^io.output-link &lt;ol&gt;\n&lt;ol&gt; ^move &lt;c&gt;            # Command name \"move\"\n&lt;c&gt; ^direction north      # Parameter \"direction\"\n\n# ... generates these two separate changes:\n(I3 ^move M1)\n(M1 ^direction north)\n</code></pre>","tags":["io","event","sml"]},{"location":"how_to/SMLOutputLinkGuide/#output-handler","title":"Output Handler","text":"<p>Use <code>AddOutputHandler</code> to register functions that are called when a specific attributes are added to the output link.</p> <p>Here you specify specific attributes that fire events when added.</p> <p>Advantages:</p> <ul> <li>Other update events do not need to be registered (such as smlEVENT_AFTER_ALL_OUTPUT_PHASES)</li> <li>Event handling model, can be very clear.</li> </ul> <p>Disadvantages:</p> <ul> <li>Full command set needs to be known before hand (only get events when   identifiers with registered attributes are added to the output link).</li> <li>Do not save identifiers and return control back to Soar--they could be   deleted.</li> <li>Not good for commands that span multiple decision cycles, retained so that   <code>^status</code> complete can be added.</li> <li>Must follow \"command\" format: top level identifier. See Command Interface   above.</li> </ul>","tags":["io","event","sml"]},{"location":"how_to/SMLOutputLinkGuide/#io-without-event-handlers","title":"IO Without Event Handlers","text":"<p>Not recommended. Reading the output link without event registration is possible. Generalized steps for this are:</p> <ol> <li>Set the stop phase to before-input.</li> <li>Call <code>RunTillOutput</code> or Run (one step only - multiple steps will lose tracked    changes).</li> <li>Read the output link.</li> </ol>","tags":["io","event","sml"]},{"location":"how_to/SoarTechnicalFAQ/","title":"Soar Technical FAQ","text":"","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#getting-soar","title":"Getting Soar","text":"","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#where-are-the-latest-soar-releases","title":"Where are the latest Soar releases?","text":"<p>Check the downloads page for pointers to downloads and release notes. Alternatively you can check out the development trunk from git. See the build documents for more information.</p>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#running-soar","title":"Running Soar","text":"","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#how-do-i-run-soar","title":"How do I run Soar?","text":"<p>If you downloaded a Soar release, navigate inside the extracted archive and run the shell scripts or batch files to run the various Soar components. The scripts set essential environment variables so the different Soar components can find their libraries and resources.</p>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#java-what-jresjdks-can-i-use","title":"Java: What JREs/JDKs can I use?","text":"<p>Use Sun JDK 6+. Other versions and vendors may work but we do not support them.</p>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#using-the-soar-java-debugger","title":"Using the Soar Java Debugger","text":"","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#what-command-line-options-does-the-debugger-accept","title":"What command line options does the debugger accept?","text":"<p>Command line options:</p> <ul> <li>remote =&gt; use a remote connection (with default ip and port values)</li> <li>ip xxx =&gt; use this IP value (implies remote connection)</li> <li>port ppp =&gt; use this port (implies remote connection)     Without any remote options we start a local kernel</li> <li>agent =&gt; on a remote connection select this agent as initial agent</li> <li>agent =&gt; on a local connection use this as the name of the initial agent</li> <li>source \"\" =&gt; load this file of productions on launch (only valid for local kernel)</li> <li>listen port =&gt; use this port to listen for remote connections (only valid for a local kernel)</li> <li>maximize =&gt; start with maximized window</li> <li>width =&gt; start with this window width</li> <li>height =&gt; start with this window height</li> <li>x -y =&gt; start with this window position (Providing width/height/x/y =&gt; not a maximized window)</li> </ul>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#if-i-run-the-debugger-for-a-while-it-starts-to-slow-down-stutter-and-then-crashes-or-runs-out-of-memory","title":"If I run the debugger for a while, it starts to slow down, stutter, and then crashes, or runs out of memory","text":"<p>The problem here is that the trace window in the debugger is using more and more memory over time, since it doesn't get rid of old stuff until you clear the window. Especially at <code>watch 5</code>, there's a lot of text being stored (even if it's mostly hidden). Long before your OS runs out of memory, though, Java runs out of heap space. You can allocate more heap space to most Java implementations using the -Xmxm flag when executing Java. For example:</p> <pre><code>java -Xmx512m -jar SoarJavaDebugger.jar\n</code></pre> <p>This will allocate 512 megs of memory for Java's heap (the default is 64 megs), and should allow you to run the debugger significantly longer.</p>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#how-do-i-use-the-debugger-with-the-graphical-demos-like-javatoh-and-javamissionaries-or-any-other-soar-application","title":"How do I use the debugger with the graphical demos like JavaTOH and JavaMissionaries? (or any other Soar application)?","text":"<ol> <li>Start the application</li> <li>Start the debugger (in Linux the debugger must be started after the    application--order doesn't matter in Windows)</li> <li>In the debugger, on the top menuBar, pull down the \"Kernel\" selection and    choose \"Connect to Remote Soar...\"</li> <li>In the popup window \"Would you like to shutdown the local kernel now\" enter    \"OK\"</li> <li>In the next popup window, if the application is on your local machine, press    \"OK\" to use the default settings. If your application is running on another    machine, enter the IP addr and press \"OK\"</li> <li>If the connection succeeds, then you can use the debugger and the application    interchangeably to control the agent. If the connection fails, then the    application either is not properly configured for SML, or no agent currently    exists in the application.</li> </ol>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#how-can-i-copypaste-a-production-into-the-debugger","title":"How can I copy/paste a production into the debugger?","text":"<p>There are several ways to do this:</p> <ul> <li>You can paste a production into the trace window.</li> <li>You can use the \"edit_production\" window in the lower-right corner. If you     supply the name of an existing production, it will fill in the window with that     production. You can then edit it and load the new version using the \"Load     Production\" button.</li> <li>If your production is in Visual Soar, you can do \"Soar Runtime\" -&gt; \"Connect\"     to connect to the debugger. Then, open the file with your production and do     \"Runtime\" -&gt; \"Send Production\" or \"Send File\" to load your production(s) into     Soar.</li> </ul>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#developing-soar","title":"Developing Soar","text":"","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#scons-is-adding-a-lot-of-ridiculous-include-directories-and-the-build-fails","title":"SCons is adding a lot of ridiculous include directories and the build fails","text":"<p>Seeing something like this means you should define <code>JAVA_HOME</code>:</p> <pre><code>g++ -o Core/CLI/CommandLineInterface.o -c -DSCONS -fvisibility=hidden -g3 -Wall -Werror -O3 -m64 -fPIC -ICore/CLI/src -ICore/CLI/include -ICore/SoarKernel/include -ICore/ElementXML/include -ICore/ConnectionSML/include -ICore/KernelSML/include -ICore/shared -I/usr/include -I/usr/include/netatalk -I/usr/include/netinet -I/usr/include/protocols -I/usr/include/dbus-1.0 -I/usr/include/blkid -I/usr/include/netax25 -I/usr/include/nfs -I/usr/include/rdma -I/usr/include/netpacket -I/usr/include/X11 -I/usr/include/c++ -I/usr/include/neteconet -I/usr/include/xen -I/usr/include/rpc -I/usr/include/gnu -I/usr/include/netash -I/usr/include/asm -I/usr/include/sound -I/usr/include/mtd -I/usr/include/asm-generic -I/usr/include/netrom -I/usr/include/compiz -I/usr/include/arpa -I/usr/include/net -I/usr/include/rpcsvc -I/usr/include/netiucv -I/usr/include/linux -I/usr/include/netrose -I/usr/include/video -I/usr/include/bits -I/usr/include/netipx -I/usr/include/uuid -I/usr/include/python2.5 -I/usr/include/sys -I/usr/include/python2.6\n</code></pre> <p>See the build document for more details.</p>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#how-do-i-get-the-trace-for-the-initial-s1-creation","title":"How do I get the trace for the initial S1 creation?","text":"<p>The initial state is created right after the agent is created but before the agent pointer is passed back to the client. Therefore, if you create the client and then register for print (or xml) output, you do not ever see the initial S1 creation.</p> <p>To get these initial print callbacks, you need to register for the after-agent-created event and register your print handlers in that function. This callback fires right after the agent is created but before S1 is created.</p>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#how-can-i-look-up-a-wme-on-the-input-link-if-i-know-its-attribute","title":"How can I look up a wme on the input link if I know its attribute?","text":"<p>Use the <code>Indentifier::FindByAttribute</code> method like this:</p> <pre><code>pAgent-&gt;GetInputLink()-&gt;FindByAttribute(\"location\", 0);\n</code></pre> <p>This works for any identifier, not just at the top level of the input link.</p>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#how-do-i-increase-the-performance-of-my-sml-application","title":"How do I increase the performance of my SML application?","text":"<p>It is often desirable to maximize the performance of your SML application. This section assumes that you just want to make things as fast as possible after you have finished debugging your application. Debugging is an inherently slow process, so these tips will be less helpful while you\u2019re still debugging.</p> <p>Compile with optimizations turned on. In Visual Studio this means doing a release build. On Linux and OS X, the default settings are probably sufficient, but you can experiment with new settings if you want (let us know if you find better settings).</p> <p>Put primary application and Soar in the same process. That is, use <code>CreateInNewThread</code> or <code>CreateInCurrentThread</code>, not <code>CreateRemoteConnection</code>. Using a remote kernel means socket communication is used, which is slow.</p> <p>Don\u2019t register for unnecessary events. Every event that is registered for causes extra work to be done. Try to find an appropriate event to register for so you don\u2019t end up getting more event calls than you actually need \u2013 that is, try to avoid registering for events which occur more frequently than you need and then filtering them on the application side.</p> <p>Don\u2019t connect the debugger. Connecting the debugger creates a remote connection and also registers for several events. Set <code>watch level 0</code>. Even if you don\u2019t have a client registered for any of the print or XML events, work is still done internally to generate some of the information that would have been sent out. Setting <code>watch level 0</code> avoids this work.</p> <p>Disable monitor productions. Again, even if no client is registered to print out the text of monitor productions, work is still done internally to prepare the text. Monitor productions can be disabled by excising them or commenting them out, but an easier method is to have each monitor production test a debug flag in working memory which is set by some initialization production or operator. Thus all of the monitor productions can be turned on or off by changing one line of code.</p> <p>Disable timers. Soar uses timers internally to generate the output of the stats command. If you don\u2019t need this information, you can use the <code>timers \u2013off</code> command to disable this bookkeeping. This can make a significant difference in the <code>watch 0</code> case.</p> <p>Avoid running agents separately. Instead of calling <code>RunSelf</code> or <code>RunSelfTilOutput</code> on each agent, just call RunAllAgents? on the kernel itself. This runs all agents together and avoids the overhead of running them separately. The absolute best you can do is to call <code>RunAllAgentsForever</code> as described in section 2.4 \u2013 this avoids repeatedly calling the <code>run</code> functions at all and will make it easier to stop and restart your application from the debugger (or other clients).</p> <p>In the case where the absolute best performance under SML is desired, use <code>CreateKernelInCurrentThread</code> instead of <code>CreateKernelInNewThread</code> and set the \u201coptimized\u201d flag to true in the parameters passed to <code>CreateKernelInCurrentThread</code>. This means Soar will execute in the same thread as your application. Without this each call to and from the Soar kernel requires a context switch (assuming a single processor machine). This method also eliminates the thread which polls for new events. This means you must poll for the events yourself by periodically calling <code>CheckForIncommingCommands</code>, which is a little more work for the programmer.</p> <p>Turn off <code>autocommits</code>. By default, SML sends WME changes to the kernel as soon as they are requested. Performance can be improved by telling SML to buffer all WME changes until an explicit call is made to commit the changes. Turning off <code>autocommits</code> is done via a call to <code>mykernel-&gt;SetAutoCommit(false)</code>. Explicitly committing WME changes is done via a call to <code>myagent-&gt;Commit()</code>. Sending all the changes at once will give a small performance boost in cases where Soar and the environment are in the same process, and a large performance boost when they are communicating over sockets. Be careful, though - the agent won't see any WMEs until they have been committed (and then not until the next input phase, as usual), and all WMEs must be committed before doing an <code>init-soar</code>, which generally means before giving the user control (since someone could call <code>init-soar</code> from an attached debugger). This typically means committing all WMEs after updating an agent's <code>input-link</code>.</p>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#when-can-i-safely-make-changes-to-the-input-link","title":"When can I safely make changes to the input-link?","text":"<p>A Soar agent only receives input during the input phase and it does this through an input phase callback while the agent is running. SML allows the environment to change the input-link at other times and those changes are buffered until the next input phase. This means you have several options for handling input: You can register for <code>smlEVENT_BEFORE_INPUT_PHASE</code> and make changes to the input link at that time. This is very close to the way the kernel naturally handles input but will often be relatively slow if Soar is running a lot faster than the environment is changing (a common situation) as this event needs to be sent each decision cycle for each agent, generating a lot of communications traffic.</p> <p>Another option is to register for an update event (<code>smlEVENT_AFTER_ALL_OUTPUT_PHASES</code> and <code>smlEVENT_AFTER_ALL_GENERATED_OUTPUT</code>), check for output at that time and create new inputs immediately. These events are called after the output phase has completed and the new input link changes will be buffered until the next input phase. This is the most common choice in existing SML environments.</p> <p>A third option is to register an output event handler, which looks for a particular attribute to be added to the output link and only then calls the registered function. This handler will be called during the output phase and again, new input will be collected and buffered until the next input phase of the agent. In general, any run event (<code>smlRunEventId</code>) or update event (<code>smlUpdateEventId</code>) is a good candidate to use for changing the input-link. Other events may not be appropriate to use. One particular example is <code>smlEVENT_BEFORE_AGENT_REINITIALIZED</code> and <code>smlEVENT_AFTER_AGENT_REINITIALIZED</code>. These events fire during an init-soar call and are dangerous to use because the system is actively destroying the entire input link and then recreating it to match the last structure defined by the environment. This happens automatically and gives the agent its best chance to continue executing again. However, if you register for these events yourself and try to change the input link during those events, the resulting behavior is likely to depend on whether the system callback occurs before or after your callback. With care this can probably all work out correctly, but you should be aware of what's going on. Similarly, making changes to I/O in response to a production firing or other such events is potentially dangerous as you might be changing input within a given execution phase rather than before or after it, leading to unpredictable results. These events are best used for monitoring Soar's behavior rather than changing it.</p>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#what-do-i-need-to-know-about-threads-in-my-sml-applications","title":"What do I need to know about threads in my SML applications?","text":"<p>You generally want to keep all interactions with the kernel in a single thread. You can make calls from other threads, but they will block if Soar is busy doing something else - like running - until the command completes. This requirement raises a few issues: If you're working with a GUI, then the handler for a \"run button\" shouldn't just call run on the kernel. If it does the GUI will wait for the run to complete before responding. This is usually not acceptable as requests to repaint the screen, other button presses etc. will be ignored. The solution is to create a new thread and run Soar in that thread. Now that Soar is running on a separate thread, when the user presses a \"stop\" button if you try to call Stop on the kernel from the UI thread it'll block. What you need to do instead is set a flag within the thread that is running Soar and use an event to check whether that flag has been set and if so call Stop then. The <code>smlEVENT_INTERRUPT_CHECK</code> event is a good candidate for this as it fires infrequently and generates little overhead.</p> <p>Similarly, as the environment changes you'll want to update the input link in the thread that is running Soar.</p> <p>The normal way to do this is again inside an event handler. The update family of events (<code>smlEVENT_AFTER_ALL_OUTPUT_PHASES</code> and <code>smlEVENT_AFTER_ALL_GENERATED_OUTPUT</code>) are good candidates to consider.</p> <p>If all of this seems a bit confusing, take a look at the Java Towers of Hanoi example that's included in the release. It demonstrates all of this behavior and is a good model to follow. If you're working on a command line application without a GUI, then the TestCommandLine application is a good reference as it demonstrates how to support interruption in a single-threaded application.</p> <p>A detailed explanation about threads in Soar is provided here.</p>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#how-do-i-properly-manage-memory-in-my-sml-application","title":"How do I properly manage memory in my SML application?","text":"<p>Memory management is actually really easy. Generally, the only objects you should explicitly delete are the kernel object and any objects you directly allocated through a call to new. In Java and Tcl, this generally means you can just let things go out of scope when you\u2019re done with them. There are a couple special cases you should be aware of, though: Agent objects are automatically deleted when the owning Kernel object is deleted (actually, when the call to <code>Kernel::Shutdown</code> is made, which you should always make before deleting the kernel). If you want to destroy an agent earlier, you can by making a call to <code>Kernel:destroyAgent</code>. Under no circumstances should you delete (in the C++ sense) an Agent object.</p> <p>In Java if you create a <code>ClientXML</code> object through <code>xml = new ClientXML()</code> you should call <code>xml.delete()</code> on it when you're done. This isn't strictly required (the garbage collector will get it eventually) but is good practice and will avoid messages about leaked memory when the application shuts down. As per the general rule, in C++ if you create it with new you\u2019re responsible for destroying it with delete.</p> <p>Since there can be multiple clients interacting with the same kernel and agents, your application needs to be listening for the appropriate events so if some other client deletes/destroys a kernel or agent your application is using, you don\u2019t crash. Specifically, listen for the <code>BEFORE_AGENT_DESTOYED</code> and <code>BEFORE_SHUTDOWN</code> events so you can clean things up as needed in your application.</p>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#what-are-the-differences-in-the-sml-interface-between-c-and-java-and-other-languages","title":"What are the differences in the SML interface between C++ and Java (and other languages)?","text":"<p>For the most part, the exact same classes and methods are available in all languages. In some cases there are differences with obvious mappings -- for example, in C++ a method might take a char whereas in Java it takes a String. One exception to this rule is in the way event callbacks are handled. The callbacks look very similar from language to language, but some languages have constraints that make a direct conversion of the C++ style impossible. In C++, event callbacks are global functions.</p> <p>In Java, it's not possible to have global functions, so the callback must belong to some class. Thus, for Java we provide an interface for each event type that the class containing the callback method must implement, and then the handling object is passed in as part of the registration. You can look at any of the example Java code to see examples of this (e.g. TestJavaSML or JavaTOH are good places to start).</p> <p>Another important difference is that in C++ and Tcl, the kernel object must be explicitly deleted after <code>Shutdown()</code>. In C++ this is just calling <code>delete mykernel;</code> whereas in Tcl it takes the form <code>$kernel -delete</code>. In Java and C#, deletion is handled internally by the <code>Shutdown()</code> method (this isn't done in C++ to make debugging easier).</p>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#how-should-i-get-started-on-my-first-cjava-sml-application","title":"How should I get started on my first C++/Java SML application?","text":"<p>See the HelloWorld document for simple example environments Start by building and running these and then replace the code with your code. Also don't forget to read the SMLQuickStartGuide. The complete documentation for the SML interface is provided in the ClientSML C++ headers (which are thoughly commented). Using a different language - don't worry, the interface is virtually the same.</p>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#how-do-i-make-a-copy-of-an-existing-project","title":"How do I make a copy of an existing project?","text":"<p>Go into the SoarSuite\\Tools folder and copy the TestClientSML folder as MyProject Within that folder, rename <code>TestClientSML.vcproj</code> as <code>MyProject.vcproj</code> Open the <code>SoarSuite\\SML.sln</code> solution file (or make a copy of this file and open that) Select \"File | Add Project | Existing Project\" and add the <code>MyProject.vcproj</code> to the solution It will be added as \"TestClientSML\". Select it in Solution Explorer, right click and choose Rename to rename it as MyProject. (Make sure you're not accidentally renaming the real TestClientSML project - you can open the TestClientSML.cpp file in the editor and then move your mouse over the tab at the top of the editor window for the open file to see the path just to be sure).</p> <p>At this point you should be able to build the project to create MyProject.exe Remove TestClientSML.cpp from the project and start adding your own code. What are the required Visual Studio project settings for my SML application?</p> <p>Your project needs to reference the <code>!ClientSML</code>, <code>!ConnectionSML</code>, and <code>!ElementXML</code> projects. Additionally, add the include directories for the src folder of each of those projects.</p>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#the-java-virtual-machine-segfaults-when-running-soar","title":"The Java Virtual Machine segfaults when running Soar","text":"<p>See the next question.</p>","tags":["sml"]},{"location":"how_to/SoarTechnicalFAQ/#sml-wmelementidentifierstringelementintelementfloatelement-pointers-become-invalid-without-my-knowledge","title":"SML WMElement/Identifier/StringElement/IntElement/FloatElement pointers become invalid without my knowledge","text":"<p>First, usage of <code>WMElement</code> in this answer refers to any of <code>WMElement</code>/<code>Identifier</code>/<code>StringElement</code>/<code>IntElement</code>/<code>FloatElement</code> (all of which are or extend <code>WMElement</code>).</p> <p>A few things to remember about WMElement pointers returned by SML methods such as CreateIdentifier:</p> <ul> <li><code>WMElement</code> objects returned by pointers are owned by SML (don't delete them),</li> <li>Pointers to <code>WMElement</code> objects may be destroyed without calling <code>DestroyWME</code>,</li> <li>Pointers to <code>WMElement</code> objects may be destroyed by SML triggered by the agent as it runs.</li> <li>A general rule: you need to keep track of whether or not a <code>WMElement</code> is valid before you use it. It will stay valid if</li> <li>You do not call <code>DestroyWME</code> on it or on a WME that causes it to get disconnected,</li> <li>You do not return control back to Soar letting it run.</li> <li>If you call <code>DestroyWME</code>, you need to be sure that you don't hang on to any     WMElement objects that the WME you destroyed was keeping valid. Most of the time     your working memory structure is a tree so you only need to keep track of the     children of any Identifier you destroy.</li> </ul> <p>In Java/Python/Tcl/CSharp, <code>WMElement ConvertToIdentifier</code> or other Convert- function returns something that should be equal to something else but isn't.</p> <p>In our language interfaces covered by SWIG, such as Java, Python, Tcl, and CSharp, <code>ConvertToIdentifier</code>, <code>ConvertToStringElement</code>, <code>ConvertToIntElement</code>, and <code>ConvertToFloatElement</code> issue references to objects that wrap pointers. If these pointers were compared, they would be equal. Unfortunately, comparing references to these objects wrapping equivalent pointers returns <code>false</code> - that they are unequal.</p> <p>A workaround is to not compare references, or use other language supported reference equality in this case. Instead, compare the <code>time tags</code> by calling <code>GetTimeTag</code> on the reference.</p>","tags":["sml"]},{"location":"reference/","title":"Reference","text":""},{"location":"reference/CommandLineOptionsForDebuggerAndCLI/","title":"Command-Line Options for the Java Debugger and CLI","text":"","tags":["debugger"]},{"location":"reference/CommandLineOptionsForDebuggerAndCLI/#soar-java-debugger-command-line-options","title":"Soar Java Debugger Command Line Options","text":"<ul> <li>remote Use a remote connection (with default ip and port values)</li> <li>ip xxx Use this IP value (implies remote connection)</li> <li>port ppp Use this port (implies remote connection, without any remote options     we start a local kernel)</li> <li>agent <code>&lt;name&gt;</code> On a remote connection select this agent as initial agent</li> <li>agent <code>&lt;name&gt;</code> On a local connection use this as the name of the initial agent</li> <li>source <code>&lt;path&gt;</code> Load this file of productions on launch (only valid for local kernel)</li> <li>quitonfinish When combined with source causes the debugger to exit after sourcing that one file</li> <li>listen ppp Use this port to listen for remote connections (only valid for a local kernel)</li> <li>maximize Start with maximized window</li> <li>width <code>&lt;width&gt;</code> Start with this window width</li> <li>height <code>&lt;height&gt;</code> Start with this window height</li> <li>x <code>&lt;x&gt;</code> -y <code>&lt;y&gt;</code> Start with this window position</li> <li>cascade Cascade each window that starts (offsetting from the -x <code>&lt;x&gt;</code> -y <code>&lt;y&gt;</code>     if given). This option now always on. (Providing width/height/x/y =&gt; not a     maximized window)</li> </ul>","tags":["debugger"]},{"location":"reference/CommandLineOptionsForDebuggerAndCLI/#soar-cli-command-line-options","title":"Soar-CLI Command Line Options","text":"<ul> <li><code>-l</code> Listen on, i.e. launches Soar kernel in new thread</li> <li><code>-n</code> No syntax coloring</li> <li><code>-p</code> <code>&lt;port&gt;</code> Listens on port <code>&lt;port&gt;</code></li> <li><code>-s</code> <code>&lt;file&gt;</code> Sources file <code>&lt;file&gt;</code> on load</li> </ul> <p>To manage multiple agents, you can use the commands \"create\", \"list\", and \"switch\".</p>","tags":["debugger"]},{"location":"reference/CommandLineOptionsForDebuggerAndCLI/#troubleshooting","title":"Troubleshooting","text":"<p>If you have problems with the debugger, try deleting any .soar files in your home directory. Corrupt settings can cause the java debugger to fail to launch.</p>","tags":["debugger"]},{"location":"reference/cli/","title":"Soar-Cli","text":"<p>Help files for the Soar command line interface</p> <p>When issuing commands, the command name can be shortened so long as there is no ambiguity (e.g., <code>pref</code> instead of <code>preferences</code>). Arbitrary aliases may also be assigned using the <code>alias</code> command. Some of the more common shortcuts are listed with each command's synopsis under \"Default Aliases\".</p>"},{"location":"reference/cli/cmd_alias/","title":"alias","text":""},{"location":"reference/cli/cmd_alias/#alias","title":"alias","text":"<p>Define a new alias of existing commands and arguments.</p>"},{"location":"reference/cli/cmd_alias/#synopsis","title":"Synopsis","text":"<pre><code>alias\nalias &lt;name&gt; [args]\nalias -r &lt;name&gt;\n</code></pre>"},{"location":"reference/cli/cmd_alias/#adding-a-new-alias","title":"Adding a new alias","text":"<p>This command defines new aliases by creating Soar procedures with the given name. The new procedure can then take an arbitrary number of arguments which are post-pended to the given definition and then that entire string is executed as a command. The definition must be a single command, multiple commands are not allowed. The alias procedure checks to see if the name already exists, and does not destroy existing procedures or aliases by the same name. Existing aliases can be removed by using the unalias command.</p>"},{"location":"reference/cli/cmd_alias/#removing-an-existing-alias","title":"Removing an existing alias","text":"<p>To undefine a previously created alias, use the <code>-r</code> argument along with the name of the alias to remove.</p> <p><code>alias -r existing-alias</code></p> <p>Note:  If you are trying to create an alias for a command that also has a <code>-r</code> option, make sure to enclose it in quotes.  For example:</p> <p><code>alias unalias \"alias -r\"</code></p>"},{"location":"reference/cli/cmd_alias/#printing-existing-aliases","title":"Printing Existing Aliases","text":"<p>With no arguments, alias returns the list of defined aliases. With only the name given, alias returns the current definition.  </p>"},{"location":"reference/cli/cmd_alias/#examples","title":"Examples","text":"<p>The alias <code>wmes</code> is defined as:</p> <pre><code>alias wmes print -i\n</code></pre> <p>If the user executes a command such as:</p> <pre><code>wmes {(* ^superstate nil)}\n</code></pre> <p>... it is as if the user had typed this command:</p> <pre><code>print -i {(* ^superstate nil)}\n</code></pre> <p>To check what a specific alias is defined as, you would type</p> <pre><code>alias wmes\n</code></pre>"},{"location":"reference/cli/cmd_alias/#default-alias-aliases","title":"Default Alias Aliases","text":"<pre><code>a               alias\nunalias, un     alias -r     \n</code></pre>"},{"location":"reference/cli/cmd_chunk/","title":"chunk","text":""},{"location":"reference/cli/cmd_chunk/#chunk","title":"chunk","text":"<p>Sets the parameters for explanation-based chunking.</p>"},{"location":"reference/cli/cmd_chunk/#synopsis","title":"Synopsis","text":"<pre><code>===================================================\n           Chunk Commands and Settings\n===================================================\n? | help                                              Print this help listing\ntimers                                 [ on | OFF ]   Timing statistics (no args to print stats)\nstats                                                 Print statistics on learning\n------------------- Settings ----------------------\nalways | NEVER | only | except                        When Soar will learn new rules\nbottom-only                            [ on | OFF ]   Learn only from bottom sub-state\nnaming-style                     [ numbered | RULE]   Numeric names or rule-based names\nmax-chunks                                 50         Max chunks learned per phase\nmax-dupes                                   3         Max duplicate chunks (per rule, per phase)\n------------------- Debugging ---------------------\ninterrupt                              [ on | OFF ]   Stop after learning from any rule\nexplain-interrupt                      [ on | OFF ]   Stop after learning rule watched \nwarning-interrupt                      [ on | OFF ]   Stop after detecting learning issue\n------------------- Fine Tune ---------------------\nsingleton                                             Print all WME singletons\nsingleton                &lt;type&gt; &lt;attribute&gt; &lt;type&gt;    Add a WME singleton pattern\nsingleton -r             &lt;type&gt; &lt;attribute&gt; &lt;type&gt;    Remove a WME singleton pattern\n----------------- EBC Mechanisms ------------------\nadd-ltm-links                          [ on | OFF ]   Recreate LTM links in results\nadd-osk                                [ on | OFF ]   Incorporate operator selection rules\nmerge                                  [ ON | off ]   Merge redundant conditions\nlhs-repair                             [ ON | off ]   Add conds for unconnected LHS IDs\nrhs-repair                             [ ON | off ]   Add conds for unconnected RHS IDs\nuser-singletons                        [ ON | off ]   Unify with domain singletons\n---------- Correctness Guarantee Filters ----------     Allow rules to form that...\nallow-local-negations                  [ ON | off ]   ...used local negative reasoning\nallow-opaque*                          [ ON | off ]   ...used knowledge from a LTM recall\nallow-missing-osk*                     [ ON | off ]   ...tested operators selected through OSK\nallow-uncertain-operators*             [ ON | off ]   ...tested operators selected probabilistically\n* disabled\n---------------------------------------------------\n\nTo change a setting:                                  chunk &lt;setting&gt; [&lt;value&gt;]\nFor a detailed explanation of these settings:         help chunk\n</code></pre>"},{"location":"reference/cli/cmd_chunk/#description","title":"Description","text":"<p>The <code>chunk</code> command controls the parameters for explanation-based chunking. With no arguments, this command prints out a basic summary of the current learning parameters, how many rules have been learned and which states have learning active. With an <code>?</code> argument, it will list all sub-commands, options and their current values.</p>"},{"location":"reference/cli/cmd_chunk/#turning-on-explanation-based-chunking","title":"Turning on Explanation-Based Chunking","text":"<p>Chunking is disabled by default. Learning can be turned on or off at any point during a run. Also note that Soar uses most aspects of EBC to create justifications as well, so many aspects of the chunking algorithm still occur even when learning is off. <pre><code>chunk always:      Soar will always attempt to learn rules from sub-state \n                   problem-solving. \nchunk never:       Soar will never attempt to learn rules.\nchunk unflagged:   Chunking is on in all states _except_ those that have had RHS \n                   `dont-learn` actions executed in them. \nchunk flagged:     Chunking is off for all states except those that are flagged \n                   via a RHS `force-learn` actions.\n</code></pre> The <code>flagged</code> argument and its companion <code>force-learn</code> RHS action allow Soar developers to turn learning on in a particular problem space, so that they can focus on debugging the learning problems in that particular problem space without having to address the problems elsewhere in their programs at the same time. Similarly, the <code>unflagged</code> flag and its companion <code>dont-learn</code> RHS action allow developers to temporarily turn learning off for debugging purposes. These facilities are provided as debugging tools, and do not correspond to any theory of learning in Soar.</p> <p>The <code>bottom-only</code> setting control when chunks are formed when there are multiple levels of subgoals. With bottom-up learning, chunks are learned only in states in which no subgoal has yet generated a chunk. In this mode, chunks are learned only for the \"bottom\" of the subgoal hierarchy and not the intermediate levels. With experience, the subgoals at the bottom will be replaced by the chunks, allowing higher level subgoals to be chunked.</p>"},{"location":"reference/cli/cmd_chunk/#debugging-explanation-based-chunking","title":"Debugging Explanation-Based Chunking","text":"<p>The best way to understand why and how rules formed is to use the <code>explain</code> command. It will create detailed snapshots of everything that existed when a rule or justification formed that you can interactively explore.  See  explain for more information.  You can even use it in conjunction with the visualizer to create graphs depicting the dependency between rules in a sub-state.</p> <p>The <code>stats</code> command will print a detailed table containing statistics about all chunking activity during that run.</p> <p>The <code>interrupt</code> setting forces Soar to stop after forming any rule.</p> <p>The <code>explain-interrupt</code> setting forces Soar to stop when it attempts to form a rule from a production that is being watched by the explainer. See explain for more information.</p> <p>The <code>warning interrupts</code> setting forces Soar to stop when it attempts to form a rule but detects an issue that may be problematic.</p> <p>The <code>record-utility</code> command is a tool to determine how much processing may be saved by a particular learned rule. When enabled, Soar will detect that a chunk matched, but will not fire it. Assuming that the rule is correct, this should lead to an impasse that causes a duplicate chunk to form. The amount of time and decision cycles spent in that impasse are recorded and stored for the rule. Rules are also flagged if a duplicate is not detected or if an impasse is not generated. </p> <p>This feature is not yet implemented.</p>"},{"location":"reference/cli/cmd_chunk/#preventing-possible-correctness-issues","title":"Preventing Possible Correctness Issues","text":""},{"location":"reference/cli/cmd_chunk/#chunk-allow-local-negations","title":"chunk allow-local-negations","text":"<p>The option <code>allow-local-negations</code> control whether or not chunks can be created that are derived from rules that check local WMEs in the substate don't exist. Chunking through local negations can result in overgeneral chunks, but disabling this ability will reduce the number of chunks formed. The default is to enable chunking through local negations.</p> <p>If chunking through local negations is disabled, to see when chunks are discarded (and why), set <code>watch --learning print</code> (see watch command).</p> <p>The following commands are not yet enabled.  Soar will currently allow all of these situations.</p>"},{"location":"reference/cli/cmd_chunk/#allow-missing-osk","title":"allow-missing-osk","text":"<p>Used operator selection rules to choose operator</p>"},{"location":"reference/cli/cmd_chunk/#allow-opaque","title":"allow-opaque","text":"<p>Used knowledge from opaque knowledge retrieval</p>"},{"location":"reference/cli/cmd_chunk/#allow-uncertain-operators","title":"allow-uncertain-operators","text":"<p>Used operators selected probabilistically</p>"},{"location":"reference/cli/cmd_chunk/#allow-conflated-reasoning","title":"allow-conflated-reasoning","text":"<p>Tests a WME that has multiple reasons it exists</p>"},{"location":"reference/cli/cmd_chunk/#other-settings-that-control-when-rules-are-learned","title":"Other Settings that Control WHEN Rules are Learned","text":""},{"location":"reference/cli/cmd_chunk/#chunk-max-chunks","title":"chunk max-chunks","text":"<p>The <code>max-chunks</code> command is used to limit the maximum number of chunks that may be created during a decision cycle. The initial value of this variable is 50; allowable settings are any integer greater than 0.</p> <p>The chunking process will end after max-chunks chunks have been created, even if there are more results that have not been backtraced through to create chunks, and Soar will proceed to the next phase. A warning message is printed to notify the user that the limit has been reached.</p> <p>This limit is included in Soar to prevent getting stuck in an infinite loop during the chunking process. This could conceivably happen because newly-built chunks may match immediately and are fired immediately when this happens; this can in turn lead to additional chunks being formed, etc. </p> <p>Important note:</p> <p>If you see this warning, something is seriously wrong; Soar will be unable to guarantee consistency of its internal structures. You should not continue execution of the Soar program in this situation; stop and determine whether your program needs to build more chunks or whether you've discovered a bug (in your program or in Soar itself).</p>"},{"location":"reference/cli/cmd_chunk/#chunk-max-dupes","title":"chunk max-dupes","text":"<p>The <code>max-dupes</code> command is used to limit the maximum number of duplicate chunks that can form from a particular rule in a single decision cycle. The initial value of this variable is 3; allowable settings are any integer greater than 0.  Note that this limit is per-rule, per-state.  With the default value, each rule can match three times in a sub-state and create two duplicate, reject rules before Soar will stop attempting to create new rules based on that rule.  The limit is reset the next decision cycle.</p> <p>This limit is included in Soar to prevent slowing down when multiple matches of a rule in a substate produce the same general rule. Explanation-based chunking can now produce very general chunks, so this can happen in problem states in which the logic leads to multiple matches, which leads to results being created multiple times in the same decision cycle.</p>"},{"location":"reference/cli/cmd_chunk/#settings-that-alter-the-mechanisms-that-ebc-uses","title":"Settings that Alter the Mechanisms that EBC Uses","text":""},{"location":"reference/cli/cmd_chunk/#chunk-add-osk","title":"chunk add-osk","text":"<p>The option <code>add-osk</code> control whether or not operator selection knowledge is backtraced through when creating justifications and chunks.  When this option is disabled, only requirement preferences (requires and prohibits) will be added backtraced through.  When this option is enabled, relevant desirability prefs (better, best, worse, worst, indifferent) will also be added, producing more specific and possibly correct chunks. This feature is still experimental, so the default is to not include operator selection knowledge.</p> <p>The following commands are not yet enabled.  Soar will always use the EBC mechanisms listed below.</p>"},{"location":"reference/cli/cmd_chunk/#variablize-identity","title":"variablize-identity","text":"<p>Variablize symbols based on identity analysis</p>"},{"location":"reference/cli/cmd_chunk/#variablize-rhs-funcs","title":"variablize-rhs-funcs","text":"<p>Variablize and compose RHS functions</p>"},{"location":"reference/cli/cmd_chunk/#enforce-constraints","title":"enforce-constraints","text":"<p>Track and enforce transitive constraints</p>"},{"location":"reference/cli/cmd_chunk/#repair","title":"repair","text":"<p>Repair rules that aren't fully connected</p>"},{"location":"reference/cli/cmd_chunk/#merge","title":"merge","text":"<p>Merge redundant conditions</p>"},{"location":"reference/cli/cmd_chunk/#user-singletons","title":"user-singletons","text":"<p>Unify identities using domain-specific singletons</p> <p>If backtracing traces through the same WME multiple times via different backtrace paths, a resulting chunk may have duplicate conditions for that WME. This could be undesirable. Enabling user-singletons allows the user to specify duplicate conditions that should be merged.</p> <p>Singletons are defined using the <code>chunk singleton &lt;type&gt; &lt;attr&gt; &lt;type&gt;</code> command, where <code>&lt;type&gt;</code> is either \"state\", \"identifier\", or \"constant\", and <code>&lt;attr&gt;</code> is the domain-specific attribute to unify within chunks.</p>"},{"location":"reference/cli/cmd_chunk/#chunk-naming-style","title":"Chunk Naming Style","text":"<p>The numbered style for naming newly-created chunks is: <pre><code>&lt;prefix&gt;&lt;chunknum&gt;\n</code></pre> The rule-based (default) style for naming chunks is: <pre><code>&lt;prefix&gt;*&lt;original-rule-name&gt;*&lt;impassetype&gt;*&lt;dc&gt;-&lt;dcChunknum&gt;\n</code></pre> where:</p> <ul> <li>prefix is either chunk or justification, depending on whether learning was on for that state,</li> <li>chunknum is a counter starting at 1 for the first chunk created,</li> <li>original-rule-name is the name of the production that produced the result that resulted in this chunk,</li> <li>dc is the number of the decision cycle in which the chunk was formed,</li> <li>impassetype is one of Tie, Conflict, Failure, StateNoChange, OpNoChange,</li> <li>dcChunknum is the number of the chunk within that specific decision cycle.</li> </ul> <p>Note that when using the rule-based naming format, a chunk based on another chunk will have a name that begins with prefix followed by <code>-xN</code>, for example <code>chunk-x3*apply-rule*42-2</code>.</p>"},{"location":"reference/cli/cmd_chunk/#default-aliases","title":"Default Aliases","text":"<pre><code>learn    chunk\ncs       chunk --stats\n</code></pre>"},{"location":"reference/cli/cmd_chunk/#see-also","title":"See Also","text":"<p>explain trace visualize</p>"},{"location":"reference/cli/cmd_debug/","title":"debug","text":""},{"location":"reference/cli/cmd_debug/#debug","title":"debug","text":"<p>Contains commands that provide access to Soar's internals.  Most users will not need to access these commands.</p>"},{"location":"reference/cli/cmd_debug/#synopsis","title":"Synopsis","text":"<pre><code>======================================================================\n                     Debug Commands and Settings\n======================================================================\nallocate [pool blocks]         Allocates extra memory to a memory pool\ninternal-symbols                                   Prints symbol table\nport                                             Prints listening port\ntime &lt;command&gt; [args]           Executes command and prints time spent\n</code></pre>"},{"location":"reference/cli/cmd_debug/#debug-allocate","title":"debug allocate","text":"<pre><code>debug allocate [pool blocks]\n</code></pre> <p>This <code>allocate</code> command allocates additional blocks of memory for a specified memory pool.  Each block is 32 kilobyte.</p> <p>Soar allocates blocks of memory for its memory pools as it is needed during a run (or during other actions like loading productions). Unfortunately, this behavior translates to an increased run time for the first run of a memory-intensive agent. To mitigate this, blocks can be allocated before a run by using this command.</p> <p>Issuing the command with no parameters lists current pool usage, exactly like stats command's memory flag.</p> <p>Issuing the command with part of a pool's name and a positive integer will allocate that many additional blocks for the specified pool. Only the first few letters of the pool's name are necessary. If more than one pool starts with the given letters, which pool will be chosen is unspecified.</p> <p>Memory pool block size in this context is approximately 32 kilobytes, the exact size determined during agent initialization.</p>"},{"location":"reference/cli/cmd_debug/#debug-internal-symbols","title":"debug internal-symbols","text":"<p>The <code>internal-symbols</code> command prints information about the Soar symbol table. Such information is typically only useful for users attempting to debug Soar by locating memory leaks or examining I/O structure.</p>"},{"location":"reference/cli/cmd_debug/#debug-port","title":"debug port","text":"<p>The <code>port</code> command prints the port the kernel instance is listening on.</p>"},{"location":"reference/cli/cmd_debug/#debug-time","title":"debug time","text":"<pre><code>debug time command [arguments]\n</code></pre> <p>The <code>time</code> command uses a system clock timer to record the time spent while executing a command.  The most common use for this is to time how long an agent takes to run.</p>"},{"location":"reference/cli/cmd_debug/#see-also","title":"See Also","text":"<p>stats</p>"},{"location":"reference/cli/cmd_decide/","title":"decide","text":""},{"location":"reference/cli/cmd_decide/#decide","title":"decide","text":"<p>Commands and settings related to the selection of operators during the Soar decision process</p>"},{"location":"reference/cli/cmd_decide/#synopsis","title":"Synopsis","text":"<pre><code>=============================================================================\n-                      Decide Sub-Commands and Options                      -\n=============================================================================\ndecide                          [? | help]\n-----------------------------------------------------------------------------\ndecide numeric-indifferent-mode [--avg --sum]\n-----------------------------------------------------------------------------\ndecide indifferent-selection\ndecide indifferent-selection   &lt;policy&gt;\n                               &lt;policy&gt; = [--boltzmann | --epsilon-greedy |\n                                           --first | --last | -- softmax ]\ndecide indifferent-selection   &lt;param&gt; [value]\n                               &lt;param&gt; = [--epsilon --temperature]\ndecide indifferent-selection   [--reduction-policy| -p] &lt;param&gt; [&lt;policy&gt;]\ndecide indifferent-selection   [--reduction-rate| -r] &lt;param&gt; &lt;policy&gt; [&lt;rate&gt;]\ndecide indifferent-selection   [--auto-reduce] [setting]\ndecide indifferent-selection   [--stats]\n----------------------------------------------------------------------------\ndecide predict\ndecide select                  &lt;operator ID&gt;\n-----------------------------------------------------------------------------\ndecide set-random-seed         [&lt;seed&gt;] \n-----------------------------------------------------------------------------\nFor a detailed explanation of sub-commands:    help decide\n</code></pre>"},{"location":"reference/cli/cmd_decide/#summary-screen","title":"Summary Screen","text":"<p>Using the <code>decide</code> command without any arguments will display key elements of Soar's current decision settings: <pre><code>=======================================================\n                     Decide Summary\n=======================================================\nNumeric indifference mode:                          sum\n-------------------------------------------------------\nExploration Policy:                             softmax\nAutomatic Policy Parameter Reduction:               off\nEpsilon:                                       0.100000\nEpsilon Reduction Policy:                   exponential\nTemperature:                                  25.000000\nTemperature Reduction Policy:               exponential\n-------------------------------------------------------\n\nUse 'decide ?' for a command overview or 'help decide' for the manual page.\n</code></pre></p>"},{"location":"reference/cli/cmd_decide/#decide-numeric-indifferent-mode","title":"decide numeric-indifferent-mode","text":"<p>The <code>numeric-indifferent-mode</code> command sets how multiple numeric indifferent preference values given to an operator are combined into a single value for use in random selection.</p> <p>The default procedure is <code>--sum</code> which sums all numeric indifferent preference values given to the operator, defaulting to 0 if none exist.  The alternative <code>--avg</code> mode will average the values, also defaulting to 0 if none exist.</p>"},{"location":"reference/cli/cmd_decide/#decide-indifferent-selection","title":"decide indifferent-selection","text":"<p>The <code>indifferent-selection</code> command allows the user to set options relating to selection between operator proposals that are mutually indifferent in preference memory.</p> <p>The primary option is the exploration policy (each is covered below). When Soar starts, softmax is the default policy.</p> <p>Note:  As of version 9.3.2, the architecture no longer automatically changes the policy to epsilon-greedy the first time Soar-RL is enabled.</p> <p>Some policies have parameters to temper behavior. The indifferent-selection command provides basic facilities to automatically reduce these parameters exponentially and linearly each decision cycle by a fixed rate. In addition to setting these policies/rates, the auto-reduce option enables the automatic reduction system (disabled by default), for which the Soar decision cycle incurs a small performance cost.</p>"},{"location":"reference/cli/cmd_decide/#indifferent-selection-options","title":"indifferent-selection options:","text":"Option Description <code>-s, --stats</code> Summary of settings <code>policy</code> Set exploration policy <code>parameter [exploration policy parameters]</code> Get/Set exploration policy parameters (if value not given, returns the current value) <code>parameter [reduction_policy](value]</code> Get/Set exploration policy parameter reduction policy (if policy not given, returns the current) <code>parameter reduction_policy [exploration policy parameter]</code> Get/Set exploration policy parameter reduction rate for a policy (if rate not give, returns the current) <code>-a, --auto-reduce [on,off](reduction-rate]</code> Get/Set auto-reduction setting (if setting not provided, returns the current)"},{"location":"reference/cli/cmd_decide/#indifferent-selection-exploration-policies","title":"indifferent-selection exploration policies:","text":"Option Description <code>-b, --boltzmann</code> Tempered softmax (uses temperature) <code>-g, --epsilon-greedy</code> Tempered greedy (uses epsilon) <code>-x, --softmax</code> Random, biased by numeric indifferent values (if a non-positive value is encountered, resorts to a uniform random selection) <code>-f, --first</code> Deterministic, first indifferent preference is selected <code>-l, --last</code> Deterministic, last indifferent preference is selected"},{"location":"reference/cli/cmd_decide/#indifferent-selection-exploration-policy-parameters","title":"indifferent-selection exploration policy parameters:","text":"Parameter Name Acceptable Values Default Value <code>-e, --epsilon</code> <code>[0, 1]</code> <code>0.1</code> <code>-t, --temperature</code> <code>(0, inf)</code> <code>25</code>"},{"location":"reference/cli/cmd_decide/#indifferent-selection-auto-reduction-policies","title":"indifferent-selection auto-reduction policies:","text":"Parameter Name Acceptable Values Default Value <code>exponential default</code> <code>[0, 1]</code> <code>1</code> <code>linear</code> <code>[0, inf]</code> <code>0</code>"},{"location":"reference/cli/cmd_decide/#decide-predict","title":"decide predict","text":"<p>The predict command determines, based upon current operator proposals, which operator will be chosen during the next decision phase. If predict determines an operator tie will be encountered, \"tie\" is returned. If predict determines no operator will be selected (state no-change), \"none\" is returned. If predict determines a conflict will arise during the decision phase, \"conflict\" is returned. If predict determines a constraint failure will occur, \"constraint\" is returned. Otherwise, predict will return the id of the operator to be chosen. If operator selection will require probabilistic selection, and no alterations to the probabilities are made between the call to predict and decision phase, predict will manipulate the random number generator to enforce its prediction.</p>"},{"location":"reference/cli/cmd_decide/#decide-select","title":"decide select","text":"<p>The select command will force the selection of an operator, whose id is supplied as an argument, during the next decision phase. If the argument is not a proposed operator in the next decision phase, an error is raised and operator selection proceeds as if the select command had not been called. Otherwise, the supplied operator will be selected as the next operator, regardless of preferences. If select is called with no id argument, the command returns the operator id currently forced for selection (by a previous call to select), if one exists.</p>"},{"location":"reference/cli/cmd_decide/#example","title":"Example","text":"<p>Assuming operator \"O2\" is a valid operator, this would select it as the next operator to be selected:</p> <pre><code>decide select O2\n</code></pre>"},{"location":"reference/cli/cmd_decide/#decide-set-random-seed","title":"decide set-random-seed","text":"<p>Seeds the random number generator with the passed seed. Calling <code>decide set-random-seed</code> (or equivalently, <code>decide srand</code>) without providing a seed will seed the generator based on the contents of /dev/urandom (if available) or else based on time() and clock() values.</p>"},{"location":"reference/cli/cmd_decide/#example_1","title":"Example","text":"<pre><code>decide set-random-seed 23\n</code></pre>"},{"location":"reference/cli/cmd_decide/#default-aliases","title":"Default Aliases","text":"<pre><code>inds           indifferent-selection\nsrand          set-random-seed\n</code></pre>"},{"location":"reference/cli/cmd_decide/#see-also","title":"See Also","text":"<p>rl</p>"},{"location":"reference/cli/cmd_echo/","title":"echo","text":""},{"location":"reference/cli/cmd_echo/#echo","title":"echo","text":"<p>Print a string to the current output device.</p>"},{"location":"reference/cli/cmd_echo/#synopsis","title":"Synopsis","text":"<pre><code>echo [--nonewline] [string]\n</code></pre>"},{"location":"reference/cli/cmd_echo/#options","title":"Options","text":"Option Description <code>string</code> The string to print. <code>-n, --nonewline</code> Supress printing of the newline character"},{"location":"reference/cli/cmd_echo/#description","title":"Description","text":"<p>This command echos the args to the current output stream. This is normally stdout but can be set to a variety of channels. If an arg is <code>--nonewline</code> then no newline is printed at the end of the printed strings. Otherwise a newline is printed after printing all the given args. Echo is the easiest way to add user comments or identification strings in a log file.</p>"},{"location":"reference/cli/cmd_echo/#example","title":"Example","text":"<p>This example will add these comments to the screen and any open log file.</p> <pre><code>echo This is the first run with disks = 12\n</code></pre>"},{"location":"reference/cli/cmd_echo/#see-also","title":"See Also","text":"<p>clog</p>"},{"location":"reference/cli/cmd_epmem/","title":"epmem","text":""},{"location":"reference/cli/cmd_epmem/#epmem","title":"epmem","text":"<p>Control the behavior of episodic memory.</p>"},{"location":"reference/cli/cmd_epmem/#synopsis","title":"Synopsis","text":"<pre><code>epmem\nepmem -e|--enable|--on\nepmem -d|--disable|--off\nepmem -i|--init\nepmem -c|--close\nepmem -g|--get &lt;parameter&gt;\nepmem -s|--set &lt;parameter&gt; &lt;value&gt;\nepmem -S|--stats [&lt;statistic&gt;]\nepmem -t|--timers [&lt;timer&gt;]\nepmem -v|--viz &lt;episode id&gt;\nepmem -p|--print &lt;episode id&gt;\nepmem -b|--backup &lt;file name&gt;\n</code></pre>"},{"location":"reference/cli/cmd_epmem/#options","title":"Options:","text":"Option Description <code>-e, --enable, --on</code> Enable episodic memory. <code>-d, --disable, --off</code> Disable episodic memory. <code>-i, --init</code> Re-initialize episodic memory <code>-c, --close</code> Disconnect from episodic memory <code>-g, --get</code> Print current parameter setting <code>-s, --set</code> Set parameter value <code>-S, --stats</code> Print statistic summary or specific statistic <code>-t, --timers</code> Print timer summary or specific statistic <code>-v, --viz</code> Print episode in graphviz format <code>-p, --print</code> Print episode in user-readable format <code>-b, --backup</code> Creates a backup of the episodic database on disk"},{"location":"reference/cli/cmd_epmem/#description","title":"Description","text":"<p>The <code>epmem</code> command is used to change all behaviors of the episodic memory module, except for watch output, which is controlled by the <code>trace --epmem</code> command.</p>"},{"location":"reference/cli/cmd_epmem/#parameters","title":"Parameters","text":"<p>Due to the large number of parameters, the <code>epmem</code> command uses the  <code>--get|--set &lt;parameter&gt; &lt;value&gt;</code> convention rather than individual switches for each parameter.  Running <code>epmem</code> without any switches displays a summary of the parameter settings.</p>"},{"location":"reference/cli/cmd_epmem/#main-parameters","title":"Main Parameters:","text":"Parameter Description Possible values Default <code>append</code> Controls whether database is overwritten or appended when opening or re-initializing <code>on</code>, <code>off</code> <code>off</code> <code>balance</code> Linear weight of match cardinality (1) vs. working memory activation (0) used in calculating match score <code>[</code>0, 1<code>]</code> 1 <code>database</code> Database storage method <code>file</code>, <code>memory</code> <code>memory</code> <code>exclusions</code> Toggle the exclusion of an attribute string constant any string <code>epmem, smem</code> <code>force</code> Forces episode encoding/ignoring in the next storage phase <code>ignore</code>, <code>remember</code>, <code>off</code> <code>off</code> <code>learning</code> Episodic memory enabled <code>on</code>, <code>off</code> <code>off</code> <code>merge</code> Controls how retrievals interact with long-term identifiers in working memory <code>none</code>, <code>add</code> <code>none</code> <code>path</code> Location of database file empty, some path empty <code>phase</code> Decision cycle phase to encode new episodes and process epmem link commands <code>output</code>, <code>selection</code> <code>output</code> <code>trigger</code> How episode encoding is triggered <code>dc</code>, <code>output</code>, <code>none</code> <code>output</code>"},{"location":"reference/cli/cmd_epmem/#performance-parameters","title":"Performance Parameters:","text":"Parameter Description Possible values Default <code>cache-size</code> Number of memory pages used in the SQLite cache 1, 2, ... 10000 <code>graph-match</code> Graph matching enabled <code>on</code>, <code>off</code> <code>on</code> <code>graph-match-ordering</code> Ordering of identifiers during graph match <code>undefined</code>, <code>dfs</code>, <code>mcv</code> <code>undefined</code> <code>lazy-commit</code> Delay writing semantic store changes to file until agent exits <code>on</code>, <code>off</code> <code>on</code> <code>optimization</code> Policy for committing data to disk <code>safety</code>, <code>performance</code> <code>performance</code> <code>page-size</code> Size of each memory page used in the SQLite cache 1k, 2k, 4k, 8k, 16k, 32k, 64k 8k <code>timers</code> Timer granularity <code>off</code>, <code>one</code>, <code>two</code>, <code>three</code> <code>off</code> <p>The <code>learning</code> parameter turns the episodic memory module on or off. When <code>learning</code> is set to <code>off</code>, no new episodes are encoded and no commands put on the epmem link are processed.  This is the same as using the enable and disable commands.</p> <p>The <code>phase</code> parameter determines which decision cycle phase episode encoding and retrieval will be performed.</p> <p>The <code>trigger</code> parameter controls when new episodes will be encoded.  When it is set to <code>output</code>, new episodes will be encoded only if the agent made modifications to the output-link during that decision cycle.  When set to 'dc', new episodes will be encoded every decision cycle.</p> <p>The <code>exclusions</code> parameter can be used to prevent episodic memory from encoding parts of working memory into new episodes.  The value of <code>exclusions</code> is a list of string constants.  During encoding, episodic memory will walk working memory starting from the top state identifier.  If it encounters a WME whose attribute is a member of the <code>exclusions</code> list, episodic memory will ignore that WME and abort walking the children of that WME, and they will not be included in the encoded episode.  Note that if the children of the excluded WME can be reached from top state via an alternative non-excluded path, they will still be included in the encoded episode.  The <code>exclusions</code> parameter behaves differently from other parameters in that issuing <code>epmem --set exclusions &lt;val&gt;</code> does not set its value to <code>&lt;val&gt;</code>. Instead, it will toggle the membership of <code>&lt;val&gt;</code> in the <code>exclusions</code> list.</p> <p>The <code>path</code> parameter specifies the file system path the database is stored in.  When <code>path</code> is set to a valid file system path and database mode is set to file, then the SQLite database is written to that path.</p> <p>The append parameter will determine whether all existing episodes recorded in a database on disk will be erased when epmem loads it. Note that this affects episodic memory re-initialization also, i.e. if the append setting is off, all episodic memories stored to disk will be lost when an init-soar is performed. Note that episodic memory cannot currently append to an in-memory database.  If you perform an init-soar while using an in-memory database, all current episodes stored will be cleared.</p> <p>Note that changes to database, path and append will not have an effect until the database is used after an initialization. This happens either shortly after launch (on first use) or after a database initialization command is issued.  To switch databases or database storage types after running, set your new parameters and then perform an <code>epmem --init</code>.</p> <p>The <code>epmem --backup</code> command can be used to make a copy of the current state of the database, whether in memory or on disk. This command will commit all outstanding changes before initiating the copy.</p> <p>When the database is stored to disk, the <code>lazy-commit</code> and <code>optimization</code> parameters control how often cached database changes are written to disk.  These parameters trade off safety in the case of a program crash with database performance.  When <code>optimization</code> is set to <code>performance</code>, the agent will have an exclusive lock on the database, meaning it cannot be opened concurrently by another SQLite process such as SQLiteMan. The lock can be relinquished by setting the database to memory or another database and issuing init-soar/<code>epmem --init</code> or by shutting down the Soar kernel.</p> <p>The <code>balance</code> parameter sets the linear weight of match cardinality vs. cue activation. As a performance optimization, when the value is 1 (default), activation is not computed. If this value is not 1 (even close, such as 0.99), and working memory activation is enabled, this value will be computed for each leaf WME, which may incur a noticeable cost, depending upon the overall complexity of the retrieval.</p> <p>The <code>graph-match-ordering</code> parameter sets the heuristic by which identifiers are ordered during graph match (assuming <code>graph-match</code> is <code>on</code>). The default, <code>undefined</code>, does not enforce any order and may be sufficient for small cues. For more complex cues, there will be a one-time sorting cost, during each retrieval, if the parameter value is changed. The currently available heuristics are depth-first search (<code>dfs</code>) and most-constrained variable (<code>mcv</code>). It is advised that you attempt these heuristics to improve performance if the <code>query_graph_match</code> timer reveals that graph matching is dominating retrieval time.</p> <p>The <code>merge</code> parameter controls how the augmentations of retrieved long-term identifiers (LTIs) interact with an existing LTI in working memory. If the LTI is not in working memory or has no augmentations in working memory, this parameter has no effect. If the augmentation is in working memory and has augmentations, by default (<code>none</code>), episodic memory will not augment the LTI. If the parameter is set to <code>add</code> then any augmentations that augmented the LTI in a retrieved episode are added to working memory.</p>"},{"location":"reference/cli/cmd_epmem/#statistics","title":"Statistics","text":"<p>Episodic memory tracks statistics over the lifetime of the agent. These can be accessed using <code>epmem --stats &lt;statistic&gt;</code>.  Running <code>epmem --stats</code> without a statistic will list the values of all statistics.  Unlike timers, statistics will always be updated.  Available statistics are:</p> Name Label Description <code>time</code> Time Current episode ID <code>db-lib-version</code> SQLite Version SQLite library version <code>mem-usage</code> Memory Usage Current SQLite memory usage in bytes <code>mem-high</code> Memory Highwater High SQLite memory usage watermark in bytes <code>queries</code> Queries Number of times the query command has been processed <code>nexts</code> Nexts Number of times the next command has been processed <code>prevs</code> Prevs Number of times the previous command has been processed <code>ncb-wmes</code> Last Retrieval WMEs Number of WMEs added to working memory in last reconstruction <code>qry-pos</code> Last Query Positive Number of leaf WMEs in the query cue of last cue-based retrieval <code>qry-neg</code> Last Query Negative Number of leaf WMEs in the neg-query cue of the last cue-based retrieval <code>qry-ret</code> Last Query Retrieved Episode ID of last retrieval <code>qry-card</code> Last Query Cardinality Match cardinality of last cue-based retrieval <code>qry-lits</code> Last Query Literals Number of literals in the DNF graph of last cue-based retrieval"},{"location":"reference/cli/cmd_epmem/#timers","title":"Timers","text":"<p>Episodic memory also has a set of internal timers that record the durations of certain operations.  Because fine-grained timing can incur runtime costs, episodic memory timers are off by default. Timers of different levels of detail can be turned on by issuing <code>epmem --set timers &lt;level&gt;</code>, where the levels can be <code>off</code>, <code>one</code>, <code>two</code>, or <code>three</code>, <code>three</code> being most detailed and resulting in all timers being turned on.  Note that none of the episodic memory statistics nor timing information is reported by the <code>stats</code> command.</p> <p>All timer values are reported in seconds.</p> <p>Level one</p> Timer Description <code>_total</code> Total epmem operations <p>Level two</p> Timer Description <code>epmem_api</code> Agent command validation <code>epmem_hash</code> Hashing symbols <code>epmem_init</code> Episodic store initialization <code>epmem_ncb_retrieval</code> Episode reconstruction <code>epmem_next</code> Determining next episode <code>epmem_prev</code> Determining previous episode <code>epmem_query</code> Cue-based query <code>epmem_storage</code> Encoding new episodes <code>epmem_trigger</code> Deciding whether new episodes should be encoded <code>epmem_wm_phase</code> Converting preference assertions to working memory changes <p>Level three</p> Timer Description <code>ncb_edge</code> Collecting edges during reconstruction <code>ncb_edge_rit</code> Collecting edges from relational interval tree <code>ncb_node</code> Collecting nodes during reconstruction <code>ncb_node_rit</code> Collecting nodes from relational interval tree <code>query_cleanup</code> Deleting dynamic data structures <code>query_dnf</code> Building the first level of the DNF <code>query_graph_match</code> Graph match <code>query_result</code> Putting the episode in working memory <code>query_sql_edge</code> SQL query for an edge <code>query_sql_end_ep</code> SQL query for the end of the range of an edge <code>query_sql_end_now</code> SQL query for the end of the now of an edge <code>query_sql_end_point</code> SQL query for the end of the point of an edge <code>query_sql_start_ep</code> SQL query for the start of the range of an edge <code>query_sql_start_now</code> SQL query for the start of the now of an edge <code>query_sql_start_point</code> SQL query for the start of the point of an edge <code>query_walk</code> Walking the intervals <code>query_walk_edge</code> Expanding edges while walking the intervals <code>query_walk_interval</code> Updating satisfaction while walking the intervals"},{"location":"reference/cli/cmd_epmem/#visualization","title":"Visualization","text":"<p>When debugging agents using episodic memory it is often useful to inspect the contents of individual episodes.  Running <code>epmem --viz &lt;episode id&gt;</code> will output the contents of an episode in graphviz format.  For more information on this format and visualization tools, see http://www.graphviz.org. The <code>epmem --print</code> option has the same syntax, but outputs text that is similar to using the <code>print</code> command to get the substructure of an identifier in working memory, which is possibly more useful for interactive debugging.</p>"},{"location":"reference/cli/cmd_epmem/#see-also","title":"See Also","text":"<p>trace wm</p>"},{"location":"reference/cli/cmd_explain/","title":"explain","text":""},{"location":"reference/cli/cmd_explain/#explain","title":"explain","text":"<p>Allows you to explore how rules were learned.</p>"},{"location":"reference/cli/cmd_explain/#synopsis","title":"Synopsis","text":"<pre><code>======= Explainer Commands and Settings =======\nexplain ?                                             Print this help listing\n---------------- What to Record ---------------\nall                                    [ on | OFF ]   Record all rules learned\njustifications                         [ on | OFF ]   Record justifications\nrecord &lt;chunk-name&gt;                                   Record specific rule\nlist-chunks                                           List all rules learned\nlist-justifications                                   List all justifications\n----------- Starting an Explanation -----------\nchunk [&lt;chunk name&gt; | &lt;chunk id&gt; ]                    Start discussing chunk\nformation                                             Describe formation\n----------- Browsing an Explanation -----------\ninstantiation &lt;inst id&gt;                               Explain instantiation\nexplanation-trace                                     Switch explanation trace\nwm-trace                                              Switch to WM trace\n------------ Supporting Analysis --------------\nconstraints                                           Display extra transitive \n                                                       constraints required by \n                                                       problem-solving\nidentity                                              Display identity to \n                                                       identity set mappings\nstats                                                 Display statistics about \n                                                       currently discussed chunk\n------------------ Settings -------------------\nafter-action-report                    [ on | OFF ]   Print statistics to file \n                                                       on init and exit\nonly-chunk-identities                  [ ON | off ]   Identity analysis only \n                                                       prints identities sets \n                                                       found in chunk\n-----------------------------------------------\n\nTo change a setting:                               explain &lt;setting&gt; [&lt;value&gt;]\nFor a detailed explanation of these settings:      help explain\n</code></pre>"},{"location":"reference/cli/cmd_explain/#summary-screen","title":"Summary Screen","text":"<p>Using the <code>explain</code> command without any arguments will display a summary of which rule firings the explainer is watching for learning.  It also shows which chunk or justification the user has specified is the current focus of its output, i.e. the chunk being discussed.</p> <p>Tip:  This is a good way to get a chunk id so that you don't have to type or paste in a chunk name.</p> <pre><code>=======================================================\n                   Explainer Summary\n=======================================================\nWatch all chunk formations                            Yes\nExplain justifications                                No\nNumber of specific rules watched                      0\n\nChunks available for discussion:                      chunkx2*apply2 (c 14)\n                                                      chunk*apply*o (c 13)\n                                                      chunkx2*apply2 (c 12)\n                                                      chunk*apply*d (c 11)\n                                                      chunkx2*apply2 (c 6)\n                                                      chunk*apply* (c 15)\n                                                      chunkx2*apply (c 8)\n                                                      chunk*apply*c (c 5)\n                                                      chunkx2*apply (c 10)\n                                                      chunk*apply (c 1)\n\n* Note:  Printed the first 10 chunks. 'explain list' to see other 6 chunks.\n\nCurrent chunk being discussed:                        chunk*apply*down-gripper(c 3)\n\nUse 'explain chunk [ &lt;chunk-name&gt; | id ]' to discuss the formation of that chunk.\nUse 'explain ?' to learn more about explain's sub-command and settings.\n</code></pre>"},{"location":"reference/cli/cmd_explain/#explain-chunk","title":"explain chunk","text":"<p>This starts the process.</p> <p>Tip:  Use <code>c</code>, which is an alias to <code>explain chunk</code>, to quickly start discussing a chunk, for example:</p> <pre><code>soar % c 3\nNow explaining chunk*apply*move-gripper-above*pass*top-state*OpNoChange*t6-1.\n- Note that future explain commands are now relative\n  to the problem-solving that led to that chunk.\n\nExplanation Trace                                     Using variable identity IDs                  Shortest Path to Result Instantiation\n\nsp {chunk*apply*move-gripper-above*pass*top-state*OpNoChange*t6-1\n1:    (&lt;s1&gt; ^top-state &lt;s2&gt;)                          ([140] ^top-state [162])\n     -{\n2:    (&lt;s1&gt; ^operator &lt;o*1&gt;)                          ([140] ^operator [141])\n3:    (&lt;o*1&gt; ^name evaluate-operator)                 ([141] ^name evaluate-operator)\n     }\n4:    (&lt;s2&gt; ^gripper &lt;g1&gt;)                            ([162] ^gripper [156])                       i 30 -&gt; i 31\n5:    (&lt;g1&gt; ^position up)                             ([156] ^position up)                         i 30 -&gt; i 31\n6:    (&lt;g1&gt; ^holding nothing)                         ([156] ^holding nothing)                     i 30 -&gt; i 31\n7:    (&lt;g1&gt; ^above &lt;t1&gt;)                              ([156] ^above [157])                         i 30 -&gt; i 31\n8:    (&lt;s2&gt; ^io &lt;i2&gt;)                                 ([162] ^io [163])                            i 31\n9:    (&lt;i2&gt; ^output-link &lt;i1&gt;)                        ([163] ^output-link [164])                   i 31\n10:   (&lt;i1&gt; ^gripper &lt;g2&gt;)                            ([164] ^gripper [165])                       i 31\n11:   (&lt;s2&gt; ^clear { &lt;&gt; &lt;t1&gt; &lt;b1&gt; })                  ([162] ^clear { &lt;&gt;[161]  [161] })            i 30 -&gt; i 31\n12:   (&lt;s1&gt; ^operator &lt;o1&gt;)                           ([140] ^operator [149])\n13:   (&lt;o1&gt; ^moving-block &lt;b1&gt;)                       ([149] ^moving-block [161])\n14:   (&lt;o1&gt; ^name pick-up)                            ([149] ^name pick-up)\n      --&gt;\n1:    (&lt;g2&gt; ^command move-gripper-above +)            ([165] ^command move-gripper-above +)\n2:    (&lt;g2&gt; ^destination &lt;c1&gt; +)                      ([165] ^destination [161] +)\n}\n</code></pre>"},{"location":"reference/cli/cmd_explain/#explain-formation","title":"explain formation","text":"<p><code>explain formation</code> provides an explanation of the initial rule that fired which created a result. This is what is called the 'base instantiation' and is what led to the chunk being learned. Other rules may also be base instantiations if they previously created children of the base instantiation's results. They also will be listed in the initial formation output.</p> <p><pre><code>soar % explain formation\n------------------------------------------------------------------------------------\nThe formation of chunk 'chunk*apply*move-gripper-above*pass*top-state*OpNoChange*t6-1' (c 1)\n------------------------------------------------------------------------------------\n\nInitial base instantiation (i 31) that fired when apply*move-gripper-above*pass*top-state matched at level 3 at time 6:\n\nExplanation trace of instantiation # 31            (match of rule apply*move-gripper-above*pass*top-state at level 3)\n (produced chunk result)\n                                                   Identities instead of variables       Operational    Creator\n\n1:    (&lt;s&gt; ^operator &lt;op&gt;)                         ([159] ^operator [160])                   No         i 30 (pick-up*propose*move-gripper-above)\n2:    (&lt;op&gt; ^name move-gripper-above)              ([160] ^name move-gripper-above)          No         i 30 (pick-up*propose*move-gripper-above)\n3:    (&lt;op&gt; ^destination &lt;des&gt;)                    ([160] ^destination [161])                No         i 30 (pick-up*propose*move-gripper-above)\n4:    (&lt;s&gt; ^top-state &lt;t*1&gt;)                       ([159] ^top-state [162])                  No         i 27 (elaborate*state*top-state)\n5:    (&lt;t*1&gt; ^io &lt;i*1&gt;)                            ([162] ^io [163])                         Yes        Higher-level Problem Space\n6:    (&lt;i*1&gt; ^output-link &lt;o*1&gt;)                   ([163] ^output-link [164])                Yes        Higher-level Problem Space\n7:    (&lt;o*1&gt; ^gripper &lt;gripper&gt;)                   ([164] ^gripper [165])                    Yes        Higher-level Problem Space\n   --&gt;\n1:    (&lt;gripper&gt; ^command move-gripper-above +)    ([165] ^command move-gripper-above +)\n2:    (&lt;gripper&gt; ^destination &lt;des&gt; +)             ([165] ^destination [161] +)\n------\n</code></pre> This chunk summarizes the problem-solving involved in the following 5 rule firings: <pre><code>   i 27 (elaborate*state*top-state)\n   i 28 (elaborate*state*operator*name)\n   i 29 (pick-up*elaborate*desired)\n   i 30 (pick-up*propose*move-gripper-above)\n   i 31 (apply*move-gripper-above*pass*top-state)\n</code></pre></p>"},{"location":"reference/cli/cmd_explain/#explain-instantiation","title":"explain instantiation","text":"<p>This is probably one of the most common things you will do while using the explainer.  You are essentially browsing the instantiation graph one rule at a time.</p> <p>Tip:  Use <code>i</code>, which is an alias to <code>explain instantiation</code>, to quickly view an instantiation, for example:</p> <pre><code>soar % i 30\nExplanation trace of instantiation # 30            (match of rule pick-up*propose*move-gripper-above at level 3)\n- Shortest path to a result: i 30 -&gt; i 31\n                                                   Identities instead of variables       Operational    Creator\n\n1:    (&lt;s&gt; ^name pick-up)                          ([152] ^name pick-up)                     No         i 28 (elaborate*state*operator*name)\n2:    (&lt;s&gt; ^desired &lt;d*1&gt;)                         ([152] ^desired [153])                    No         i 29 (pick-up*elaborate*desired)\n3:    (&lt;d*1&gt; ^moving-block &lt;mblock&gt;)               ([153] ^moving-block [154])               No         i 29 (pick-up*elaborate*desired)\n4:    (&lt;s&gt; ^top-state &lt;ts&gt;)                        ([152] ^top-state [155])                  No         i 27 (elaborate*state*top-state)\n5:    (&lt;ts&gt; ^clear &lt;mblock&gt;)                       ([155] ^clear [154])                      Yes        Higher-level Problem Space\n6:    (&lt;ts&gt; ^gripper &lt;g&gt;)                          ([155] ^gripper [156])                    Yes        Higher-level Problem Space\n7:    (&lt;g&gt; ^position up)                           ([156] ^position up)                      Yes        Higher-level Problem Space\n8:    (&lt;g&gt; ^holding nothing)                       ([156] ^holding nothing)                  Yes        Higher-level Problem Space\n9:    (&lt;g&gt; ^above { &lt;&gt; &lt;mblock&gt; &lt;a*1&gt; })           ([156] ^above { &lt;&gt;[154]  [157] })         Yes        Higher-level Problem Space\n   --&gt;\n1:    (&lt;s&gt; ^operator &lt;op1&gt; +)                      ([152] ^operator [158] +)\n2:    (&lt;op1&gt; ^name move-gripper-above +)           ([158] ^name move-gripper-above +)\n3:    (&lt;op1&gt; ^destination &lt;mblock&gt; +)              ([158] ^destination [154] +)\n</code></pre>"},{"location":"reference/cli/cmd_explain/#explain-explanation-trace-and-wm-trace","title":"explain explanation-trace and wm-trace","text":"<p>In most cases, users spend most of their time browsing the explanation trace. This is where chunking learns most of the subtle relationships that you are likely to be debugging. But users will also need to examine the working memory trace to see the specific values matched.  </p> <p>To switch between traces, you can use the <code>explain e</code> and the <code>explain w</code> commands.</p> <p>Tip:  Use <code>et</code> and 'wt', which are aliases to the above two commands, to quickly switch between traces.</p> <pre><code>soar % explain w\nWorking memory trace of instantiation # 30     (match of rule pick-up*propose*move-gripper-above at level 3)\n1:    (S9 ^name pick-up)                               No         i 28 (elaborate*state*operator*name)\n2:    (S9 ^desired D6)                                 No         i 29 (pick-up*elaborate*desired)\n3:    (D6 ^moving-block B3)                            No         i 29 (pick-up*elaborate*desired)\n4:    (S9 ^top-state S1)                               No         i 27 (elaborate*state*top-state)\n5:    (S1 ^clear B3)                                   Yes        Higher-level Problem Space\n6:    (S1 ^gripper G2)                                 Yes        Higher-level Problem Space\n7:    (G2 ^position up)                                Yes        Higher-level Problem Space\n8:    (G2 ^holding nothing)                            Yes        Higher-level Problem Space\n9:    (G2 ^above { &lt;&gt; B3 T1 })                         Yes        Higher-level Problem Space\n   --&gt;\n1:    (S9 ^operator O9) +\n2:    (O9 ^name move-gripper-above) +\n3:    (O9 ^destination B3) +\n</code></pre>"},{"location":"reference/cli/cmd_explain/#explain-constraints","title":"explain constraints","text":"<p>This feature explains any constraints on the value of variables in the chunk that were required by the problem-solving that occurred in the substate. If these constraints were not met, the problem-solving would not have occurred.</p> <p>Explanation-based chunking tracks constraints as they apply to identity sets rather than how they apply to specific variables or identifiers.  This means that sometimes constraints that appear in a chunk may have been a result of conditions that tested sub-state working memory element. Such conditions don't result in actual conditions in the chunk, but they can provide constraints. <code>explain constraints</code> allows users to see where such constraints came from.</p> <p>This feature is not yet implemented. You can use <code>explain stats</code> to see if any transitive constraints were added to a particular chunk.</p>"},{"location":"reference/cli/cmd_explain/#explain-identity","title":"explain identity","text":"<p><code>explain identity</code> will show the mappings from variable identities to identity sets. If available, the variable in a chunk that an identity set maps to will also be displayed. (Requires a debug build because of efficiency cost.)</p> <p>Variable identities are the ID values that are displayed when explaining an individual chunk or instantiation. An identity set is a set of variable identities that were unified to a particular variable mapping. The null identity set indicates identities that should not be generalized, i.e. they retain their matched literal value even if the explanation trace indicates that the original rule had a variable in that element.</p> <p>By default, only identity sets that appear in the chunk will be displayed in the identity analysis. To see the identity set mappings for other sets, change the <code>only-chunk-identities</code> setting to <code>off</code>.</p> <pre><code>soar % explain identity\n=========================================================================\n-             Variablization Identity to Identity Set Mappings          -\n=========================================================================\n\n-== NULL Identity Set ==-\n\nThe following variable identities map to the null identity set and will\nnot be generalized: 282 301 138 291 355 336 227 309 328 318 128 218 345\n\n-== How variable identities map to identity sets ==-\n\nVariablization IDs      Identity     CVar    Mapping Type\n\nInstantiation 36:\n  125 -&gt; 482          | IdSet 12  | &lt;s&gt;       | New identity set\n  126 -&gt; 493          | IdSet 11  | &lt;o&gt;       | New identity set\nInstantiation 38:\nInstantiation 41:\n  146 -&gt; 482          | IdSet 12  | &lt;s&gt;       | New identity set\n  147 -&gt; 493          | IdSet 11  | &lt;o&gt;       | New identity set\nInstantiation 42:\n  151 -&gt; 180          | IdSet 1   | &lt;ss&gt;      | New identity set\n  149 -&gt; 482          | IdSet 12  | &lt;s&gt;       | New identity set\n  150 -&gt; 493          | IdSet 11  | &lt;o&gt;       | New identity set\n  307 -&gt; 180          | IdSet 1   | &lt;ss&gt;      | Added to identity set\n  187 -&gt; 180          | IdSet 1   | &lt;ss&gt;      | Added to identity set\n  334 -&gt; 180          | IdSet 1   | &lt;ss&gt;      | Added to identity set\n  173 -&gt; 180          | IdSet 1   | &lt;ss&gt;      | Added to identity set\n  280 -&gt; 180          | IdSet 1   | &lt;ss&gt;      | Added to identity set\nInstantiation 53:\n  219 -&gt; 489          | IdSet 15  | &lt;b&gt;       | New identity set\nInstantiation 61:\nInstantiation 65:\n  319 -&gt; 492          | IdSet 20  | &lt;t&gt;       | New identity set\n</code></pre>"},{"location":"reference/cli/cmd_explain/#explain-stats","title":"explain stats","text":"<p><code>explain stats</code> prints statistics about the chunk being discussed. <pre><code>===========================================================\nStatistics for 'chunk*apply*move-gripper-above*pass*top-state*OpNoChange*t6-1' (c 1):\n===========================================================\nNumber of conditions                                       14\nNumber of actions                                          2\nBase instantiation                                         i 31 (apply*move-gripper-above*pass*top-state)\n\n===========================================================\n                 Generality and Correctness\n===========================================================\n\nTested negation in local substate                          No\nLHS required repair                                        No\nRHS required repair                                        No\nWas unrepairable chunk                                     No\n\n===========================================================\n                      Work Performed\n===========================================================\nInstantiations backtraced through                          5\nInstantiations skipped                                     6\nConstraints collected                                      1\nConstraints attached                                       0\nDuplicates chunks later created                            0\nConditions merged                                          2\n</code></pre></p>"},{"location":"reference/cli/cmd_explain/#after-action-reports","title":"After-Action Reports","text":"<p>The explainer has an option to create text files that contain statistics about the rules learned by an agent during a particular run. When enabled, the explainer will write out a file with the statistics when either Soar exits or a <code>soar init</code> is executed.  This option is still considered experimental and in beta.</p>"},{"location":"reference/cli/cmd_explain/#visualizing-an-explanation","title":"Visualizing an Explanation","text":"<p>Soar's <code>visualize</code> command allows you to create images that represent processing that the explainer recorded.  There are two types of explainer-related visualizations.</p> <p>(1) The visualizer can create an image that shows the entire instantiation graph at once and how it contributed to the learned rule.  The graph includes arrows that show the dependencies between actions in one rule and conditions in others.  This image is one of the most effective ways to understand how a chunk was formed, especially for particularly complex chunks.  To use this feature, first choose a chunk for discussion.  You can then issue the <code>visualize</code> command with the appropriate settings.</p> <p>(2) The visualizer can also create an image that shows how identities were joined during identity analysis.  This can be useful in determining why two elements were assigned the same variable.</p>"},{"location":"reference/cli/cmd_explain/#default-aliases","title":"Default Aliases","text":"<pre><code>c    explain chunk\ni    explain instantiation\n\nef   explain formation\nei   explain identities\nes   explain stats\n\net   explain explanation-trace\nwt   explain wm-trace\n</code></pre>"},{"location":"reference/cli/cmd_explain/#see-also","title":"See Also","text":"<p>chunk visualize</p>"},{"location":"reference/cli/cmd_file_system/","title":"file_system","text":""},{"location":"reference/cli/cmd_file_system/#file-system","title":"File System","text":"<p>Soar can handle the following Unix-style file system navigation commands</p>"},{"location":"reference/cli/cmd_file_system/#pwd","title":"pwd","text":"<p>Print the current working directory.</p>"},{"location":"reference/cli/cmd_file_system/#ls","title":"ls","text":"<p>List the contents of the current working directory.</p>"},{"location":"reference/cli/cmd_file_system/#cd","title":"cd","text":"<p>Change the current working directory. If run with no arguments, returns to the directory that the command line interface was started in, often referred to as the home directory.</p>"},{"location":"reference/cli/cmd_file_system/#dirs","title":"dirs","text":"<p>This command lists the directory stack. Agents can move through a directory structure by pushing and popping directory names. The dirs command returns the stack.</p>"},{"location":"reference/cli/cmd_file_system/#pushd","title":"pushd","text":"<p>Push the directory on to the stack. Can be relative path name or a fully specified one.</p>"},{"location":"reference/cli/cmd_file_system/#popd","title":"popd","text":"<p>Pop the current working directory off the stack and change to the next directory on the stack. Can be relative pathname or a fully specified path.</p>"},{"location":"reference/cli/cmd_file_system/#default-aliases","title":"Default Aliases","text":"<pre><code>chdir        cd\ndir          ls\ntopd         pwd\n</code></pre>"},{"location":"reference/cli/cmd_gp/","title":"gp","text":""},{"location":"reference/cli/cmd_gp/#gp","title":"gp","text":"<p>Generate productions according to a specified pattern.</p>"},{"location":"reference/cli/cmd_gp/#synopsis","title":"Synopsis","text":"<pre><code>gp { production_body }\n</code></pre>"},{"location":"reference/cli/cmd_gp/#description","title":"Description","text":"<p>The gp command defines a pattern used to generate and source a set of Soar productions. <code>production_body</code> is a single argument that looks almost identical to a standard Soar rule that would be used with the sp command. Indeed, any syntax that is allowed in sp is also allowed in gp.</p> <p>Patterns in gp are specified with sets of whitespace-seprated values in square brackets. Every combination of values across all square-bracketed value lists will be generated. Values with whitespaces can be used if wrapped in pipes. Characters can also be escaped with a backslash (so string literals with embedded pipes and spaces outside of string literals are both possible).</p> <p>gp is primarily intended as an alternative to <code>:template</code> rules for reinforcement learning. <code>:template</code> rules generate new rules as patterns occur at run time. Unfortunately, this incurs a high run time cost. If all possible values are known in advance, then the rules can be generated using gp at source time, thus allowing code to run faster. gp is not appropriate when all possible values are not known or if the total number of possible rules is very large (and the system is likely to encounter only a small subset at run time). It is also possible to combine gp and <code>:template</code> (e.g., if some of the values are known and not others). This should reduce the run time cost of <code>:template</code>.</p> <p>There is nothing that actually restricts gp to being used for RL, although for non-RL rules, a disjunction list (using <code>&lt;&lt;</code> and <code>&gt;&gt;</code>) is better where it can be used. More esoteric uses may include multiple bracketed value lists inside a disjunction list, or even variables in bracketed value lists.</p> <p>Each rule generated by gp has <code>*integer</code> appended to its name (where <code>integer</code> is some incrementing number).</p>"},{"location":"reference/cli/cmd_gp/#examples","title":"Examples","text":"<p>Template version of rule:</p> <pre><code>sp {water-jug*fill\n   :template\n   (state &lt;s1&gt; ^name water-jug ^operator &lt;op&gt; +\n               ^jug &lt;j1&gt; &lt;j2&gt;)\n   (&lt;op&gt; ^name fill ^fill-jug.volume &lt;fvol&gt;)\n   (&lt;j1&gt; ^volume 3 ^contents &lt;c1&gt;)\n   (&lt;j2&gt; ^volume 5 ^contents &lt;c2&gt;)\n--&gt;\n   (&lt;s1&gt; ^operator &lt;op&gt; = 0)\n}\n</code></pre> <p><code>gp</code> version of rule (generates 144 rules):</p> <pre><code>gp {water-jug*fill\n   (state &lt;s1&gt; ^name water-jug ^operator &lt;op&gt; +\n               ^jug &lt;j1&gt; &lt;j2&gt;)\n   (&lt;op&gt; ^name fill ^fill-jug.volume [3 5])\n   (&lt;j1&gt; ^volume 3 ^contents [0 1 2 3])\n   (&lt;j2&gt; ^volume 5 ^contents [0 1 2 3 4 5])\n--&gt;\n   (&lt;s1&gt; ^operator &lt;op&gt; = 0)\n}\n</code></pre> <p>Esoteric example (generates 24 rules):</p> <pre><code>gp {strange-example\n   (state &lt;s1&gt; ^&lt;&lt; [att1 att2] [att3 att4] &gt;&gt; [ val |another val| |strange val\\|| ])\n--&gt;\n   (&lt;s1&gt; ^foo [bar &lt;bar&gt;])\n}\n</code></pre> <p>testgp.soar contains many more examples.</p>"},{"location":"reference/cli/cmd_gp/#see-also","title":"See Also","text":"<p>sp</p>"},{"location":"reference/cli/cmd_help/","title":"help","text":""},{"location":"reference/cli/cmd_help/#help","title":"help","text":"<p>Provide formatted usage information about Soar commands.</p>"},{"location":"reference/cli/cmd_help/#synopsis","title":"Synopsis","text":"<pre><code>help [command_name]\n</code></pre>"},{"location":"reference/cli/cmd_help/#default-aliases","title":"Default Aliases","text":"<ul> <li><code>?</code></li> <li><code>man</code></li> </ul>"},{"location":"reference/cli/cmd_help/#description","title":"Description","text":"<p>This command prints formatted help for the given command name. Issue alone to see what topics have help available.</p>"},{"location":"reference/cli/cmd_load/","title":"load","text":""},{"location":"reference/cli/cmd_load/#load","title":"load","text":"<p>Loads soar files, rete networks, saved percept streams and external libraries.</p>"},{"location":"reference/cli/cmd_load/#synopsis","title":"Synopsis","text":"<pre><code>============================================================\n-               Load Sub-Commands and Options              -\n============================================================\nload                            [? | help]\n------------------------------------------------------------\nload file                       [--all --disable] &lt;filename&gt;\nload file                       [--verbose]     ]\n------------------------------------------------------------\nload library                    &lt;filename&gt; &lt;args...&gt;\n------------------------------------------------------------\nload rete-network               --load &lt;filename&gt;\n------------------------------------------------------------\nload percepts                   --open &lt;filename&gt;\nload percepts                   --close\n------------------------------------------------------------\n</code></pre>"},{"location":"reference/cli/cmd_load/#load-file","title":"load file","text":"<p>Load and evaluate the contents of a file. The <code>filename</code> can be a relative path or a fully qualified path. The source will generate an implicit push to the new directory, execute the command, and then pop back to the current working directory from which the command was issued. This is traditionally known as the source command.</p>"},{"location":"reference/cli/cmd_load/#options","title":"Options:","text":"Option Description <code>filename</code> The file of Soar productions and commands to load. <code>-a, --all</code> Enable a summary for each file sourced <code>-d, --disable</code> Disable all summaries <code>-v, --verbose</code> Print excised production names"},{"location":"reference/cli/cmd_load/#summaries","title":"Summaries","text":"<p>After the source completes, the number of productions sourced and excised is summarized:</p> <p><pre><code>agent&gt; source demos/mac/mac.soar\n******************\nTotal: 18 productions sourced.\nSource finished.\nagent&gt; source demos/mac/mac.soar\n#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*\nTotal: 18 productions sourced. 18 productions excised.\nSource finished.\n</code></pre> This can be disabled by using the <code>-d</code> flag.</p>"},{"location":"reference/cli/cmd_load/#multiple-summaries","title":"Multiple Summaries","text":"<p>A separate summary for each file sourced can be enabled using the <code>-a</code> flag:</p> <pre><code>agent&gt; source demos/mac/mac.soar -a\n_firstload.soar: 0 productions sourced.\nall_source.soar: 0 productions sourced.\n**\ngoal-test.soar: 2 productions sourced.\n***\nmonitor.soar: 3 productions sourced.\n****\nsearch-control.soar: 4 productions sourced.\ntop-state.soar: 0 productions sourced.\nelaborations_source.soar: 0 productions sourced.\n_readme.soar: 0 productions sourced.\n**\ninitialize-mac.soar: 2 productions sourced.\n*******\nmove-boat.soar: 7 productions sourced.\nmac_source.soar: 0 productions sourced.\nmac.soar: 0 productions sourced.\nTotal: 18 productions sourced.\nSource finished.\n</code></pre>"},{"location":"reference/cli/cmd_load/#listing-excised-productions","title":"Listing Excised Productions","text":"<pre><code>agent&gt; source demos/mac/mac.soar -d\n******************\nSource finished.\nagent&gt; source demos/mac/mac.soar -d\n#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*\nSource finished.\n</code></pre> <p>A list of excised productions is available using the <code>-v</code> flag:</p> <p><pre><code>agent&gt; source demos/mac/mac.soar -v\n#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*\nTotal: 18 productions sourced. 18 productions excised.\nExcised productions:\n        mac*detect*state*success\n        mac*evaluate*state*failure*more*cannibals\n        monitor*move-boat\n        monitor*state*left\n...\n</code></pre> Combining the <code>-a</code> and <code>-v</code> flags add excised production names to the output for each file.</p>"},{"location":"reference/cli/cmd_load/#load-rete-network","title":"load rete-network","text":"<p>The <code>load rete-network</code> command loads a Rete net previously saved. The Rete net is Soar's internal representation of production memory; the conditions of productions are reordered and common substructures are shared across different productions. This command provides a fast method of saving and loading productions since a special format is used and no parsing is necessary. Rete-net files are portable across platforms that support Soar.</p> <p>If the filename contains a suffix of <code>.Z</code>, then the file is compressed automatically when it is saved and uncompressed when it is loaded. Compressed files may not be portable to another platform if that platform does not support the same uncompress utility.</p>"},{"location":"reference/cli/cmd_load/#usage","title":"Usage:","text":"<pre><code>load rete-network -l &lt;filename&gt;\n</code></pre>"},{"location":"reference/cli/cmd_load/#load-percepts","title":"load percepts","text":"<p>Replays input stored using the capture-input command. The replay file also includes a random number generator seed and seeds the generator with that.</p>"},{"location":"reference/cli/cmd_load/#synopsis_1","title":"Synopsis","text":"<pre><code>load percepts --open filename\nload percepts --close\n</code></pre>"},{"location":"reference/cli/cmd_load/#options_1","title":"Options","text":"Option Description <code>filename</code> Open filename and load input and random seed. <code>-o, --open</code> Reads captured input from file in to memory and seeds the random number generator. <code>-c, --close</code> Stop replaying input."},{"location":"reference/cli/cmd_load/#load-library","title":"load library","text":"<p>Load a shared library into the local client (for the purpose of, e.g., providing custom event handling).</p>"},{"location":"reference/cli/cmd_load/#options_2","title":"Options:","text":"Option Description <code>library_name</code> The root name of the library (without the .dll or .so extension; this is added for you depending on your platform). <code>arguments</code> Whatever arguments the library's initialization function is expecting, if any."},{"location":"reference/cli/cmd_load/#technical-details","title":"Technical Details","text":"<p>Sometimes, a user will want to extend an existing environment. For example, the person may want to provide custom RHS functions, or register for print events for the purpose of logging trace information. If modifying the existing environment is cumbersome or impossible, then the user has two options: create a remote client that provides the functionality, or use load library. <code>load library</code> creates extensions in the local client, making it orders of magnitude faster than a remote client.</p> <p>To create a loadable library, the library must contain the following function:</p> <pre><code>#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n    EXPORT char* sml_InitLibrary(Kernel* pKernel, int argc, char** argv) {\n        // Your code here\n    }\n\n#ifdef __cplusplus\n} // extern \"C\"\n#endif\n</code></pre> <p>This function is called when <code>load library</code> loads your library. It is responsible for any initialization that you want to take place (e.g.  registering custom RHS functions, registering for events, etc).</p> <p>The <code>argc</code> and <code>argv</code> arguments are intended to mirror the arguments that a standard SML client would get. Thus, the first argument is the name of the library, and the rest are whatever other arguments are provided. This is to make it easy to use the same codebase to create a loadable library or a standard remote SML client (e.g. when run as a standard client, just pass the arguments main gets into <code>sml_InitLibrary</code>).</p> <p>The return value of <code>sml_InitLibrary</code> is for any error messages you want to return to the load-library call. If no error occurs, return a zero-length string.</p> <p>An example library is provided in the <code>Tools/TestExternalLibraryLib</code> project. This example can also be compiled as a standard remote SML client. The  <code>Tools/TestExternalLibraryExe</code> project tests loading the <code>TestExternalLibraryLib</code> library.</p>"},{"location":"reference/cli/cmd_load/#load-library-examples","title":"Load Library Examples","text":"<p>To load <code>TestExternalLibraryLib</code>:</p> <pre><code>load library TestExternalLibraryLib\n</code></pre> <p>To load a library that takes arguments (say, a logger):</p> <pre><code>load library my-logger -filename mylog.log\n</code></pre>"},{"location":"reference/cli/cmd_load/#default-aliases","title":"Default aliases","text":"<pre><code>source               load file            \nrete-net, rn         load rete-network    \nreplay-input         load input           \nload-libarary        load library         \n</code></pre>"},{"location":"reference/cli/cmd_load/#see-also","title":"See Also","text":"<p>file system decide production save</p>"},{"location":"reference/cli/cmd_output/","title":"output","text":""},{"location":"reference/cli/cmd_output/#output","title":"output","text":"<p>Controls settings related to Soar's output</p>"},{"location":"reference/cli/cmd_output/#synopsis","title":"Synopsis","text":"<pre><code>=======================================================\n-           Output Sub-Commands and Options           -\n=======================================================\noutput                                       [? | help]\n-------------------------------------------------------\nenabled                                              on   Globally toggle all output\nconsole                                             off   Send output to std::out for debugging\ncallbacks                                            on   Send output to standard print callback\n-------------------------------------------------------\nagent-logs                  &lt;channel-number&gt; [ON | off]   Whether agent log channel prints\nagent-writes                                         on   Allow RHS-funtion output\n-------------------------------------------------------\noutput log                   [--append | -A] &lt;filename&gt;   Log all output to file\noutput log                               --add &lt;string&gt;\noutput log                                    [--close]\n-------------------------------------------------------\noutput command-to-file         [-a] &lt;file&gt; &lt;cmd&gt; [args]   Log output from single command\n-------------------------------------------------------\necho-commands                                       off   Echo commands to debugger\nprint-depth                                           1   Default print depth\nwarnings                                             on   Print all warnings\n-------------------------------------------------------\nTo view/change a setting:                                 output &lt;setting&gt; [&lt;value&gt;]\n\nFor a detailed explanation of these settings:             help output\n</code></pre>"},{"location":"reference/cli/cmd_output/#summary-screen","title":"Summary Screen","text":"<p>Using the <code>output</code> command without any arguments will display some key output settings: <pre><code>=======================================================\n-                   Output Status                     -\n=======================================================\nPrinting enabled                                    Yes   \nPrinting to std::out                                Yes   \n-------------------------------------------------------\nAgent RHS write output                               on   \nAll agent log channels enabled.\n-------------------------------------------------------\nWarnings                                             on   \n-------------------------------------------------------\nSoar release compilation                            OFF   \nDebug printing                                       ON   \n-------------------------------------------------------\n</code></pre></p>"},{"location":"reference/cli/cmd_output/#output-command-to-file","title":"output command-to-file","text":"<p>This command logs a single command. It is almost equivalent to opening a log using clog, running the command, then closing the log, the only difference is that input isn't recorded.</p> <p>Running this command while a log is open is an error. There is currently not support for multiple logs in the command line interface, and this would be an instance of multiple logs.</p> <p>This command echoes output both to the screen and to a file, just like clog.</p>"},{"location":"reference/cli/cmd_output/#options","title":"Options:","text":"Option Description <code>-a, --append</code> Append if file exists. <code>filename</code> The file to log the results of the command to <code>command</code> The command to log <code>args</code> Arguments for command"},{"location":"reference/cli/cmd_output/#output-log","title":"output log","text":"<p>The <code>output log</code> command allows users to save all user-interface input and output to a file. When Soar is logging to a file, everything typed by the user and everything printed by Soar is written to the file (in addition to the screen).</p> <p>Invoke <code>output log</code> with no arguments to query the current logging status. Pass a filename to start logging to that file (relative to the command line interface's home directory). Use the <code>close</code> option to stop logging.</p>"},{"location":"reference/cli/cmd_output/#usage","title":"Usage","text":"<pre><code>output log [-A] filename\noutput log --add string\noutput log --close\n</code></pre>"},{"location":"reference/cli/cmd_output/#options_1","title":"Options:","text":"Option Description <code>filename</code> Open filename and begin logging. <code>-c, --close</code> Stop logging, close the file. <code>-a, --add string</code> Add the given string to the open log file. <code>-A, --append</code> Opens existing log file named <code>filename</code> and logging is added at the end of the file."},{"location":"reference/cli/cmd_output/#examples","title":"Examples","text":"<p>To initiate logging and place the record in foo.log:</p> <pre><code>output log foo.log\n</code></pre> <p>To append log data to an existing foo.log file:</p> <pre><code>output log -A foo.log\n</code></pre> <p>To terminate logging and close the open log file:</p> <pre><code>output log -c\n</code></pre>"},{"location":"reference/cli/cmd_output/#known-issues-with-log","title":"Known Issues with log","text":"<p>Does not log everything when structured output is selected.</p>"},{"location":"reference/cli/cmd_output/#general-output-settings","title":"General Output Settings","text":"<p>Invoke a sub-command with no arguments to query the current setting. Partial commands are accepted.</p> Option Valid Values Default <code>echo-commands</code> yes or no off <code>print-depth</code> &gt;= 1 1 <code>verbose</code> yes or no no <code>warnings</code> yes or no yes"},{"location":"reference/cli/cmd_output/#output-agent-logs","title":"output agent-logs","text":"<p>A Soar agent has 100 log channels available. By default, all are turned on. The <code>log</code> RHS-function allows printing as with the <code>write</code> function, but limits output to only the specified log channel. </p>"},{"location":"reference/cli/cmd_output/#output-echo-commands","title":"output echo-commands","text":"<p><code>output echo-commands</code> will echo typed commands to other connected debuggers. Otherwise, the output is displayed without the initiating command, and this can be confusing.</p>"},{"location":"reference/cli/cmd_output/#output-print-depth","title":"output print-depth","text":"<p>The <code>print-depth</code> command reflects the default depth used when working memory elements are printed (using the print). The default value is 1. This default depth can be overridden on any particular call to the print command by explicitly using the <code>--depth</code> flag, e.g. <code>print --depth 10 args</code>.</p> <p>By default, the print command prints objects in working memory, not just the individual working memory element. To limit the output to individual working memory elements, the <code>--internal</code> flag must also be specified in the print command. Thus when the print depth is <code>0</code>, by default Soar prints the entire object, which is the same behavior as when the print depth is <code>1</code>. But if <code>--internal</code> is also specified, then a depth of <code>0</code> prints just the individual WME, while a depth of <code>1</code> prints all WMEs which share that same identifier. This is true when printing timetags, identifiers or WME patterns.</p> <p>When the depth is greater than <code>1</code>, the identifier links from the specified WME's will be followed, so that additional substructure is printed. For example, a depth of <code>2</code> means that the object specified by the identifier, wme-pattern, or timetag will be printed, along with all other objects whose identifiers appear as values of the first object. This may result in multiple copies of the same object being printed out. If <code>--internal</code> is also specified, then individuals WMEs and their timetags will be printed instead of the full objects.</p>"},{"location":"reference/cli/cmd_output/#output-verbose","title":"output verbose","text":"<p>The <code>verbose</code> command enables tracing of a number of low-level Soar execution details during a run. The details printed by <code>verbose</code> are usually only valuable to developers debugging Soar implementation details.</p>"},{"location":"reference/cli/cmd_output/#output-warnings","title":"output warnings","text":"<p>The <code>warnings</code> command enables and disables the printing of warning messages. At startup, warnings are initially enabled. If warnings are disabled using this command, then some warnings may still be printed, since some are considered too important to ignore.</p> <p>The warnings that are printed apply to the syntax of the productions, to notify the user when they are not in the correct syntax. When a lefthand side error is discovered (such as conditions that are not linked to a common state or impasse object), the production is generally loaded into production memory anyway, although this production may never match or may seriously slow down the matching process. In this case, a warning would be printed only if warnings were <code>on</code>.  Righthand side errors, such as preferences that are not linked to the state, usually result in the production not being loaded, and a warning regardless of the warnings setting.</p>"},{"location":"reference/cli/cmd_output/#default-aliases","title":"Default Aliases","text":"<pre><code>ctf                        output command-to-file\nclog                       output log\ndefault-wme-depth          output print-depth\necho-commands              output echo-commands\nverbose                    output verbose\nwarnings                   output warnings\n</code></pre>"},{"location":"reference/cli/cmd_preferences/","title":"preference","text":""},{"location":"reference/cli/cmd_preferences/#preferences","title":"preferences","text":"<p>Examine details about the preferences that support the specified identifier and attribute.</p>"},{"location":"reference/cli/cmd_preferences/#synopsis","title":"Synopsis","text":"<pre><code>preferences [options] [identifier [attribute]]\n</code></pre>"},{"location":"reference/cli/cmd_preferences/#options","title":"Options","text":"Option Description <code>-0, -n, --none</code> Print just the preferences themselves <code>-1, -N, --names</code> Print the preferences and the names of the productions that generated them <code>-2, -t, --timetags</code> Print the information for the <code>--names</code> option above plus the timetags of the wmes matched by the LHS of the indicated productions <code>-3, -w, --wmes</code> Print the information for the <code>--timetags</code> option above plus the entire WME matched on the LHS. <code>-o, --object</code> Print the support for all the WMEs that comprise the object (the specified identifier). <code>identifier</code> Must be an existing Soar object identifier. <code>attribute</code> Must be an existing attribute of the specified identifier."},{"location":"reference/cli/cmd_preferences/#description","title":"Description","text":"<p>The <code>preferences</code> command prints all the preferences for the given object identifier and attribute. If identifier and attribute are not specified, they default to the current state and the current operator. The Soar syntax attribute carat (<code>^</code>) is optional when specifying the attribute. The optional arguments indicates the level of detail to print about each preference.</p> <p>This command is useful for examining which candidate operators have been proposed and what relationships, if any, exist among them.  If a preference has o-support, the string, <code>:O</code> will also be printed.</p> <p>When only the identifier is specified on the command line, if the identifier is a state, Soar uses the default attribute <code>^operator</code>. If the identifier is not a state, Soar prints the support information for all WMEs whose value is the identifier.</p> <p>When an identifier and the <code>--object</code> flag are specified, Soar prints the preferences / WME support for all WMEs comprising the specified identifier.</p> <p>For the time being, numeric-indifferent preferences are listed under the heading <code>binary indifferents:</code>.</p> <p>By default, using the <code>--wmes</code> option with a WME on the top state will only print the timetags. To change this, the kernel can be recompiled with <code>DO_TOP_LEVEL_REF_CTS</code>, but this has other consequences (see comments in <code>kernel.h</code>).</p>"},{"location":"reference/cli/cmd_preferences/#examples","title":"Examples","text":"<p>This example prints the preferences on <code>(S1 ^operator)</code> and the production names which created the preferences:</p> <pre><code>soar&gt; preferences S1 operator --names\nPreferences for S1 ^operator:\n\nacceptables:\n  O2 (fill) + :I \n    From water-jug*propose*fill\n\n  O3 (fill) + :I \n    From water-jug*propose*fill\n\nunary indifferents:\n  O2 (fill) = :I \n    From water-jug*propose*fill\n\n  O3 (fill) = :I \n    From water-jug*propose*fill\n\nselection probabilities:\n  O3 (fill) + =0. :I (50.0%)\n    From water-jug*propose*fill\n\n  O2 (fill) + =0. :I (50.0%)\n    From water-jug*propose*fill\n</code></pre> <p>If the current state is <code>S1</code>, then the above syntax is equivalent to:</p> <pre><code>preferences -n\n</code></pre> <p>This example shows the support for the WMEs with the ^jug attribute:</p> <pre><code>soar&gt; preferences s1 jug\n\nPreferences for S1 ^jug:\n\nacceptables:\n  (S1 ^jug I4)  :O \n  (S1 ^jug J1)  :O \n</code></pre> <p>This example shows the support for the WMEs with value <code>J1</code>, and the productions that generated them:</p> <pre><code>soar&gt; pref J1 -1\n\nSupport for (33: O3 ^fill-jug J1)\n  (O3 ^fill-jug J1)  =0. :I (100.0%)\n    From water-jug*propose*fill\n\nSupport for (22: S1 ^jug J1)\n  (S1 ^jug J1)  =0. :O (100.0%)\n    From water-jug*apply*initialize-water-jug\n</code></pre> <p>This example shows the support for all WMEs that make up the object <code>S1</code>:</p> <pre><code>soar&gt; pref -o s1\n\nSupport for S1 ^name:\n  (S1 ^name water-jug)  :O \nSupport for S1 ^jug:\n  (S1 ^jug I4)  :O \n  (S1 ^jug J1)  :O \nSupport for S1 ^svs:\nPreferences for S1 ^operator:\nacceptables:\n  O2 (fill) + :I \n  O3 (fill) + :I \n\nunary indifferents:\n  O2 (fill) = :I \n  O3 (fill) = :I \nSupport for S1 ^smem:\nSupport for S1 ^epmem:\nSupport for S1 ^reward-link:\nArch-created wmes for S1 :\n(2: S1 ^superstate nil)\n(1: S1 ^type state)\nInput (IO) wmes for S1 :\n(15: S1 ^io I1)\n</code></pre>"},{"location":"reference/cli/cmd_preferences/#default-aliases","title":"Default Aliases","text":"<ul> <li><code>pref</code></li> </ul>"},{"location":"reference/cli/cmd_preferences/#see-also","title":"See Also","text":"<p>decide</p>"},{"location":"reference/cli/cmd_print/","title":"print","text":""},{"location":"reference/cli/cmd_print/#print","title":"print","text":"<p>Print items in working memory or production memory.</p>"},{"location":"reference/cli/cmd_print/#synopsis","title":"Synopsis","text":"<pre><code>print [options] [production_name]\nprint [options] identifier|timetag|pattern\nprint [--gds --stack]\n</code></pre>"},{"location":"reference/cli/cmd_print/#options","title":"Options","text":""},{"location":"reference/cli/cmd_print/#production-printing-options","title":"Production printing options:","text":"Option Description <code>-a, --all</code> print the names of all productions currently loaded <code>-c, --chunks</code> print the names of all chunks currently loaded <code>-D, --defaults</code> print the names of all default productions currently loaded <code>-j, --justifications</code> print the names of all justifications currently loaded. <code>-r, --rl</code> Print Soar-RL rules <code>-T, --template</code> Print Soar-RL templates <code>-u, --user</code> print the names of all user productions currently loaded <code>production_name</code> print the production named <code>production-name</code>"},{"location":"reference/cli/cmd_print/#production-print-formatting","title":"Production print formatting:","text":"Option Description <code>-f, --full</code> When printing productions, print the whole production. This is the default when printing a named production. <code>-F, --filename</code> also prints the name of the file that contains the production. <code>-i, --internal</code> items should be printed in their internal form. For productions, this means leaving conditions in their reordered (rete net) form. <code>-n, --name</code> When printing productions, print only the name and not the whole production. This is the default when printing any category of productions, as opposed to a named production."},{"location":"reference/cli/cmd_print/#working-memory-printing-options","title":"Working memory printing options:","text":"Option Description <code>-d, --depth n</code> This option overrides the default printing depth (see the default-wme-depth command for more detail). <code>-e, --exact</code> Print only the wmes that match the pattern <code>-i, --internal</code> items should be printed in their internal form. For working memory, this means printing the individual elements with their timetags and activation, rather than the objects. <code>-t, --tree</code> wmes should be printed in in a tree form (one wme per line). <code>-v, --varprint</code> Print identifiers enclosed in angle brackets. <code>identifier</code> print the object <code>identifier</code>. <code>identifier</code> must be a valid Soar symbol such as S1 <code>pattern</code> print the object whose working memory elements matching the given <code>pattern</code>. See Description for more information on printing objects matching a specific <code>pattern</code>. <code>timetag</code> print the object in working memory with the given <code>timetag</code>"},{"location":"reference/cli/cmd_print/#subgoal-stack-printing-options","title":"Subgoal stack printing options:","text":"Option Description <code>-s, --stack</code> Specifies that the Soar goal stack should be printed. By default this includes both states and operators. <code>-o, --operators</code> When printing the stack, print only operators. <code>-S, --states</code> When printing the stack, print only states."},{"location":"reference/cli/cmd_print/#printing-the-goal-dependency-set","title":"Printing the Goal Dependency Set:","text":"<p><code>print --gds</code></p> <p>The Goal Dependency Set (GDS) is described in a subsection of the <code>The Soar Architecture</code> chapter of the manual. This command is a debugging command for examining the GDS for each goal in the stack. First it steps through all the working memory elements in the rete, looking for any that are included in any goal dependency set, and prints each one. Then it also lists each goal in the stack and prints the wmes in the goal dependency set for that particular goal. This command is useful when trying to determine why subgoals are disappearing unexpectedly: often something has changed in the goal dependency set, causing a subgoal to be regenerated prior to producing a result.</p> <p><code>print --gds</code> is horribly inefficient and should not generally be used except when something is going wrong and you need to examine the Goal Dependency Set.</p>"},{"location":"reference/cli/cmd_print/#description","title":"Description","text":"<p>The print command is used to print items from production memory or working memory. It can take several kinds of arguments. When printing items from working memory, the Soar objects are printed unless the <code>--internal</code> flag is used, in which case the wmes themselves are printed.</p> <pre><code>(identifier ^attribute value [activation] [+])\n</code></pre> <p>The activation value is only printed if activation is turned on. See wma.</p> <p>The pattern is surrounded by parentheses. The <code>identifier</code>, <code>attribute</code>, and <code>value</code> must be valid Soar symbols or the wildcard symbol <code>*</code> which matches all occurrences. The optional <code>+</code> symbol restricts pattern matches to acceptable preferences. If wildcards are included, an object will be printed for each pattern match, even if this results in the same object being printed multiple times.</p>"},{"location":"reference/cli/cmd_print/#examples","title":"Examples","text":"<p>Print the objects in working memory (and their timetags) which have wmes with identifier <code>s1</code> and value <code>v2</code> (note: this will print the entire <code>s1</code> object for each match found):</p> <pre><code>print --internal (s1 ^* v2)\n</code></pre> <p>Print the Soar stack which includes states and operators:</p> <pre><code>print --stack\n</code></pre> <p>Print the named production in its RETE form:</p> <pre><code>print -if named*production\n</code></pre> <p>Print the names of all user productions currently loaded:</p> <pre><code>print -u\n</code></pre> <p>Default print vs tree print:</p> <pre><code>print s1 --depth 2\n(S1 ^io I1 ^reward-link R1 ^superstate nil ^type state)\n  (I1 ^input-link I2 ^output-link I3)\n\nprint s1 --depth 2 --tree\n(S1 ^io I1)\n  (I1 ^input-link I2)\n  (I1 ^output-link I3)\n(S1 ^reward-link R1)\n(S1 ^superstate nil)\n(S1 ^type state)\n</code></pre>"},{"location":"reference/cli/cmd_print/#default-aliases","title":"Default Aliases","text":"<p>p              print pc             print --chunks ps             print --stack wmes           print --depth 0 --internal varprint       print --varprint --depth 100 gds_print      print --gds</p>"},{"location":"reference/cli/cmd_print/#see-also","title":"See Also","text":"<p>output trace wm</p>"},{"location":"reference/cli/cmd_production/","title":"production","text":""},{"location":"reference/cli/cmd_production/#production","title":"production","text":"<p>Commands to manipulate Soar rules and analyze their usage.</p>"},{"location":"reference/cli/cmd_production/#synopsis","title":"Synopsis","text":"<pre><code>==================================================================\n-               Production Sub-Commands and Options              -\n==================================================================\nproduction                    [? | help]\n------------------------------------------------------------------\nproduction break              [--clear --print]\nproduction break              --set &lt;prod-name&gt;\n------------------------------------------------------------------\nproduction excise             &lt;production-name&gt;\nproduction excise             [--all --chunks --default ]\n                              [--never-fired --rl       ]\n                              [--task --templates --user]\n------------------------------------------------------------------\nproduction find               [--lhs --rhs         ] &lt;pattern&gt;\n                              [--show-bindings     ]\n                              [--chunks --nochunks ]\n------------------------------------------------------------------\nproduction firing-counts      [--all --chunks --default --rl]  [n]\n                              [--task --templates --user --fired]\nproduction firing-counts      &lt;prod-name&gt;\n------------------------------------------------------------------\nproduction matches            [--names --count  ]  &lt;prod-name&gt;\n                              [--timetags --wmes]\nproduction matches            [--names --count  ] [--assertions ]\n                              [--timetags --wmes] [--retractions]\n------------------------------------------------------------------\nproduction memory-usage       [options] [max]\nproduction memory-usage       &lt;production_name&gt;\n------------------------------------------------------------------\nproduction optimize-attribute [symbol [n]]\n------------------------------------------------------------------\nproduction watch              [--disable --enable] &lt;prod-name&gt;\n------------------------------------------------------------------\n\nFor a detailed explanation of sub-commands:    help production\n</code></pre>"},{"location":"reference/cli/cmd_production/#summary-screen","title":"Summary Screen","text":"<p>Using the <code>production</code> command without any arguments will display a summary of how many rules are loaded into memory:</p> <pre><code>=======================================================\n-                     Productions                     -\n=======================================================\nUser rules                                            0\nDefault rules                                         0\nChunks                                                0\nJustifications                                        0\n-------------------------------------------------------\nTotal                                                 0\n-------------------------------------------------------\nUse 'production ?' to learn more about the command\n</code></pre>"},{"location":"reference/cli/cmd_production/#production-break","title":"production break","text":"<p>Toggles the <code>:interrupt</code> flag on a rule at run-time, which stops the Soar decision cycle when the rule fires. The <code>break</code> command can be used to toggle the <code>:interrupt</code> flag on production rules which did not have it set in the original source file, which stops the Soar decision cycle when the rule fires. This is intended to be used for debugging purposes.</p>"},{"location":"reference/cli/cmd_production/#synopsis_1","title":"Synopsis","text":"<pre><code>production break -c|--clear &lt;production-name&gt;\nproduction break -p|--print\nproduction break -s|--set &lt;production-name&gt;\nproduction break &lt;production-name&gt;\n</code></pre>"},{"location":"reference/cli/cmd_production/#options","title":"Options:","text":"Parameter Argument Description <code>-c, --clear</code> &lt;production-name&gt; Clear :interrupt flag from a production. <code>-p, --print</code> (none) Print which production rules have had their :interrupt flags set. (none) (none) Print which production rules have had their :interrupt flags set. <code>-s, --set</code> &lt;production-name&gt; Set :interrupt flag on a production rule. (none) &lt;production-name&gt; Set flag :interrupt on a production rule."},{"location":"reference/cli/cmd_production/#production-excise","title":"production excise","text":"<p>This command removes productions from Soar's memory. The command must be called with either a specific production name or with a flag that indicates a particular group of productions to be removed. </p> <p>Note:  As of Soar 9.6, using the flag <code>-a</code> or <code>--all</code> no longer causes a <code>soar init</code>.</p>"},{"location":"reference/cli/cmd_production/#synopsis_2","title":"Synopsis","text":"<pre><code>production excise production_name\nproduction excise options\n</code></pre>"},{"location":"reference/cli/cmd_production/#options_1","title":"Options:","text":"Option Description <code>-a, --all</code> Remove all productions from memory and perform an init-soar command <code>-c, --chunks</code> Remove all chunks (learned productions) and justifications from memory <code>-d, --default</code> Remove all default productions (<code>:default</code>) from memory <code>-n, --never-fired</code> Excise rules that have a firing count of 0 <code>-r, --rl</code> Excise Soar-RL rules <code>-t, --task</code> Remove chunks, justifications, and user productions from memory <code>-T, --templates</code> Excise Soar-RL templates <code>-u, --user</code> Remove all user productions (but not chunks or default rules) from memory <code>production_name</code> Remove the specific production with this name."},{"location":"reference/cli/cmd_production/#examples","title":"Examples:","text":"<p>This command removes the production <code>my*first*production</code> and all chunks:</p> <pre><code>production excise my*first*production --chunks\n</code></pre> <p>This removes all productions:</p> <pre><code>production excise --all\n</code></pre>"},{"location":"reference/cli/cmd_production/#production-find","title":"production find","text":"<p>Find productions by condition or action patterns.</p>"},{"location":"reference/cli/cmd_production/#synopsis_3","title":"Synopsis","text":"<pre><code>production find [-lrs[n|c]] pattern\n</code></pre>"},{"location":"reference/cli/cmd_production/#options_2","title":"Options:","text":"Option Description <code>-c, --chunks</code> Look only for chunks that match the pattern. <code>-l, --lhs</code> Match pattern only against the conditions (left-hand side) of productions (default). <code>-n, --nochunks</code> Disregard chunks when looking for the pattern. <code>-r, --rhs</code> Match pattern against the actions (right-hand side) of productions. <code>-s, --show-bindings</code> Show the bindings associated with a wildcard pattern. <code>pattern</code> Any pattern that can appear in productions."},{"location":"reference/cli/cmd_production/#description","title":"Description","text":"<p>The <code>production find</code> command is used to find productions in production memory that include conditions or actions that match a given <code>pattern</code>. The pattern given specifies one or more condition elements on the left hand side of productions (or negated conditions), or one or more actions on the right-hand side of productions. Any pattern that can appear in productions can be used in this command. In addition, the asterisk symbol, <code>*</code>, can be used as a wildcard for an attribute or value. It is important to note that the whole pattern, including the parenthesis, must be enclosed in curly braces for it to be parsed properly.</p> <p>The variable names used in a call to production find do not have to match the variable names used in the productions being retrieved.</p> <p>The <code>production find</code> command can also be restricted to apply to only certain types of productions, or to look only at the conditions or only at the actions of productions by using the flags.</p>"},{"location":"reference/cli/cmd_production/#production-find-examples","title":"Production Find Examples:","text":"<p>Find productions that test that some object <code>gumby</code> has an attribute <code>alive</code> with value <code>t</code>. In addition, limit the rules to only those that test an operator named <code>foo</code>:</p> <pre><code>production find (&lt;state&gt; ^gumby &lt;gv&gt; ^operator.name foo)(&lt;gv&gt; ^alive t)\n</code></pre> <p>Note that in the above command, <code>&lt;state&gt;</code> does not have to match the exact variable name used in the production.</p> <p>Find productions that propose the operator <code>foo</code>:</p> <pre><code>production find --rhs (&lt;x&gt; ^operator &lt;op&gt; +)(&lt;op&gt; ^name foo)\n</code></pre> <p>Find chunks that test the attribute ^pokey:</p> <pre><code>production find --chunks (&lt;x&gt; ^pokey *)\n</code></pre> <p>Examples using the water-jugs demo:</p> <pre><code>source demos/water-jug/water-jug.soar\nproduction-find (&lt;s&gt; ^name *)(&lt;j&gt; ^volume *)\nproduction-find (&lt;s&gt; ^name *)(&lt;j&gt; ^volume 3)\nproduction-find --rhs (&lt;j&gt; ^* &lt;volume&gt;)\n</code></pre>"},{"location":"reference/cli/cmd_production/#production-firing-counts","title":"production firing-counts","text":"<p>Print the number of times productions have fired.</p>"},{"location":"reference/cli/cmd_production/#synopsis_4","title":"Synopsis","text":"<pre><code>production firing-counts [type] [n]\nproduction firing-counts production_name\n</code></pre>"},{"location":"reference/cli/cmd_production/#options_3","title":"Options:","text":"<p>If given, an option can take one of two forms -- an integer or a production name:</p> Option Description <code>n</code> List the top <code>n</code> productions. If <code>n</code> is 0, only the productions which haven't fired are listed <code>production_name</code> Print how many times a specific production has fired <code>-f, --fired</code> Prints only rules that have fired <code>-c, --chunks</code> Print how many times chunks (learned rules) fired <code>-j, --justifications</code> Print how many times justifications fired <code>-d, --default</code> Print how many times default productions (<code>:default</code>) fired <code>-r, --rl</code> Print how many times Soar-RL rules fired <code>-T, --templates</code> Print how many times Soar-RL templates fired <code>-u, --user</code> Print how many times user productions (but not chunks or default rules) fired"},{"location":"reference/cli/cmd_production/#description_1","title":"Description","text":"<p>The <code>production firing-counts</code> command prints the number of times each production has fired; production names are given from most frequently fired to least frequently fired. With no arguments, it lists all productions. If an integer argument, <code>n</code>, is given, only the top <code>n</code> productions are listed.  If <code>n</code> is zero (0), only the productions that haven't fired at all are listed. If --fired is used, the opposite happens.  Only rules that have fired are listed. If a production name is given as an argument, the firing count for that production is printed.</p> <p>Note that firing counts are reset by a call to [soar init] (cmd_soar).</p>"},{"location":"reference/cli/cmd_production/#examples_1","title":"Examples:","text":"<p>This example prints the 10 productions which have fired the most times along with their firing counts:</p> <pre><code>production firing-counts 10\n</code></pre> <p>This example prints the firing counts of production <code>my*first*production</code>:</p> <pre><code>production firing-counts my*first*production\n</code></pre> <p>This example prints all rules that have fired at least once:</p> <pre><code>production firing-counts -f\n</code></pre>"},{"location":"reference/cli/cmd_production/#production-matches","title":"production matches","text":"<p>The <code>production matches</code> command prints a list of productions that have instantiations in the match set, i.e., those productions that will retract or fire in the next propose or apply phase. It also will print partial match information for a single, named production.</p>"},{"location":"reference/cli/cmd_production/#synopsis_5","title":"Synopsis","text":"<pre><code>production matches [options] production_name\nproduction matches [options] -[a|r]\n</code></pre>"},{"location":"reference/cli/cmd_production/#options_4","title":"Options:","text":"Option Description <code>production_name</code> Print partial match information for the named production. <code>-n, --names, -c, --count</code> For the match set, print only the names of the productions that are about to fire or retract (the default). If printing partial matches for a production, just list the partial match counts. <code>-t, --timetags</code> Also print the timetags of the wmes at the first failing condition <code>-w, --wmes</code> Also print the full wmes, not just the timetags, at the first failing condition. <code>-a, --assertions</code> List only productions about to fire. <code>-r, --retractions</code> List only productions about to retract."},{"location":"reference/cli/cmd_production/#printing-the-match-set","title":"Printing the match set","text":"<p>When printing the match set (i.e., no production name is specified), the default action prints only the names of the productions which are about to fire or retract. If there are multiple instantiations of a production, the total number of instantiations of that production is printed after the production name, unless <code>--timetags</code> or <code>--wmes</code> are specified, in which case each instantiation is printed on a separate line.</p> <p>When printing the match set, the <code>--assertions</code> and <code>--retractions</code> arguments can be specified to restrict the output to print only the assertions or retractions.</p>"},{"location":"reference/cli/cmd_production/#printing-partial-matches-for-productions","title":"Printing partial matches for productions","text":"<p>In addition to printing the current match set, the <code>matches</code> command can be used to print information about partial matches for a named production. In this case, the conditions of the production are listed, each preceded by the number of currently active matches for that condition. If a condition is negated, it is preceded by a minus sign <code>-</code>. The pointer <code>&gt;&gt;&gt;&gt;</code> before a condition indicates that this is the first condition that failed to match.</p> <p>When printing partial matches, the default action is to print only the counts of the number of WME's that match, and is a handy tool for determining which condition failed to match for a production that you thought should have fired. At levels <code>--timetags</code> and <code>--wmes</code> the <code>matches</code> command displays the WME's immediately after the first condition that failed to match -- temporarily interrupting the printing of the production conditions themselves.</p>"},{"location":"reference/cli/cmd_production/#notes","title":"Notes:","text":"<p>When printing partial match information, some of the matches displayed by this command may have already fired, depending on when in the execution cycle this command is called. To check for the matches that are about to fire, use the matches command without a named production.</p> <p>In Soar 8, the execution cycle (decision cycle) is input, propose, decide, apply output; it no longer stops for user input after the decision phase when running by decision cycles (<code>run -d 1</code>). If a user wishes to print the match set immediately after the decision phase and before the apply phase, then the user must run Soar by phases (<code>run -p 1</code>).</p>"},{"location":"reference/cli/cmd_production/#examples_2","title":"Examples:","text":"<p>This example prints the productions which are about to fire and the WMEs that match the productions on their left-hand sides:</p> <pre><code>production matches --assertions --wmes\n</code></pre> <p>This example prints the WME timetags for a single production.</p> <pre><code>production matches -t my*first*production\n</code></pre>"},{"location":"reference/cli/cmd_production/#production-memory-usage","title":"production memory-usage","text":"<p>Print memory usage for partial matches.</p>"},{"location":"reference/cli/cmd_production/#synopsis_6","title":"Synopsis","text":"<pre><code>production memory-usage [options] [number]\nproduction memory-usage production_name\n</code></pre>"},{"location":"reference/cli/cmd_production/#options_5","title":"Options:","text":"Option Description <code>-c, --chunks</code> Print memory usage of chunks. <code>-d, --default</code> Print memory usage of default productions. <code>-j, --justifications</code> Print memory usage of justifications. <code>-u, --user</code> Print memory usage of user-defined productions. <code>production_name</code> Print memory usage for a specific production. <code>number</code> Number of productions to print, sorted by those that use the most memory. <code>-T, --template</code> Print memory usage of Soar-RL templates."},{"location":"reference/cli/cmd_production/#description_2","title":"Description","text":"<p>The <code>memory-usage</code> command prints out the internal memory usage for full and partial matches of production instantiations, with the productions using the most memory printed first. With no arguments, the <code>memory-usage</code> command prints memory usage for all productions.  If a <code>production_name</code> is specified, memory usage will be printed only for that production. If a positive integer <code>number</code> is given, only <code>number</code> productions will be printed: the <code>number</code> productions that use the most memory. Output may be restricted to print memory usage for particular types of productions using the command options.</p> <p>Memory usage is recorded according to the tokens that are allocated in the Rete network for the given production(s). This number is a function of the number of elements in working memory that match each production. Therefore, this command will not provide useful information at the beginning of a Soar run (when working memory is empty) and should be called in the middle (or at the end) of a Soar run.</p> <p>The <code>memory-usage</code> command is used to find the productions that are using the most memory and, therefore, may be taking the longest time to match (this is only a heuristic). By identifying these productions, you may be able to rewrite your program so that it will run more quickly. Note that memory usage is just a heuristic measure of the match time: A production might not use much memory relative to others but may still be time-consuming to match, and excising a production that uses a large number of tokens may not speed up your program, because the Rete matcher shares common structure among different productions.</p> <p>As a rule of thumb, numbers less than 100 mean that the production is using a small amount of memory, numbers above 1000 mean that the production is using a large amount of memory, and numbers above 10,000 mean that the production is using a very large amount of memory.</p>"},{"location":"reference/cli/cmd_production/#production-optimize-attribute","title":"production optimize-attribute","text":"<p>Declare a symbol to be multi-attributed so that conditions in productions that test that attribute are re-ordered so that the rule can be matched more efficiently.</p>"},{"location":"reference/cli/cmd_production/#synopsis_7","title":"Synopsis","text":"<pre><code>production optimize-attribute [symbol [n]]\n</code></pre>"},{"location":"reference/cli/cmd_production/#options_6","title":"Options:","text":"Option Description <code>symbol</code> Any Soar attribute. <code>n</code> Integer greater than 1, estimate of degree of simultaneous values for attribute."},{"location":"reference/cli/cmd_production/#description_3","title":"Description:","text":"<p>This command is used to improve efficiency of matching against attributes that can have multiple values at once. <pre><code>(S1 ^foo bar1)\n(S1 ^foo bar2)\n(S1 ^foo bar3)\n</code></pre> If you know that a certain attribute will take on multiple values, <code>optimize-attribute</code> can be used to provide hints to the production condition reorderer so that it can produce better orderings that allow the Rete network to match faster. This command has no effect on the actual contents of working memory and is only used to improve efficiency in problematic situations.</p> <p><code>optimize-attribute</code> declares a symbol to be an attribute which can take on multiple values. The optional <code>n</code> is an integer (greater than 1) indicating an upper limit on the number of expected values that will appear for an attribute. If <code>n</code> is not specified, the value 10 is used for each declared multi-attribute. More informed values will tend to result in greater efficiency.</p> <p>Note that <code>optimize-attribute</code> declarations must be made before productions are loaded into soar or this command will have no effect.</p>"},{"location":"reference/cli/cmd_production/#example","title":"Example:","text":"<p>Declare the symbol \"thing\" to be an attribute likely to take more than 1 but no more than 4 values:</p> <pre><code>production optimize-attribute thing 4\n</code></pre>"},{"location":"reference/cli/cmd_production/#production-watch","title":"production watch","text":"<p>Trace firings and retractions of specific productions.</p>"},{"location":"reference/cli/cmd_production/#synopsis_8","title":"Synopsis","text":"<pre><code>production watch [-d|e] [production name]\n</code></pre>"},{"location":"reference/cli/cmd_production/#options_7","title":"Options:","text":"Option Description <code>-d, --disable, --off</code> Turn production watching off for the specified production. If no production is specified, turn production watching off for all productions. <code>-e, --enable, --on</code> Turn production watching on for the specified production. The use of this flag is optional, so this is watch's default behavior. If no production is specified, all productions currently being watched are listed. <code>production name</code> The name of the production to watch."},{"location":"reference/cli/cmd_production/#description_4","title":"Description","text":"<p>The <code>production watch</code> command enables and disables the tracing of the firings and retractions of individual productions. This is a companion command to watch, which cannot specify individual productions by name.</p> <p>With no arguments, production watch lists the productions currently being traced. With one production-name argument, production watch enables tracing the production; <code>--enable</code> can be explicitly stated, but it is the default action.</p> <p>If <code>--disable</code> is specified followed by a production-name, tracing is turned off for the production. When no production-name is specified, <code>--enable</code> lists all productions currently being traced, and <code>--disable</code> disables tracing of all productions.</p> <p>Note that <code>production watch</code> now only takes one production per command. Use multiple times to watch multiple functions.</p>"},{"location":"reference/cli/cmd_production/#default-aliases","title":"Default Aliases","text":"<pre><code>ex                         production excise\nexcise                     production excise\nfc                         production firing-counts\nfiring-counts              production firing-counts\nmatches                    production matches\nmemories                   production memory-usage\nmulti-attributes           production optimize-attribute\npbreak                     production break\nproduction-find            production find\npw                         production watch\npwatch                     production watch\n</code></pre>"},{"location":"reference/cli/cmd_production/#see-also","title":"See Also","text":"<p>soar init sp trace</p>"},{"location":"reference/cli/cmd_rl/","title":"rl","text":""},{"location":"reference/cli/cmd_rl/#rl","title":"rl","text":"<p>Control how numeric indifferent preference values in RL rules are updated via reinforcement learning.</p>"},{"location":"reference/cli/cmd_rl/#synopsis","title":"Synopsis","text":"<pre><code>rl -g|--get &lt;parameter&gt;\nrl -s|--set &lt;parameter&gt; &lt;value&gt;\nrl -t|--trace &lt;parameter&gt; &lt;value&gt;\nrl -S|--stats &lt;statistic&gt;\n</code></pre>"},{"location":"reference/cli/cmd_rl/#options","title":"Options:","text":"Option Description <code>-g, --get</code> Print current parameter setting <code>-s, --set</code> Set parameter value <code>-t, --trace</code> Print, clear, or init traces <code>-S, --stats</code> Print statistic summary or specific statistic"},{"location":"reference/cli/cmd_rl/#description","title":"Description","text":"<p>The <code>rl</code> command sets parameters and displays information related to reinforcement learning.  The <code>print</code> and <code>trace</code> commands display additional RL related information not covered by this command.</p>"},{"location":"reference/cli/cmd_rl/#parameters","title":"Parameters","text":"<p>Due to the large number of parameters, the <code>rl</code> command uses the <code>--get|--set &lt;parameter&gt; &lt;value&gt;</code> convention rather than individual switches for each parameter.  Running <code>rl</code> without any switches displays a summary of the parameter settings.</p> Parameter Description Possible values Default chunk-stop If enabled, chunking does not create duplicate RL rules that differ only in numeric-indifferent preference value <code>on</code>, <code>off</code> <code>on</code> decay-mode How the learning rate changes over time <code>normal</code>, <code>exponential</code>, <code>logarithmic</code>, <code>delta-bar-delta</code> <code>normal</code> discount-rate Temporal discount (gamma) <code>[</code>0, 1<code>]</code> 0.9 eligibility-trace-decay-rate Eligibility trace decay factor (lambda) <code>[</code>0, 1<code>]</code> 0 eligibility-trace-tolerance Smallest eligibility trace value not considered 0 (0, inf) 0.001 hrl-discount Discounting of RL updates over time in impassed states <code>on</code>, <code>off</code> <code>off</code> learning Reinforcement learning enabled <code>on</code>, <code>off</code> <code>off</code> learning-rate Learning rate (alpha) <code>[</code>0, 1<code>]</code> 0.3 step-size-parameter Secondary learning rate <code>[</code>0,1<code>]</code> 1 learning-policy Value update policy <code>sarsa</code>, <code>q-learning</code>, <code>off-policy-gq-lambda</code>, <code>on-policy-gq-lambda</code> <code>sarsa</code> meta Store rule metadata in header string <code>on</code>, <code>off</code> <code>off</code> meta-learning-rate Delta-Bar-Delta learning parameter <code>[</code>0, 1<code>]</code> 0.1 temporal-discount Discount RL updates over gaps <code>on</code>, <code>off</code> <code>on</code> temporal-extension Propagation of RL updates over gaps <code>on</code>, <code>off</code> <code>on</code> trace Update the trace <code>on</code>, <code>off</code> <code>off</code> update-log-path File to log information about RL rule updates <code>\"\"</code>, <code>&lt;filename&gt;</code> <code>\"\"</code>"},{"location":"reference/cli/cmd_rl/#apoptosis-parameters","title":"Apoptosis Parameters:","text":"Parameter Description Possible values Default <code>apoptosis</code> Automatic excising of productions via base-level decay <code>none</code>, <code>chunks</code>, <code>rl-chunks</code> <code>none</code> <code>apoptosis-decay</code> Base-level decay parameter <code>[</code>0, 1<code>]</code> 0.5 <code>apoptosis-thresh</code> Base-level threshold parameter (negates supplied value) (0, inf) 2 <p>Apoptosis is a process to automatically excise chunks via the base-level decay model (where rule firings are the activation events). A value of <code>chunks</code> has this apply to any chunk, whereas <code>rl-chunks</code> means only chunks that are also RL rules can be forgotten.</p>"},{"location":"reference/cli/cmd_rl/#rl-statistics","title":"RL Statistics","text":"<p>Soar tracks some RL statistics over the lifetime of the agent. These can be accessed using <code>rl --stats &lt;statistic&gt;</code>. Running <code>rl --stats</code> without a statistic will list the values of all statistics.</p> Option Description <code>update-error</code> Difference between target and current values in last RL update <code>total-reward</code> Total accumulated reward in the last update <code>global-reward</code> Total accumulated reward since agent initialization"},{"location":"reference/cli/cmd_rl/#rl-delta-bar-delta","title":"RL Delta-Bar-Delta","text":"<p>This is an experimental feature of Soar RL. It based on the work in Richard S. Sutton's paper \"Adapting Bias by Gradient Descent: An Incremental Version of Delta-Bar-Delta\", available online at http://incompleteideas.net/papers/sutton-92a.pdf. Delta Bar Delta (DBD) is implemented in Soar RL as a decay mode. It changes the way all the rules in the eligibility trace get their values updated. In order to implement this, the agent gets an additional learning parameter <code>meta-learning-rate</code> and each rule gets two additional decay parameters: beta and h. The meta learning rate is set manually; the per-rule features are handled automatically by the DBD algorithm. The key idea is that the meta parameters keep track of how much a rule's RL value has been updated recently, and if a rule gets updates in the same direction multiple times in a row then subsequent updates in the same direction will have more effect. So DBD acts sort of like momentum for the learning rate.</p> <p>To enable DBD, use <code>rl --set decay-mode delta-bar-delta</code>. To change the meta learning rate, use e.g. <code>rl --set meta-learning-rate 0.1</code>. When you execute <code>rl</code>, under the \"Experimental\" section of output you'll see the current settings for <code>decay-mode</code> and <code>meta-learning-rate</code>. Also, if a rule gets printed concisely (e.g. by executing <code>p</code>), and the rule is an RL rule, and the decay mode is set to delta-bar-delta, then instead of printing the rule name followed by the update count and the RL value, it will print the rule name, beta, h, update count, and RL value.</p> <p>Note that DBD is a different feature than <code>meta</code>. Meta determines whether metadata about a production is stored in its header string. If meta is on and DBD is on, then each rule's beta and h values will be stored in the header string in addition to the update count, so you can print out the rule, source it later and that metadata about the rule will still be in place.</p>"},{"location":"reference/cli/cmd_rl/#rl-gqlambda","title":"RL GQ(\\(\\lambda\\))","text":"<p>Linear GQ(\\(\\lambda\\)) is a gradient-based off-policy temporal-difference learning algorithm, as developed by Hamid Maei and described by Adam White and Rich Sutton (https://arxiv.org/pdf/1705.03967.pdf). This reinforcement learning option provides off-policy learning quite effectively. This is a good approach in cases when agent training performance is less important than agent execution performance. GQ(\\(\\lambda\\)) converges despite irreversible actions and other difficulties approaching the training goal. Convergence should be guaranteed for stable environments.</p> <p>To change the secondary learning rate that only applies when learning with GQ(\\(\\lambda\\)), set the rl <code>step-size-parameter</code>. It controls how fast the secondary set of weights changes to allow GQ(\\(\\lambda\\)) to improve the rate of convergence to a stable policy. Small learning rates such as 0.01 or even lower seems to be good practice.</p> <p><code>rl --set learning-policy off-policy-gq-lambda</code> will set Soar to use linear GQ(\\(\\lambda\\)). It is preferable to use GQ(\\(\\lambda\\)) over sarsa or q-learning when multiple weights are active in parallel and sequences of actions required for agents to be successful are sufficiently complex that divergence is possible. To take full advantage of GQ(\\(\\lambda\\)), it is important to set <code>step-size-parameter</code> to a reasonable value for a secondary learning rate, such as 0.01.</p> <p><code>rl --set learning-policy on-policy-gq-lambda</code> will set Soar to use a simplification of GQ(\\(\\lambda\\)) to make it on-policy while otherwise functioning identically. It is still important to set <code>step-size-parameter</code> to a reasonable value for a secondary learning rate, such as 0.01.</p> <p>For more information, please see the relevant slides on http://www-personal.umich.edu/~bazald/b/publications/009-sw35-gql.pdf</p>"},{"location":"reference/cli/cmd_rl/#rl-update-logging","title":"RL Update Logging","text":"<p>Sets a path to a file that Soar RL will write to whenever a production's RL value gets updated. This can be useful for logging these updates without having to capture all of Soar's output and parse it for these updates. Enable with e.g. <code>rl --set update-log-path rl\\_log.txt</code>. Disable with <code>rl --set update-log-path \"\"</code> - that is, use the empty string \"\" as the log path. The current log path appears under the experimental section when you execute \"rl\".</p>"},{"location":"reference/cli/cmd_rl/#rl-trace","title":"RL Trace","text":"<p>If <code>rl --set trace on</code> has been called, then proposed operators will be recorded in the trace for all goal levels. Along with operator names and other attribute-value pairs, transition probabilities derived from their numeric preferences are recorded.</p> <p>Legal arguments following <code>rl -t</code> or <code>rl --trace</code> are as follows:</p> Option Description <code>print</code> Print the trace for the top state. <code>clear</code> Erase the traces for all goal levels. <code>init</code> Restart recording from the beginning of the traces for all goal levels. <p>These may be followed by an optional numeric argument specifying a specific goal level to print, clear, or init. <code>rl -t init</code> is called automatically whenever Soar is reinitialized. However, <code>rl -t clear</code> is never called automatically.</p> <p>The format in which the trace is printed is designed to be used by the program dot, as part of the Graphviz suite. The command <code>ctf rl.dot rl -t</code> will print the trace for the top state to the file \"rl.dot\". (The default behavior for <code>rl -t</code> is to print the trace for the top state.)</p> <p>Here are some sample dot invocations for the top state:</p> Option Description <code>dot -Tps rl.dot -o rl.ps</code> <code>ps2pdf rl.ps</code> <code>dot -Tsvg rl.dot -o rl.svg</code> <code>inkscape -f rl.svg -A rl.pdf</code> <p>The .svg format works better for large traces.</p>"},{"location":"reference/cli/cmd_rl/#see-also","title":"See Also","text":"<p>excise print trace</p>"},{"location":"reference/cli/cmd_run/","title":"run","text":""},{"location":"reference/cli/cmd_run/#run","title":"run","text":"<p>Begin Soar's execution cycle.</p>"},{"location":"reference/cli/cmd_run/#synopsis","title":"Synopsis","text":"<pre><code>run -[d|e|o|p][g][u|n][s] [count] [-i e|p|d|o]\n</code></pre>"},{"location":"reference/cli/cmd_run/#options","title":"Options","text":"Option Description <code>-d, --decision</code> Run Soar for count decision cycles. <code>-e, --elaboration</code> Run Soar for count elaboration cycles. <code>-o, --output</code> Run Soar until the nth time output is generated by the agent. Limited by the value of max-nil-output-cycles. <code>-p, --phase</code> Run Soar by phases. A phase is either an input phase, proposal phase, decision phase, apply phase, or output phase. <code>-s, --self</code> If other agents exist within the kernel, do not run them at this time. <code>-u, --update</code> Sets a flag in the update event callback requesting that an environment updates. This is the default if <code>--self</code> is not specified. <code>-n, --noupdate</code> Sets a flag in the update event callback requesting that an environment does not update. This is the default if <code>--self</code> is specified. <code>count</code> A single integer which specifies the number of cycles to run Soar. <code>-i, --interleave</code> Support round robin execution across agents at a finer grain than the run-size parameter. <code>e</code> = elaboration, <code>p</code> = phase, <code>d</code> = decision, <code>o</code> = output <code>-g, --goal</code> Run agent until a goal retracts"},{"location":"reference/cli/cmd_run/#deprecated-run-options","title":"Deprecated Run Options:","text":"<p>These may be reimplemented in the future.</p> Option Description <code>--operator</code> Run Soar until the nth time an operator is selected. <code>--state</code> Run Soar until the nth time a state is selected."},{"location":"reference/cli/cmd_run/#description","title":"Description","text":"<p>The <code>run</code> command starts the Soar execution cycle or continues any execution that was temporarily stopped. The default behavior of run, with no arguments, is to cause Soar to execute until it is halted or interrupted by an action of a production, or until an external interrupt is issued by the user. The <code>run</code> command can also specify that Soar should run only for a specific number of Soar cycles or phases (which may also be prematurely stopped by a production action or the stop-soar command). This is helpful for debugging sessions, where users may want to pay careful attention to the specific productions that are firing and retracting.</p> <p>The <code>run</code> command takes optional arguments: an integer, <code>count</code>, which specifies how many units to run; and a <code>units</code> flag indicating what steps or increments to use. If <code>count</code> is specified, but no <code>units</code> are specified, then Soar is run by decision cycles. If <code>units</code> are specified, but <code>count</code> is unpecified, then <code>count</code> defaults to '1'. If both are unspecified, Soar will run until either a <code>halt</code> is executed, an interrupt is received, or max stack depth is reached.</p> <p>If there are multiple Soar agents that exist in the same Soar process, then issuing a run command in any agent will cause all agents to run with the same set of parameters, unless the flag <code>--self</code> is specified, in which case only that agent will execute.</p> <p>If an environment is registered for the kernel's update event, then when the event it triggered, the environment will get information about how the run was executed. If a run was executed with the <code>--update</code> option, then then event sends a flag requesting that the environment actually update itself. If a run was executed with the --noupdate option, then the event sends a flag requesting that the environment not update itself. The <code>--update</code> option is the default when run is specified without the <code>--self</code> option is not specified. If the <code>--self</code> option is specified, then the <code>--noupdate</code> option is on by default. It is up to the environment to check for these flags and honor them.</p> <p>Some use cases include:</p> Option Description <code>run --self</code> runs one agent but not the environment <code>run --self --update</code> runs one agent and the environment <code>run</code> runs all agents and the environment <code>run --noupdate</code> runs all agents but not the environment"},{"location":"reference/cli/cmd_run/#setting-an-interleave-size","title":"Setting an interleave size","text":"<p>When there are multiple agents running within the same process, it may be useful to keep agents more closely aligned in their execution cycle than the run increment (<code>--elaboration, --phases, --decisions, --output</code>) specifies. For instance, it may be necessary to keep agents in \"lock step\" at the phase level, even though the run command issued is for 5 decisions. Some use cases include:</p> Option Description <code>run -d 5 -i p</code> run the agent one phase and then move to the next agent, looping over agents until they have run for 5 decision cycles <code>run -o 3 -i d</code> run the agent one decision cycle and then move to the next agent. When an agent generates output for the 3rd time, it no longer runs even if other agents continue. <p>The <code>interleave</code> parameter must always be equal to or smaller than the specified run parameter.</p>"},{"location":"reference/cli/cmd_run/#note","title":"Note","text":"<p>If Soar has been stopped due to a <code>halt</code> action, an init-soar command must be issued before Soar can be restarted with the run command.</p>"},{"location":"reference/cli/cmd_run/#default-aliases","title":"Default Aliases","text":"<pre><code>d             run -d 1\ne             run -e 1\nstep          run -d 1\n</code></pre>"},{"location":"reference/cli/cmd_save/","title":"save","text":""},{"location":"reference/cli/cmd_save/#save","title":"save","text":"<p>Saves chunks, rete networks and percept streams.</p>"},{"location":"reference/cli/cmd_save/#synopsis","title":"Synopsis","text":"<pre><code>======================================================\n-            Save Sub-Commands and Options           -\n======================================================\nsave [? | help]\n------------------------------------------------------\nsave agent                           &lt;filename&gt;\nsave chunks                          &lt;filename&gt;\n------------------------------------------------------\nsave percepts                        --open &lt;filename&gt;\nsave percepts                        [--close --flush]\n------------------------------------------------------\nsave rete-network                    --save &lt;filename&gt;\n------------------------------------------------------\nFor a detailed explanation of sub-commands:  help save\n</code></pre>"},{"location":"reference/cli/cmd_save/#save-agent","title":"save agent","text":"<p>The <code>save agent</code> command will write all procedural and semantic memory to disk, as well as many commonly used settings. This command creates a standard <code>.soar</code> text file, with semantic memory stored as a series of <code>smem --add</code> commands.</p>"},{"location":"reference/cli/cmd_save/#save-chunks","title":"save chunks","text":"<p>The <code>save chunks</code> command will write all chunks in memory to disk. This command creates a standard <code>.soar</code> text file.  </p>"},{"location":"reference/cli/cmd_save/#save-rete-network","title":"save rete-network","text":"<p>The <code>save rete-network</code> command saves the current Rete net to a file. The Rete net is Soar's internal representation of production memory; the conditions of productions are reordered and common substructures are shared across different productions. This command provides a fast method of saving and loading productions since a special format is used and no parsing is necessary. Rete-net files are portable across platforms that support Soar.</p> <p>Note that justifications cannot be present when saving the Rete net. Issuing a production excise -j before saving a Rete net will remove all justifications.</p> <p>If the filename contains a suffix of <code>.Z</code>, then the file is compressed automatically when it is saved and uncompressed when it is loaded. Compressed files may not be portable to another platform if that platform does not support the same uncompress utility.</p>"},{"location":"reference/cli/cmd_save/#usage","title":"Usage:","text":"<pre><code>save rete-network -s &lt;filename&gt;\n</code></pre>"},{"location":"reference/cli/cmd_save/#save-percepts","title":"save percepts","text":"<p>Store all incoming input wmes in a file for reloading later. Commands are recorded decision cycle by decision cycle. Use the command load percepts to replay the sequence.</p> <p>Note that this command seeds the random number generator and writes the seed to the capture file.</p>"},{"location":"reference/cli/cmd_save/#options","title":"Options:","text":"Option Description <code>filename</code> Open filename and begin recording input. <code>-o, --open</code> Writes captured input to file overwriting any existing data. <code>-f, --flush</code> Writes input to file as soon as it is encountered instead of storing it in RAM and writing when capturing is turned off. <code>-c, --close</code> Stop capturing input and close the file, writing captured input unless the flush option is given."},{"location":"reference/cli/cmd_save/#usage_1","title":"Usage","text":"<pre><code>save percepts -o &lt;filename&gt;\n...\nsave percepts -c\n</code></pre>"},{"location":"reference/cli/cmd_save/#default-aliases","title":"Default Aliases","text":"<pre><code>capture-input        save percepts\n</code></pre>"},{"location":"reference/cli/cmd_save/#see-also","title":"See Also","text":"<p>production soar load</p>"},{"location":"reference/cli/cmd_smem/","title":"smem","text":""},{"location":"reference/cli/cmd_smem/#smem","title":"smem","text":"<p>Controls the behavior of and displays information about semantic memory. </p>"},{"location":"reference/cli/cmd_smem/#synopsis","title":"Synopsis","text":"<pre><code>=======================================================\n-             Semantic Memory Sub-Commands            -\n=======================================================\nsmem [? | help]                                           Print help screen\nsmem [--enable | --disable ]                              Turn smem on/off\nsmem [--get | --set]                 &lt;option&gt; [&lt;value&gt;]   Print or set a parameter\nsmem --add                        { (id ^attr value)* }   Add memory to smem\nsmem --backup                                &lt;filename&gt;   Save copy of database\nsmem --clear                                              Delete contents of smem\nsmem --export                        &lt;filename&gt; [&lt;LTI&gt;]   Save database to file\nsmem --init                                               Reinit smem store\nsmem --query                           {(cue)* [&lt;num&gt;]}   Query smem via given cue\nsmem --remove                 { (id [^attr [value]])* }   Remove smem structures\n------------------------ Printing ---------------------\nprint                                                 @   Print all smem contents\nprint                                             &lt;LTI&gt;   Print specific smem memory\nsmem --history                                    &lt;LTI&gt;   Print memory activation history\n=======================================================\n-        Semantic Memory Parameters  (use --set)      -\n=======================================================\nenabled                                             off\ndatabase                              [ MEMORY | file ]   Store database in memory or file\nappend                                               on   Append or overwrite after init\npath                                                      Path to database on disk\n---------------------- Activation ---------------------\nactivation-mode    [ RECENCY | frequency | base-level ]   \nactivate-on-query                          [ ON | off ]\nbase-decay                                          0.5   Decay amount for base-level activation\nbase-update-policy     [ STABLE | naive | incremental ]   \nbase-incremental-threshes                            10   Integer &gt; 0\nthresh                                              100   Integer &gt;= 0\nbase-inhibition                            [ on | OFF ]   \n---------- Experimental Spreading Activation ----------\nspreading                                  [ on | OFF ]   \nspreading-limit                                     300   integer &gt; 0\nspreading-depth-limit                                10   integer &gt; 0\nspreading-baseline                               0.0001   1 &gt; decimal &gt; 0\nspreading-continue-probability                      0.9   1 &gt; decimal &gt; 0\nspreading-loop-avoidance                   [ on | OFF ]\nspreading-edge-updating                    [ on | OFF ]\nspreading-wma-source                       [ on | OFF ]\nspreading-edge-update-factor                       0.99   1 &gt; decimal &gt; 0\n------------- Database Optimization Settings ----------\nlazy-commit                                          on   Delay writing store until exit\noptimization                   [ safety | PERFORMANCE ]   \ncache-size                                        10000   Number of memory pages for SQLite cache\npage-size                                            8k   Size of each memory page\n----------------- Timers and Statistics ---------------\ntimers                      [ OFF | one | two | three ]   How detailed timers should be\nsmem --timers                                 [&lt;timer&gt;]   Print summary or specifics\nsmem --stats                                   [&lt;stat&gt;]   Print summary or specifics\n                  ---------------------\nTimers: smem_api, smem_hash, smem_init, smem_query,\n        smem_ncb_retrieval, three_activation\n        smem_storage, _total\nStats:  act_updates, db-lib-version, edges, mem-usage,\n        mem-high, nodes, queries, retrieves, stores\n-------------------------------------------------------\nFor a detailed explanation of these settings:             help smem\n</code></pre>"},{"location":"reference/cli/cmd_smem/#summary-output","title":"Summary Output","text":"<p>With no arguments, <code>smem</code> will return a quick summary of key aspects of semantic memory. <pre><code>====================================================\n              Semantic Memory Summary\n====================================================\nEnabled                                          off\nStorage                                       Memory   (append after init)\n----------------------------------------------------\nNodes                                              2\nEdges                                              1\nMemory Usage                                  406784   bytes\n----------------------------------------------------\nFor a full list of smem's sub-commands and settings:  smem ?\n</code></pre></p>"},{"location":"reference/cli/cmd_smem/#options","title":"Options:","text":"Commands Description <code>-e, --enable, --on</code> Enable semantic memory. <code>-d, --disable, --off</code> Disable semantic memory. <code>-g, --get</code> Print current parameter setting <code>-s, --set</code> Set parameter value <code>-c, --clear</code> Deletes all memories <code>-x, --export</code> Creates an agent-sourceable copy of semantic memory on disk <code>-i, --init</code> Deletes all memories if append is off <code>-S, --stats</code> Print statistic summary or specific statistic <code>-t, --timers</code> Print timer summary or specific statistic <code>-a, --add</code> Add concepts to semantic memory <code>-r, --remove</code> Remove concepts from semantic memory <code>-q, --query</code> Print concepts in semantic store matching some cue <code>-h, --history</code> Print activation history for some LTI <code>-b, --backup</code> Creates a backup of the semantic database on disk"},{"location":"reference/cli/cmd_smem/#printing","title":"Printing","text":"<p>To print from semantic memory, the standard print command can be used, for example, to print a specific LTI:</p> <p><code>p @23</code></p> <p>To print the entire semantic store:</p> <p><code>p @</code></p> <p>Note that such print commands will honor the --depth parameter passed in.</p> <p>The command <code>trace --smem</code> displays additional trace information for semantic memory not controlled by this command.</p>"},{"location":"reference/cli/cmd_smem/#parameters","title":"Parameters","text":"<p>Due to the large number of parameters, the <code>smem</code> command uses the  <code>--get|--set &lt;parameter&gt; &lt;value&gt;</code> convention rather than individual switches for each parameter.  Running <code>smem</code> without any switches displays a summary of the parameter settings.</p> Parameter Description Possible values Default <code>append</code> Controls whether database is overwritten or appended when opening or re-initializing <code>on</code>, <code>off</code> <code>off</code> <code>database</code> Database storage method <code>file</code>, <code>memory</code> <code>memory</code> <code>learning</code> Semantic memory enabled <code>on</code>, <code>off</code> <code>off</code> <code>path</code> Location of database file empty, some path empty <p>The <code>learning</code> parameter turns the semantic memory module on or off. This is the same as using the enable and disable commands.</p> <p>The <code>path</code> parameter specifies the file system path the database is stored in. When <code>path</code> is set to a valid file system path and database mode is set to file, then the SQLite database is written to that path.</p> <p>The <code>append</code> parameter will determine whether all existing facts stored in a database on disk will be erased when semantic memory loads. Note that this affects semantic memory re-initialization also, i.e. if the append setting is off, all semantic facts stored to disk will be lost when a <code>soar init</code> is performed. For semantic memory, <code>append</code> mode is by default on.</p> <p>Note that changes to database, <code>path</code> and <code>append</code> will not have an effect until the database is used after an initialization.  This happens either shortly after launch (on first use) or after a database initialization command is issued.  To switch databases or database storage types while running, set your new parameters and then perform an <code>smem --init</code> command.</p>"},{"location":"reference/cli/cmd_smem/#activation-parameters","title":"Activation Parameters:","text":"Parameter Description Possible values Default activation-mode Sets the ordering bias for retrievals that match more than one memory <code>recency</code>, <code>frequency</code>, <code>base-level</code> <code>recency</code> activate-on-query Determines if the results of queries should be activated <code>on</code>, <code>off</code> <code>on</code> base-decay Sets the decay parameter for base-level activation computation <code>&gt;</code> 0 0.5 base-update-policy Sets the policy for re-computing base-level activation <code>stable</code>, <code>naive</code>, <code>incremental</code> <code>stable</code> base-incremental-threshes Sets time deltas after which base-level activation is re-computed for old memories 1, 2, 3, ... 10 thresh Threshold for activation locality 0, 1, ... 100 base-inhibition Sets whether or not base-level activation has a short-term inhibition factor. <code>on</code>, <code>off</code> <code>off</code> <p>If <code>activation-mode</code> is <code>base-level</code>, three parameters control bias values. The <code>base-decay</code> parameter sets the free decay parameter in the base-level model. Note that we do implement the (Petrov, 2006) approximation, with a history size set as a compile-time parameter (default=10). The <code>base-update-policy</code> sets the frequency with which activation is recomputed. The default, <code>stable</code>, only recomputes activation when a memory is referenced (through storage or retrieval). The <code>naive</code> setting will update the entire candidate set of memories (defined as those that match the most constraining cue WME) during a retrieval, which has severe performance detriment and should be used for experimentation or those agents that require high-fidelity retrievals. The <code>incremental</code> policy updates a constant number of memories, those with last-access ages defined by the <code>base-incremental-threshes</code> set. The <code>base-inhibition</code> parameter switches an additional prohibition factor <code>on</code> or <code>off</code>.</p>"},{"location":"reference/cli/cmd_smem/#performance-parameters","title":"Performance Parameters:","text":"Parameter Description Possible values Default cache-size Number of memory pages used in the SQLite cache 1, 2, ... 10000 lazy-commit Delay writing semantic store changes to file until agent exits <code>on</code>, <code>off</code> <code>on</code> optimization Policy for committing data to disk <code>safety</code>, <code>performance</code> <code>performance</code> page-size Size of each memory page used in the SQLite cache 1k, 2k, 4k, 8k, 16k, 32k, 64k 8k timers Timer granularity <code>off</code>, <code>one</code>, <code>two</code>, <code>three</code> <code>off</code> <p>When the database is stored to disk, the <code>lazy-commit</code> and <code>optimization</code> parameters control how often cached database changes are written to disk.  These parameters trade off safety in the case of a program crash with database performance.  When <code>optimization</code> is set to <code>performance</code>, the agent will have an exclusive lock on the database, meaning it cannot be opened concurrently by another SQLite process such as SQLiteMan.  The lock can be relinquished by setting the database to memory or another database and issuing init-soar/<code>smem --init</code> or by shutting down the Soar kernel.</p>"},{"location":"reference/cli/cmd_smem/#statistics","title":"Statistics","text":"<p>Semantic memory tracks statistics over the lifetime of the agent. These can be accessed using <code>smem --stats &lt;statistic&gt;</code>.  Running <code>smem --stats</code> without a statistic will list the values of all statistics.  Unlike timers, statistics will always be updated. </p> <p>Available statistics are:</p> Name Label Description <code>act_updates</code> Activation Updates Number of times memory activation has been calculated <code>db-lib-version</code> SQLite Version SQLite library version <code>edges</code> Edges Number of edges in the semantic store <code>mem-usage</code> Memory Usage Current SQLite memory usage in bytes <code>mem-high</code> Memory Highwater High SQLite memory usage watermark in bytes <code>nodes</code> Nodes Number of nodes in the semantic store <code>queries</code> Queries Number of times the query command has been issued <code>retrieves</code> Retrieves Number of times the retrieve command has been issued <code>stores</code> Stores Number of times the store command has been issued"},{"location":"reference/cli/cmd_smem/#timers","title":"Timers","text":"<p>Semantic memory also has a set of internal timers that record the durations of certain operations.  Because fine-grained timing can incur runtime costs, semantic memory timers are off by default. Timers of different levels of detail can be turned on by issuing <code>smem --set timers &lt;level&gt;</code>, where the levels can be <code>off</code>, <code>one</code>, <code>two</code>, or <code>three</code>, <code>three</code> being most detailed and resulting in all timers being turned on.  Note that none of the semantic memory statistics nor timing information is reported by the <code>stats</code> command.</p> <p>All timer values are reported in seconds.</p> <p>Level one</p> Timer Description <code>_total</code> Total smem operations <p>Level two</p> Timer Description <code>smem_api</code> Agent command validation <code>smem_hash</code> Hashing symbols <code>smem_init</code> Semantic store initialization <code>smem_ncb_retrieval</code> Adding concepts (and children) to working memory <code>smem_query</code> Cue-based queries <code>smem_storage</code> Concept storage <p>Level three</p> Timer Description three_activation Recency information maintenance"},{"location":"reference/cli/cmd_smem/#smem-add","title":"smem --add","text":"<p>Concepts can be manually added to the semantic store using the <code>smem --add &lt;concept&gt;</code> command.  The format for specifying the concept is similar to that of adding WMEs to working memory on the RHS of productions. For example:</p> <pre><code>smem --add {\n   (&lt;arithmetic&gt; ^add10-facts &lt;a01&gt; &lt;a02&gt; &lt;a03&gt;)\n   (&lt;a01&gt; ^digit1 1 ^digit-10 11)\n   (&lt;a02&gt; ^digit1 2 ^digit-10 12)\n   (&lt;a03&gt; ^digit1 3 ^digit-10 13)\n}\n</code></pre> <p>Although not shown here, the common \"dot-notation\" format used in writing productions can also be used for this command. Unlike agent storage, manual storage is automatically recursive. Thus, the above example will add a new concept (represented by the temporary \"arithmetic\" variable) with three children.  Each child will be its own concept with two constant attribute/value pairs.</p>"},{"location":"reference/cli/cmd_smem/#smem-remove","title":"smem --remove","text":"<p>Part or all of the information in the semantic store of some LTI can be manually removed from the semantic store using the</p> <pre><code>smem --remove &lt;concept&gt;\n</code></pre> <p>command. The format for specifying what to remove is similar to that of adding WMEs to working memory on the RHS of productions.  For example: <pre><code>smem --remove {\n   (@34 ^good-attribute |gibberish value|)\n}\n</code></pre> If <code>good-attribute</code> is multi-valued, then all values will remain in the store except <code>|gibberish value|</code>. If <code>|gibberish value|</code> is the only value, then <code>good-attribute</code> will also be removed. It is not possible to use the common \"dot-notation\" for this command. Manual removal is not recursive.</p> <p>Another example highlights the ability to remove all of the values for an attribute: <pre><code>smem --remove {\n   (@34 ^bad-attribute)\n}\n</code></pre> When a value is not given, all of the values for the given attribute are removed from the LTI in the semantic store.</p> <p>Also, it is possible to remove all augmentations of some LTI from the semantic store: <pre><code>smem --remove {\n   (@34)\n}\n</code></pre> This would remove all attributes and values of <code>@34</code> from the semantic store. The LTI will remain in the store, but will lack augmentations.</p> <p>(Use the following at your own risk.)  Optionally, the user can force removal even in the event of an error: <pre><code>smem -r {(@34 ^bad-attribute ^bad-attribute-2)} force\n</code></pre> Suppose that LTI <code>@34</code> did not contain <code>bad-attribute</code>. The above example would remove <code>bad-attribute-2</code> even though it would indicate an error (having not found <code>bad-attribute</code>).</p>"},{"location":"reference/cli/cmd_smem/#smem-query","title":"smem --query","text":"<p>Queries for LTIs in the semantic store that match some cue can be initialized external to an agent using the <code>smem --query &lt;cue&gt; [&lt;num&gt;]</code> command. The format for specifying the cue is similar to that of adding a new identifier to working memory in the RHS of a rule: <pre><code>smem --query {\n    (&lt;cue&gt; ^attribute &lt;wildcard&gt; ^attribute-2 |constant|)\n}\n</code></pre> Note that the root of the cue structure must be a variable and should be unused in the rest of the cue structure. This command is for testing and the full range of queries accessible to the agent are not yet available for the command. For example, math queries are not supported.</p> <p>The additional option of <code>&lt;num&gt;</code> will trigger the display of the top <code>&lt;num&gt;</code> most activated LTIs that matched the cue.</p> <p>The result of a manual query is either to print that no LTIs could be found or to print the information associated with LTIs that were found in the <code>print &lt;lti&gt;</code> format.</p>"},{"location":"reference/cli/cmd_smem/#smem-history","title":"smem --history","text":"<p>When the activation-mode of a semantic store is set to base-level, some history of activation events is stored for each LTI. This history of when some LTI was activated can be displayed: <pre><code>        smem --history @34\n</code></pre> In the event that semantic memory is not using base-level activation, <code>history</code> will mimic <code>print</code>.</p>"},{"location":"reference/cli/cmd_smem/#experimental-spreading-activation","title":"Experimental Spreading Activation","text":"Parameter Description Possible values Default spreading Controls whether spreading activation is on or off. <code>on</code>, <code>off</code> <code>off</code> spreading-limit Limits amount of spread from any LTI 0, 1, ... 300 spreading-depth-limit Limits depth of spread from any LTI 0, 1, ..., 10 10 spreading-baseline Gives minimum to spread values. 0, ..., 1 0.0001 spreading-continue-probability Gives 1 - (decay factor of spread with distance) 0, ..., 1 0.9 spreading-loop-avoidance Controls whether spread traversal avoids self-loops <code>on</code>, <code>off</code> <code>off</code> <p>Spreading activation has been added as an additional mechanism for ranking LTIs in response to a query. Spreading activation is only compatible with base-level activation. <code>activation-mode</code> must be set to <code>base-level</code> in order to also use spreading. They are additive. Spreading activation serves to rank LTIs that are connected to those currently instanced in Working Memory more highly than those which are unconnected. Note that spreading should be turned on before running an agent. Also, be warned that an agent which loads a database with spreading activation active at the time of back-up currently has undefined behavior and will likely crash as spreading activation currently maintains state in the database.</p> <p>Spreading activation introduces additional parameters. <code>spreading-limit</code> is an absolute cap on the number of LTIs that can receive spread from a given instanced LTI. <code>spreading-depth-limit</code> is an absolute cap on the depth to which a Working Memory instance of some LTI can spread into the SMem network. <code>spreading-baseline</code> provides a minimum amount of spread that an element can receive. <code>spreading-continue-probability</code> sets the amount of spread that is passed on with greater depth. (It can also be thought of as 1-decay where decay is the loss of spread magnitude with depth.) <code>spreading-loop-avoidance</code> is a boolean parameter which controls whether or not any given spread traversal can loop back onto itself.</p> <p>Note that the default settings here are not necessarily appropriate for your application. For many applications, simply changing the structure of the network can yield wildly different query results even with the same spreading parameters.</p>"},{"location":"reference/cli/cmd_smem/#see-also","title":"See Also","text":"<p>print trace visualize</p>"},{"location":"reference/cli/cmd_soar/","title":"soar","text":""},{"location":"reference/cli/cmd_soar/#soar","title":"soar","text":"<p>Commands and settings related to running Soar</p>"},{"location":"reference/cli/cmd_soar/#synopsis","title":"Synopsis","text":"<pre><code>======= Soar General Commands and Settings =======\nsoar ?                                                 Print this help listing\nsoar init                                              Re-initializes Soar\nsoar stop [--self]                                     Stop Soar execution\nsoar version                                           Print version number\n------------------- Settings ----------------------\nkeep-all-top-oprefs                    [ on | OFF ]    Keep prefs for o-supported WMEs in top-state\nmax-elaborations                                100    Max elaborations per decision cycle\nmax-goal-depth                                   23    Halt at this goal stack depth\nmax-nil-output-cycles                            15    Impasse after this many nil outputs\nmax-dc-time                                       0    Interrupt after this much time\nmax-memory-usage                          100000000    Threshold for memory warning\nmax-gp                                        20000    Max rules gp can generate\nstop-phase   [input|proposal|decision|APPLY|output]    Phase before which Soar will stop\ntcl                                    [ on | OFF ]    Allow Tcl code in commands\ntimers                                 [ ON | off ]    Profile Soar\nwait-snc                               [ on | OFF ]    Wait instead of impasse\n-----------------------------------------------\nTo change a setting:                                   soar &lt;setting&gt; [&lt;value&gt;]\nFor a detailed explanation of these settings:          help soar\n</code></pre>"},{"location":"reference/cli/cmd_soar/#summary-view","title":"Summary View","text":"<p>Using the <code>soar</code> command without any arguments will display a summary of Soar's current state of execution and which capabilities of Soar are enabled: <pre><code>=======================================================\n                     Soar 9.6.0 Summary\n=======================================================\nEnabled:                                           Core\nDisabled:                EBC, SMem, EpMem, SVS, RL, WMA\n-------------------------------------------------------\nNumber of rules:                                     52\nDecisions                                            20\nElaborations                                         61\n-------------------------------------------------------\nState stack                        S1, S21 ... S29, S33\nCurrent number of states                              5\nNext phase                                        apply\n-------------------------------------------------------\n</code></pre></p> <p>To enable a particular capability of Soar, see the corresponding documentation for that component.</p>"},{"location":"reference/cli/cmd_soar/#soar-init","title":"soar init","text":"<p>The <code>init</code> command re-initializes Soar. It removes all elements from working memory, wiping out the goal stack, and resets all runtime statistics. The firing counts for all productions are reset to zero. The <code>soar init</code> command allows a Soar program that has been halted to be reset and start its execution from the beginning.</p> <p><code>soar init</code> does not remove any productions from production memory; to do this, use the production excise command. Note, however, that all justifications will be removed because they will no longer be supported.</p>"},{"location":"reference/cli/cmd_soar/#soar-stop","title":"soar stop","text":"<pre><code>soar stop [--self]\n</code></pre> <p>The <code>soar stop</code> command stops any running Soar agents. It sets a flag in the Soar kernel so that Soar will stop running at a \"safe\" point and return control to the user.  The <code>--self</code> option will stop only the soar agent where the command is issued. All other agents continue running as previously specified.</p> <p>This command is usually not issued at the command line prompt - a more common use of this command would be, for instance, as a side-effect of pressing a button on a Graphical User Interface (GUI).</p> <p>Note that if a graphical interface doesn't periodically do an \"update\"/flush the pending I/O, then it may not be possible to interrupt a Soar agent from the command line.</p>"},{"location":"reference/cli/cmd_soar/#soar-version","title":"soar version","text":"<p>This command prints the version of Soar to the screen.</p>"},{"location":"reference/cli/cmd_soar/#settings","title":"Settings","text":"<p>Invoke a sub-command with no arguments to query the current setting.  Partial commands are accepted.</p> Option Valid Values Default <code>keep-all-top-oprefs</code> on or off off <code>max-dc-time</code> &gt;= 0 0 <code>max-elaborations</code> &gt; 0 100 <code>max-goal-depth</code> &gt; 0 23 <code>max-gp</code> &gt; 0 20000 <code>max-memory-usage</code> &gt; 0 100000000 <code>max-nil-output-cycles</code> &gt; 0 15 <code>stop-phase</code> apply <code>tcl</code> on or off off <code>timers</code> on or off on <code>wait-snc</code> &gt;= 1 1"},{"location":"reference/cli/cmd_soar/#soar-keep-all-top-oprefs","title":"soar keep-all-top-oprefs","text":"<p>Enabling <code>keep-all-top-oprefs</code> turns off an optimization that reduces memory usage by discarding any internal preferences for WMEs that already have top-level o-support. Turning this setting off allows those preferences to be examined during debugging.</p>"},{"location":"reference/cli/cmd_soar/#soar-max-dc-time","title":"soar max-dc-time","text":"<p><code>max-dc-time</code> sets a maximum amount of time a decision cycle is permitted. After output phase, the elapsed decision cycle time is checked to see if it is greater than the old maximum, and the maximum dc time stat is updated  (see stats). At this time, this threshold is also checked. If met or exceeded, Soar stops at the end of the current output phase with an interrupted state.</p>"},{"location":"reference/cli/cmd_soar/#soar-max-elaborations","title":"soar max-elaborations","text":"<p><code>max-elaborations</code> sets and prints the maximum number of elaboration cycles allowed in a single decision cycle. </p> <p>If <code>n</code> is given, it must be a positive integer and is used to reset the number of allowed elaboration cycles. The default value is 100. max-elaborations with no arguments prints the current value.</p> <p>The elaboration phase will end after <code>max-elaboration</code> cycles have completed, even if there are more productions eligible to fire or retract; and Soar will proceed to the next phase after a warning message is printed to notify the user. This limits the total number of cycles of parallel production firing but does not limit the total number of productions that can fire during elaboration.</p> <p>This limit is included in Soar to prevent getting stuck in infinite loops (such as a production that repeatedly fires in one elaboration cycle and retracts in the next); if you see the warning message, it may be a signal that you have a bug your code. However some Soar programs are designed to require a large number of elaboration cycles, so rather than a bug, you may need to increase the value of <code>max-elaborations</code>.</p> <p><code>max-elaborations</code> is checked during both the Propose Phase and the Apply Phase. If Soar runs more than the max-elaborations limit in either of these phases, Soar proceeds to the next phase (either Decision or Output) even if quiescence has not been reached.</p>"},{"location":"reference/cli/cmd_soar/#soar-max-goal-depth","title":"soar max-goal-depth","text":"<p>The <code>max-goal-depth</code> command is used to limit the maximum depth of sub-states that an agent can subgoal to. The initial value of this variable is 100; allowable settings are any integer greater than 0. This limit is also included in Soar to prevent getting stuck in an infinite recursive loop, which may come about due to deliberate actions or via an agent bug, such as dropping inadvertently to state-no-change impasses.</p>"},{"location":"reference/cli/cmd_soar/#soar-max-gp","title":"soar max-gp","text":"<p><code>max-gp</code> is used to limit the number of productions produced by a gp command. It is easy to write a gp rule that has a combinatorial explosion and hangs for a long time while those productions are added to memory. The <code>max-gp</code> setting bounds this.</p>"},{"location":"reference/cli/cmd_soar/#soar-max-memory-usage","title":"soar max-memory-usage","text":"<p>The <code>max-memory-usage</code> setting is used to trigger the memory usage exceeded event. The initial value of this is 100MB (100,000,000); allowable settings are any integer greater than 0. </p> <p>NOTE: The code supporting this event is not enabled by default because the test can be computationally expensive and is needed only for specific embedded applications. Users may enable the test and event generation by uncommenting code in <code>mem.cpp</code>.</p>"},{"location":"reference/cli/cmd_soar/#soar-max-nil-output-cycles","title":"soar max-nil-output-cycles","text":"<p><code>max-nil-output-cycles</code> sets and prints the maximum number of nil output cycles (output cycles that put nothing on the output link) allowed when running using run-til-output (<code>run --output</code>). If <code>n</code> is not given, this command prints the current number of nil-output-cycles allowed. If <code>n</code> is given, it must be a positive integer and is used to reset the maximum number of allowed nil output cycles.</p> <p><code>max-nil-output-cycles</code> controls the maximum number of output cycles that generate no output allowed when a <code>run --out</code> command is issued. After this limit has been reached, Soar stops. The default initial setting of <code>n</code> is 15.</p>"},{"location":"reference/cli/cmd_soar/#soar-stop-phase","title":"soar stop-phase","text":"<p><code>stop-phase</code> allows the user to control which phase Soar stops in. When running by decision cycle it can be helpful to have agents stop at a particular point in its execution cycle.  The precise definition is that \"running for n decisions and stopping before phase ph means to run until the decision cycle counter has increased by n and then stop when the next phase is ph\". The phase sequence (as of this writing) is: input, proposal, decision, apply, output. Stopping after one phase is exactly equivalent to stopping before the next phase.</p>"},{"location":"reference/cli/cmd_soar/#soar-tcl","title":"soar tcl","text":"<p>Enabling the <code>tcl</code> setting augments Soar's prompt with Tcl scripting capabilities. In other words, it provides the ability to run Tcl code from any Soar command line by passing all Soar commands first through a Tcl interpreter for processing. (Each agent has its own Tcl interpreter.)</p> <p>This command provides Tcl capabilities to both local and remote clients, including the java-based debugger.  It processes Tcl commands in both the Soar command line and any files sourced. Productions can make Tcl calls by writing <code>(exec tcl  | &lt;Tcl code&gt; |)</code> clauses on the RHS of rules.  Soar symbols and variables can be included in RHS item.</p> <p>Important Notes:</p> <ul> <li>If you source a file that turns tcl on, you cannot use any Tcl code until the source command returns. </li> </ul> <p>If you'd like to have Tcl turned on automatically when Soar launches, add the <code>soar tcl on</code> command to your settings.soar file in the main Soar directory. This activates Tcl mode on initial launch, allowing you to immediately source files that use Tcl code.</p> <ul> <li> <p><code>soar tcl off</code> is currently not supported due to memory issues.</p> </li> <li> <p>Only one RHS Tcl call will produce output.</p> </li> </ul> <p>Soar rhs commands <code>write</code> (and even something like <code>echo</code>) will always work.  But for Tcl commands that produce output, for example, a 'puts' command or a custom Tcl proc that produces output as a side effect, only the last one will display output. Note that all rhs Tcl calls do get executed, so they will do what they are supposed to do, including perhaps writing output to a file.  The print output just doesn\u2019t get redirected to the right place, despite being produced. As a workaround, a user can make sure that there is only one Tcl call which needs to produce output and that it comes after any other Tcl RHS actions.</p> <ul> <li> <p>Does not support Tk code.  Tk is a widget toolkit that many Tcl programs use to provide a GUI, for example, the old Soar TSI debugger.</p> </li> <li> <p>Tcl code that tries to do low-level Soar SML calls may or may not work.Creating and deleting a kernel will certainly not work.  But other things like creating an agent may work fine.  This caveat is inherent to the design of Tcl as a plug-in without a main event loop.</p> </li> <li> <p>Third-party Tcl code that requires a Tcl event loop may or may not work, for example, the Tcl <code>after</code> command. </p> </li> </ul>"},{"location":"reference/cli/cmd_soar/#soar-timers","title":"soar timers","text":"<p>This setting is used to control the timers that collect internal profiling information while Soar is running. With no arguments, this command prints out the current timer status. Timers are ENABLED by default. The default compilation flags for soar enable the basic timers and disable the detailed timers. The timers command can only enable or disable timers that have already been enabled with compiler directives. See the stats command for more info on the Soar timing system.</p>"},{"location":"reference/cli/cmd_soar/#soar-wait-snc","title":"soar wait-snc","text":"<p><code>wait-snc</code> controls an architectural wait state. On some systems, especially those that model expert knowledge, a state-no-change may represent a wait state rather than an impasse. The waitsnc command allows the user to switch to a mode where a state-no-change that would normally generate an impasse (and subgoaling), instead generates a wait state. At a wait state, the decision cycle will repeat (and the decision cycle count is incremented) but no state-no-change impasse (and therefore no substate) will be generated.</p>"},{"location":"reference/cli/cmd_soar/#examples","title":"Examples","text":"<pre><code>soar init\nsoar stop -s\nsoar timers off\nsoar stop-phase output                 // stop before output phase\nsoar max-goal-depth 100\nsoar max-elaborations\n</code></pre>"},{"location":"reference/cli/cmd_soar/#default-aliases","title":"Default Aliases","text":"<pre><code>init                             soar init\nis                               soar init\ninit-soar                        soar init\ninterrupt                        soar stop\nss                               soar stop\nstop                             soar stop\nstop-soar                        soar stop\ngp-max                           soar max-gp\nmax-dc-time                      soar max-dc-time \nmax-elaborations                 soar max-elaborations\nmax-goal-depth                   soar max-goal-depth\nmax-memory-usage                 soar max-memory-usage\nmax-nil-output-cycles            soar max-nil-output-cycles \nset-stop-phase                   soar stop-phase\ntimers                           soar timers\nversion                          soar version\nwaitsnc                          soar wait-snc\n</code></pre>"},{"location":"reference/cli/cmd_soar/#see-also","title":"See Also","text":"<p>production excise run stats</p>"},{"location":"reference/cli/cmd_sp/","title":"sp","text":""},{"location":"reference/cli/cmd_sp/#sp","title":"sp","text":"<p>Define a Soar production.</p>"},{"location":"reference/cli/cmd_sp/#synopsis","title":"Synopsis","text":"<pre><code>sp {production_body}\n</code></pre>"},{"location":"reference/cli/cmd_sp/#options","title":"Options","text":"Option Description <code>production_body</code> A Soar production."},{"location":"reference/cli/cmd_sp/#description","title":"Description","text":"<p>The <code>sp</code> command creates a new production and loads it into production memory.  <code>production_body</code> is a single argument parsed by the Soar kernel, so it should be enclosed in curly braces to avoid being parsed by other scripting languages that might be in the same process. The overall syntax of a rule is as follows:</p> <pre><code>  name\n      [\"documentation-string\"]\n      [FLAG*]\n      LHS\n      --&gt;\n      RHS\n</code></pre> <p>The first element of a rule is its name. If given, the documentation-string must be enclosed in double quotes. Optional flags define the type of rule and the form of support its right-hand side assertions will receive. The specific flags are listed in a separate section below. The LHS defines the left-hand side of the production and specifies the conditions under which the rule can be fired. Its syntax is given in detail in a subsequent section. The --&gt; symbol serves to separate the LHS and RHS portions. The RHS defines the right-hand side of the production and specifies the assertions to be made and the actions to be performed when the rule fires. The syntax of the allowable right-hand side actions are given in a later section. (See the Syntax of Soar Programs chapter of the manual for naming conventions and discussion of the design and coding of productions.)</p> <p>If the name of the new production is the same as an existing one, the old production will be overwritten (excised).</p> <p>Rules matching the following requirement are flagged upon being created/sourced: a rule is a Soar-RL rule if and only if its right hand side (RHS) consists of a single numeric preference and it is not a template rule (see FLAGs below). This format exists to ease technical requirements of identifying/updating Soar-RL rules, as well as to make it easy for the agent programmer to add/maintain RL capabilities within an agent. (See the Reinforcement Learning chapter of the manual for further details.)</p>"},{"location":"reference/cli/cmd_sp/#rule-flags","title":"Rule Flags","text":"<p>The optional flags are given below. Note that these switches are preceded by a colon instead of a dash -- this is a Soar parser convention.</p> <pre><code>:o-support      specifies that all the RHS actions are to be given\n                o-support when the production fires\n\n:i-support     specifies that all the RHS actions are only to be given\n                i-support when the production fires\n\n:default        specifies that this production is a default production\n                (this matters for excise -task and trace task)\n\n:chunk          specifies that this production is a chunk\n                (this matters for learn trace)\n\n:interrupt      specifies that Soar should stop running when this\n                production matches but before it fires\n                (this is a useful debugging tool)\n\n:template       specifies that this production should be used to generate\n                new reinforcement learning rules by filling in those\n                variables that match constants in working memory\n</code></pre> <p>Multiple flags may be used, but not both of <code>o-support</code> and <code>no-support</code>.</p> <p>Although you could force your productions to provide o-support or i-support by using these commands --- regardless of the structure of the conditions and actions of the production --- this is not proper coding style. The <code>o-support</code> and <code>i-support</code> flags are included to help with debugging, but should not be used in a standard Soar program.</p>"},{"location":"reference/cli/cmd_sp/#examples","title":"Examples","text":"<pre><code>sp {blocks*create-problem-space\n     \"This creates the top-level space\"\n     (state &lt;s1&gt; ^superstate nil)\n     --&gt;\n     (&lt;s1&gt; ^name solve-blocks-world ^problem-space &lt;p1&gt;)\n     (&lt;p1&gt; ^name blocks-world)\n}\n</code></pre>"},{"location":"reference/cli/cmd_sp/#see-also","title":"See Also","text":"<p>production chunk trace</p>"},{"location":"reference/cli/cmd_stats/","title":"stats","text":""},{"location":"reference/cli/cmd_stats/#stats","title":"stats","text":"<p>Print information on Soar's runtime statistics.</p>"},{"location":"reference/cli/cmd_stats/#synopsis","title":"Synopsis","text":"<pre><code>stats [options]\n</code></pre>"},{"location":"reference/cli/cmd_stats/#options","title":"Options","text":"Option Description <code>-m, --memory</code> report usage for Soar's memory pools <code>-l, --learning</code> report statistics about rules learned via explanation-based chunking <code>-r, --rete</code> report statistics about the rete structure <code>-s, --system</code> report the system (agent) statistics (default) <code>-M, --max</code> report the per-cycle maximum statistics (decision cycle time, WM changes, production fires) <code>-R, --reset</code> zero out the per-cycle maximum statistics reported by <code>--max</code> command <code>-t, --track</code> begin tracking the per-cycle maximum statistics reported by <code>--max</code> for each cycle (instead of only the max value) <code>-T, --stop-track</code> stop and clear tracking of the per-cycle maximum statistics <code>-c, --cycle</code> print out collected per-cycle maximum statistics saved by <code>--track</code> in human-readable form <code>-C, --cycle-csv</code> print out collected per-cycle maximum statistics saved by <code>--track</code> in comma-separated form <code>-S, --sort N</code> sort the tracked cycle stats by column number <code>N</code>, see table below"},{"location":"reference/cli/cmd_stats/#-sort-parameters","title":"--sort parameters:","text":"Option Description <code>0</code> Use default sort <code>1, -1</code> Sort by decision cycle (use negative for descending) <code>2, -2</code> Sort by DC time (use negative for descending) <code>3, -3</code> Sort by WM changes (use negative for descending) <code>4, -4</code> Sort by production firings (use negative for descending)"},{"location":"reference/cli/cmd_stats/#description","title":"Description","text":"<p>This command prints Soar internal statistics. The argument indicates the component of interest, <code>--system</code> is used by default.</p> <p>With the <code>--system</code> flag, the stats command lists a summary of run statistics, including the following:</p> <ul> <li>Version --- The Soar version number, hostname, and date of the run.</li> <li>Number of productions --- The total number of productions loaded in the system, including all chunks built during problem solving and all default productions.</li> <li>Timing Information --- Might be quite detailed depending on the flags set at compile time. See note on timers below.</li> <li>Decision Cycles --- The total number of decision cycles in the run and the average time-per-decision-cycle in milliseconds.</li> <li>Elaboration cycles --- The total number of elaboration cycles that were executed during the run, the average number of elaboration cycles per decision cycle, and the average time-per-elaboration-cycle in milliseconds. This is not the total number of production firings, as productions can fire in parallel.</li> <li>Production Firings --- The total number of productions that were fired.</li> <li>Working Memory Changes --- This is the total number of changes to working memory. This includes all additions and deletions from working memory. Also prints the average match time.</li> <li>Working Memory Size --- This gives the current, mean and maximum number of working memory elements.</li> </ul> <p>The stats argument <code>--memory</code> provides information about memory usage and Soar's memory pools, which are used to allocate space for the various data structures used in Soar.</p> <p>The stats argument <code>--learning</code> provides information about rules learned through Soar's explanation-based chunking mechanism.  This is the same output that <code>chunk stats</code> provides.  For statistics about a specific rule learned, see the <code>explain</code> command.</p> <p>The stats argument <code>--rete</code> provides information about node usage in the Rete net, the large data structure used for efficient matching in Soar.</p> <p>The <code>--max</code> argument reports per-cycle maximum statistics for decision cycle time, working memory changes, and production fires. For example, if Soar runs for three cycles and there were 23 working memory changes in the first cycle, 42 in the second, and 15 in the third, the <code>--max</code> argument would report the highest of these values (42) and what decision cycle that it occurred in (2nd). Statistics about the time spent executing the decision cycle and number of productions fired are also collected and reported by <code>--max</code> in this manner. <code>--reset</code> zeros out these statistics so that new maximums can be recorded for future runs. The numbers are also zeroed out with a call to init-soar.</p> <p>The <code>--track</code> argument starts tracking the same stats as the <code>--max</code> argument but records all data for each cycle instead of the maximum values. This data can be printed using the <code>--cycle</code> or <code>--cycle-csv</code> arguments. When printing the data with <code>--cycle</code>, it may be sorted using the <code>--sort</code> argument and a column integer. Use negative numbers for descending sort. Issue <code>--stop-track</code> to reset and clear this data.</p>"},{"location":"reference/cli/cmd_stats/#a-note-on-timers","title":"A Note on Timers","text":"<p>The current implementation of Soar uses a number of timers to provide time-based statistics for use in the stats command calculations. These timers are:</p> <ul> <li>total CPU time</li> <li>total kernel time</li> <li>phase kernel time (per phase)</li> <li>phase callbacks time (per phase)</li> <li>input function time</li> <li>output function time</li> </ul> <p>Total CPU time is calculated from the time a decision cycle (or number of decision cycles) is initiated until stopped. Kernel time is the time spent in core Soar functions. In this case, kernel time is defined as the all functions other than the execution of callbacks and the input and output functions. The total kernel timer is only stopped for these functions. The phase timers (for the kernel and callbacks) track the execution time for individual phases of the decision cycle (i.e., input phase, preference phase, working memory phase, output phase, and decision phase). Because there is overhead associated with turning these timers on and off, the actual kernel time will always be greater than the derived kernel time (i.e., the sum of all the phase kernel timers). Similarly, the total CPU time will always be greater than the derived total (the sum of the other timers) because the overhead of turning these timers on and off is included in the total CPU time. In general, the times reported by the single timers should always be greater than than the corresponding derived time.  Additionally, as execution time increases, the difference between these two values will also increase. For those concerned about the performance cost of the timers, all the run time timing calculations can be compiled out of the code by defining <code>NO_TIMING_STUFF</code> (in <code>kernel.h</code>) before compilation.</p>"},{"location":"reference/cli/cmd_stats/#examples","title":"Examples","text":"<p>Track per-cycle stats then print them out using default sort:</p> <pre><code>stats --track\nrun\nstop\nstats --cycle\n</code></pre> <p>Print out per-cycle stats sorting by decision cycle time</p> <pre><code>stats --cycle --sort 2\n</code></pre> <p>Print out per-cycle stats sorting by firing counts, descending</p> <pre><code>stats --cycle --sort -4\n</code></pre> <p>Save per-cycle stats to file <code>stats.csv</code></p> <pre><code>ctf stats.csv stats --cycle-csv\n</code></pre>"},{"location":"reference/cli/cmd_stats/#default-aliases","title":"Default Aliases","text":"<pre><code>st       stats\n</code></pre>"},{"location":"reference/cli/cmd_stats/#see-also","title":"See Also","text":"<p>timers init-soar command-to-file</p>"},{"location":"reference/cli/cmd_svs/","title":"svs","text":""},{"location":"reference/cli/cmd_svs/#svs","title":"svs","text":"<p>Control the behavior of the Spatial Visual System</p> <p>Syntax: <pre><code>svs &lt;elements to inspect&gt;\nsvs [--enable | -e | --on | --disable | -d | --off]\n</code></pre></p>"},{"location":"reference/cli/cmd_svs/#synopsis","title":"Synopsis","text":"<pre><code>svs &lt;path&gt; dir\nsvs &lt;path&gt; help\nsvs connect_viewer &lt;port&gt;\nsvs disconnect_viewer\nsvs filters\nsvs filters.&lt;filter_name&gt;\nsvs commands\nsvs commands.&lt;command_name&gt;\nsvs &lt;state&gt;.scene.world\nsvs &lt;state&gt;.scene.world.&lt;path-to-node&gt;\nsvs &lt;state&gt;.scene.properties\nsvs &lt;state&gt;.scene.sgel &lt;sgel-command&gt;\nsvs &lt;state&gt;.scene.draw on|off\nsvs &lt;state&gt;.scene.clear\n</code></pre>"},{"location":"reference/cli/cmd_svs/#paths","title":"Paths","text":"<p>SVS can be navigated by specifying a path after the svs command. This path mimicks a directory structure and is specified by dot notation.</p> Path Argument Description connect_viewer &lt;port&gt; Connects to a svs_viewer listening on the given port disconnect_viewer Disconnects from an active svs_viewer filters Prints out a list of all the filters filters.&lt;filter_name&gt; Prints information about a specific filter commands Prints out a list of all the soar commands commands.&lt;command_name&gt; Prints information about a specific command &lt;state&gt;.scene.world Prints information about the world &lt;state&gt;.scene.&lt;node-path&gt; Prints information about a specific node &lt;state&gt;.scene.properties Prints pos/rot/scale/tag info about all nodes &lt;state&gt;.scene.sgel &lt;sgel&gt; Sends an sgel command to the scene &lt;state&gt;.scene.draw on Causes this scene to be the one drawn on the viewer &lt;state&gt;.scene.draw off Stops this scene from being drawn in the viewer &lt;state&gt;.scene.clear Removes all objects from the given scene"},{"location":"reference/cli/cmd_svs/#description","title":"Description","text":"<p>Each path can be followed by <code>help</code> to print some help info, or followed by <code>dir</code> to see the children of that path. The <code>&lt;state&gt;</code> variable is the identifier for the substate you want to examine. For example, to do things to the topstate scene you would use <code>svs S1.scene</code>.</p>"},{"location":"reference/cli/cmd_svs/#examples","title":"Examples","text":"<p>Print the full SVS directory structure <pre><code>svs . dir\n</code></pre> Print help information about connect_viewer <pre><code>svs connect_viewer help\n</code></pre> Print information about a distance filter <pre><code>svs filters.distance\n</code></pre> Print all the nodes in the scene for substate S17 <pre><code>svs S17.scene.world dir\n</code></pre> Print information about the node wheel2 on car5 <pre><code>svs S1.scene.world.car5.wheel2\n</code></pre> Add a new node to the scene using SGEL <pre><code>svs S1.scene.sgel add ball3 world ball .5 position 1 1 1\n</code></pre></p>"},{"location":"reference/cli/cmd_trace/","title":"trace","text":""},{"location":"reference/cli/cmd_trace/#trace","title":"trace","text":"<p>Control the run-time tracing of Soar.</p>"},{"location":"reference/cli/cmd_trace/#synopsis","title":"Synopsis","text":"<pre><code>============================================================\n                    Soar Trace Messages\n============================================================\n------------------------- Level 1 --------------------------\nOperator decisions and states                             on     -d\n------------------------- Level 2 --------------------------\nPhases                                                   off     -p\nState removals caused by GDS violation                   off     -g\n------------------ Level 3: Rule firings -------------------\nDefault rules                                            off     -D\nUser rules                                               off     -u\nChunks                                                   off     -c\nJustifications                                           off     -j\nTemplates                                                off     -T\nFirings inhibited by higher-level firings                off     -W\n------------------------- Level 4 --------------------------\nWME additions and removals                               off     -w\n------------------------- Level 5 --------------------------\nPreferences                                              off     -r\n---------------- Additional Trace Messages -----------------\nChunking dependency analysis                             off     -b\nGoal dependency set changes                              off     -G\nEpisodic memory recording and queries                    off     -e\nNumeric preference calculations                          off     -i\nLearning Level                                           off     -L 0-2\nReinforcement learning value updates                     off     -R\nSemantic memory additions                                off     -s\nWorking memory activation and forgetting                 off     -a\n\nWME Detail Level                                        none     -n, -t, -f\n</code></pre>"},{"location":"reference/cli/cmd_trace/#trace-levels","title":"Trace Levels","text":"<p><pre><code>trace 0-5\n</code></pre> Use of the <code>--level</code> (<code>-l</code>) flag is optional but recommended.</p> Option Description <code>0</code> trace nothing; equivalent to <code>-N</code> <code>1</code> trace decisions; equivalent to <code>-d</code> <code>2</code> trace phases, gds, and decisions; equivalent to <code>-dpg</code> <code>3</code> trace productions, phases, and decisions; equivalent to <code>-dpgP</code> <code>4</code> trace wmes, productions, phases, and decisions; equivalent to <code>-dpgPw</code> <code>5</code> trace preferences, wmes, productions, phases, and decisions; equivalent to <code>-dpgPwr</code> <p>It is important to note that trace level <code>0</code> turns off ALL trace options, including backtracing, indifferent selection and learning. However, the other trace levels do not change these settings. That is, if any of these settings is changed from its default, it will retain its new setting until it is either explicitly changed again or the trace level is set to <code>0</code>.</p>"},{"location":"reference/cli/cmd_trace/#options","title":"Options","text":"<p><pre><code>trace [options]\n</code></pre> | Option Flag | Argument to Option | Description | |:----------------|:-----------------------|:----------------| | <code>-l, --level</code>   | <code>0</code> to <code>5</code> (see Trace Levels below) | This flag is optional but recommended. Set a specific trace level using an integer <code>0</code> to <code>5</code>, this is an inclusive operation | | <code>-N, --none</code>    | No argument            | Turns off all printing about Soar's internals, equivalent to <code>--level 0</code> | | <code>-b, --backtracing</code> | <code>remove</code> (optional)    | Print backtracing information when a chunk or justification is created | | <code>-d, --decisions</code> | <code>remove</code> (optional)    | Controls whether state and operator decisions are printed as they are made | | <code>-e, --epmem</code>   | <code>remove</code> (optional)    | Print episodic retrieval traces and IDs of newly encoded episodes  | | <code>-g, --gds</code>     | <code>remove</code> (optional)    | Controls printing of warnings when a state is removed due to the GDS | | <code>-G, --gds-wmes</code> | <code>remove</code> (optional)    | Controls printing of warnings about wme changes to GDS | | <code>-i, --indifferent-selection</code> | <code>remove</code> (optional)    | Print scores for tied operators in random indifferent selection mode | | <code>-p, --phases</code>  | <code>remove</code> (optional)    | Controls whether decisions cycle phase names are printed as Soar executes | | <code>-r, --preferences</code> | <code>remove</code> (optional)    | Controls whether the preferences generated by the traced productions are printed when those productions fire or retract | | <code>-P, --productions</code> | <code>remove</code> (optional)    | Controls whether the names of productions are printed as they fire and retract, equivalent to <code>-Dujc</code> | | <code>-R, --rl</code>      | <code>remove</code> (optional)    | Print RL debugging output | | <code>-s, --smem</code>    | <code>remove</code> (optional)    | Print log of semantic memory storage events | | <code>-w, --wmes</code>    | <code>remove</code> (optional)    | Controls the printing of working memory elements that are added and deleted as productions are fired and retracted. | | <code>-a, --wma</code>     | <code>remove</code> (optional)    | Print log of working memory activation events  | | <code>-A, --assertions</code> | <code>remove</code> (optional)    | Print assertions of rule instantiations and the preferences they generate. |</p> <p>When appropriate, a specific option may be turned off using the <code>remove</code> argument. This argument has a numeric alias; you can use <code>0</code> for <code>remove</code>. A mix of formats is acceptable, even in the same command line.</p>"},{"location":"reference/cli/cmd_trace/#tracing-productions","title":"Tracing Productions","text":"<p>By default, the names of the productions are printed as each production fires and retracts (at trace levels <code>3</code> and higher). However, it may be more helpful to trace only a specific type of production. The tracing of firings and retractions of productions can be limited to only certain types by the use of the following flags:</p> Option Flag Argument to Option Description <code>-D, --default</code> <code>remove</code> (optional) Control only default-productions as they fire and retract <code>-u, --user</code> <code>remove</code> (optional) Control only user-productions as they fire and retract <code>-c, --chunks</code> <code>remove</code> (optional) Control only chunks as they fire and retract <code>-j, --justifications</code> <code>remove</code> (optional) Control only justifications as they fire and retract <code>-T, --template</code> <code>remote</code> (optional) Soar-RL template firing trace <p>Note: The production watch command is used to trace individual productions specified by name rather than trace a type of productions, such as <code>--user</code>.</p> <p>Additionally, when tracing productions, users may set the level of detail to be displayed for WMEs that are added or retracted as productions fire and retract. Note that detailed information about WMEs will be printed only for productions that are being traced.</p> Option Flag Description <code>-n, --nowmes</code> When tracing productions, do not print any information about matching wmes <code>-t, --timetags</code> When tracing productions, print only the timetags for matching wmes <code>-f, --fullwmes</code> When tracing productions, print the full matching wmes"},{"location":"reference/cli/cmd_trace/#tracing-learning","title":"Tracing Learning","text":"Option Flag Argument to Option Description <code>-L, --learning</code> <code>noprint</code>, <code>print</code>, or <code>fullprint</code> (see table below) Controls the printing of chunks/justifications as they are created <p>As Soar is running, it may create justifications and chunks which are added to production memory. The trace command allows users to monitor when chunks and justifications are created by specifying one of the following arguments to the <code>--learning</code> command:</p> Argument Alias Effect <code>noprint</code> <code>0</code> Print nothing about new chunks or justifications (default) <code>print</code> <code>1</code> Print the names of new chunks and justifications when created <code>fullprint</code> <code>2</code> Print entire chunks and justifications when created"},{"location":"reference/cli/cmd_trace/#description","title":"Description","text":"<p>The <code>trace</code> command controls the amount of information that is printed out as Soar runs. The basic functionality of this command is to trace various levels of information about Soar's internal workings. The higher the level, the  more information is printed as Soar runs. At the lowest setting, <code>0</code> (<code>--none</code>), nothing is printed. The levels are cumulative, so that each successive level prints the information from the previous level as well as some additional information. The default setting for the level is <code>1</code>, (<code>--decisions</code>).</p> <p>The numerical arguments inclusively turn on all levels up to the number specified. To use numerical arguments to turn off a level, specify a number which is less than the level to be turned off. For instance, to turn off tracing of productions, specify <code>--level 2</code> (or 1 or 0). Numerical arguments are provided for shorthand convenience. For more detailed control over the trace settings, the named arguments should be used.</p> <p>With no arguments, this command prints information about the current trace status, i.e., the values of each parameter.</p> <p>For the named arguments, including the named argument turns on only that setting. To turn off a specific setting, follow the named argument with <code>remove</code> or <code>0</code>.</p> <p>The named argument <code>--productions</code> is shorthand for the four arguments <code>--default</code>, <code>--user</code>, <code>--justifications</code>, and <code>--chunks</code>.</p>"},{"location":"reference/cli/cmd_trace/#examples","title":"Examples","text":"<p>The most common uses of trace are by using the numeric arguments which indicate trace levels. To turn off all printing of Soar internals, do any one of the following (not all possibilities listed):</p> <pre><code>trace --level 0\ntrace -l 0\ntrace -N\n</code></pre> <p>Note: You can turn off printing at an even lower level using the <code>output</code> command.</p> <p>Although the <code>--level</code> flag is optional, its use is recommended:</p> <pre><code>trace --level 5   ## OK\ntrace 5           ## OK, avoid\n</code></pre> <p>Be careful of where the level is on the command line, for example, if you want level 2 and preferences:</p> <pre><code>trace -r -l 2 ## Incorrect: -r flag ignored, level 2 parsed after it and overrides the setting\ntrace -r 2    ## Syntax error: 0 or remove expected as optional argument to -r\ntrace -r -l 2 ## Incorrect: -r flag ignored, level 2 parsed after it and overrides the setting\ntrace 2 -r    ## OK, avoid\ntrace -l 2 -r ## OK\n</code></pre> <p>To turn on printing of decisions, phases and productions, do any one of the following (not all possibilities listed):</p> <pre><code>trace --level 3\ntrace -l 3\ntrace --decisions --phases --productions\ntrace -d -p -P\n</code></pre> <p>Individual options can be changed as well. To turn on printing of decisions and WMEs, but not phases and productions, do any one of the following (not all possibilities listed):</p> <pre><code>trace --level 1 --wmes\ntrace -l 1 -w\ntrace --decisions --wmes\ntrace -d --wmes\ntrace -w --decisions\ntrace -w -d\n</code></pre> <p>To turn on printing of decisions, productions and WMEs, and turns phases off, do any one of the following (not all possibilities listed):</p> <pre><code>trace --level 4 --phases remove\ntrace -l 4 -p remove\ntrace -l 4 -p 0\ntrace -d -P -w -p remove\n</code></pre> <p>To trace the firing and retraction of decisions and only user productions, do any one of the following (not all possibilities listed):</p> <pre><code>trace -l 1 -u\ntrace -d -u\n</code></pre> <p>To trace decisions, phases and all productions except user productions and justifications, and to see full WMEs, do any one of the following (not all possibilities listed):</p> <pre><code>trace --decisions --phases --productions --user remove --justifications remove --fullwmes\ntrace -d -p -P -f -u remove -j 0\ntrace -f -l 3 -u 0 -j 0\n</code></pre>"},{"location":"reference/cli/cmd_trace/#default-aliases","title":"Default Aliases","text":"<pre><code>v           trace -A\nw           trace\nwatch       trace\n</code></pre>"},{"location":"reference/cli/cmd_trace/#see-also","title":"See Also","text":"<p>epmem production output print run wm</p>"},{"location":"reference/cli/cmd_visualize/","title":"visualize","text":""},{"location":"reference/cli/cmd_visualize/#visualize","title":"visualize","text":"<p>Creates visualizations of Soar's memory systems or processing.</p>"},{"location":"reference/cli/cmd_visualize/#synopsis","title":"Synopsis","text":"<pre><code>======= Visualization Commands and Settings =======\nvisualize ?                                           Print this help listing\nvisualize [wm | smem | epmem] [id] [depth]            Visualize from memory system\nvisualize [ identity_graph | ebc_analysis]            Visualize EBC explainer analysis\n------------------ Presentation -------------------\nrule-format                          [ name | FULL]   Print all conditions and \n                                                      actions or just the rule name\nmemory-format                      [ node | RECORD]   Print memories as records \n                                                      or just simple nodes\nline-style                                 polyline   GraphViz line style that will\n                                                      be used\nseparate-states                        [ ON | off ]   Whether to create links\n                                                      between goal states\narchitectural-wmes                     [ on | OFF ]   Whether to include WMEs \n                                                      created by the Soar architecture\ncolor-identities                       [ on | OFF ]   Color identities in visualization\nuse-joined-identities                  [ ON | off ]   Color using final joined identities\n------------------ File Handling ------------------\nfile-name                                  soar_viz\nuse-same-file                          [ on | OFF ]   Whether to create new files each time\ngenerate-image                         [ ON | off ]   Whether an image should be created\nimage-type                                      svg   Image type that will be generated\n------------------ Post Actions -------------------\nviewer-launch                          [ ON | off ]   Launch image in viewer\neditor-launch                          [ on | OFF ]   Open data file in editor\nprint-debug                            [ on | OFF ]   Print data file to screen\n                                                      for debugging\n</code></pre>"},{"location":"reference/cli/cmd_visualize/#description","title":"Description","text":"<p>The <code>visualize</code> command will generate graphical representations of either Soar memory structure or the analysis that explanation-based chunking performed to learn a rule.  </p> <p>This command can be instructed to automatically launch a viewer to see the visual representation.  If you have an editor that can open graphviz files, you can have Soar launch that automatically as well. (Such editors allow you to move things around and lay out the components of the visualization exactly as you want them.)</p>"},{"location":"reference/cli/cmd_visualize/#visualizing-memory","title":"Visualizing Memory","text":"<p><code>visualize [wm | smem | epmem] [id] [depth]</code></p> <p>The first argument is the memory system that you want to visualize.</p> <p>The optional id argument allows you to specify either a root identifier from which to start working memory or semantic memory visualizations, or an episode ID for episodic memory visualization.</p> <p>The depth argument specifies how many levels of augmentation that will be printed.</p>"},{"location":"reference/cli/cmd_visualize/#visualizing-how-a-rule-was-learned","title":"Visualizing How a Rule was Learned","text":"<p><code>visualize [ identity_graph | ebc_analysis]</code></p> <p><code>visualize identity_graph</code> will create a visualization of how the final identities used in a learned rule were determined. This shows all identities involved and how the identity analysis joined them based on the problem-solving that occurred.</p> <p><code>visualize ebc_analysis</code> will create a visualization of the chunk that was learned and all rules that fired in a substate that contributed to a rule being learned. In addition to all of the dependencies between rules that fired, this visualization also shows which conditions in the instantiations tested knowledge in the superstate and hence contributed to a conditions in the final learned rule.</p>"},{"location":"reference/cli/cmd_visualize/#presentation-settings","title":"Presentation Settings","text":"<p><code>rule-format</code>:  This setting only applies to visualizing EBC processing. The <code>full</code> format will print all conditions and actions of the rule. The <code>name</code> format will only print a simple object with the rule name.</p> <p><code>memory-format</code>:  This setting only applies to visualizing memory systems. The <code>node</code> format will print a single graphical object for every symbol, using a circle for identifiers and a square for constants.  The <code>record</code> format will print a database-style record for each identifier with all of its augmentations as fields.  Links to other identifiers appear as arrows.</p> <p><code>line-style</code> is a parameter that is passed to Graphviz and affects how lines are drawn between objects. See the Graphviz documentation for legal values.</p> <p><code>separate-states</code> is a parameter that determines whether a link to a state symbol is drawn. When this setting is on, Soar will not connect states and instead will represent it as a constant. This setting only applies to visualizing memory systems.</p> <p><code>architectural-wmes</code> is a parameter that determines whether working memory elements created by the architecture, for example I/O and the various memory sub-system links, will be included in the visualization. This setting only applies to visualizing memory systems.</p>"},{"location":"reference/cli/cmd_visualize/#file-handling-settings","title":"File Handling Settings","text":"<p><code>file-name</code> specifies the base file name that Soar will use when creating both graphviz data files and images. You can specify a path as well, for example \"visualization/soar_viz\", but make sure the directory exists first!</p> <p><code>use-same-file</code> tells the visualizer to always overwrite the same files for each visualization. When off, Soar will create a new visualization each time by using the base file name and adding a new number to it each time. Note that this command does not yet handle file creation as robustly as it could. If the file already exists, it will simply overwrite it rather than looking for a new file name. </p> <p><code>generate-image</code> specifies whether the visualizer should render the graphviz file into an image. This setting is overridden if the viewer-launch setting is enabled. </p> <p><code>image-type</code> specifies what kind of image that visualizer should create. Graphviz is capable of rendering to a staggering number of different image types. The default that the visualizer uses is SVG, which is a vector-based format that can be scaled without loss of clarity. For other legal formats, see the Graphviz or DOT documentation. </p>"},{"location":"reference/cli/cmd_visualize/#post-action-settings","title":"Post Action Settings","text":"<p>After the data and image files are generated, the visualizer can automatically launch an external program to view or edit the output.</p> <p><code>viewer-launch</code> specifies whether to launch an image viewer. Most web browser can view SVG files.</p> <p><code>editor-launch</code> specifies whether to launch whatever program is associated with <code>.gv</code> files. For example, on OSX, the program OmniGraffle can be used to great effect.</p> <p><code>print-debug</code> specifies whether to print the raw Graphviz output to the screen. If you are having problems, you may want to use this setting to see what it is generating for your agent.</p> <p>Note that your operating system chooses which program to launch based on the file type. This feature has not been tested extensively on other platforms. Certain systems may not allow Soar to launch an external program.</p>"},{"location":"reference/cli/cmd_visualize/#see-also","title":"See Also","text":"<p>explain epmem smem chunk</p>"},{"location":"reference/cli/cmd_wm/","title":"wm","text":""},{"location":"reference/cli/cmd_wm/#wm","title":"wm","text":"<p>Commands and settings related to working memory and working memory activation.  There are four sub-commands:  <code>add</code>, <code>remove</code>, <code>activation</code>, and <code>watch</code>.</p>"},{"location":"reference/cli/cmd_wm/#synopsis","title":"Synopsis","text":"<pre><code>=========================================================\n-               WM Sub-Commands and Options             -\n=========================================================\nwm              [? | help]\n---------------------------------------------------------\nwm add          &lt;id&gt; [^]&lt;attribute&gt; &lt;value&gt; [+]\nwm remove       &lt;timetag&gt;\n---------------------------------------------------------\nwm activation   --get &lt;parameter&gt;\n                --set &lt;parameter&gt;                 &lt;value&gt;\n                      activation             [ on | OFF ]\n                      petrov-approx          [ on | OFF ]\n                      forgetting             [ on | OFF ]\n                      fake-forgetting        [ on | OFF ]\n                      forget-wme                      all  [all, lti]\n                      decay-rate                     -0.5  [0 to 1]\n                      decay-thresh                     -2  [0 to infinity]\n                      max-pow-cache                    10  MB\n                      timers                          off  [off, one]\n                --history &lt;timetag&gt;\n                --stats                                    Print forget stats\n                --timers [&lt;timer&gt;]                         Print timing results\n                  &lt;timer&gt; = wma_forgetting or wma_history\n---------------------------------------------------------\nwm watch        --add-filter    --type &lt;t&gt;  pattern\n                --remove-filter --type &lt;t&gt;  pattern\n                --list-filter  [--type &lt;t&gt;]\n                --reset-filter [--type &lt;t&gt;]\n                              &lt;t&gt; = adds, removes or both\n---------------------------------------------------------\n\nFor a detailed explanation of sub-commands:       help wm\n</code></pre>"},{"location":"reference/cli/cmd_wm/#wm-activation","title":"wm activation","text":"<p>The <code>wm activation</code> command changes the behavior of and displays information about working memory activation.</p> <p>To get the activation of individual WMEs, use <code>print -i</code>.  To get the reference history of an individual WME, use  <code>wm activation -h|--history</code>&lt;<code>timetag</code>&gt;. For example:</p> <pre><code>print --internal s1\n(4000016: S1 ^ct 1000000 [3.6])\n(4: S1 ^epmem E1 [1])\n(11: S1 ^io I1 [1])\n(20: S1 ^max 1000000 [3.4])\n(18: S1 ^name ct [3.4])\n(4000018: S1 ^operator O1000001 [1] +)\n(4000019: S1 ^operator O1000001 [1])\n(3: S1 ^reward-link R1 [1])\n(8: S1 ^smem S2 [1])\n(2: S1 ^superstate nil [1])\n(14: S1 ^top-state S1 [1])\n(1: S1 ^type state [1])\n</code></pre> <p>The bracketed values are activation. To get the history of an individual element:</p> <pre><code>wm activation --history 18\nhistory (60/5999999, first @ d1):\n 6 @ d1000000 (-1)\n 6 @ d999999 (-2)\n 6 @ d999998 (-3)\n 6 @ d999997 (-4)\n 6 @ d999996 (-5)\n 6 @ d999995 (-6)\n 6 @ d999994 (-7)\n 6 @ d999993 (-8)\n 6 @ d999992 (-9)\n 6 @ d999991 (-10)\n\nconsidering WME for decay @ d1019615\n</code></pre> <p>This shows the last 60 references (of 5999999 in total, where the first occurred at decision cycle 1). For each reference, it says how many references occurred in the cycle (such as 6 at decision 1000000, which was one cycle ago at the time of executing this command). Note that references during the current cycle will not be reflected in this command (or computed activation value) until the end of output phase. If <code>forgetting</code> is <code>on</code>, this command will also display the cycle during which the WME will be considered for decay. Even if the WME is not referenced until then, this is not necessarily the cycle at which the WME will be forgotten. However, it is guaranteed that the WME will not be forgotten before this cycle.</p>"},{"location":"reference/cli/cmd_wm/#options","title":"Options:","text":"Option Description <code>-g, --get</code> Print current parameter setting <code>-s, --set</code> Set parameter value <code>-S, --stats</code> Print statistic summary or specific statistic <code>-t, --timers</code> Print timer summary or specific timer <code>-h, --history</code> Print reference history of a WME"},{"location":"reference/cli/cmd_wm/#parameters","title":"Parameters:","text":"<p>The <code>activation</code> command uses the <code>--get|--set &lt;parameter&gt; &lt;value&gt;</code> convention rather than individual switches for each parameter. Running <code>wm activation</code> without any switches displays a summary of the parameter settings.</p> Parameter Description Possible values Default <code>activation</code> Enable working memory activation <code>on</code>, <code>off</code> <code>off</code> <code>decay-rate</code> WME decay factor <code>[</code>0, 1<code>]</code> 0.5 <code>decay-thresh</code> Forgetting threshold <code>(</code>0, inf<code>)</code> 2.0 <code>forgetting</code> Enable removal of WMEs with low activation values <code>on</code>, <code>off</code> <code>off</code> <code>forget-wme</code> If <code>lti</code> only remove WMEs with a long-term id <code>all</code>, <code>lti</code> <code>all</code> <code>max-pow-cache</code> Maximum size, in MB, for the internal <code>pow</code> cache 1, 2, ... 10 <code>petrov-approx</code> Enables the (Petrov 2006) long-tail approximation <code>on</code>, <code>off</code> <code>off</code> <code>timers</code> Timer granularity <code>off</code>, <code>one</code> <code>off</code> <p>The <code>decay-rate</code> and <code>decay-thresh</code> parameters are entered as positive decimals, but are internally converted to, and printed out as, negative.</p> <p>The <code>petrov-approx</code> may provide additional validity to the activation value, but comes at a significant computational cost, as the model includes unbounded positive exponential computations, which cannot be reasonably cached.</p> <p>When <code>activation</code> is enabled, the system produces a cache of results of calls to the <code>pow</code> function, as these can be expensive during runtime. The size of the cache is based upon three run-time parameters (<code>decay-rate</code>, <code>decay-thresh</code>, and <code>max-pow-cache</code>), and one compile time parameter, <code>WMA_REFERENCES_PER_DECISION</code> (default value of 50), which estimates the maximum number of times a WME will be referenced during a decision. The cache is composed of <code>double</code> variables (i.e. 64-bits, currently) and the number of cache items is computed as follows:</p> <p>e^((decay_thresh - ln(max_refs)) / decay_rate)</p> <p>With the current default parameter values, this will incur about 1.04MB of memory. Holding the <code>decay-rate</code> constant, reasonable changes to <code>decay-thresh</code> (i.e. +/- 5) does not greatly change this value. However, small changes to <code>decay-rate</code> will dramatically change this profile. For instance, keeping everything else constant, a <code>decay-thresh</code> of 0.3 requires ~2.7GB and 0.2 requires ~50TB. Thus, the <code>max-pow-cache</code> parameter serves to allow you to control the space vs. time tradeoff by capping the maximum amount of memory used by this cache. If <code>max-pow-cache</code> is much smaller than the result of the equation above, you may experience somewhat degraded performance due to relatively frequent system calls to <code>pow</code>.</p> <p>If <code>forget-wme</code> is <code>lti</code> and <code>forgetting</code> is <code>on</code>, only those WMEs whose id is a long-term identifier at the decision of forgetting will be removed from working memory. If, for instance, the id is stored to semantic memory after the decision of forgetting, the WME will not be removed till some time after the next WME reference (such as testing/creation by a rule).</p>"},{"location":"reference/cli/cmd_wm/#statistics","title":"Statistics","text":"<p>Working memory activation tracks statistics over the lifetime of the agent. These can be accessed using <code>wm activation --stats &lt;statistic&gt;</code>.  Running <code>wm activation --stats</code> without a statistic will list the values of all statistics.  Unlike timers, statistics will always be updated.</p> <p>Available statistics are:</p> Name Label Description <code>forgotten-wmes</code> Forgotten WMEs Number of WMEs removed from working memory due to forgetting"},{"location":"reference/cli/cmd_wm/#timers","title":"Timers","text":"<p>Working memory activation also has a set of internal timers that record the durations of certain operations. Because fine-grained timing can incur runtime costs, working memory activation timers are off by default. Timers of different levels of detail can be turned on by issuing <code>wm activation --set timers &lt;level&gt;</code>, where the levels can be <code>off</code> or <code>one</code>, <code>one</code> being most detailed and resulting in all timers being turned on. Note that none of the working memory activation statistics nor timing information is reported by the <code>stats</code> command.</p> <p>All timer values are reported in seconds.</p> <p>Timer Levels:</p> Option Description <code>wma_forgetting</code> Time to process forgetting operations each cycle <code>wma_history</code> Time to consolidate reference histories each cycle"},{"location":"reference/cli/cmd_wm/#wm-add","title":"wm add","text":"<p>Manually add an element to working memory.</p> <pre><code>wm add id [^]attribute value [+]\n</code></pre>"},{"location":"reference/cli/cmd_wm/#options_1","title":"Options:","text":"Option Description <code>id</code> Must be an existing identifier. <code>^</code> Leading <code>^</code> on attribute is optional. <code>attribute</code> Attribute can be any Soar symbol. Use <code>*</code> to have Soar create a new identifier. <code>value</code> Value can be any soar symbol. Use <code>*</code> to have Soar create a new identifier. <code>+</code> If the optional preference is specified, its value must be <code>+</code> (acceptable)."},{"location":"reference/cli/cmd_wm/#description","title":"Description","text":"<p>Manually add an element to working memory. <code>wm add</code> is often used by an input function to update Soar's information about the state of the external world.</p> <p><code>wm add</code> adds a new wme with the given id, attribute, value and optional preference. The given id must be an existing identifier. The attribute and value fields can be any Soar symbol. If <code>*</code> is given in the attribute or value field, Soar creates a new identifier (symbol) for that field. If the preference is given, it can only have the value <code>+</code> to indicate that an acceptable preference should be created for this WME.</p> <p>Note that because the id must already exist in working memory, the WME that you are adding will be attached (directly or indirectly) to the top-level state. As with other WME's, any WME added via a call to add-wme will automatically be removed from working memory once it is no longer attached to the top-level state.</p>"},{"location":"reference/cli/cmd_wm/#examples","title":"Examples","text":"<p>This example adds the attribute/value pair <code>^message-status received</code> to the identifier (symbol) S1:</p> <pre><code>wm add S1 ^message-status received\n</code></pre> <p>This example adds an attribute/value pair with an acceptable preference to the identifier (symbol) Z2. The attribute is <code>message</code> and the value is a unique identifier generated by Soar. Note that since the <code>^</code> is optional, it has been left off in this case.</p> <pre><code>wm add Z2 message * +\n</code></pre>"},{"location":"reference/cli/cmd_wm/#warnings","title":"Warnings","text":"<p>Be careful how you use this command. It may have weird side effects (possibly even including system crashes). For example, the chunking mechanism can't backtrace through WMEs created via <code>wm add</code> nor will such WMEs ever be removed through Soar's garbage collection. Manually removing context/impasse WMEs may have unexpected side effects.</p>"},{"location":"reference/cli/cmd_wm/#wm-remove","title":"wm remove","text":"<p>Manually remove an element from working memory.</p> <pre><code>wm remove timetag\n</code></pre>"},{"location":"reference/cli/cmd_wm/#options_2","title":"Options:","text":"Option Description <code>timetag</code> A positive integer matching the timetag of an existing working memory element."},{"location":"reference/cli/cmd_wm/#description_1","title":"Description","text":"<p>The <code>wm remove</code> command removes the working memory element with the given timetag. This command is provided primarily for use in Soar input functions; although there is no programming enforcement, wm remove should only be called from registered input functions to delete working memory elements on Soar's input link.</p> <p>Beware of weird side effects, including system crashes.</p>"},{"location":"reference/cli/cmd_wm/#warnings_1","title":"Warnings","text":"<p><code>wm remove</code> should never be called from the RHS of a production: if you try to match a WME on the LHS of a production, and then remove the matched WME on the RHS, Soar will crash.</p> <p>If used other than by input and output functions interfaced with Soar, this command may have weird side effects (possibly even including system crashes). Removing input WMEs or context/impasse WMEs may have unexpected side effects. You've been warned.</p>"},{"location":"reference/cli/cmd_wm/#wm-watch","title":"wm watch","text":"<p>Print information about WMEs matching a certain pattern as they are added and removed.</p> <pre><code>wm watch -[a|r]  -t &lt;type&gt;  &gt;pattern&gt;\nwm watch -[l|R] [-t &lt;type&gt;]\n</code></pre>"},{"location":"reference/cli/cmd_wm/#options_3","title":"Options:","text":"Option Description <code>-a, --add-filter</code> Add a filter to print wmes that meet the type and pattern criteria. <code>-r, --remove-filter</code> Delete filters for printing wmes that match the type and pattern criteria. <code>-l, --list-filter</code> List the filters of this type currently in use. Does not use the pattern argument. <code>-R, --reset-filter</code> Delete all filters of this type. Does not use pattern arg. <code>-t, --type</code> Follow with a type of wme filter, see below."},{"location":"reference/cli/cmd_wm/#watch-patterns","title":"Watch Patterns:","text":"<p>The pattern is an id-attribute-value triplet:</p> <pre><code>id attribute value\n</code></pre> <p>Note that <code>*</code> can be used in place of the id, attribute or value as a wildcard that matches any string. Note that braces are not used anymore.</p>"},{"location":"reference/cli/cmd_wm/#watch-types","title":"Watch Types","text":"<p>When using the -t flag, it must be followed by one of the following:</p> Option Description <code>adds</code> Print info when a wme is <code>added</code>. <code>removes</code> Print info when a wme is <code>retracted</code>. <code>both</code> Print info when a wme is added <code>or</code> retracted. <p>When issuing a <code>-R</code> or <code>-l</code>, the <code>-t</code> flag is optional. Its absence is equivalent to <code>-t both</code>.</p>"},{"location":"reference/cli/cmd_wm/#description_2","title":"Description","text":"<p>This commands allows users to improve state tracing by issuing filter-options that are applied when watching WMEs. Users can selectively define which  <code>object-attribute-value</code> triplets are monitored and whether they are monitored for addition, removal or both, as they go in and out of working memory. </p>"},{"location":"reference/cli/cmd_wm/#examples_1","title":"Examples","text":"<p>Users can watch an <code>attribute</code> of a particular object (as long as that object already exists):</p> <pre><code>soar&gt; wm watch --add-filter -t both D1 speed *\n</code></pre> <p>or print WMEs that retract in a specific state (provided the <code>state</code> already exists):</p> <pre><code>soar&gt; wm watch --add-filter -t removes S3 * *\n</code></pre> <p>or watch any relationship between objects:</p> <pre><code>soar&gt; wm watch --add-filter -t both * ontop *\n</code></pre>"},{"location":"reference/cli/cmd_wm/#default-aliases","title":"Default Aliases","text":"<pre><code>add-wme       wm add\naw            wm add\nremove-wme    wm remove\nrw            wm remove\nwatch-wmes    wm watch\nwma           wm activation\n</code></pre>"},{"location":"reference/cli/cmd_wm/#see-also","title":"See Also","text":"<p>print trace</p>"},{"location":"soar/CommercialSoarOrganizations/","title":"Commercial Organizations Using Soar","text":"","tags":["organizations"]},{"location":"soar/CommercialSoarOrganizations/#soar-technology-inc","title":"Soar Technology, Inc.","text":"<p>Soar Technology Inc. is utilizing advanced artificial intelligence, grounded in scientific principles of human-system interaction and implemented through sound software engineering, SoarTech develops intelligent autonomous agent software for modeling and simulation, command and control, information visualization, robotics, and intelligence analysis, for the U.S. Army, Navy, Air Force, DARPA, JFCOM, DMSO and the intelligence community.</p>","tags":["organizations"]},{"location":"soar/CommercialSoarOrganizations/#cogniteam-ltd","title":"Cogniteam, Ltd.","text":"<p>Cogniteam is an Israeli company offering project development, consulting, and professional services in AI and robotics in general, and using Soar in particular. They work with major Israeli defense integrators, the Israeli Ministry of Defense, and universities.</p>","tags":["organizations"]},{"location":"soar/OtherAcademicInstitutions/","title":"Other Academic Research Groups Using Soar","text":"<p>University of Michigan: Our research focuses on extensions to the Soar architecture and the cognitive capabilities made possible by Soar. Recent architectural research includes work on reinforcement learning, episodic memory, semantic memory, mental imagery, and motor control. Our research on cognitive capabilities includes work on learning by situated interactive instruction, learning relational and continuous action models, and robot control. We work on a variety of domains that include video games, linguistics tasks, mobile robots, and planning tasks.</p> <p>Penn State: People in our lab help move the field of cognitive science. Our projects are focused on models that learn, ranging from how to provide models access to interfaces to analyzing the effects of caffeine on cognition to determining how children develop through the modeling of their development.  Other projects include the development of the Psychological Soar Tutorial and the Soar FAQ. For more information contact frank.ritter at psu.edu.</p> <p>University of Portland: Research is in improving the effectiveness of the episodic memory system. Much of the work is done external to Soar while honoring architectural requirements of Soar. Recent projects include: a survey of forgetting mechanisms, using memories to build plans, using sequences of episodes to overcome state aliasing and using experience to discover the relative importance of various WMEs that comprise an agent's episodes. Many of the insights from this research have been embodied in an advanced episodic memory system called Ziggurat. Throughout this process, the hardest part of creating an effective episodic memory system remains the same: creating an effective, domain-independent algorithm to select the best memory from a given cue.</p> <p>Pace University: An Intelligent Soar Assistant for a Virtual World Abe Guerra has built an assistant for IBM's virtual world. His agent uses Soar to reason about what a user needs and guides the user through the virtual world. The assistant interacts with the user through typed natural language commands, and can also assist with commands for using the virtual world interface. Here is an introductory paper on his project. There is also a movie of his agent navigating and a movie of his agent assisting a customer. A Soar Agent for Playing Poker Bob Follek has implemented an architecture for an autonomous poker player. His SoarBot uses Soar to play poker with the poker server set up by the University of Alberta Computer Poker Research Group. Bob can be reached at bob@codeblitz.com Researchers use Soar to build an intelligent assistant for IBM's virtual world. Agent reasons about what a user needs and guides the user through the virtual world. The assistant interacts with the user through typed natural language commands, and can also assist with commands for using the virtual world interface.  The research group also uses Soar to implement an architecture for an autonomous poker player. The agent uses Soar to play poker with the poker server set up by the University of Alberta Computer Poker Research Group.  </p> <p>University of Southern California and the Institute for Creative Technologies</p> <p>Bar Ilan University, Israel is home to the MAVERICK group, which conducts research in social intelligence, multi-agent and multi-robot systems, and plan recognition. Work in Soar has focused on developing Soar-based teamwork capabilities for modeling para-military units, multi-agent plan recognition and mirroring, and social comparison for groups.  </p>","tags":["institutions"]},{"location":"soar/Publications/","title":"Publications","text":"","tags":["research"]},{"location":"soar/Publications/#2023","title":"2023","text":"<p>N.Narayan, P. Ganeriwala, R. Jones, M. Matessa, S. Bhattacharyya, J. Davis, H. Purohit and S. Rollini (2023). Assuring Learning-Enabled Increasingly Autonomous System. IEEE SYSCON 2023.</p>","tags":["research"]},{"location":"soar/Publications/#2022","title":"2022","text":"<p>Jones, Steven (2022). A Cognitive Architecture Realization of Event Cognition Capabilities, Dissertation.</p> <p>Assanie, Mazin (2022). Learning General and Correct Procedural Knowledge in a Cognitive Architecture, Dissertation.</p> <p>Li, Justin, &amp; Boyle, Bryce. (2022) Towards a Computational Model of a Dynamic Feeling of Knowing.</p> <p>Laird, J. E. (2022) Introduction to Soar. https://arxiv.org/abs/2205.03854</p> <p>Ying Zhao, Erik Hemberg, Nate Derbinsky, Gabino Mata, and Una-May O\u2019Reilly. (2021). Simulating a logistics enterprise using an asymmetrical wargame simulation with soar reinforcement learning and coevolutionary algorithms. In Proceedings of the Genetic and Evolutionary Computation Conference Companion (GECCO \u201921). Association for Computing Machinery, New York, NY, USA, 1907\u20131915.</p> <p>Schatz, J., Jones, S. J., &amp; Laird, J. E. (2022). Modeling the Remote Associates Test as Retrievals from Semantic Memory. Cognitive Science, 46(6), e13145</p> <p>M.A.\u00a0Rovbo, P.S. Sorokoumov. (2022). Symbolic Control System for a Mobile Robotic Platform Based on SOAR Cognitive Architecture Part of the Studies in Systems, Decision and Control book series (SSDC,volume 419).</p> <p>Lindes, Peter. (2022). Constructing Meaning, Piece by Piece: A Computational Cognitive Model of Human Sentence Comprehension, Dissertation.</p> <p>Fei Lou, Qin Zhou, Joel Fuentes, Weichao Ding, and Chunhau Gu (2022). A Soar-Based Space Exploration Algorithm for Mobile Robots, Entropy Journal.</p> <p>Aaron Mininger, John E. Laird (2022). A Demonstration of Compositional, Hierarchical Interactive Task Learnng, AAAI Conference.</p>","tags":["research"]},{"location":"soar/Publications/#2021","title":"2021","text":"<p>John E. Laird (2021). An Analysis and Comparison of ACT-R and Soar, Proceedings of the Ninth Annual Conference on Advances in Cognitive Systems.</p> <p>Stearns, B. (2021). A Comprehensive Computational Model of PRIMs Theory for Task-Independent Procedural Learning, Dissertation.</p> <p>Preeti Ramaraj, Charles L. Ortiz, Jr., and Shiwali Mohan (2021). Unpacking Human Teachers\u2019 Intentions For Natural Interactive Task Learning, International Symposium on Robot and Human Interactive Communication (RO-MAN).</p> <p>Preeti Ramaraj (2021). Robots that Help Humans Build Better Mental Models of Robots, HRI Pioneers Workshop held at the ACM/IEEE International Conference on Human-Robot Interaction (HRI).</p> <p>Preeti Ramaraj (2021). Robots that Help Humans Build Better Mental Models of Robots, AAAI/SIGAI Doctoral Consortium collocated with the Thirty-Fifth Conference on Artificial Intelligence.</p> <p>Shiwali Mohan (2021). Exploring the Role of Common Model of Cognition in Designing Adaptive Coaching Interactions for Health Behavior Change, ACM Transactions on Interactive Intelligent Systems 11(1), 1-30.</p> <p>Andrea Stocco, Catherine Sibert, Zoe Steine-Hanson, Natalie Koh, John E. Laird, Christian J. Lebiere, Paul Rosenbloom (2021). Analysis of the human connectome data supports the notion of a \u201cCommon Model of Cognition\u201d for human and human-like intelligence across domains, NeuroImage 235(118035), 1-15.</p> <p>Mininger, A. (2021). Expanding Task Diversity in Explanation-Based Interactive Task Learning, Dissertation.</p>","tags":["research"]},{"location":"soar/Publications/#2020","title":"2020","text":"<p>Li, Justin. (2020) Integrating Declarative Long-Term Memory Retrievals into Reinforcement Learning ACS 2020</p> <p>Hiatt, L., &amp; Jones, S. (2020). An associative learning account for retrieval-induced forgetting, CogSci.</p> <p>Mohan, S., Klenk, M., Shreve, M., Evans, K., Ang, A., and Maxwell, J. (2020). Characterizing an Analogical Concept Memory for Newellian Cognitive Architectures, Advances in Cognitive Systems.</p> <p>Lindes, P. (2020). Intelligence and Agency, Journal of Artificial General Intelligence 11(2), 47-49. doi:10.2478/jagi-2020-0003.</p> <p>Laird, J. E. (2020). Intelligence, Knowledge &amp; Human-like Intelligence, Journal of Artificial General Intelligence 11(2), 41-44. doi:10.2478/jagi-2020-0003.</p> <p>Ramaraj, P., Klenk, M. and Mohan, S. (2020). Understanding Intentions in Human Teaching to Design Interactive Task Learning Robots, RSS 2020 Workshop: AI &amp; Its Alternatives in Assistive &amp; Collaborative Robotics: Decoding Intent.</p> <p>Lindes, P. (2020). Constructing Meaning in Small Increments., Poster presented at CogSci 2020. (Handout),</p> <p>Stearns, B., &amp; Laird, J. E. (2020). Toward Unifying Cognitive Architecture and Neural Task Set Theories, In Proceedings of The 42nd Annual Conference of the Cognitive Science Society (CogSci-20)</p> <p>Gudwin, R., Rohmer, E., Paraense, A., Froes, E., Gibaut, W., Oliveira, I., Rocha, S., Raizer, K., &amp; Feljan, A. V. (2020). The TROCA Project: An autonomous transportation robot controlled by a cognitive architecture, Cognitive Systems Research, vol.\u00a059, pp.\u00a0179-197.</p>","tags":["research"]},{"location":"soar/Publications/#2019","title":"2019","text":"<p>Jones, Steven, and John Laird. (2019). Anticipatory Thinking in Cognitive Architectures with Event Cognition Mechanisms, COGSAT@ AAAI Fall Symposium.</p> <p>Kirk, J. R., &amp; Laird, J. E. (2019). Learning hierarchical symbolic representations to support interactive task learning and knowledge transfer, Proceedings of the 28th International Joint Conference on Artificial Intelligence (pp.\u00a06095-6102). AAAI Press.</p> <p>Aaron Mininger and John E. Laird (2019). Using Domain Knowledge to Correct Anchoring Errors in a Cognitive Architecture, Advances in Cognitive Systems.</p> <p>Preeti Ramaraj, Saurav Sahay, Shachi H. Kumar, Walter S. Lasecki and John E. Laird. (2019). Towards using transparency mechanisms to build better mental models , Advances in Cognitive Systems 7th Goal Reasoning Workshop. Boston, MA.</p> <p>Peter Lindes (2019). Predictions of a Model of Language Comprehension Compared to Brain Data , Poster at the 17th International Conference on Cognitive Modeling. Abstract.</p> <p>Aaron Mininger and John E. Laird (2019). Using Domain Knowledge to Correct Anchoring Errors in a Cognitive Architecture , Proceedings of the Seventh Annual Conference on Advances in Cognitive Systems (pp.\u00a01\u201317). Boston, MA.</p> <p>Gluck, K. A. and J. E. Laird, eds.\u00a02019. Interactive Task Learning: Humans, Robots, and Agents Acquiring New Tasks through Natural Interactions , Str\u00fcngmann Forum Reports, vol.\u00a026, J. R. Lupp, series editor. Cambridge, MA: MIT Press.</p>","tags":["research"]},{"location":"soar/Publications/#2018","title":"2018","text":"<p>Stocco, A., Laird, J. E., Lebiere, C., Rosenbloom, P. S. (2018). Empirical Evidence from Neuroimaging Data for a Standard Model of the Mind , Proceedings of the 2018 Cognitive Science Conference, Madison, WI.</p> <p>Peter Lindes (2018). The Common Model of Cognition and humanlike language comprehension , Postproceedings of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures.</p> <p>Preeti Ramaraj and John E. Laird (2018). Establishing Common Ground for Learning Robots , RSS 2018: Workshop on Models and Representations for Natural Human-Robot Communication. Pittsburgh, PA.</p> <p>Bryan Stearns and John E. Laird (2018). Modeling Instruction Fetch in Procedural Learning , Proceedings of the 16th International Conference on Cognitive Modelling (ICCM). Madison, WI.</p> <p>Jule Schatz, Steven J. Jones, and John E. Laird (2018). An Architecture Approach to Modeling the Remote Associates Test , Proceedings of the 16th International Conference on Cognitive Modelling (ICCM). Madison, WI.</p> <p>Mininger, A. &amp; Laird J.E. (2018). Interactively Learning a Blend of Goal-Based and Procedural Tasks , National Conference on Artificial Intelligence, AAAI-2018.</p> <p>Laird, J. E., &amp; Mohan, S. (2018). Learning Fast and Slow: Levels of Learning in General Autonomous Intelligent Agents , National Conference on Artificial Intelligence, AAAI-2018. Senior Track, Winner of Blue Sky Award.</p> <p>Gudwin, R., Paraense, A., de Paula, S. M., Froes, E., Gibaut, W., Castro, E., Figueiredo, V., &amp; Raizer, K. (2018). An urban traffic controller using the MECA cognitive architecture, Biologically Inspired Cognitive Architectures.</p>","tags":["research"]},{"location":"soar/Publications/#2017","title":"2017","text":"<p>Laird, J. E., Lebiere, C. &amp; Rosenbloom, P. S. (2017). A Standard Model for the Mind: Toward a Common Computational Framework across Artificial Intelligence, Cognitive Science, Neuroscience, and Robotics , AI Magazine 38(4).</p> <p>Lauren Naylor and John E. Laird (2017). Opportunities and Challenges for Incorporating Runtime Ethical Constraints into a Learning Agent . Ann Arbor, Michigan.</p> <p>Ying Zhao, Emily Mooren, and Nate Derbinsky (2017). \\ Reinforcement Learning for Modeling Large-Scale Cognitive Reasoning , Proceedings of the 9th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, 2, 233-238. Madeira, Portugal.</p> <p>John E. Laird, Kevin Gluck, John Anderson, Kenneth D. Forbus Odest Chadwicke Jenkins, Christian Lebiere, Dario Salvucci, Matthias Scheutz, Andrea Thomaz, Greg Trafton, Robert E. Wray, Shiwali Mohan, and James R. Kirk (2017). Interactive Task Learning , IEEE Intelligent Systems, 32(4), 6-21, (invited).</p> <p>Chien Van Dang, Tin Trung Tran, Ki-Jong Gil, Yong-Bin Shin, Jae-Won Choi, Geon-Soo Park, and Jong-Wook Kim (2017). Application of Soar Cognitive Agent Based on Utilitarian Ethics Theory for Home Service Robots. Proceedings of the 14th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI). Jeju, Korea.</p> <p>Peter Lindes, Aaron Mininger, James R. Kirk, and John E. Laird (2017). Grounding Language for Interactive Task Learning. Proceedings of the 1st Workshop on Language Grounding for Robotics at ACL. (Supplemental Material).</p> <p>Bryan Stearns, Mazin Assanie, John E. Laird (2017). Applying Primitive Elements Theory For Procedural Transfer in Soar. Proceedings of the 15th International Conference on Cognitive Modelling (ICCM). Warwick, UK.</p> <p>Peter Lindes and John E. Laird (2017). Ambiguity Resolution in a Cognitive Model of Language Comprehension. Proceedings of the 15th International Conference on Cognitive Modelling (ICCM). Warwick, UK.</p> <p>Peter Lindes and John E. Laird (2017). Cognitive Modeling Approaches to Language Comprehension Using Construction Grammar. Proceedings of The AAAI Spring Symposium on Computational Construction Grammar and Natural Language Understanding.</p> <p>Emily M. Mooren (2017). Reinforcement learning applications to combat identification. Master\u2019s Thesis. Calhoun: The NPS Institutional Archive.</p> <p>Chien Van Dang, Tin Trung Tran, Trung Xuan Pham, Ki-Jong Gil, Yong-Bin Shin, and Jong-Wook Kim (2017). Implementation of a Refusable Human-Robot Interaction Task with Humanoid Robot by Connecting Soar and ROS. The Journal of Korea Robotics Society, Volume 12, Issue 1.</p>","tags":["research"]},{"location":"soar/Publications/#2016","title":"2016","text":"<p>DiFilippo, N. M. (2016). Framework for the automated disassembly of electronic waste using the Soar cognitive architecture , University of Rhode Island.</p> <p>J P\u00e9rez, E Cerezo, FJ Ser\u00f3n (2016). E-VOX: A Socially Enhanced Semantic ECA. Proceedings of the International Workshop on Social Learning and Multimodal Interaction for Designing Artificial Agents. Tokyo, Japan \u2014 November 2016.</p> <p>Kirk, J., Mininger, A., Laird, J. (2016). Learning task goals interactively with visual demonstrations. Biologically Inspired Cognitive Architectures. New York, New York, 2016.</p> <p>Kirk, J. and Laird, J. (2016). Learning General and Efficient Representations of Novel Games Through Interactive Instruction. In Proceedings of the Fourth Annual Conference on Advances in Cognitive Systems. Evanston, Illinois</p> <p>Jones, S. J., Wandzel, A. R., Laird, J. E. (2016). Efficient Computation of Spreading Activation Using Lazy Evaluation. Proceedings of the 14th International Conference on Cognitive Modeling (ICCM). University Park, Pennsylvania</p> <p>Kirk, J., Mininger, A., and Laird, J. E. (2016). A demonstration of interactive task learning , In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence.</p> <p>Mininger, A., and Laird, J. E. (2016). Interactively Learning Strategies for Handling References to Unseen or Unknown Objects. In Proceedings of the Fourth Annual Conference on Advances in Cognitive Systems.</p> <p>Lindes, Peter and John E. Laird (2016). Toward Integrating Cognitive Linguistics and Cognitive Language Processing. Proceedings of the 14th International Conference on Cognitive Modeling (ICCM). University Park, Pennsylvania.</p> <p>Li, J., Jones, S. J., Mohan, S., Derbinsky, N. (2016). Architectural Mechanisms for Mitigating Uncertainty during Long-Term Declarative Knowledge Access. Proceedings of the 4th Annual Conference on Advances in Cognitive Systems (ACS). Evanston, Illinois.</p>","tags":["research"]},{"location":"soar/Publications/#2015","title":"2015","text":"<p>Shiwali Mohan (2015). From Verbs to Tasks: An Integrated Account of Learning Tasks from Situated Interactive Instruction. Ph.D.\u00a0Thesis, University of Michigan, 2015.</p> <p>Mohan, S., Kirk, J., Mininger, A., Laird, J. E., (2015). Agent Requirements for Effective and Efficient Task-Oriented Dialog. AAAI 2015 Fall Symposium Series, 2015.</p> <p>S. Bhattacharyya, J. Davis, T. Vogl, M. Fix, A. McLean, M. Matessa and L. Smith-Velazquez (2015). Enhancing Autonomy with Trusted Cognitive Modeling. Related presentation: Enhancing Autonomy with Trust: Pilot license to the autonomy.</p> <p>Li, J., and Laird, J. E. (2015). Spontaneous Retrieval for Prospective Memory: Effects of Encoding Specificity and Retention Interval. Proceedings of the 13th International Conference on Cognitive Modeling (ICCM). Groningen, The Netherlands.</p> <p>Li, J., and Laird, J. E. (2015). Spontaneous Retrieval from Long-Term Memory in a Cognitive Architecture. Proceedings of the 29th AAAI Conference on Artificial Intelligence (AAAI). Austin, TX.</p>","tags":["research"]},{"location":"soar/Publications/#2014","title":"2014","text":"<p>Kirk, J., Laird, J. E. (2014). Interactive task learning for simple games. Advances in Cognitive Systems 3, 11-28.</p> <p>Laird, J. E., Mohan, S. (2014). A case study of knowledge integration across multiple memories in Soar. Biologically Inspired Cognitive Architectures, 8, 93-99.</p> <p>Mohan, S., Laird, J. (2014). Learning Goal-Oriented Hierarchical Tasks from Situated Interactive Instruction. Proceedings of the 27th AAAI Conference on Artificial Intelligence (AAAI).</p> <p>Laird et al.\u00a0(2014). Report on the NSF-funded Workshop on Interactive Task Learning **</p> <p>J.-Y. Puigbo, A. Pumarola, C. Angulo, and Ricardo Tellez (2014). Using a Cognitive Architecture for General-purpose Service Robot Control, Connection Science, Special Issue on AI and Cognition.</p>","tags":["research"]},{"location":"soar/Publications/#2013","title":"2013","text":"<p>Joseph Z. Xu (2013). Learning Integrated Relational and Continuous Action Models for Continuous Domains. Ph.D.\u00a0Thesis, University of Michigan, 2013.</p> <p>Mohan, S., Mininger, A., Laird, J. E. (2013). Towards an Indexical model of situated comprehension for real-world cognitive agents. Advances in Cognitive Systems 3, 163-182.</p> <p>Kirk, J. and Laird J. E. (2013). Learning Task Formulations through Situated Interactive Instruction. Proceedings of the 2nd Conference on Advances in Cognitive Systems. Baltimore, Maryland</p> <p>Mohan, S., Mininger, A., Laird J. E. (2013). Towards an Indexical Model of Situated Language Comprehension for Real-World Cognitive Agents. Proceedings of the 2nd Conference on Advances in Cognitive Systems. Baltimore, Maryland</p> <p>Laird, J. E. (2013). Reflections on Abstractions for General Artificial Intelligence, AAAI Fall Symposium on Abstractions for Intelligence, Washington, D.C.</p> <p>Laird, J. E. and Mohan, S. (2013). A Case Study of Knowledge Integration Across Multiple Memories in Soar, AAAI Fall Symposium on Abstractions for Intelligence, Washington, D.C.</p> <p>Gunetti, P., Dodd, T., Thompson, H. (2013). Simulation of a Soar-Based Autonomous Mission Management System for Unmanned Aircraft, Journal of Aerospace Computing, Information, and Communication, Vol. 10,</p> <p>No.\u00a02, pp.\u00a053-70. AIAA link</p> <p>Li, J., Laird, J. (2013). The Computational Problem of Prospective Memory. Proceedings of the 17th International Conference on Cognitive Modeling. Ottawa, Canada</p> <p>Li, J., Laird, J. (2013). Preemptive Strategies for Overcoming the Forgetting of Goals. Proceedings of the 27th AAAI Conference on Artificial Intelligence. Bellevue, WA.</p> <p>Mohan, S., Kirk, J., Laird, J. (2013). A Computational Model of Situated Task Learning with Interactive Instruction. Proceedings of the 12th International Conference on Cognitive Modeling. Ottawa, Canada.</p> <p>Xu, J. Z., Laird, J. E. (2013). Learning Integrated Symbolic and Continuous Action Models for Continuous Domains. Proceedings of the 27th AAAI Conference on Artificial Intelligence. Bellevue, WA.</p>","tags":["research"]},{"location":"soar/Publications/#2012","title":"2012","text":"<p>Derbinsky, N., Essl, G. (2012). Exploring Reinforcement Learning for Mobile Percussive Collaboration. Proceedings of the 12th International Conference on New Interfaces for Musical Expression (NIME). Ann Arbor, MI, USA.</p> <p>Derbinsky, N., Laird, J. E. (2012). Competence-Preserving Retention of Learned Knowledge in Soar\u2019s Working and Procedural Memories. Proceedings of the 11th International Conference on Cognitive Modeling (ICCM). Berlin, Germany.</p> <p>Derbinsky, N., Laird, J. E. (2012). Computationally Efficient Forgetting via Base-Level Activation. Proceedings of the 11th International Conference on Cognitive Modeling (ICCM). Berlin, Germany.</p> <p>Derbinsky, N., Li, J., Laird, J. E. (2012). A Multi-Domain Evaluation of Scaling in a General Episodic Memory. Proceedings of the 26th AAAI Conference on Artificial Intelligence (AAAI). Toronto, Canada.</p> <p>Derbinsky, N., Li, J., Laird, J. E. (2012). Algorithms for Scaling in a General Episodic Memory (Extended Abstract). Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems (AAMAS). Valencia, Spain.</p> <p>Laird, J. E., Kinkade, K. R., Mohan, S., and Xu, J. Z. (2012). Cognitive Robotics using the Soar Cognitive Architecture, 8th International Conference on Cognitive Robotics, (Cognitive Robotics Workshop, Twenty-Sixth Conference on Artificial Intelligence (AAAI-12)), Toronto, CA.</p> <p>Laird, J. E., Derbinsky, N. and Tinkerhess, M. (2012). Online Determination of Value-Function Structure and Action-value Estimates for Reinforcement Learning in a Cognitive Architecture, Advances in Cognitive Systems, Volume 2, December 2012, Palo Alto, California.</p> <p>Laird, J.E.: The Soar Cognitive Architecture, 2012, MIT Press.</p> <p>Laird, J.E. (2012). The Soar Cognitive Architecture, AISB Quarterly, \\#134.</p> <p>Li, J., Derbinsky, N., Laird, J. E. (2012). Functional Interactions between Memory and Recognition Judgments. Proceedings of the 26th AAAI Conference on Artificial Intelligence (AAAI). Toronto, Canada.</p> <p>Mohan, S. and Laird, J. E. (2012). Exploring Mixed-Initiative Interaction for Learning with Situated Instruction in Cognitive Agents, In Proceedings of the 26th AAAI Conference on Artificial Intelligence. (Extended Abstract).</p> <p>Mohan, S., and Laird, J. E.(2012). Situated Comprehension of Imperative Sentences in Embodied, Cognitive Agents, In The AAAI 2012 Workshop on Grounding Language for Physical Systems, Toronto CA.</p> <p>Mohan, S., Mininger, A., Kirk, J. and Laird, J. E. (2012). Acquiring Grounded Representations of Words with Situated Interactive Instruction, Advances in Cognitive Systems, Volume 2, December 2012, Palo Alto, California.</p> <p>Mohan, S., Mininger, A., Kirk, J. and Laird, J. E. (2012). Learning Grounded Language through Situated Interactive Instruction, In Papers from Robots Learning Interactively from Human Teachers (AAAI Fall Symposium Series), November 2012, Washington D.C.</p> <p>Nuxoll, A. M. Laird, J. E. (2012). Enhancing Intelligent Agents with Episodic Memory, Cognitive systems Research, 17-18,34-48.</p> <p>Shiquan Zhong, Hongwei Ma, Lizhen Zhou, Xuelian Wang, Shoufeng Ma, and Ning Jia (2012). Guidance Compliance Behavior on VMS Based on SOAR Cognitive Architecture. Mathematical Problems in Engineering, vol.\u00a02012, Article ID 530561, 21 pages.</p> <p>Stenger A., Fernando B., Heni M. (2012). Autonomous Mission Planning for UAVs: A Cognitive Approach, Proceedings des Deutschen Luft- und Raumfahrtkongress, Berlin, 10.09.-12.09.2012.</p> <p>Stensrud, B., Purcel, E., Fragomeni, G., Woods, A., Wintermute, S., and Garrity, P. (2012), No More Zombies! High-Fidelity Character Autonomy for Virtual Small-Unit Training, Proceedings of the Interservice/Industry Training, Simulation and Education Conference (I/ITSEC) 2012, Orlando, FL, December 3-6, 2012.</p> <p>Wintermute, S. (2012). Imagery in Cognitive Architecture: Representation and Control at Multiple Levels of Abstraction , Cognitive Systems Research, 19-20,1-29.</p>","tags":["research"]},{"location":"soar/Publications/#2011","title":"2011","text":"<p>Derbinsky, N., Essl, G.: Cognitive Architecture in Mobile Music Interactions. Proceedings of the International Conference on New Interfaces for Musical Expression, 104-107. Oslo, Norway.</p> <p>Derbinsky, N., Laird, J. E.: A Functional Analysis of Historical Memory Retrieval Bias in the Word Sense Disambiguation Task. Proceedings of the 25th AAAI Conference on Artificial Intelligence, 663-668. San Francisco, CA.</p> <p>Derbinsky, N., Laird, J. E.: Effective and Efficient Management of Soar\u2019s Working Memory via Base-Level Activation. Papers from the 2011 AAAI Fall Symposium Series: Advances in Cognitive Systems. Arlington, VA.</p> <p>Derbinsky, N., Laird, J. E.: A Preliminary Functional Analysis of Memory in the Word Sense Disambiguation Task. Proceedings of the 2nd Symposium on Human Memory for Artificial Agents, AISB, 25-29. York, England.</p> <p>Gorski, N. A., Laird, J. E. (2011) Learning to use episodic memory Cognitive Systems Research, 12, 144-153. doi:10.1016/j.cogsys.2010.08.001</p> <p>Laird, J. E., Derbinsky, N. Tinkerhess, M.: A Case Study in Integrating Probabilistic Decision Making and Learning in a Symbolic Cognitive Architecture: Soar Plays Dice. Papers from the 2011 AAAI Fall Symposium Series: Advances in Cognitive Systems. Arlington, VA.</p> <p>Laird, J. E., Derbinsky, N., Voigt, J. (2011). Performance Evaluation of Declarative Memory Systems in Soar, Proceedings of the 20th Behavior Representation in Modeling &amp; Simulation Conference, 33-40. Sundance, UT.</p> <p>Li, J., Laird, J. E.: Preliminary Evaluation of Long-term Memories for Fulfilling Delayed Intentions. Papers from the 2011 AAAI Fall Symposium Series: Advances in Cognitive Systems. Arlington, VA.</p> <p>Mohan, S., Laird, J. E. (2011).An Object-Oriented Approach to Reinforcement Learning in an Action Game, Proceedings of 7th the Artificial Intelligence for Interactive Digital Entertainment Conference, AIIDE 2011</p> <p>Mohan, S., Laird, J. E. (2011).Towards Situated, Interactive, Instructable Agents in a Cognitive Architecture, Papers from the 2011 AAAI Fall Symposium Series: Advances in Cognitive Systems. Arlington, VA.</p> <p>Wang, Y. (2011). Hierarchical Functional Category Learning for Efficient Value Function Approximation in Object-Based Environments. PhD Thesis, University of Michigan</p> <p>Xu, J. Z., Laird, J. E. (2011). Combining Learned Discrete and Continuous Action Models. Proceedings of the 25th AAAI Conference on Artificial Intelligence. San Francisco, CA.</p> <p>Lathrop, S., Wintermute, S., Laird, J. E. (2011). Exploring the Functional Advantages of Spatial and Visual Cognition From an Architectural Perspective. Topics in Cognitive Science 3, 796\u2013818.</p>","tags":["research"]},{"location":"soar/Publications/#2010","title":"2010","text":"<p>Derbinsky, N., Gorski, N.A.: Exploring the Space of Computational Memory Models. Proceedings of the 1st Symposium on Human Memory for Artificial Agents, AISB, 38-41. Leicester, England.</p> <p>Derbinsky, N., Laird, J. E., Smith, B.: Towards Efficiently Supporting Large Symbolic Declarative Memories. Proceedings of the 10th International Conference on Cognitive Modeling, 49-54. Philadelphia, PA.</p> <p>Derbinsky, N., Laird, J.E.: Extending Soar with Dissociated Symbolic Memories. Proceedings of the 1st Symposium on Human Memory for Artificial Agents, AISB, 31-37. Leicester, England.</p> <p>Gunetti, Dodd, Thompson, A Software Architecture for Autonomous Mission Management and Control, American Institute of Aeronautics and Astronautics, AIAA InfoTech? Aerospace Conference 2010, Paper No.\u00a02010-3305</p> <p>Gunetti, Thompson, Development and Evaluation of a Multi-Agent System for Gas-Turbine Engine Health Management, Automatic Control in Aerospace Online Journal, Year 3, Number 1, May 2010</p> <p>Laird, J. E., Wray III, R. E. (2010). Cognitive Architecture Requirements for Achieving AGI. Proceedings of the Third Conference on Artificial General Intelligence (AGI)</p> <p>Laird, J. E., Xu, J. Z., and Wintermute, S. (2010). Using Diverse Cognitive Mechanisms for Action Modeling. Proceedings of the Tenth International Conference on Cognitive Modeling, Philadelphia, PA.</p> <p>Wang, Y., Laird, J. E. (2010). Efficient Value Function Approximation with Unsupervised Hierarchical Categorization for a Reinforcement Learning Agent. International Conference on Intelligent Agent Technology (IAT-10), Toronto. (Best Paper Award Nomination)</p> <p>Wang, Y., Laird, J. E. (2010). A Computational Model of Functional Category Learning in a Cognitive Architecture. Proceedings of the Tenth International Conference on Cognitive Modeling (ICCM-10), Philadelphia, PA.</p> <p>Wintermute, S. (2010). Using Imagery to Simplify Perceptual Abstraction in Reinforcement Learning Agents. Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence (AAAI-10), Atlanta, Georgia</p> <p>Wintermute, S. (2010). Abstraction, Imagery, and Control in Cognitive Architecture. PhD Thesis, University of Michigan, Ann Arbor.</p> <p>Xu, J. Z., Laird, J. E. (2010). Instance-Based Online Learning of Deterministic Relational Action Models. Proceedings of the 24th AAAI Conference on Artificial Intelligence. Atlanta, GA.</p>","tags":["research"]},{"location":"soar/Publications/#2009","title":"2009","text":"<p>Bloch, M.K. Hierarchical Reinforcement Learning in the Taxicab Domain. (Report No.\u00a0CCA-TR-2009-02). Ann Arbor, MI: Center for Cognitive Architecture, University of Michigan. (2009)</p> <p>Derbinsky, N., Laird, J.E.: Efficiently Implementing Episodic Memory. Proceedings of the 8th International Conference on Case-Based Reasoning, 403-417. Seattle, WA.</p> <p>Fridman, N. &amp; Kaminka, G.A. (2009). Comparing Human and Synthetic Group Behaviors: A Model Based on Social Psychology. Proceedings of the 9th International Conference on Cognitive Modeling (ICCM-09). Manchester, UK.</p> <p>Gorski, N.A., and Laird, J.E. (2009). Evaluating Evaluations: A Comparative Study of Metrics for Comparing Learning Performances (Report No.\u00a0CCA-TR-2009-05). Ann Arbor, MI: Center for Cognitive Architecture, University of Michigan.</p> <p>Gorski, N.A. &amp; Laird, J.E. (2009). Learning to Use Episodic Memory. Proceedings of the 9th International Conference on Cognitive Modeling (ICCM-09). Manchester, UK.</p> <p>Jones, R.M., Stensrud, B.S. and Taylor, G. (2009), Knowledge-Rich Intelligent Agents for Special Operations Forces (SOF) TrainingProceedings of the 2009 Special Operations Forces Industry Conference (SOFIC), Tampa, FL. June 2-4, 2009.</p> <p>Laird, J.E. (2009). Towards Cognitive Robotics, SPIE Defense and Sensing Conferences, Orlando, FL.</p> <p>Laird, J.E., Derbinsky, N.: A Year of Episodic Memory. Proceedings of the Workshop on Grand Challenges for Reasoning from Experiences, IJCAI, 7-10. Pasadena, CA.</p> <p>Laird, J.E., Wray, R.E., Marinier, R.P., Langley, P. (2009) Claims and Challenges in Evaluating Human-Level Intelligent Systems, Proceedings of the Second Conference on Artificial General Intelligence.</p> <p>Langley, P., Laird, J.E., &amp; Rogers, S. (2009). Cognitive architectures: Research issues and challenges. Cognitive Systems Research 10, 141-160.</p> <p>Lonsdale, D., McGhee, J., Hendrickson, R. &amp; Christensen, C. (2009). Incremental Processing and Resource Usage. Proceedings of the 9th International Conference on Cognitive Modeling (ICCM-09). Manchester, UK.</p> <p>Mohan, S., Laird, J.E.: Learning to Play Mario. (Report No.\u00a0CCA-TR-2009-03). Ann Arbor, MI: Center for Cognitive Architecture, University of Michigan. (2009)</p> <p>Rosenbloom, P.S. (2009). Towards a New Cognitive Hourglass: Uniform Implementation of a Cognitive Architecture via Factor Graphs.Proceedings of the 9th International Conference on Cognitive Modeling (ICCM-09). Manchester, UK.</p> <p>Wintermute, S. (2009). Integrating Reasoning and Action through Simulation. In Proceedings of the Second Conference on Artificial General Intelligence (AGI-09). Arlington, VA.</p> <p>Wintermute, S. (2009). An Overview of Spatial Processing in Soar/SVS (Report No.\u00a0CCA-TR-2009-01). Ann Arbor, MI: Center for Cognitive Architecture, University of Michigan.</p> <p>Wintermute, S. (2009). Representing Problems (and Plans) Using Imagery In Papers from the 2009 AAAI Fall Symposium Series: Multi-Representational Architectures for Human-Level Intelligence, Arlington, VA, November 2009. AAAI Press.</p> <p>Wintermute, S., and Laird, J.E. (2009). Imagery as Compensation for an Imperfect Abstract Problem Representation. In Proceedings of The 31st Annual Conference of the Cognitive Science Society (CogSci-09)</p> <p>Xu, J., Wintermute, S., Wang, Y. J., Laird, J. Transferring Learned Search Heuristics (Report No.\u00a0CCA-TR-2009-04). Ann Arbor, MI: Center for Cognitive Architecture, University of Michigan. (2009)</p>","tags":["research"]},{"location":"soar/Publications/#2008","title":"2008","text":"<p>Gunetti, P., Thompson, H.: A Soar-Based Planning Agent for Gas-Turbine Engine Control and Health Management, Proceedings of the 17th IFAC World Congress, 2008, Volume \\# 17, part 1.</p> <p>Gunetti, Mills, Thompson, A Distributed Intelligent Agent architecture for Gas-Turbine Engine Health Monitoring, Proceedings of the 46th AIAA Aerospace Sciences Meeting and Exhibit, Reno, NV, 2008</p> <p>Laird, J. E. (2008). Extending the Soar Cognitive Architecture. In Proceedings of the First Conference on Artificial General Intelligence (AGI-08).</p> <p>Marinier, R. and Laird, J. E. (2008). Emotion-Driven Reinforcement Learning. CogSci 2008, Washington, D.C.</p> <p>Marinier, R., Laird, J. E., and Lewis, R. L. (2008). A Computational Unification of Cognitive Behavior and Emotion. Journal of Cognitive Systems Research.</p> <p>Stensrud, B., Taylor, G., Schricker, B., Montefusco, J. and Maddox, J. (2008), An Intelligent User Interface for Enhancing Computer Generated Forces Proceedings of the 2008 Fall Simulation Interoperability Workshop (SIW), Orlando, FL, September 15-19, 2008.</p> <p>Wintermute, S. and Laird, J. E. (2008). Bimodal Spatial Reasoning with Continuous Motion. Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence (AAAI-08), Chicago, Illinois</p> <p>Wintermute, S. and Lathrop, S.D. AI and Mental Imagery. In Papers from the 2008 AAAI Fall Symposium Series: Naturally Inspired AI, Arlington, VA, November 2008. AAAI Press.</p>","tags":["research"]},{"location":"soar/Publications/#2007","title":"2007","text":"<p>Cohen, M. A., Ritter, F. E., Haynes, S. R. (2007). Using Reflective Learning to Master Opponent Strategy in a Competitive Environment.Proceedings of the Eighth International Conference on Cognitive Modeling. Ann Arbor, MI.</p> <p>Gorski, N. A. and Laird, J. E. (2007). Investigating Transfer Learning in the Urban Combat Testbed. (Report No.\u00a0CCA-TR-2007-02). Ann Arbor, MI: Center for Cognitive Architecture, University of Michigan.</p> <p>Hogewoning, E., Broekens, J., Eggermont, J., Bovenkamp, E.G.P. Strategies for Affect-Controlled Action-Selection in Soar-RL. Proceedings of the 2nd. International Work-Conference on the Interplay between Natural and Artificial Computation (IWINAC), 2007. Murcia, Spain. LNCS 4528 (pp.\u00a0501-510), Springer.</p> <p>Jones, R. M., Lebiere, C., &amp; Crossman, J. A. (2007). Comparing modeling idioms in ACT-R and Soar. Proceedings of the Eighth International Conference on Cognitive Modeling. Ann Arbor, MI.</p> <p>Lathrop, S.D., and Laird, J.E. (2007). Towards Incorporating Visual Imagery into a Cognitive Architecture. Proceedings of the Eighth International Conference on Cognitive Modeling. Ann Arbor, MI.</p> <p>Magerko, B. Evaluating Preemptive Story Direction in the Interactive Drama Architecture. Journal of Game Development, vol.\u00a03, 2007. In press.</p> <p>Marinier, R.P., Laird, J.E. 2007. Computational Modeling of Mood and Feeling from Emotion. CogSci 2007. Nashville, TN.</p> <p>Nuxoll, A. M. and Laird, J. E. (2007). Extending Cognitive Architecture with Episodic Memory. In Proceedings of the 22nd National Conference on Artificial Intelligence (AAAI).</p> <p>Pearson, D., Gorski, N. A., Lewis, R. L., and Laird, J. E. (2007). Storm: A Framework for Biologically-Inspired Cognitive Architecture Research.Proceedings of the 8th International Conference on Cognitive Modeling. Ann Arbor, MI.</p> <p>Taylor, G., Stensrud, B., Eitelman, S. and Dunham, C. (2007), Towards Automating Airspace Management, Proceedings of the Computational Intelligence for Security and Defense Applications (CISDA) Conference, Honolulu, Hi. April 1-5, 2007.</p> <p>Wang, Y., and Laird, J.E. 2007. The Importance of Action History in Decision Making and Reinforcement Learning.</p> <p>Wintermute, S. and Laird, J.E. Predicate Projection in a Bimodal Spatial Reasoning System. Proceedings of the Twenty-Second AAAI Conference on Artificial Intelligence (AAAI-07), Vancouver, Canada</p> <p>Wintermute, S., Xu, J., and Laird, J.E. SORTS: A Human-Level Approach to Real-Time Strategy AI. Proceedings of the Third Artificial Intelligence and Interactive Digital Entertainment Conference (AIIDE-07), Stanford, California</p> <p>Wintermute, S., Xu, J., Irizarry, J. 2007. SORTS: Integrating Soar with a Real-Time Strategy Game (Report No.\u00a0CCA-TR-2007-01). Ann Arbor, MI: Center for Cognitive Architecture, University of Michigan.</p> <p>Yakir, A., and Kaminka, G. (2007). An Integrated Development Environment and Architecture for Soar-Based Agents. Nineteenth Innovative Applications of Artificial Intelligence Conference (IAAI-07), Vancouver, B.C., Canada.</p>","tags":["research"]},{"location":"soar/Publications/#2006","title":"2006","text":"<p>Gorski, N.A., and Laird, J.E. Experiments in Transfer Across Multiple Learning Mechanisms. Proceedings of the ICML-06 Workshop on Structural Knowledge Transfer for Machine Learning. Pittsburgh, PA.</p> <p>Jones, R. M., &amp; Wray, R. E. (2006). Comparative analysis of frameworks for knowledge-intensive agents. AI Magazine 27 (2), 45-56.</p> <p>Jones, R. M., Crossman, J. A., Lebiere, C., &amp; Best, B. J. (2006). An abstract language for cognitive modeling. Proceedings of the Seventh International Conference on Cognitive Modeling. Trieste, Italy: Edizioni Goliandiche.</p> <p>Kennedy, W.G., and Trafton, J.G. Long-Term Learning in Soar and ACT-R. Proceedings of the Seventh International Conference on Cognitive Modeling, (pp 162-168). Trieste, Italy: Edizioni Goliardiche.</p> <p>Konik, T., and Laird, J. 2006. Learning Goal Hierarchies from Structured Observations and Expert Annotations, Machine Learning. 64(1-3) 263-287.</p> <p>Lathrop, S., and Laird, J.E. 2006. Incorporating Visual Imagery into a Cognitive Architecture: An Initial Theory, Design and Implementation.</p> <p>Magerko, B., Stensrud, B., and Holt, L. Bringing the Schoolhouse Inside the Box - A Tool for Engaging, Individualized Training. 25th Army Science Conference, 2006. Orlando, FL.</p> <p>Marinier, R. and Laird, J. A Cognitive Architecture Theory of Comprehension and Appraisal. To be presented at Agent Construction and Emotion 2006, Vienna, Austria, April 2006.</p> <p>Ritter, F.E., Haynes, S. R., Cohen, M., Howes, A., John, B., Best, B., Lebiere, C., Jones, R. M., Crossman, J., Lewis, R. L., St.\u00a0Amant, R., McBride, S. P., Urbas, L., Leuchter, S., &amp; Vera, A. (2006). High-level behavior representation languages revisited. In /Proceedings of the Seventh International Conference on Cognitive Modeling,/ 404-407. Trieste, Italy: Edizioni Goliandiche.</p> <p>Rosenbloom, R. 2006, A Cognitive Odyssey: From the Power Law of Practice to a General Learning Mechanism and Beyond, in Tutorials in Quantitative Methods for Psychology, 2(2) 6-14.</p> <p>Stensrud, B., Taylor, G. and Crossman, J., (2006) IF-Soar: A Virtual, Speech-Enabled Agent for Indirect Fire Training, Proceedings of the 25th Army Science Conference, Orlando, FL.</p> <p>Wang, Y., and Laird, J.E. 2006. Integrating Semantic Memory into a Cognitive Architecture.</p>","tags":["research"]},{"location":"soar/Publications/#2005","title":"2005","text":"<p>Chong, R.S., Wray, R.E. Inheriting constraint in hybrid cognitive architectures: Appyling the EASE architecture to performance and learning in a simplified air traffic control task. In K. Gluck and R. Pew, eds, Modeling Human Behavior with Integrated Cognitive Architectures: Comparison, Evaluation, and Validation, 237\u2013304. Lawrence Erlbaum Associates, 2005.</p> <p>Jones, R. M. (2005). An introduction to cognitive architectures for modeling and simulation. /Proceedings of the Interservice/Industry Training/Simulation and Education Conference 2005./ Orlando, FL.</p> <p>Magerko, B, Wray, RE, Holt, LS, Stensrud, B. Customizing interactive training through individualized content and increased engagement. In Proceedings of the Interservice/Industry Training, Simulation and Education Conference (I/ITSEC) 2005, Orlando, FL, Dec 2005. National Training Systems Association.</p> <p>Magerko, B. Story Representation and Interactive Drama. 1st Artificial Intelligence and Interactive Digital Entertainment Conference, 2005. Marina Del Rey, CA.</p> <p>Nason, S. and Laird, J. E. (2005). Soar-RL: Integrating Reinforcement Learning with Soar. Cognitive Systems Research, 6, 51-59.</p> <p>Pearson, D.J., Laird, J.E. Incremental Learning of Procedural Planning Knowledge in Challenging Environments. To appear in special issue of Computational Intelligence on \u201cLearning to Improve Reasoning\u201d.</p> <p>Wallace, S. A. S-Assess: A Library for Self-Assessment. In Proceedings of the Fourth International Conference on Autonomous Agents and Multiagent Systems (AAMAS-05). pp.\u00a0256-263. Utrecht, The Netherlands. 2005.</p> <p>Wray, R.E., Chong, R.S. Comparing cognitive models and human behavior representations: Computational tools for expressing human behavior. Proceedings of the Infotech@Aerospace 2005 Conference, Arlington, VA, Sep 2005. American Institute of Aeronautics and Astronautics.</p> <p>Wray, R.E., Jones, R.M. An introduction to Soar as an agent architecture. In, R. Sun (ed), Cognition and Multi-agent Interaction: From Cognitive Modeling to Social Simulation, Cambridge University Press, pp 53\u201378, 2005.</p> <p>Wray, R.E., Laird, J.E., Nuxoll, A., Stokes, D., Kerfoot, A. Synthetic adversaries for urban combat training. AI Magazine, 26(3):82\u201392, 2005.</p>","tags":["research"]},{"location":"soar/Publications/#2004","title":"2004","text":"<p>Bovenkamp, E.G.P., Dijkstra, J., Bosch, J.G., and J.H.C. Reiber (2004). Multi-Agent segmentation of IVUS images. Pattern Recognition, 37, 647-663.</p> <p>Crossman, J., Wray, R. E., Jones, R. M., &amp; Lebiere, C. (2004). A High Level Symbolic Representation for Behavior Modeling. Paper presented at the 2004 Behavioral Representation in Modeling and Simulation, Arlington, VA.</p> <p>Jones, R. M. (2004). An introduction to cognitive architectures for modeling and simulation. /Proceedings of the Interservice/Industry Training/Simulation and Education Conference 2004./ Orlando, FL.</p> <p>Jones, R. M., &amp; Wray, R. E. (2004). Comparative Analysis of Frameworks for Knowledge-Intensive Intelligent Agents. Paper presented at the AAAI Fall Symposium Series on Achieving Human-level Intelligence through Integrated Systems and Research, Alexandria, VA.</p> <p>Jones, R. M., &amp; Wray, R. E. (2004). Toward an abstract machine architecture for intelligence. /Proceedings of the 2004 AAAI Workshop on Intelligent Agent Architectures: Combining the Strengths of Software Engineering and Cognitive Systems/.</p> <p>Jones, R. M., &amp; Wray, R. E. (2004). Toward an abstract machine architecture for intelligence. Paper presented at the AAAI Workshop on Intelligent Agent Architectures: Combining the Strengths of Software Engineering and Cognitive Systems, San Jose, CA.</p> <p>Jones, R. M., Wallace, A. J., &amp; Wessling, J. (2004). An intelligent synthetic wingman for army rotary wing aircraft. /Proceedings of the Interservice/Industry Training/Simulation and Education Conference 2004./ Orlando, FL.</p> <p>Konik, T., and Laird, J. (2004). Learning Goal Hierarchies from Structured Observations and Expert Annotations. In 14th International Conference on Inductive Logic Programming (ILP-2004), Lecture Notes in AI 3194. Springer</p> <p>Magerko, B. and Laird, J.E. Mediating the Tension Between Plot and Interaction. AAAI Workshop Series: Challenges in Game Artificial Intelligence, 2004. San Jose, California, 108-112.</p> <p>Magerko, B., Laird, J. E., Assanie, M., Kerfoot, A., Stokes, D., AI Characters and Directors for Interactive Computer Games, Proceedings of the 2004 Innovative Applications of Artificial Intelligence Conference, San Jose, CA, July 2004. AAAI Press.</p> <p>Marinier, R. and Laird, J. E. (2004). Towards a Comprehensive Computational Model of Emotions and Feelings. International Conference on Cognitive Modelling.</p> <p>Nason, S. and Laird, J. E., Soar-RL, Integrating Reinforcement Learning with Soar, International Conference on Cognitive Modeling, 2004.</p> <p>Nuxoll, A., Laird, J. E., A Cognitive Model of Episodic Memory Integrated With a General Cognitive Architecture, International Conference on Cognitive Modeling 2004.</p> <p>Nuxoll, A., Laird, J., James, M. Comprehensive Working Memory Activation in Soar. International Conference on Cognitive Modeling, Poster, 2004.</p> <p>Pearson, D. J., Laird, J. E. Redux: Example-Driven Diagrammatic Tools for Rapid Knowledge Acquisition, Proceedings of Behavior Representation in Modeling and Simulation, 2004, Washington, D.C.</p> <p>Taylor, G., &amp; Wray, R. E. (2004). Behavior Design Patterns: Engineering Human Behavior Models. Paper presented at the 2004 Behavioral Representation in Modeling and Simulation Conference, Arlington, VA.</p> <p>Wray, R. E., Laird, J. E., Nuxoll, A., Stokes, D., Kerfoot, A., Synthetic Adversaries for Urban Combat Training, Proceedings of the 2004 Innovative Applications of Artificial Intelligence Conference, San Jose, CA, July 2004. AAAI Press.</p> <p>Wray, R. E., Lisse, S., and Beard, J. Investigating ontology infrastructures for execution-oriented autonomous agents. Papers from the 2004 AAAI Spring Symposium Series: Knowledge Representation and Ontology for Autonomous Systems, Stanford, CA, March 2004. AAAI Press.</p>","tags":["research"]},{"location":"soar/Publications/#2003","title":"2003","text":"<p>Biddle, E. S., Henninger, A., Franceschini, R., &amp; Jones, R. M. (2003). Emotion modeling to enhance behavior representation: A survey of approaches. /Proceedings of the Interservice/Industry Training/Simulation and Education Conference 2003. /Orlando, FL.</p> <p>Chong, R. S., and Wray, R. E. RULEX-EM: Incorporating exemplars and memory effects in a hypothesis-testing model of category learning. Proceedings of the First European Cognitive Science Conference, Osnabrueck, Germany, Sep 2003. Lawrence Erlbaum Associates.</p> <p>Henninger, A. E., Jones, R. M., &amp; Chown, E. (2003). Behaviors that emerge from emotion and cognition: Implementation and evaluation of a symbolic-connectionist architecture. /Proceedings of the Seventh International Conference on Autonomous Agents/.</p> <p>Jones, R. M., &amp; Wray, R. E., III. (2003). Design principles for heavy intelligent agents. /Proceedings of the Seventh International Conference on Autonomous Agents/. Melbourne, Australia.</p> <p>Kennedy, W.G., and De Jong, K.A. Characteristics of long-term learning in Soar and its application to the utility problem. In Proceedings of the fifth international conference on machine learning (pp.\u00a0337-344). Menlo Park: AAAI Press.</p> <p>Magerko, B. and Laird, J. \u201cBuilding an Interactive Drama Architecture\u201d 1st International Conference on Technologies for Interactive Digital Storytelling and Entertainment, Darmstadt, Germany, March 2003.</p> <p>Pearson, D. J., Laird, J. E. \u201cExample-driven Diagrammatic Tools For Rapid Knowledge Acquisition\u201d, Visualizing Information in Knowledge Engineering (2003). A workshop at K-CAP 2003 (Second International Conference on Knowledge Capture). Oct 2003.</p> <p>Wallace, S. Validating Complex Agent Behavior, Ph.D.\u00a0Thesis University of Michigan, Ann Arbor, MI, 2003.</p> <p>Wallace. S. A., Laird, J. E. Comparing Agents and Humans Using Behavioral Bounding. International Joint Conference on Artificial Intelligence (IJCAI-03).</p> <p>Wray, R.E., and Chong, R. S. Quantitative Explorations of Category Learning using Symbolic Concept Acquisition. Proceedings of the 5th International Conference on Cognitive Modeling. Bamberg, Germany. April, 2003.</p> <p>Wray, R.E., Laird, J. E. (2003) \u201cVariability in Human Behavior Modeling for Military Simulations\u201d, Behavior Representation in Modeling and Simulation Conference. Scottsdale, AZ.</p> <p>Wray, R.E., Laird, J. E. An architectural approach to consistency in hierarchical execution. Journal of Artificial Intelligence Research. 19. 355\u2013398. 2003.</p>","tags":["research"]},{"location":"soar/Publications/#2002","title":"2002","text":"<p>Chown, E., Jones, R. M., &amp; Henninger, A. E. (2002). An architecture for emotional decision-making agents. /Proceedings of the Sixth International Conference on Autonomous Agents./ Bologna, Italy.</p> <p>Henninger, A. E., Jones, R. M., &amp; Chown, E. (2002). Behaviors that emerge from emotion and cognition: A first evaluation. /Proceedings of the Interservice/Industry Training /Simulation and Education Conference 2002/. Orlando, FL.</p> <p>Jones, R. M., Henninger, A. E., &amp; Chown, E. (2002). Interfacing behavior moderators with intelligent synthetic forces. /Proceedings of the Eleventh Conference on Computer Generated Forces and Behavior Representation./ Orlando, FL.</p> <p>Laird, J.E., Assanie, M., Bachelor, B., Benninghoff, N., Enam, S., Jones, B., Kerfoot, A., Lauver, C., Magerko, B., Sheiman, J. Stokes, D. Wallace, S. A Testbed for Developing Intelligent Synthetic Characters. In Artificial Intelligence and Interactive Entertainment: Papers from the 2002 AAAI Spring Symposium, 2002. Menlo Park, CA.</p> <p>Taylor, G. E., Jones, R. M., Goldstein, M. and Frederiksen, R. and Wray, R. E. VISTA: A Generic Toolkit for Visualizing Agent Behavior. Proceedings of the Eleventh Conference on Computer Generated Forces and Behavioral Representation. Institute for Simulation and Training. pp.\u00a0157\u2013167. May 2002.</p> <p>Wray, R. E., Beisaw, J. C., Jones, R. M., Koss, F. V., Nielsen, P. E. and Taylor, G. E. General, maintainable, extensible communications for computer generated forces. Proceedings of the Eleventh Conference on Computer Generated Forces and Behavioral Representation. Institute for Simulation and Training. pp.\u00a0563\u2013570. May 2002.</p> <p>Wray, R. E., Laird, J. E., Nuxoll, A., &amp; Jones, R. M. (2002). Intelligent opponents for virtual reality trainers. /Proceedings of the Interservice/Industry Training /Simulation and Education Conference 2002/. Orlando, FL.</p> <p>Zachary, W., Jones, R. M., &amp; Taylor, G. (2002). How to communicate to users what is inside a cognitive model. /Proceedings of the Eleventh Conference on Computer Generated Forces and Behavior Representation./ Orlando, FL.</p>","tags":["research"]},{"location":"soar/Publications/#2001","title":"2001","text":"<p>Henninger, A. E., Jones, R. M., &amp; Chown, E. (2001). A symbolic-connectionist framework for representing emotions in computer generated forces. /Proceedings of the Interservice/Industry Training /Simulation and Education Conference 2001/. Orlando, FL.</p> <p>Jones, R. M., Chown, E., &amp; Henninger, A. E. (2001). A hybrid symbolic-connectionist approach to modeling emotions. /Emotional and intelligent II: The tangled knot of social cognition, /papers from the 2001 Fall symposium (Technical Report no. FS-01-02). Menlo Park, CA: AAAI Press.</p> <p>Wray, R. E. and Jones, R. M. Resolving contentions between initial and learned knowledge. In Proceedings of the 2001 International Conference on Artificial Intelligence, Las Vegas, NV, June 2001.</p>","tags":["research"]},{"location":"soar/Publications/#2000","title":"2000","text":"<p>Jones, R. M., &amp; Kenny, P. G. (2000). Lessons learned from integrating STOW technology into an operational naval environment. /Proceedings of the 2000 Spring Simulation Interoperability Workshop/. Orlando, FL.</p> <p>Nielsen, P. E., Koss, F. V., Taylor, G. E., &amp; Jones, R. M. (2000). Communication with intelligent agents. /Proceedings of the Interservice/Industry Training Simulation and Education Conference 2000 /(pp.\u00a0824-834). Orlando, FL.</p>","tags":["research"]},{"location":"soar/Publications/#1999","title":"1999","text":"<p>Jones, R. M. (1999). Graphical visualization of situational awareness and mental state for intelligent computer-generated forces. /Proceedings of the Eighth Conference on Computer Generated Forces and Behavioral Representation/, 219-222. Orlando, FL.</p> <p>Jones, R. M., Laird, J. E., Nielsen, P. E., Coulter, K. J., Kenny, P., &amp; Koss, F. V. (1999). Automated intelligent pilots for combat flight simulation. /AI Magazine, 20/(1), 27-41.</p> <p>Ritter, F. E., Jones, R. M., &amp; Baxter, G. D. (1999). Reusable models and graphical interfaces: Realising the potential of a unified theory of cognition. In U. Schmid, J. Krems, &amp; F. Wysotzki (Eds.), /Mind modeling: A cognitive science approach to reasoning, learning and discovery /(pp.\u00a083-109). Lengerich, Germany: Pabst Scientific.</p>","tags":["research"]},{"location":"soar/Publications/#1998","title":"1998","text":"<p>Jones, R. M. (1998). A graphical user interface for human control of intelligent synthetic forces. /Proceedings of the Seventh Conference on Computer Generated Forces and Behavioral Representation/. Orlando, FL.</p> <p>Jones, R. M., Laird, J. E., &amp; Nielsen P. E. (1998). Automated intelligent pilots for combat flight simulation. /Proceedings of the Tenth Annual Conference on Innovative Applications of Artificial Intelligence/, 1047-1054. Menlo Park, CA: AAAI Press.</p> <p>Jones, R. M., Laird, J. E., &amp; Nielsen P. E. (1998). Real-time intelligent characters for a non-visual simulation environment. /Proceedings of the Computer Animation \u201998 Conference/.</p> <p>Jones, R. M., Neville, K., &amp; Laird, J. E. (1998). Modeling pilot fatigue with a synthetic behavior model. /Proceedings of the Seventh Conference on Computer Generated Forces and Behavioral Representation/. Orlando, FL.</p> <p>Laird, J. E., &amp; Jones R. M. (1998). Building advanced autonomous AI systems for large scale real time simulations. /Proceedings of the/ /Computer Game Developers Conference, /365-378. Long Beach, CA: Miller Freeman.</p> <p>Laird, J. E., Coulter, K. J., Jones, R. M., Kenny, P. G., Koss, F., &amp; Nielsen, P. E. (1998). Integrating intelligent computer generated forces in distributed simulations: TacAir-Soar in STOW-97. /Proceedings of the 1998 Spring Simulation Interoperability Workshop. Orlando, FL.</p> <p>Laird, J. E., Jones, R. M., &amp; Nielsen, P. E. (1998). Lessons learned from TacAir-Soar in STOW-97. /Proceedings of the Seventh Conference on Computer Generated Forces and Behavioral Representation/. Orlando, FL.</p> <p>Wray, R. E. and Laird, J. E. Maintaining consistency in hierarchical reasoning. In Proceedings of the Fifteenth National Conference on Artificial Intelligence, pages 928\u2013935, Madison, Wisconsin, 1998.</p>","tags":["research"]},{"location":"soar/Publications/#1997","title":"1997","text":"<p>Jones, R. M., &amp; Laird, J. E. (1997). Constraints on the design of a high-level model of cognition. /Proceedings of the Nineteenth Annual Conference of the Cognitive Science Society.</p>","tags":["research"]},{"location":"soar/Publications/#1996","title":"1996","text":"<p>Jones, R. M., Laird, J. E., &amp; Nielsen, P. E. (1996). Moving intelligent automated forces into theater-level scenarios. /Proceedings of the Sixth Conference on Computer Generated Forces and Behavioral Representation/, 113-117. Orlando, FL.</p> <p>Laird, J. E., Pearson, D. J., Jones, R. M., &amp; Wray, R. E., III. (1996). Dynamic knowledge integration during plan execution. /Plan execution: Problems and issues, /papers from the 1996 Fall symposium (Technical Report No.\u00a0FS-96-01). Menlo Park, CA: AAAI Press.</p>","tags":["research"]},{"location":"soar/Publications/#1992","title":"1992","text":"<p>Brian G. Milnes, Garrett Pelton, Robert Doorenbos, Mike H Laird, Paul Rosenbloom, and Allen Newell. 1992. A Specification of the Soar Cognitive Architecture in Z. Technical Report. Carnegie Mellon Univ., Pittsburgh, PA, USA.</p>","tags":["research"]},{"location":"soar/ResearchGroups/","title":"Soar Research Groups","text":"<p>There are many institutions conducting Soar research all over the world. In the following subsections, you can find links to some of them:</p> <ul> <li>University of Michigan Soar Group   A full listing of all members of the University of Michigan Soar group and Alumnae</li> <li>Other Academic Institutions   A listing of various research groups around the world who use Soar in their work.</li> <li>Commercial Soar Organizations   A listing of companies that use Soar in commercial applications or consulting work.   Soar researchers keep in touch via the soar-group email mailing lists, which you can join on this page.</li> </ul> <p>If you would like to have a link to your research group or company listed on these pages, please send a brief summary and the URL to laird@umich.edu with the subject \"Soar Research Group\".</p>","tags":["research"]},{"location":"soar/tags/","title":"Tags","text":"<p>Following is a list of relevant tags:</p>"},{"location":"soar/tags/#ros","title":"ROS","text":"<ul> <li>Building Soar and ROS1</li> </ul>"},{"location":"soar/tags/#agent-debugging","title":"agent debugging","text":"<ul> <li>Design Dogma</li> <li>Java Soar Debugger Intro</li> </ul>"},{"location":"soar/tags/#compile","title":"compile","text":"<ul> <li>Building Soar and ROS1</li> <li>How to compile SML Clients</li> </ul>"},{"location":"soar/tags/#debugger","title":"debugger","text":"<ul> <li>Command-Line Options for the Java Debugger and CLI</li> <li>Java Soar Debugger Intro</li> </ul>"},{"location":"soar/tags/#eaters","title":"eaters","text":"<ul> <li>Tank and Eaters Configuration</li> </ul>"},{"location":"soar/tags/#event","title":"event","text":"<ul> <li>SML Output Link Guide</li> </ul>"},{"location":"soar/tags/#institutions","title":"institutions","text":"<ul> <li>Academic Institutions</li> </ul>"},{"location":"soar/tags/#io","title":"io","text":"<ul> <li>SML Output Link Guide</li> </ul>"},{"location":"soar/tags/#kernel-programming","title":"kernel programming","text":"<ul> <li>Basic Kernel Terminology</li> <li>Timers</li> <li>Waterfall</li> <li>CLI Parsing Code</li> <li>IO and Reward Links</li> <li>Memory Leak Debugging with Visual Studio</li> </ul>"},{"location":"soar/tags/#organizations","title":"organizations","text":"<ul> <li>Commercial Soar Organizations</li> </ul>"},{"location":"soar/tags/#research","title":"research","text":"<ul> <li>Publications</li> <li>Research Groups</li> </ul>"},{"location":"soar/tags/#sml","title":"sml","text":"<ul> <li>Threads in SML</li> <li>SML Output Link Guide</li> <li>Soar Technical FAQ</li> <li>Soar Markup Language</li> </ul>"},{"location":"soar/tags/#substate","title":"substate","text":"<ul> <li>Waterfall</li> </ul>"},{"location":"soar/tags/#threads","title":"threads","text":"<ul> <li>Threads in SML</li> </ul>"},{"location":"soar_manual/","title":"The Soar User\u2019s Manual","text":"<p>John E. Laird, Clare Bates Congdon, Mazin Assanie, Nate Derbinsky and Joseph Xu</p> <p>Additional contributions by:</p> <p>Mitchell Bloch, Karen J. Coulter, Steven Jones, Aaron Mininger, Preeti Ramaraj and Bryan Stearns</p> <p>Division of Computer Science and Engineering University of Michigan</p> <p>Errors may be reported to John E. Laird (laird@umich.edu)</p> <p>Copyright \u00a9 1998 - 2023, The Regents of the University of Michigan</p> <p>Development of earlier versions of this manual were supported under contract N00014-92- K-2015 from the Advanced Systems Technology Office of the Advanced Research Projects Agency and the Naval Research Laboratory, and contract N66001-95-C-6013 from the Advanced Systems Technology Office of the Advanced Research Projects Agency and the Naval Command and Ocean Surveillance Center, RDT&amp;E division.</p>"},{"location":"soar_manual/01_Introduction/","title":"Introduction","text":"<p>Soar has been developed to be an architecture for constructing general intelligent systems. It has been in use since 1983, and has evolved through many different versions. This manual documents the most current of these: version 9.6.1.</p> <p>Our goals for Soar include that it ultimately be an architecture that can:</p> <ul> <li>be used to build systems that work on the full range of tasks expected of an intelligent agent, from highly routine to extremely difficult, open-ended problems;</li> <li>represent and use appropriate forms of knowledge, such as procedural, declarative, episodic, and possibly iconic;</li> <li>employ the full range of possible problem solving methods;</li> <li>interact with the outside world; and</li> <li>learn about all aspects of the tasks and its performance on those tasks.</li> </ul> <p>In other words, our intention is for Soar to support all the capabilities required of a general intelligent agent. Below are the major principles that are the cornerstones of Soar\u2019s design:</p> <ol> <li>The number of distinct architectural mechanisms should be minimized. Classically    Soar had only a single representation of permanent knowledge (production rules), a    single representation of temporary knowledge (objects with attributes and values), a    single mechanism for generating goals (automatic subgoaling), and a single learning    mechanism (chunking). It was only as Soar was applied to diverse tasks in complex    environments that we found these mechanisms to be insufficient and added new long-    term memories (semantic and episodic) and learning mechanisms (semantic, episodic,    and reinforcement learning) to extend Soar agents with crucial new functionalities.</li> <li>All decisions are made through the combination of relevant knowledge at run-time.    In Soar, every decision is based on the current interpretation of sensory data and any    relevant knowledge retrieved from permanent memory. Decisions are never precompiled    into uninterruptible sequences.</li> </ol>"},{"location":"soar_manual/01_Introduction/#using-this-manual","title":"Using this Manual","text":"<p>We expect that novice Soar users will read the manual in the order it is presented. Not all users will makes use of the mechanisms described in chapters 4-8, but it is important to know that these capabilities exist.</p> <p>Chapter 2 and Chapter 3 describe Soar from different perspectives: Chapter 2 describes the Soar architecture, but avoids issues of syntax, while Chapter 3 describes the syntax of Soar, including the specific conditions and actions allowed in Soar productions.</p> <p>Chapter 4 describes chunking, Soar\u2019s mechanism to learn new procedural knowledge (productions).</p> <p>Chapter 5 describes reinforcement learning (RL), a mechanism by which Soar\u2019s procedural knowledge is tuned given task experience.</p> <p>Chapter 6 and Chapter 7 describe Soar\u2019s long-term declarative memory systems, semantic and episodic.</p> <p>Chapter 8 describes the Spatial Visual System (SVS), a mechanism by which Soar can convert complex perceptual input into practical semantic knowledge.</p> <p>Chapter 9 describes the Soar user interface \u2014 how the user interacts with Soar. The chapter is a catalog of user-interface commands, grouped by functionality. The most accurate and up-to-date information on the syntax of the Soar User Interface is found online, at the Soar web site, at https://github.com/SoarGroup/Soar/wiki/CommandIndex.</p> <p>Advanced users will refer most often to Chapter 9, flipping back to Chapters 2 and 3 to answer specific questions.</p> <p>Chapters 2 and 3 make use of a Blocks World example agent. The Soar code for this agent can be downloaded at https://web.eecs.umich.edu/~soar/blocksworld.soar or found here.</p>"},{"location":"soar_manual/01_Introduction/#additional-back-matter","title":"Additional Back Matter","text":"<p>After these chapters is an index; the last pages of this manual contain a summary and index of the user-interface functions for quick reference.</p>"},{"location":"soar_manual/01_Introduction/#not-described-in-this-manual","title":"Not Described in This Manual","text":"<p>Some of the more advanced features of Soar are not described in this manual, such as how to interface with a simulator, or how to create Soar applications using multiple interacting agents. The Soar project website (see link below) has additional help documents and resources.</p> <p>For novice Soar users, try The Soar 9 Tutorial, which guides the reader through several example tasks and exercises.</p>"},{"location":"soar_manual/01_Introduction/#contacting-the-soar-group","title":"Contacting the Soar Group","text":"<p>The primary website for Soar is:</p> <p>http://soar.eecs.umich.edu/</p> <p>Look here for the latest Soar-related downloads, documentation, FAQs, and announcements, as well as links to information about specific Soar research projects and researchers.</p> <p>Soar kernel development is hosted on GitHub at</p> <p>https://github.com/SoarGroup</p> <p>This site contains the public GitHub repository, a wiki describing the command-line interface, and an issue tracker where users can report bugs or suggests features.</p> <p>To contact the Soar group or get help, or to receive notifications of significant developments in Soar, we recommend that you register with one or both of our email lists:</p> <p>For questions about using Soar, you can use the soar-help list. For other discussion or to receive announcements, use the soar-group list.</p> <p>Also, please do not hesitate to file bugs on our issue tracker:</p> <p>https://github.com/SoarGroup/Soar/issues</p> <p>To avoid redundant entries, please search for duplicate issues first.</p>"},{"location":"soar_manual/01_Introduction/#for-those-without-internet-access","title":"For Those Without Internet Access","text":"<p>Mailing Address:</p> <pre><code>The Soar Group\nArtificial Intelligence Laboratory\nUniversity of Michigan\n2260 Hayward Street\nAnn Arbor, MI 48109-2121\nUSA\n</code></pre>"},{"location":"soar_manual/01_Introduction/#different-platforms-and-operating-systems","title":"Different Platforms and Operating Systems","text":"<p>Soar runs on a wide variety of platforms, including Linux, Unix (although not heavily tested), Mac OS X, and Windows 10, 7, possibly 8 and Vista, XP, 2000 and NT). We currently test Soar on both 32-bit and 64-bit versions of Ubuntu Linux, OS X 10, and Windows 10.</p> <p>This manual documents Soar generally, although all references to files and directories use Unix format conventions rather than Windows-style folders.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/","title":"The Soar Architecture","text":"<p>This chapter describes the Soar architecture. It covers all aspects of Soar except for the specific syntax of Soar\u2019s memories and descriptions of the Soar user-interface commands.</p> <p>This chapter gives an abstract description of Soar. It starts by giving an overview of Soar and then goes into more detail for each of Soar\u2019s main memories (working memory, production memory, and preference memory) and processes (the decision procedure, learning, and input and output).</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#an-overview-of-soar","title":"An Overview of Soar","text":"<p>The design of Soar is based on the hypothesis that all deliberate goal-oriented behavior can be cast as the selection and application of operators to a state. A state is a representation of the current problem-solving situation; an operator transforms a state (makes changes to the representation); and a goal is a desired outcome of the problem-solving activity.</p> <p>As Soar runs, it is continually trying to apply the current operator and select the next operator (a state can have only one operator at a time), until the goal has been achieved. The selection and application of operators is illustrated in Figure 2.1.</p> Soar is continually trying to select and apply operators. <p>Soar has separate memories (and different representations) for descriptions of its current situation and its long-term procedural knowledge. In Soar, the current situation, including data from sensors, results of intermediate inferences, active goals, and active operators is held in working memory. Working memory is organized as objects. Objects are described in terms of their attributes; the values of the attributes may correspond to sub-objects, so the description of the state can have a hierarchical organization. (This need not be a strict hierarchy; for example, there\u2019s nothing to prevent two objects from being \"substructure\" of each other.)</p> <p>Long-term procedural knowledge is held in production memory. Procedural knowledge specifies how to respond to different situations in working memory, can be thought of as the program for Soar. The Soar architecture cannot solve any problems without the addition of long-term procedural knowledge. (Note the distinction between the \"Soar architecture\" and the \"Soar program\": The former refers to the system described in this manual, common to all users, and the latter refers to knowledge added to the architecture.)</p> <p>A Soar program contains the knowledge to be used for solving a specific task (or set of tasks), including information about how to select and apply operators to transform the states of the problem, and a means of recognizing that the goal has been achieved.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#types-of-procedural-knowledge-in-soar","title":"Types of Procedural Knowledge in Soar","text":"<p>Soar\u2019s procedural knowledge can be categorized into four distinct types of knowledge:</p> <ol> <li>Inference Rules    In Soar, we call these state elaborations. This knowledge provides monotonic inferences    that can be made about the state in a given situation. The knowledge created by such    rules are not persistent and exist only as long as the conditions of the rules are met.</li> <li>Operator Proposal Knowledge    Knowledge about when a particular operator is appropriate for a situation. Note    that multiple operators may be appropriate in a given context. So, Soar also needs    knowledge to determine which of the candidates to choose:</li> <li>Operator Selection Knowledge    Knowledge about the desirability of an operator in a particular situation.    Such knowledge can be either in terms of a single operator (e.g. never choose    this operator in this    situation) or relational (e.g. prefer this operator over another in this situation).</li> <li>Operator Application Rules    Knowledge of how a specific selected operator modifies the state. This knowledge    creates persistent changes to the state that remain even after the rule no longer matches    or the operator is no longer selected.</li> </ol> <p>Note that state elaborations can indirectly affect operator selection and application by creating knowledge that the proposal and application rules match on.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#problem-solving-functions-in-soar","title":"Problem-Solving Functions in Soar","text":"<p>These problem-solving functions are the primitives for generating behavior that is relevant to the current situation: elaborating the state, proposing candidate operators, comparing the candidates, and applying the operator by modifying the state. These functions are driven by the knowledge encoded in a Soar program.</p> <p>Soar represents that knowledge as production rules. Production rules are similar to \"if- then\" statements in conventional programming languages. (For example, a production might say something like \"if there are two blocks on the table, then suggest an operator to move one block on top of the other block\"). The \"if\" part of the production is called its conditions and the \"then\" part of the production is called its actions. When the conditions are met in the current situation as defined by working memory, the production is matched and it will fire, which means that its actions are executed, making changes to working memory.</p> <p>Selecting the current operator, involves making a decision once sufficient knowledge has been retrieved. This is performed by Soar\u2019s decision procedure, which is a fixed procedure that interprets preferences that have been created by the knowledge retrieval functions. The knowledge-retrieval and decision-making functions combine to form Soar\u2019s decision cycle.</p> <p>When the knowledge to perform the problem-solving functions is not directly available in productions, Soar is unable to make progress and reaches an impasse. There are three types of possible impasses in Soar:</p> <ol> <li>An operator cannot be selected because no new operators are proposed.</li> <li>An operator cannot be selected because multiple operators are proposed and    the comparisons are insufficient to determine which one should be selected.</li> <li>An operator has been selected, but there is insufficient knowledge to apply it.</li> </ol> <p>In response to an impasse, the Soar architecture creates a substate in which operators can be selected and applied to generate or deliberately retrieve the knowledge that was not directly available; the goal in the substate is to resolve the impasse. For example, in a substate, a Soar program may do a lookahead search to compare candidate operators if comparison knowledge is not directly available. Impasses and substates are described in more detail in Impasses and Substates.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#an-example-task-the-blocks-world","title":"An Example Task: The Blocks-World","text":"<p>We will use a task called the blocks-world as an example throughout this manual. In the blocks-world task, the initial state has three blocks named A, B, and C on a table; the operators move one block at a time to another location (on top of another block or onto the table); and the goal is to build a tower withAon top,Bin the middle, andCon the bottom. The initial state and the goal are illustrated in Figure 2.2.</p> <p>The Soar code for this task is available online at https://web.eecs.umich.edu/~soar/blocksworld.soar or in the here.  You do not need to look at the code at this point.</p> The initial state and goal of the \"blocks-world\" task. <p>The operators in this task move a single block from its current location to a new location; each operator is represented with the following information:</p> <ul> <li>the name of the block being moved</li> <li>the current location of the block (the \"thing\" it is on top of)</li> <li>the destination of the block (the \"thing\" it will be on top of)</li> </ul> <p>The goal in this task is to stack the blocks so that C is on the table, with block B on top of block C, and block A on top of block B.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#representation-of-states-operators-and-goals","title":"Representation of States, Operators, and Goals","text":"<p>The initial state in our blocks-world task - before any operators have been proposed or selected - is illustrated in Figure 2.3.</p> <p>A state can have only one selected operator at a time but it may also have a number of potential operators that are in consideration. These proposed operators should not be confused with the active, selected operator.</p> <p>Figure 2.4 illustrates working memory after the first operator has been selected. There are six operators proposed, and only one of these is actually selected.</p> <p>Goals are either represented explicitly as substructures of the working memory state with general rules that recognize when the goal is achieved, or are implicitly represented in the Soar program by goal-specific rules that test the state for specific features and recognize when the goal is achieved. The point is that sometimes a description of the goal will be available in the state for focusing the problem solving, whereas other times it may not.  Although representing a goal explicitly has many advantages, some goals are difficult to explicitly represent on the state.</p> <p>For example, the goal in our blocks-world task is represented implicitly in the provided Soar program. This is because a single production rule monitors the state for completion of the goal and halts Soar when the goal is achieved. (Syntax of Soar programs will be explained in Chapter 3.) If the goal was an explicit working memory structure, a rule could compare the configuration of blocks to that structure instead of having the goal embedded within the rule\u2019s programming.</p> An abstract illustration of the initial state of the blocks world as working memory objects. At this stage of problem solving, no operators have been proposed or selected. An abstract illustration of working memory in the blocks world after the first operator has been selected."},{"location":"soar_manual/02_TheSoarArchitecture/#proposing-candidate-operators","title":"Proposing candidate operators","text":"<p>As a first step in selecting an operator, one or more candidate operators are proposed.  Operators are proposed by rules that test features of the current state. When the blocks- world task is run, the Soar program will propose six distinct (but similar) operators for the initial state as illustrated in Figure 2.5. These operators correspond to the six different actions that are possible given the initial state.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#comparing-candidate-operators-preferences","title":"Comparing candidate operators: Preferences","text":"<p>The second step Soar takes in selecting an operator is to evaluate or compare the candidate operators. In Soar, this is done via rules that test the proposed operators and the current state, and then create preferences(stored in preference memory). Preferences assert the relative or absolute merits of the candidate operators. For example, a preference may say that operator A is a \"better\" choice than operator B at this particular time, or a preference may say that operator A is the \"best\" thing to do at this particular time. Preferences are discussed in detail in how preferences are evaluated to decide an operator.</p> The six operators proposed for the initial state of the blocks world each move one block to a new location."},{"location":"soar_manual/02_TheSoarArchitecture/#selecting-a-single-operator-decision","title":"Selecting a single operator: Decision","text":"<p>Soar attempts to select a single operator as a decision, based on the preferences available for the candidate operators. There are four different situations that may arise:</p> <ol> <li>The available preferences unambiguously prefer a single operator.</li> <li>The available preferences suggest multiple operators, and prefer a subset that can be    selected from randomly.</li> <li>The available preferences suggest multiple operators,but neither case 1 or 2 above hold.</li> <li>The available preferences do not suggest any operators.</li> </ol> <p>In the first case, the preferred operator is selected. In the second case, one of the subset is selected randomly. In the third and fourth cases, Soar has reached an impasse in problem solving, and a new substate is created. Impasses are discussed in Impasses and Substates.</p> <p>In our blocks-world example, the second case holds, and Soar can select one of the operators randomly</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#applying-the-operator","title":"Applying the operator","text":"<p>An operator applies by making changes to the state; the specific changes that are appropriate depend on the operator and the current state.</p> <p>There are two primary approaches to modifying the state: indirect and direct. Indirect changes are used in Soar programs that interact with an external environment: The Soar program sends motor commands to the external environment and monitors the external environment for changes. The changes are reflected in an updated state description, garnered from sensors. Soar may also make direct changes to the state; these correspond to Soar doing problem solving \"in its head\". Soar programs that do not interact with an external environment can make only direct changes to the state.</p> <p>Internal and external problem solving should not be viewed as mutually exclusive activities in Soar. Soar programs that interact with an external environment will generally have operators that make direct and indirect changes to the state: The motor command is represented as substructure of the state and it is a command to the environment. Also, a Soar program may maintain an internal model of how it expects an external operator will modify the world; if so, the operator must update the internal model (which is substructure of the state).</p> <p>When Soar is doing internal problem solving, it must know how to modify the state descriptions appropriately when an operator is being applied. If it is solving the problem in an external environment, it must know what possible motor commands it can issue in order to affect its environment.</p> <p>The example blocks-world task described here does not interact with an external environment. Therefore, the Soar program directly makes changes to the state when operators are applied. There are four changes that may need to be made when a block is moved in our task:</p> <ol> <li>The block that is being moved is no longer where it was (it is no longer \"on top\" of    the same thing).</li> <li>The block that is being moved is in a new location (it is \"on top\" of a new thing).</li> <li>The place that the block used to be in is now clear.</li> <li>The place that the block is moving to is no longer clear \u2014 unless it is the table, which    is always considered \"clear\".<sup>1</sup></li> </ol> <p>The blocks-world task could also be implemented using an external simulator. In this case, the Soar program does not update all the \"on top\" and \"clear\" relations; the updated state description comes from the simulator.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#making-inferences-about-the-state","title":"Making inferences about the state","text":"<p>Making monotonic inferences about the state is the other role that Soar long-term procedural knowledge may fulfill. Such elaboration knowledge can simplify the encoding of operators because entailments of a set of core features of a state do not have to be explicitly included in application of the operator. In Soar, these inferences will be automatically retracted when the situation changes such that the inference no longer holds.</p> <p>For instance, our example blocks-world task uses an elaboration to keep track of whether or not a block is \"clear\". The elaboration tests for the absence of a block that is \"on top\" of a particular block; if there is no such \"on top\", the block is \"clear\". When an operator application creates a new \"on top\", the corresponding elaboration retracts, and the block is no longer \"clear\".</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#problem-spaces","title":"Problem Spaces","text":"<p>If we were to construct a Soar system that worked on a large number of different types of problems, we would need to include large numbers of operators in our Soar program. For a specific problem and a particular stage in problem solving, only a subset of all possible operators are actually relevant. For example, if our goal is to count the blocks on the table, operators having to do with moving blocks are probably not important, although they may still be \"legal\". The operators that are relevant to current problem-solving activity define the space of possible states that might be considered in solving a problem, that is, they define the problem space.</p> <p>Soar programs are implicitly organized in terms of problem spaces because the conditions for proposing operators will restrict an operator to be considered only when it is relevant. The complete problem space for the blocks world is shown in Figure 2.6. Typically, when</p> The problem space in the blocks-world includes all operators that move blocks from one location to another and all possible configurations of the three blocks. <p>Soar solves a problem in this problem space, it does not explicitly generate all of the states, examine them, and then create a path. Instead, Soar isin a specific state at a given time (represented in working memory), attempting to select an operator that will move it to a new state. It uses whatever knowledge it has about selecting operators given the current situation, and if its knowledge is sufficient, it will move toward its goal.</p> <p>The same problem could be recast in Soar as a planning problem, where the goal is to develop a plan to solve the problem, instead of just solving the problem. In that case, a state in Soar would consist of a plan, which in turn would have representations of blocks-world states and operators from the original space. The operators would perform editing operations on the plan, such as adding new blocks-world operators, simulating those operators, etc. In both formulations of the problem, Soar is still applying operators to generate new states, it is just that the states and operators have different content.</p> <p>The remaining sections in this chapter describe the memories and processes of Soar: work- ing memory, production memory, preference memory, Soar\u2019s execution cycle (the decision procedure), learning, and how input and output fit in.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#working-memory-the-current-situation","title":"Working memory: The Current Situation","text":"<p>Soar represents the current problem-solving situation in its working memory. Thus, working memory holds the current state and operator and is Soar\u2019s \"short-term\" knowledge, reflecting the current knowledge of the world and the status in problem solving.</p> <p>Working memory contains elements called working memory elements, or WMEs for short. Each WME contains a very specific piece of information; for example, a WME might say that \"B1 is a block\". Several WMEs collectively may provide more information about the same object, for example, \"B1 is a block\", \"B1 is named A\", \"B1 is on the table\", etc. These WMEs are related because they are all contributing to the description of something that is internally known to Soar as \"B1\". B1 is called an identifier; the group of WMEs that share this identifier are referred to as an object in working memory. Each WME describes a different attribute of the object, for example, its name or type or location; each attribute has a value associated with it, for example, the name is A, the type is block, and the position is on the table. Therefore, each WME is an identifier-attribute-value triple, and all WMEs with the same identifier are part of the same object.</p> <p>Objects in working memory are linked to other objects: The value of one WME may be an identifier of another object. For example, a WME might say that \"B1 is on top of T1\", and another collection of WMEs might describe the object T1: \"T1 is a table\", \"T1 is brown\", and \"T1 is on top of F1\". And still another collection of WMEs might describe the object F1: \"F1 is a floor\", etc. All objects in working memory must be linked to a state, either directly or indirectly (through other objects). Objects that are not linked to a state will be automatically removed from working memory by the Soar architecture.</p> <p>WMEs are also often called augmentations because they \"augment\" the object, providing more detail about it. While these two terms are somewhat redundant, WME is a term that is used more often to refer to the contents of working memory (as a single identifier-attribute-value triple), while augmentation is a term that is used more often to refer to the description of an object. Working memory is illustrated at an abstract level in Figure 2.3.</p> <p>The attribute of an augmentation is usually a constant, such as <code>name</code> or <code>type</code>, because in a sense, the attribute is just a label used to distinguish one link in working memory from another.<sup>2</sup></p> <p>The value of an augmentation may be either a constant, such as <code>red</code>, or an identifier, such as 06. When the value is an identifier, it refers to an object in working memory that may have additional substructure. In semantic net terms, if a value is a constant, then it is a terminal node with no links; if it is an identifier it is a non terminal node.</p> <p>One key concept of Soar is that working memory is a set, which means that there can never be two elements in working memory at the same time that have the same identifier-attribute- value triple (this is prevented by the architecture). However, it is possible to have multiple working memory elements that have the same identifier and attribute, but that each have different values. When this happens, we say the attribute is a multi-valued attribute, which is often shortened to be multi-attribute.</p> <p>An object is defined by its augmentations and not by its identifier. An identifier is simply a label or pointer to the object. On subsequent runs of the same Soar program, there may be an object with exactly the same augmentations, but a different identifier, and the program will still reason about the object appropriately. Identifiers are internal markers for Soar; they can appear in working memory, but they never appear in a production.</p> <p>There is no predefined relationship between objects in working memory and \"real objects\" in the outside world. Objects in working memory may refer to real objects, such as block A; features of an object, such as the color red or shape cube; a relation between objects, such as on top; classes of objects, such as blocks; etc. The actual names of attributes and values have no meaning to the Soar architecture (aside from a few WMEs created by the architecture itself). For example, Soar doesn\u2019t care whether the things in the blocks world are called \"blocks\" or \"cubes\" or \"chandeliers\". It is up to the Soar programmer to pick suitable labels and to use them consistently.</p> <p>The elements in working memory arise from one of four sources:</p> <ol> <li>Productions: The actions on the RHS of productions create most working memory    elements.</li> <li>Architecture:<ul> <li>(a) State augmentations: The decision procedure automatically creates some special   state augmentations (type, superstate, impasse, ...) whenever a state is created.   States are created during initialization (the first state) or because of an impasse   (a substate).</li> <li>(b) Operator augmentations: The decision procedure creates the operator   augmentation of the state based on preferences. This records the selection of   the current operator.</li> </ul> </li> <li>Memory Systems </li> <li>SVS</li> <li>The Environment: External I/O systems create working memory elements on the    input-link for sensory data.</li> </ol> <p>The elements in working memory are removed in six different ways:</p> <ol> <li>The decision procedure automatically removes all state augmentations it creates when    the impasse that led to their creation is resolved.</li> <li>The decision procedure removes the operator augmentation of the state when that    operator is no longer selected as the current operator.</li> <li>Production actions that user <code>reject</code> preferences remove working memory elements that    were created by other productions.</li> <li>The architecture automatically removes i-supported WMEs when the productions that    created them no longer match.</li> <li>The I/O system removes sensory data from the input-link when it is no longer valid.</li> <li>The architecture automatically removes WMEs that are no longer linked to a state    (because some other WME has been removed).</li> </ol> <p>For the most part, the user is free to use any attributes and values that are appropriate for the task. However, states have special augmentations that cannot be directly created, removed, or modified by rules. These include the augmentations created when a state is created, and the state\u2019s operator augmentation that signifies the current operator (and is created based on preferences). The specific attributes that the Soar architecture automatically creates are listed in Impasses in Working Memory and in Production. Productions may create any other attributes for states.</p> <p>Preferences are held in a separate preference memory where they cannot be tested by productions. There is one notable exception. Since a soar program may need to reason about candidate operators,acceptable preferences are made available in working memory as well.  The <code>acceptable</code> preferences can then be tested by productions, which allows a Soar program to reason about candidates operators to determine which one should be selected. Preference memory and the different types of preferences will be discussed in Section Preference Memory: Selection Knowledge.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#production-memory-long-term-procedural-knowledge","title":"Production Memory: Long-term Procedural Knowledge","text":"<p>Soar represents long-term procedural knowledge as productions that are stored in production memory, illustrated in Figure 2.7. Each production has a set of conditions and a set of actions. If the conditions of a production match working memory, the production fires, and the actions are performed.</p> An abstract view of production memory. The productions are not related to one another."},{"location":"soar_manual/02_TheSoarArchitecture/#the-structure-of-a-production","title":"The structure of a production","text":"<p>In the simplest form of a production, conditions and actions refer directly to the presence (or absence) of objects in working memory. For example, a production might say:</p> <pre><code>CONDITIONS: block A is clear\n            block B is clear\nACTIONS:    suggest an operator to move block A ontop of block B\n</code></pre> <p>This is not the literal syntax of productions, but a simplification. The actual syntax is presented in Chapter 3.</p> <p>The conditions of a production may also specify the absence of patterns in working memory. For example, the conditions could also specify that \"block A is not red\" or \"there are no red blocks on the table\". But since these are not needed for our example production, there are no examples of negated conditions for now.</p> <p>The order of the conditions of a production do not matter to Soar except that the first condition must directly test the state. Internally, Soar will reorder the conditions so that the matching process can be more efficient. This is a mechanical detail that need not concern most users. However, you may print your productions to the screen or save them in a file; if they are not in the order that you expected them to be, it is likely that the conditions have been reordered by Soar.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#variables-in-productions-and-multiple-instantiations","title":"Variables in productions and multiple instantiations","text":"<p>In the example production above, the names of the blocks are \"hardcoded\", that is, they are named specifically. In Soar productions, variables are used so that a production can apply to a wider range of situations.</p> <p>When variables are bound to specific symbols in working memory elements by Soar\u2019s match- ing process, Soar creates an instantiation of the production. This instantiation consists of the matched production along with a specific and consistent set of symbols that matched the variables. A production instantiation is consistent only if every occurrence of a variable is bound to the same value. Multiple instantiations of the same production can be created since the same production may match multiple times, each with different variable bindings. If blocks A and B are clear, the first production (without variables) will suggest one operator. However, consider a new proposal production that used variables to test the names of the block. Such a production will be instantiated twice and therefore suggest two operators: one operator to move block A on top of block B and a second operator to move block B on top of block A.</p> <p>Because the identifiers of objects are determined at runtime, literal identifiers cannot appear in productions. Since identifiers occur in every working memory element, variables must be used to test for identifiers, and using the same variables across multiple occurrences is what links conditions together.</p> <p>Just as the elements of working memory must be linked to a state in working memory, so must the objects referred to in a production\u2019s conditions. That is, one condition must test a state object and all other conditions must test that same state or objects that are linked to that state.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#architectural-roles-of-productions","title":"Architectural roles of productions","text":"<p>Soar productions can fulfill the following four roles, by retrieving  different types of procedural knowledge:</p> <ol> <li>Operator proposal</li> <li>Operator comparison</li> <li>Operator application</li> <li>State elaboration</li> </ol> <p>A single production should not fulfill more than one of these roles (except for proposing an operator and creating an absolute preference for it). Although productions are not declared to be of one type or the other, Soar examines the structure of each production and classifies the rules automatically based on whether they propose and compare operators, apply operators, or elaborate the state.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#production-actions-and-persistence","title":"Production Actions and Persistence","text":"<p>Generally, actions of a production either create preferences for operator selection, or cre- ate/remove working memory elements. For operator proposal and comparison, a production creates preferences for operator selection. These preferences should persist only as long as the production instantiation that created them continues to match. When the production instantiation no longer matches, the situation has changed, making the preference no longer relevant. Soar automatically removes the preferences in such cases. These preferences are said to have i-support (for \"instantiation support\"). Similarly, state elaborations are simple inferences that are valid only so long as the production matches. Working memory elements created as state elaborations also have i-support and remain in working memory only as long as the production instantiation that created them continues to match working memory. For example, the set of relevant operators changes as the state changes, thus the proposal of operators is done with i-supported preferences. This way, the operator proposals will be retracted when they no longer apply to the current situation.</p> <p>However, the actions of productions that apply an operator, either by adding or removing elements from working memory, persist regardless of whether the operator is still selected or the operator application production instantiation still matches. For example, in placing a block on another block, a condition is that the second block be clear. However, the action of placing the first block removes the fact that the second block is clear, so the condition will no longer be satisfied.</p> <p>Thus, operator application productions do not retract their actions, even if they no longer match working memory. This is called o-support (for \"operator support\"). Working memory elements that participate in the application of operators are maintained throughout the existence of the state in which the operator is applied, unless explicitly removed (or if they become unlinked). Working memory elements are removed by a reject action of a operator- application rule.</p> <p>Whether a working memory element receives o-support or i-support is determined by the structure of the production instantiation that creates the working memory element. O-support is given only to working memory elements created by operator-application productions in the state where the operator was selected.</p> <p>An operator-application production tests the current operator of a state and modifies the state. Thus, a working memory element receives o-support if it is for an augmentation of the current state or substructure of the state, and the conditions of the instantiation that created it test augmentations of the current operator.</p> <p>During productions matching, all productions that have their conditions met fire, creating preferences which may add or remove working memory elements. Also, working memory elements and preferences that lose i-support are removed from working memory. Thus, several new working memory elements and preferences may be created, and several existing working memory elements and preferences may be removed at the same time. (Of course, all this doesn\u2019t happen literally at the same time, but the order of firings and retractions is unimportant, and happens in parallel from a functional perspective.)</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#preference-memory-selection-knowledge","title":"Preference Memory: Selection Knowledge","text":"<p>The selection of the current operator is determined by the preferences in preference memory. Preferences are suggestions or imperatives about the current operator, or information about how suggested operators compare to other operators. Preferences refer to operators by using the identifier of a working memory element that stands for the operator. After preferences have been created for a state, the decision procedure evaluates them to select the current operator for that state.</p> <p>For an operator to be selected, there will be at least one preference for it, specifically, a preference to say that the value is a candidate for the operator attribute of a state (this is done with either an  <code>\"acceptable</code> or <code>\"require\"</code> preference). There may also be others, for example to say that the value is \"best\".</p> <p>Preferences remain in preference memory until removed for one of the reasons previously discussed in Production Actions and Persistence.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#preference-semantics","title":"Preference Semantics","text":"<p>This section describes the semantics of each type of preference. More details on the preference resolution process are provided in How preferences are evaluated to decide an operator.</p> <p>Only a single value can be selected as the current operator, that is, all values are mutually exclusive. In addition, there is no implicit transitivity in the semantics of preferences. If A is indifferent to B, and B is indifferent to C, A and C will not be indifferent to one another unless there is a preference that A is indifferent to C (or C and A are both indifferent to all competing values).</p> <ul> <li> <p>Acceptable (+) An <code>acceptable</code> preference states that a value is a candidate for selection. All values, except those with require preferences, must have an <code>acceptable</code> preference in order to be selected. If there is only one value with an <code>acceptable</code> preference (and none with a require preference), that value will be selected as long as it does not also have a reject or a prohibit preference.</p> </li> <li> <p>Reject (-) A <code>reject</code> preference states that the value is not a candidate for selection.</p> </li> <li> <p>Better (<code>&gt;value</code>), Worse (<code>&lt;value</code>) A <code>better</code> or <code>worse</code> preference states, for the two values involved, that one value should not be selected if the other value is a candidate. <code>Better</code> and <code>worse</code> allow for the creation of a partial ordering between candidate values. <code>Better</code> and <code>worse</code> are simple inverses of each other, so that A better than B is equivalent to be worse than A.</p> </li> <li> <p>Best (&gt;) A <code>best</code> preference states that the value may be better than any competing value (unless there are other competing values that are also \"best\"). If a value is <code>best</code> (and not <code>rejected</code>, <code>prohibited</code>, or worse than another), it will be selected over any other value that is not also <code>best</code> (or required). If two such values are <code>best</code>, then any remaining preferences for those candidates (worst,indifferent) will be examined to determine the selection. Note that if a value (that is not <code>rejected</code> or <code>prohibited</code>) is better than a <code>best</code> value, the better value will be selected. (This result is counter- intuitive, but allows explicit knowledge about the relative worth of two values to dominate knowledge of only a single value. A require preference should be used when a value must be selected for the goal to be achieved.)</p> </li> <li> <p>Worst (&lt;) A <code>worst</code> preference states that the value should be selected only if there are no alternatives. It allows for a simple type of default specification. The semantics of the worst preference are similar to those for the <code>best</code> preference.</p> </li> <li> <p>Unary Indifferent (=) A <code>unary indifferent</code> preference states that there is positive knowledge that a single value is as good or as bad a choice as other expected alternatives.  When two or more competing values both have indifferent preferences, by default, Soar chooses randomly from among the alternatives. (The <code>decide indifferent-selection</code> function can be used to change this behavior).</p> </li> <li> <p>Binary Indifferent (=value) A <code>binary indifferent</code> preference states that two values are mutually indifferent and it does not matter which of these values are selected. It behaves like a unary in different preference, except that the operator value given this preference is only made indifferent to the operator value given as the argument.</p> </li> <li> <p>Numeric-Indifferent (=number) A <code>numeric-indifferent</code> preference is used to bias the random selection from mutually indifferent values. This preference includes a unary indifferent preference, and behaves in that manner when competing with another value having a unary indifferent preference. But when a set of competing operator values have <code>numeric-indifferent</code> preferences, the decision mechanism will choose an operator based on their numeric-indifferent values and the exploration policy. The available exploration policies and how they calculate selection probability are detailed in the documentation for the indifferent-selection command. When a single operator is given multiple <code>numeric-indifferent</code> preferences, they are either averaged or summed into a single value based on the setting of the <code>numeric-indifferent-mode</code> command. Numeric-indifferent preferences that are created by RL rules can be adjusted by the reinforcement learning mechanism. In this way, it\u2019s possible for an agent to begin a task with only arbitrarily initialized numeric indifferent preferences and with experience learn to make the optimal decisions.  See chapter 5 for more information.</p> </li> <li> <p>Require (!) A <code>require</code> preference states that the value must be selected if the goal is to be achieved. A <code>required</code> value is preferred over all others. Only a single operator value should be given a <code>require</code> preference at a time.</p> </li> <li> <p>Prohibit (~) A <code>prohibit</code> preference states that the value cannot be selected if the goal is to be achieved. If a value has a prohibit preference, it will not be selected for a value of an augmentation, independent of the other preferences.</p> </li> </ul> <p>If there is an <code>acceptable</code> preference for a value of an operator, and there are no other competing values, that operator will be selected. If there are multiple <code>acceptable</code> preferences for the same state but with different values, the preferences must be evaluated to determine which candidate is selected.</p> <p>If the preferences can be evaluated without conflict, the appropriate operator augmentation of the state will be added to working memory. This can happen when they all suggest the same operator or when one operator is preferable to the others that have been suggested. When the preferences conflict, Soar reaches an impasse, as described in Impasses and Substates.</p> <p>Preferences can be confusing; for example, there can be two suggested values that are both \"best\" (which again will lead to an impasse unless additional preferences resolve this conflict); or there may be one preference to say that value A is better than valueB and a second preference to say that value B is better than valueA.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#how-preferences-are-evaluated-to-decide-an-operator","title":"How preferences are evaluated to decide an operator","text":"<p>During the decision phase, operator preferences are evaluated in a sequence of eight steps, in an effort to select a single operator. Each step handles a specific type of preference, as illustrated in Figure 2.8. (The figure should be read starting at the top where all the operator preferences are collected and passed into the procedure. At each step, the procedure either exits through a arrow to the right, or passes to the next step through an arrow to the left.)</p> <p>Input to the procedure is the set of current operator preferences, and the output consists of:</p> <ol> <li>A subset of the candidate operators, which is either the empty set, a single, winning    candidate, or a larger set of candidates that may be conflicting, tied, or indifferent.</li> <li>An impasse-type.</li> </ol> <p>The procedure has several potential exit points. Some occur when the procedure has detected a particular type of impasse. The others occur when the number of candidates has been reduced to one (necessarily the winner) or zero (a no-change impasse).</p> An illustration of the preference resolution process. There are eight steps; only five of these provide exits from the resolution process. <p>Each step in Figure 2.8 is described below:</p> <ul> <li> <p>RequireTest (!) This test checks for required candidates in preference memory and also constraint-failure impasses involving require preferences, cf. Impasses and Substates.</p> <ul> <li>If there is exactly one candidate operator with a require preference and that   candidate does not have a prohibit preference, then that candidate is the winner   and preference semantics terminates.</li> <li>Otherwise \u2014 If there is more than one required candidate, then a constraint-   failure impasse is recognized and preference semantics terminates by returning   the set of required candidates.</li> <li>Otherwise \u2014 If there is a required candidate that is also prohibited, a constraint-   failure impasse with the required/prohibited value is recognized and preference   semantics terminates.</li> <li>Otherwise \u2014 There is no required candidate; candidates are passed to AcceptableCollect.</li> </ul> </li> <li> <p>AcceptableCollect (+) This operation builds a list of operators for which there is an acceptable preference in preference memory. This list of candidate operators is passed to the ProhibitFilter.</p> </li> <li> <p>ProhibitFilter (~) This filter removes the candidates that have prohibit preferences in memory. The rest of the candidates are passed to the RejectFilter.</p> </li> <li> <p>RejectFilter (-) This filter removes the candidates that have reject preferences in mem- ory.</p> </li> <li> <p>Exit Point 1:</p> <ul> <li>At this point, if the set of remaining candidates is empty, a no-change impasse is   created with no operators being selected.</li> <li>If the set has one member, preference semantics terminates and this set is re-   turned.</li> <li>Otherwise, the remaining candidates are passed to the BetterWorseFilter.</li> </ul> </li> <li> <p>BetterWorseFilter (&gt;), (&lt;) This filter removes any candidates that are worse than an- other candidate.</p> </li> <li> <p>Exit point 2:  </p> <ul> <li>If the set of remaining candidates is empty, a conflict impasse is created returning   the set of all candidates passed into this filter, i.e. all of the conflicted operators.</li> <li>If the set of remaining candidates has one member, preference semantics terminates and this set is returned.</li> <li>Otherwise, the remaining candidates are passed to the BestFilter.</li> </ul> </li> <li> <p>BestFilter (&gt;) If some remaining candidate has a best preference, this filter removes any candidates that do not have a best preference. If there are no best preferences for any of the current candidates, the filter has no effect. The remaining candidates are passed to the WorstFilter.</p> </li> <li> <p>Exit Point 3:</p> <ul> <li>At this point, if the set of remaining candidates is empty, a no-change impasse is   created with no operators being selected.</li> <li>If the set has one member, preference semantics terminates and this set is re-   turned.</li> <li>Otherwise, the remaining candidates are passed to the WorstFilter.</li> </ul> </li> <li> <p>WorstFilter (&lt;) This filter removes any candidates that have a <code>worst</code> preference. If all    remaining candidates have <code>worst</code> preferences or there are no <code>worst</code> preferences, this    filter has no effect.</p> </li> <li> <p>Exit Point 4:</p> <ul> <li>At this point, if the set of remaining candidates is empty, a no-change impasse is   created with no operators being selected.</li> <li>If the set has one member, preference semantics terminates and this set is re-   turned.</li> <li>Otherwise, the remaining candidates are passed to the IndifferentFilter.</li> </ul> </li> <li> <p>IndifferentFilter (=) This operation traverses the remaining candidates and marks each    candidate for which one of the following is true:</p> <ul> <li>the candidate has a unary indifferent preference</li> <li>the candidate has a numeric indifferent preference</li> </ul> </li> </ul> <p>This filter then checks every candidate that is not one of the above two types to see if it has a binary indifferent preference with every other candidate. If one of the candidates fails this test, then the procedure signals a tie impasse and returns the complete set of candidates that were passed into the IndifferentFilter. Otherwise, the candidates are mutually indifferent, in which case an operator is chosen according to the method set by the <code>decide indifferent-selection</code> command.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#soars-execution-cycle-without-substates","title":"Soar\u2019s Execution Cycle: Without Substates","text":"<p>The execution of a Soar program proceeds through a number of decision cycles. Each cycle has five phases:</p> <ol> <li>Input: New sensory data comes into working memory.</li> <li>Proposal: Productions fire (and retract) to interpret new data (state    elaboration), propose operators for the current situation (operator proposal),    and compare proposed operators (operator comparison). All of the actions of    these productions are i-supported. All matched productions fire in parallel (and    all retractions occur in parallel), and matching and firing continues until    there are no more additional complete matches or retractions of productions    (quiescence).</li> <li>Decision: A new operator is selected, or an impasse is detected and a new state is    created.</li> <li>Application: Productions fire to apply the operator (operator application).    The actions of these productions will be o-supported. Because of changes from    operator application productions, other productions with i-supported actions may    also match or retract. Just as during proposal, productions fire and retract in    parallel until quiescence.</li> <li>Output: Output commands are sent to the external environment.</li> </ol> <p>The cycles continue until the halt action is issued from the Soar program (as the action of a production) or until Soar is interrupted by the user.</p> <p>An important aspect of productions in Soar to keep in mind is that all productions will always fire whenever their conditions are met, and retract whenever their conditions are no longer met. The exact details of this process are shown in Figure 2.9. The Proposal and Application phases described above are both composed of as many elaboration cycles as are necessary to reach quiescence. In each elaboration cycle, all matching productions fire and the working memory changes or operator preferences described through their actions are made. After each elaboration cycle, if the working memory changes just made change the set of matching productions, another cycle ensues. This repeats until the set of matching rules remains unchanged, a situation called quiescence.</p> A detailed illustration of Soar\u2019s decision cycle. <p>After quiescence is reached in the Proposal phase, the Decision phase ensues, which is the architectural selection of a single operator, if possible. Once an operator is selected, the Apply phase ensues, which is practically the same as the Proposal phase, except that any productions that apply the chosen operator (they test for the selection of that operator in their conditions) will now match and fire.</p> <p>During the processing of these phases, it is possible that the preferences that resulted in the selection of the current operator could change. Whenever operator preferences change, the preferences are re-evaluated and if a different operator selection would be made, then the current operator augmentation of the state is immediately removed. However, a new operator is not selected until the next decision phase, when all knowledge has had a chance to be retrieved. In other words, if, during the Apply phase, the production(s) that proposed the selected operator retract, that Apply phase will immediately end.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#input-and-output","title":"Input and Output","text":"<p>Many Soar users will want their programs to interact with a real or simulated environment. For example, Soar programs may control a robot, receiving sensory inputs and sending command outputs. Soar programs may also interact with simulated environments, such as a flight simulator. Input is viewed as Soar\u2019s perception and output is viewed as Soar\u2019s motor abilities.</p> <p>When Soar interacts with an external environment, it must make use of mechanisms that allow it to receive input from that environment and to effect changes in that environment; the mechanisms provided in Soar are called input functions and output functions.</p> <ul> <li>Input functions add and delete elements from working memory in response to changes in the external environment.</li> <li>Output functions attempt to effect changes in the external environment.</li> </ul> <p>Input is processed at the beginning of each execution cycle and output occurs at the end of each execution cycle. See Soar I/O: Input and Output in Soar for more information.</p> <p>A simplified version of the Soar algorithm:  <pre><code>Soar\n   while (HALT not true) Cycle;\n\nCycle\n   InputPhase;\n   ProposalPhase;\n   DecisionPhase;\n   ApplicationPhase;\n   OutputPhase;\n\nProposalPhase\n   while (some i-supported productions are waiting to fire or retract)\n   FireNewlyMatchedProductions;\n   RetractNewlyUnmatchedProductions;\n\nDecisionPhase\n   for (each state in the stack,\n      starting with the top-level state)\n   until (a new decision is reached)\n      EvaluateOperatorPreferences; /_ for the state being considered _/\n      if (one operator preferred after preference evaluation)\n         SelectNewOperator;\n      else /_ could be no operator available or _/\n         CreateNewSubstate; /_ unable to decide between more than one _/\n\nApplicationPhase\n   while (some productions are waiting to fire or retract)\n      FireNewlyMatchedProductions;\n      RetractNewlyUnmatchedProductions;\n</code></pre></p>"},{"location":"soar_manual/02_TheSoarArchitecture/#impasses-and-substates","title":"Impasses and Substates","text":"<p>When the decision procedure is applied to evaluate preferences and determine the operator augmentation of the state, it is possible that the preferences are either incomplete or inconsistent. The preferences can be incomplete in that no acceptable operators are suggested, or that there are insufficient preferences to distinguish among <code>acceptable</code> operators. The preferences can be inconsistent if, for instance, operator A is preferred to operator B, and operator B is preferred to operator A. Since preferences are generated independently across different production instantiations, there is no guarantee that they will be consistent.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#impasse-types","title":"Impasse Types","text":"<p>There are four types of impasses that can arise from the preference scheme.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#tie-impasse","title":"Tie impasse","text":"<p>A tie impasse arises if the preferences do not distinguish between two or more operators that have <code>acceptable</code> preferences. If two operators both have best or worst preferences, they will tie unless additional preferences distinguish between them.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#conflict-impasse","title":"Conflict impasse","text":"<p>A conflict impasse arises if at least two values have conflicting better or worse preferences (such as A is better than B and B is better than A) for an operator, and neither one is rejected, prohibited, or required.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#constraint-failure-impasse","title":"Constraint-failure impasse","text":"<p>A constraint-failure impasse arises if there is more than one <code>required</code> value for an operator, or if a value has both a <code>require</code> and a <code>prohibit</code> preference. These preferences represent constraints on the legal selections that can be made for a decision and if they conflict, no progress can be made from the current situation and the impasse cannot be resolved by additional preferences.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#no-change-impasse","title":"No-change impasse","text":"<p>A no-change impasse arises if a new operator is not selected during the decision procedure. There are two types of no-change impasses: </p> <ul> <li> <p>A State no-change impasse occurs when there are no <code>acceptable</code> (or <code>require</code>) preferences to suggest operators for the current state (or all the <code>acceptable</code> values have also been rejected). The decision procedure cannot select a new operator.</p> </li> <li> <p>A Operator no-change impasse occurs when either a new operator is selected for the current state but no additional productions match during the application phase, or a new operator is not selected during the next decision phase.</p> </li> </ul> <p>There can be only one type of impasse at a given level of subgoaling at a time. Given the semantics of the preferences, it is possible to have a tie or conflict impasse and a constraint- failure impasse at the same time. In these cases, Soar detects only the constraint-failure impasse.</p> <p>The impasse is detected during the selection of the operator, but happens because one of the four problem-solving functions (described in  Problem-Solving function in Soar)  was incomplete.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#creating-new-states","title":"Creating New States","text":"<p>Soar handles these inconsistencies by creating a new state, called a substate in which the goal of the problem solving is to resolve the impasse. Thus, in the substate, operators will be selected and applied in an attempt either to discover which of the tied operators should be selected, or to apply the selected operator piece by piece. The substate is often called a subgoal because it exists to resolve the impasse, but is sometimes called a substate because the representation of the subgoal in Soar is as a state.</p> <p>The initial state in the subgoal contains a complete description of the cause of the impasse, such as the operators that could not be decided among (or that there were no operators proposed) and the state that the impasse arose in. From the perspective of the new state, the latter is called the <code>superstate</code>. Thus, the <code>superstate</code> is part of the substructure of each state, represented by the Soar architecture using the <code>superstate</code> attribute. (The initial state, created in the 0th decision cycle, contains a <code>superstate</code> attribute with the value of <code>nil</code> - the top-level state has no superstate.)</p> <p>The knowledge to resolve the impasse may be retrieved by any type of problem solving, from searching to discover the implications of different decisions, to asking an outside agent for advice. There is no a priori restriction on the processing, except that it involves applying operators to states.</p> <p>In the substate, operators can be selected and applied as Soar attempts to solve the sub- goal. (The operators proposed for solving the subgoal may be similar to the operators in the superstate, or they may be entirely different.) While problem solving in the subgoal, additional impasses may be encountered, leading to new subgoals. Thus, it is possible for Soar to have a stack of subgoals, represented as states: Each state has a single superstate (except the initial state) and each state may have at most one substate. Newly created subgoals are considered to be added to the bottom of the stack; the first state is therefore called the top-level state.<sup>3</sup> See Figure 2.11 for a simplified illustrations of a subgoal stack.</p> A simplified illustration of a subgoal stack. <p>Soar continually attempts to retrieve knowledge relevant to all goals in the subgoal stack, although problem-solving activity will tend to focus on the most recently created state. However, problem solving is active at all levels, and productions that match at any level will fire.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#results","title":"Results","text":"<p>In order to resolve impasses, subgoals must generate results that allow the problem solving at higher levels to proceed. The results of a subgoal are the working memory elements and preferences that were created in the substate, and that are also linked directly or indirectly to a superstate (any superstate in the stack). A preference or working memory element is said to be created in a state if the production that created it tested that state and this is the most recent state that the production tested. Thus, if a production tests multiple states, the preferences and working memory elements in its actions are considered to be created in the most recent of those states (the lowest-level state) and is not considered to have been created in the other states. The architecture automatically detects if a preference or working memory element created in a substate is also linked to a superstate.</p> <p>These working memory elements and preferences will not be removed when the impasse is resolved because they are still linked to a superstate, and therefore, they are called the results of the subgoal. A result has either i-support or o-support; the determination of support is described below.</p> <p>A working memory element or preference will be a result if its identifier is already linked to a superstate. A working memory element or preference can also become a result indirectly if, after it is created and it is still in working memory or preference memory, its identifier becomes linked to a superstate through the creation of another result. For example, if the problem solving in a state constructs an operator for a superstate, it may wait until the operator structure is complete before creating an <code>acceptable</code> preference for the operator in the superstate. The <code>acceptable</code> preference is a result because it was created in the state and is linked to the superstate (and, through the superstate, is linked to the top-level state). The substructures of the operator then become results because the operator\u2019s identifier is now linked to the superstate.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#justifications-support-for-results","title":"Justifications: Support for results","text":"<p>Recall from section Production Actions and Persistance that WMEs with i-support disappear as soon as the production that created them retract,<sup>4</sup> whereas WMEs with o-support (created through applying an operator) persist in working memory until deliberately removed.</p> <p>Some results receive i-support, while others receive o-support. The type of support received by a result is determined by the function it plays in the superstate, and not the function it played in the state in which it was created. For example, a result might be created through operator application in the state that created it; however, it might only be a state elaboration in the superstate. The first function would lead to o-support, but the second would lead to i-support.</p> <p>In order for the architecture to determine whether a result receives i-support or o-support, Soar must first determine the function that the working memory element or preference plays (that is, whether the result should be considered an operator application or not). To do this, Soar creates a temporary production, called a justification. The justification summarizes the processing in the substate that led to the result:</p> <ul> <li> <p>The conditions of a justification are those working memory elements that exist in the superstate (and above) that were necessary for producing the result. This is determined by collecting all of the working memory elements tested by the productions that fired in the subgoal that led to the creation of the result, and then removing those conditions that test working memory elements created in the subgoal.</p> </li> <li> <p>The action of the justification is the result of the subgoal.</p> </li> </ul> <p>Thus, when the substate disappears, the generated justification serves as the production that supports any subgoal results.</p> <p>Soar determines i-support or o-support for the justification and its actions just as it would for any other production, as described in section Production Actions and Persistence.  If the justification is an operator application, the result will receive o-support. Otherwise, the result gets i-support from the justification. If such a result loses i-support from the justification, it will be retracted if there is no other support.</p> <p>Justifications include any negated conditions that were in the original productions that participated in producing the results, and that test for the absence of superstate working memory elements. Negated conditions that test for the absence of working memory elements that are local to the substate are not included, which can lead to overgeneralization in the justification (see Sections Operational Analysis and Collapsed Negative Reasoning for details).</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#chunking-learning-procedural-knowledge","title":"Chunking: Learning Procedural Knowledge","text":"<p>When an operator impasse is resolved, it means that Soar has, through problem solving, gained access to knowledge that was not readily available before. Therefore, when an impasse is resolved, Soar has an opportunity to learn, by summarizing and generalizing the processing in the substate.</p> <p>One of Soar\u2019s learning mechanisms is called chunking (See chapter 4 for more information); it attempts to create a new production, called a chunk. The conditions of the chunk are the elements of the state that (through some chain of production firings) allowed the impasse to be resolved; the action of the production is the working memory element or preference that resolved the impasse (the result of the impasse). The conditions and action are variablized so that this new production may match in a similar situation in the future and prevent an impasse from arising.</p> <p>Chunks and justifications are very similar in that they both summarize substate results. They are, in fact, generated by the architecture using the same result dependency trace mechanisms. However, there are some important distinctions:</p> <ol> <li>Justifications disappear as soon as its conditions no longer match.</li> <li>Chunks contain variables so that they may match working memory in other situations;    justifications are similar to an instantiated chunk.</li> </ol> <p>In other words, a chunk might be thought of as a permanent and potentially more generalized form of a justification. Since the result that solves the impasse problem is learned in a chunk, whenever the agent encounters the same situation again as that which resulted in the original impasse, it can simply fire the chunk to generate the same result previously derived, preempting the need for a substate and repeated deliberate problem solving.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#the-calculation-of-o-support","title":"The calculation of o-support","text":"<p>This section provides a more detailed description of when an action is given o-support by an instantiation.<sup>5</sup> The content here is somewhat more advanced, and the reader unfamiliar with rule syntax (explained in Chapter 3) may wish to skip this section and return at a later point.</p> <p>Support is given by the production; that is, all working memory changes generated by the actions of a single instantiated production will have the same support (an action that is not given o-support will have i-support). The conditions and actions of a production rule will here be referred to using the shorthand of LHS and RHS (for Left-Hand Side and Right-Hand Side), respectively.</p> <p>A production must meet the following two requirements to have o-supported actions:</p> <ol> <li> <p>The RHS has no operator proposals, i.e. nothing of the form    <pre><code>(&lt;s&gt; ^operator &lt;o&gt; +)\n</code></pre></p> </li> <li> <p>The LHS has a condition that tests the current operator, i.e. something of the form    <pre><code>(&lt;s&gt; ^operator &lt;o&gt;)\n</code></pre></p> </li> </ol> <p>In condition 1, the variable <code>&lt;s&gt;</code> must be bound to a state identifier. In condition 2, the variable <code>&lt;s&gt;</code> must be bound to the lowest state identifier. That is to say, each (positive) condition on the LHS takes the form <code>(id ^attr value)</code>, some of these id\u2019s match state identifiers, and the system looks for the deepest matched state identifier. The tested current operator must be on this state. For example, in this production,</p> <pre><code>sp {elaborate*state*operator\\*name\n   (state &lt;s&gt; ^superstate &lt;s1&gt;)\n   (&lt;s1&gt; ^operator &lt;o&gt;)\n   (&lt;o&gt; ^name &lt;name&gt;)\n   --&gt;\n   (&lt;s&gt; ^name something)}\n</code></pre> <p>the RHS action gets i-support. Of course, the state bound to <code>&lt;s&gt;</code> is destroyed when  <code>(&lt;s1&gt; ^operator &lt;o&gt;)</code> retracts, so o-support would make little difference. On the other hand, this production,</p> <pre><code>   sp {operator*superstate*application\n   (state &lt;s&gt; ^superstate &lt;s1&gt;)\n              ^operator &lt;o&gt;)\n   (&lt;o&gt; ^name &lt;name&gt;)\n   --&gt;\n   (&lt;s1&gt; ^sub-operator-name &lt;name&gt;)}\n</code></pre> <p>gives o-support to its RHS action, which remains after the substate bound to <code>&lt;s&gt;</code> is destroyed.</p> <p>An extension of condition 1 is that operator augmentations should always receive i-support (augmentations define the proposed operator). Soar has been written to recognize augmentations directly off the operator (ie, <code>(&lt;o&gt; ^augmentation value)</code>), and to attempt to give them i-support. However, what should be done about a production that simultaneously tests an operator, doesn\u2019t propose an operator, adds an operator augmentation, and adds a non-operator augmentation?</p> <p>For example:</p> <pre><code>sp {operator*augmentation*application\n   (state &lt;s&gt; ^task test-support\n              ^operator &lt;o&gt;)\n   --&gt;\n   (&lt;o&gt; ^new augmentation)\n   (&lt;s&gt; ^new augmentation)}\n</code></pre> <p>In such cases, both receive i-support. Soar will print a warning on firing this production, because this is considered bad coding style.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#removal-of-substates-impasse-resolution","title":"Removal of Substates: Impasse Resolution","text":"<p>Problem solving in substates is an important part of what Soar does, and an operator impasse does not necessarily indicate a problem in the Soar program. They are a way to decompose a complex problem into smaller parts and they provide a context for a program to deliberate about which operator to select. Operator impasses are necessary, for example, for Soar to do any learning about problem solving (as will be discussed in Chapter 4). This section describes how impasses may be resolved during the execution of a Soar program, how they may be eliminated during execution without being resolved, and some tips on how to modify a Soar program to prevent a specific impasse from occurring in the first place.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#resolving-impasses","title":"Resolving Impasses","text":"<p>An impasse is resolved when processing in a subgoal creates results that lead to the selection of a new operator for the state where the impasse arose. When an operator impasse is resolved, Soar has an opportunity to learn, and the substate (and all its substructure) is removed from working memory.</p> <p>Here are possible approaches for resolving specific types of impasses are listed below:</p> <ul> <li> <p>Tie impasse \u2014 A tie impasse can be resolved by productions that create preferences that prefer one option (<code>better</code>, <code>best</code>, <code>require</code>), eliminate alternatives (<code>worse</code>, <code>worst</code>, <code>reject</code>,<code>prohibit</code>), or make all of the objects indifferent (<code>indifferent</code>).</p> </li> <li> <p>Conflict impasse \u2014 A conflict impasse can be resolved by productions that create preferences to require one option (<code>require</code>), or eliminate the alternatives (<code>reject</code>, <code>prohibit</code>).</p> </li> <li> <p>Constraint-failure impasse \u2014 A constraint-failure impasse cannot be resolved by additional preferences, but may be prevented by changing productions so that they create fewer <code>require</code> or <code>prohibit</code> preferences. A substate can resolve a constraint-failure impasse through actions that cause all but one of the conflicting preferences to retract.</p> </li> <li> <p>State no-change impasse \u2014 A state no-change impasse can be resolved by productions that create <code>acceptable</code> or <code>require</code> preferences for operators.</p> </li> <li> <p>Operator no-change impasse \u2014 An operator no-change impasse can be resolved by productions that apply the operator, change the state so the operator proposal no longer matches, or cause other operators to be proposed and preferred.</p> </li> </ul>"},{"location":"soar_manual/02_TheSoarArchitecture/#eliminating-impasses","title":"Eliminating Impasses","text":"<p>An impasse is resolved when results are created that allow progress to be made in the state where the impasse arose. In Soar, an impasse can be eliminated (but not resolved) when a higher level impasse is resolved, eliminated, or regenerated. In these cases, the impasse becomes irrelevant because higher-level processing can proceed. An impasse can also become irrelevant if input from the outside world changes working memory which in turn causes productions to fire that make it possible to select an operator. In these cases, the impasse is eliminated, but not \"resolved\", and Soar does not learn in this situation.</p> <p>For example, in the blocks-world domain, an agent might deliberate in a substate to deter- mine whether it should move block A onto block C or block B onto block C in its current situation. If a child suddenly throws block A out a window, this problem solving becomes irrelevant, and the impasse is eliminated.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#regenerating-impasses","title":"Regenerating Impasses","text":"<p>An impasse is regenerated when the problem solving in the subgoal becomes inconsistent with the current situation. During problem solving in a subgoal, Soar monitors which aspect of the surrounding situation (the working memory elements that exist in superstates) the problem solving in the subgoal has depended upon. If those aspects of the surrounding situation change, either because of changes in input or because of results, the problem solving in the subgoal is inconsistent, and the state created in response to the original impasse is removed and a new state is created. Problem solving will now continue from this new state. The impasse is not \"resolved\", and Soar does not learn in this situation.</p> <p>The reason for regeneration is to guarantee that the working memory elements and preferences created in a substate are consistent with higher level states. As stated above, inconsistency can arise when a higher level state changes either as a result of changes in what is sensed in the external environment, or from results produced in the subgoal. The problem with inconsistency is that once inconsistency arises, the problem being solved in the subgoal may no longer be the problem that actually needs to be solved. Luckily, not all changes to a superstate lead to inconsistency.</p> <p>In order to detect inconsistencies, Soar maintains a Goal Dependency Set (GDS) for every subgoal/substate. The dependency set consists of all working memory elements that were tested in the conditions of productions that created o-supported working memory elements that are directly or indirectly linked to the substate (in other words, any superstate knowledge used to derive persistent substate knowledge). Whenever such an o-supported WME is created, Soar records which superstate WMEs were tested, directly or indirectly, to create it. Whenever any of the WMEs in the dependency set of a substate change, the substate is regenerated. (See Sections print  and trace for how to examine GDS information through the user-interface.)</p> <p>Note that the creation of i-supported structures in a subgoal does not increase the dependency set, nor do o-supported results. Thus, only subgoals that involve the creation of internal o-support working memory elements risk regeneration, and then only when the basis for the creation of those elements changes.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#substate-removal","title":"Substate Removal","text":"<p>Whenever a substate is removed, all working memory elements and preferences that were created in the substate that are not results are removed from working memory. In Figure 2.11, state <code>S3</code> will be removed from working memory when the impasse that created it is resolved, that is, when sufficient preferences have been generated so that one of the operators for state <code>S2</code> can be selected. When state <code>S3</code> is removed, operator <code>O9</code> will also be removed, as will the <code>acceptable</code> preferences for <code>O7</code>, <code>O8</code>, and <code>O9</code>, and the <code>impasse</code>, <code>attribute</code>, and <code>choices</code> augmentations of state <code>S3</code>. These working memory elements are removed because they are no longer linked to the subgoal stack. The <code>acceptable</code> preferences for operators <code>O4</code>, <code>O5</code>, and <code>O6</code> remain in working memory. They were linked to state <code>S3</code>, but since they are also linked to state <code>S2</code>, they will stay in working memory until <code>S2</code> is removed (or until they are retracted or rejected).</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#soars-cycle-with-substates","title":"Soar\u2019s Cycle: With Substates","text":"<p>When there are multiple substates, Soar\u2019s cycle remains basically the same but has a few minor changes.</p> <p>The main change when there are multiple substates is that at each phase of the decision cycle, Soar goes through the substates, from oldest (highest) to newest (lowest), completing any necessary processing at that level for that phase before doing any processing in the next substate. When firing productions for the proposal or application phases, Soar processes the firing (and retraction) of rules, starting from those matching the oldest substate to the newest. Whenever a production fires or retracts, changes are made to working memory and preference memory, possibly changing which productions will match at the lower levels (productions firing within a given level are fired in parallel \u2013 simulated). Productions firings at higher levels can resolve impasses and thus eliminate lower states before the productions at the lower level ever fire. Thus, whenever a level in the state stack is reached, all production activity is guaranteed to be consistent with any processing that has occurred at higher levels.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#removal-of-substates-the-goal-dependency-set","title":"Removal of Substates: The Goal Dependency Set","text":"<p>This subsection describes the Goal Dependency Set (GDS) with discussions on the motivation for the GDS and behavioral consequences of the GDS from a developer/modeler\u2019s point of view. It goes into greater detail than might be beneficial for someone becoming familiar with the general operation of Soar for the first time. Readers may skip this section and return later if desired.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#why-the-gds-was-needed","title":"Why the GDS was needed","text":"<p>As a symbol system, Soar attempts to approximate a true knowledge level but will necessarily always fall short. We can informally think of the way in which Soar falls short as its peculiar \"psychology.\" Those interested in using Soar to model human cognition would like Soar\u2019s psychology to approximate human psychology. Those using Soar to create agent systems would like to make Soar\u2019s processing approximate the knowledge level as closely as possible. Soar 7 had a number of symbol-level quirks that appeared inconsistent with human psychology and that made building large-scale, knowledge-based systems in Soar more difficult than necessary. Bob Wray\u2019s thesis <sup>6</sup> addressed many of these symbol-level problems in Soar, among them logical inconsistency in symbol manipulations, non-contemporaneous constraints in chunks , race conditions in rule firings and in the decision process, and contention between original task knowledge and learned knowledge.</p> <p>The Goal Dependency Set implements a solution to logical inconsistencies between persis- tent (o-supported) WMEs in a substate and its \"context\". The context consists of all the WMEs in any superstates above the local goal/state.<sup>7</sup> In Soar, any action (application) of an operator receives an o-support preference. This preference makes the resulting WME persistent: it will remain in memory until explicitly removed or until its local state is removed, regardless of whether it continues to be justified.</p> <p>Persistent WMEs are pervasive in Soar, because operators are the main unit of problem solving. Persistence is necessary for taking any non-monotonic step in a problem space. However, persistent WMEs also are dependent on WMEs in the superstate context. The problem in Soar prior to GDS, especially when trying to create a large-scale system, is that the knowledge developer must always think about which dependencies can be \"ignored\" and which may affect the persistent WME. For example, imagine an exploration robot that makes a persistent decision to travel to some distant destination based, in part, on its power reserves. Now suppose that the agent notices that its power reserves have failed. If this change is not communicated to the state where the travel decision was made, the agent will continue to act as if its full power reserves were still available.</p> <p>Of course, for this specific example, the knowledge designer can encode some knowledge to react to this inconsistency. The fundamental problem is that the knowledge designer has to consider all possible interactions between all o-supported WMEs and all contexts. Soar systems often use the architecture\u2019s impasse mechanism to realize a form of decomposition.  These potential interactions mean that the knowledge developer cannot focus on individual problem spaces in isolation when creating knowledge, which makes knowledge development more difficult. Further, in all but the simplest systems, the knowledge designer will miss some potential interactions. The result is that agents were unnecessarily brittle, failing in difficult-to-understand, difficult-to-duplicate ways.</p> <p>The GDS also solves the the problem of non-contemporaneous constraints in chunks. A non-contemporaneous constraint refers to two or more conditions that never co-occur simultaneously. An example might be a driving robot that learned a rule that attempted to match \"red light\" and \"green light\" simultaneously. Obviously, for functioning traffic lights, this rule would never fire. By ensuring that local persistent elements are always consistent with the higher-level context, non-contemporaneous constraints in chunks are guaranteed not to happen.</p> <p>The GDS captures context dependencies during processing, meaning the architecture will identify and respond to inconsistencies automatically. The knowledge designer then does not have to consider potential inconsistencies between local, o-supported WMEs and the context.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#behavior-level-view-of-the-goal-dependency-set","title":"Behavior-level view of the Goal Dependency Set","text":"<p>The following discussion covers what the GDS does, and how that impacts production knowledge design and implementation.</p> <p>Operation of the Goal Dependency Set: Consider i-support. The persistence of an i-supported (\"instantiation supported\") WME depends upon the creating production instantiation (and, more specifically, the features the instantiation tests). When one of the conditions in the production instantiation no longer matches, the instantiation is retracted, resulting in the loss of that support for the WME. I-support is illustrated in Figure 2.12. A copy of A in the subgoal,As, is retracted automatically when A changes to A\u2019. The substate WME persists only as long as it remains justified by A.</p> <p>In the broadest sense, we can say that some feature <code>&lt;b&gt;</code> is \"dependent\" upon another element <code>&lt;a&gt;</code> if <code>&lt;a&gt;</code> was used in the creation of <code>&lt;b&gt;</code>, i.e., if <code>&lt;a&gt;</code> was tested in the production instantiation that created <code>&lt;b&gt;</code>. Further, a dependent change with respect to feature <code>&lt;b&gt;</code> is a change to any of its instantiating features. This applies to both i-supported and o- supported WMEs. In Figure 2.12, the change from A to A\u2019 is a dependent change for feature 1 because A was used to create 1.</p> <p>When A changes, the persistent WME 1 may be no longer consistent with its context (e.g., A\u2019). The specific solution to this problem through GDS is inspired by the dependency analysis portion of the justification/chunking algorithm (see Chapter 4). Whenever an o- supported WME is created in the local state, the superstate dependencies of that new feature are determined and added to the goal dependency set (GDS) of that state. Conceptually speaking, whenever a working memory change occurs, the dependency sets for every state in the context hierarchy are compared to working memory changes. If a removed element is found in a GDS, the state is removed from memory (along with all existing substructure). The dependency set includes only dependencies for o-supported features. For example, in Figure 2.13, at time \\(t_0\\) , because only i-supported features have been created in the subgoal, the dependency set is empty.</p> Simplified Representation of the context dependencies (above the line), local o-supported WMEs (below the line), and the generation of a result. Prior to GDS, this situation led to non-contemporaneous constraints in the chunk that generates 3. The Dependency Set in Soar. <p>Three types of features can be tested in the creation of an o-supported feature. Each requires a slightly different type of update to the dependency set.</p> <ol> <li>Elements in the superstate: WMEs in the superstate are added directly to the    goal\u2019s dependency set. In Figure 2.13, the persistent subgoal item 3 is dependent upon    A and D. These superstate WMEs are added to the subgoal\u2019s dependency set when 3    is added to working memory at time \\(t_1\\). It does not matter that A is i-supported and    Do-supported.</li> <li>Local i-supported features: Local i-supported features are not added to the goal    dependency set. Instead, the superstate WMEs that led to the creation of the i-    supported feature are determined and added to the GDS. In the example, when 4    is created,A, B and C must be added to the dependency set because they are the    superstate features that led to 1 , which in turn led to 2 and finally 4. However, because    item A was previously added to the dependency set at \\(t_1\\) , it is unnecessary to add it    again.</li> <li>Local o-supported features: The dependencies of a local o-supported feature have    already been added to the state\u2019s GDS. Thus, tests of local o-supported WMEs do not    require additions to the dependency set. In Figure 2.13, the creation of element 5 does    not change the dependency set because it is dependent only upon persistent items 3    and 4 , whose features had been previously added to the GDS.</li> </ol> <p>At any time after t 1 , either the D to D\u2019 or A to A\u2019 transition would cause the removal of the entire subgoal. TheEtoE\u2019transition causes no retraction becauseEis not in the goal\u2019s dependency set.</p> <p>The role of the GDS in agent design: The GDS places some design time constraints on operator implementation. These constraints are:</p> <ul> <li>Operator actions that are used to remember a previous state/situation should be asserted in the top state.</li> <li>All operator elaborations should be i-supported.</li> <li>Any operator with local actions should be designed to be re-entrant.</li> </ul> <p>Because any dependencies for o-supported subgoal WMEs will be added to the GDS, the developer must decide if an o-supported element should be represented in a substate or the top state. This decision is straightforward if the functional role of the persistent element is considered. Four important capabilities that require persistence are:</p> <ol> <li>Reasoning hypothetically: Some structures may need to reflect hypothetical states.    These are \"assumptions\" because a hypothetical inference cannot always be grounded    in the current context. In problem solvers with truth maintenance, only assumptions    are persistent.</li> <li>Reasoning non-monotonically: Sometimes the result of an inference changes one    of the structures on which the inference is dependent. As an example, consider the    task of counting. Each newly counted item replaces the old value of the count.</li> <li>Remembering: Agents oftentimes need to remember an external situation or    stimulus, even when that perception is no longer available.</li> <li>Avoiding Expensive Computations: In some situations, an agent may have the    information needed to derive some belief in a new world state but the expense of    performing the necessary computation makes this derivation undesirable. For example,    in dynamic, complex domains, determining when to make an expensive calculation is    often formulated as an explicit agent task.</li> </ol> <p>When remembering or avoiding an expensive computation, the agent/designer is making a commitment to retain something even though it might not be supported in the current context. These WMEs should be asserted in the top state. For many Soar systems, especially those focused on execution in a dynamic environment, most o-supported elements will need to be stored on the top state.</p> <p>For any kind of local, non-monotonic reasoning about the context (counting, projection planning), features should be stored locally. When a dependent context change occurs, the GDS interrupts the processing by removing the state. While this may seem like a severe over-reaction, formal and empirical analysis have suggested that this solution is less computationally expensive than attempting to identify the specific dependent assumption.</p>"},{"location":"soar_manual/02_TheSoarArchitecture/#footnotes","title":"Footnotes","text":"<ul> <li>[1]: In this blocks-world task, the table always has    room for another block, so it is represented as always being \"clear\".</li> <li>[2]: In order to allow these links to have some    substructure, the attribute name may be an identifier, which means that the    attribute may itself have attributes and values, as specified by additional    working memory elements.</li> <li>[3]:  The original state is the \"top\" of the stack    because as Soar runs, this state (created first), will be at the top of the    computer screen, and substates will appear on the screen below the top-level    state.</li> <li>[4]: Technically, an i-supported WME is only retracted    when it loses instantiation support, not when the creating production is    retracting. For example, a WME could receive i-support from several different    instantiated productions and the retraction of only one would not lead to the    retraction of the WME.  justification. If such a result loses i-support from the    justification, it will be retracted if there is no other support.</li> <li>[5]: In the past, Soar had various experimental    support mode settings. Since version 9.6, the support mode used is what was    previously called mode 4.  with rule syntax (explained in Chapter    3) may wish to skip this section and return at a    later point.</li> <li>[6]: Robert E. Wray. Ensuring Reasoning Consistency in    Hierarchical Architectures. PhD thesis, University of Michigan, 1998.</li> <li>[7]: This subsection will primarily use \"state,\" not    \"goal.\" While these terms are often used nearly-interchangeably in the context    of Soar, states refer to the set of WMEs comprising knowledge related to a    peculiar level of goal. TheGoalDependency Set is the set of state elements upon    which a goal depends.  </li> </ul>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/","title":"The Syntax of Soar Programs","text":"<p>This chapter describes in detail the syntax of elements in working memory, preference mem- ory, and production memory, and how impasses and I/O are represented in working memory and in productions. Working memory elements and preferences are created as Soar runs, while productions are created by the user or through chunking. The bulk of this chapter explains the syntax for writing productions.</p> <p>The first section of this chapter describes the structure of working memory elements in Soar; the second section describes the structure of preferences; and the third section describes the structure of productions. The fourth section describes the structure of impasses. An overview of how input and output appear in working memory is presented in the fifth section. Further discussion of Soar I/O can be found on the Soar website.</p> <p>This chapter assumes that you understand the operating principles of Soar, as presented in the Soar architecture.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#working-memory","title":"Working Memory","text":"<p>Working memory contains working memory elements (WME\u2019s). As described in Chapter 2, WME\u2019s can be created by the actions of productions, the evaluation of preferences, the Soar architecture, and via the input/output system.</p> <p>A WME is a tuple consisting of three symbols: an identifier, an attribute, and a value, where the entire WME is enclosed in parentheses and the attribute is preceded by an up-arrow (<code>^</code>). A template for a working memory element is:</p> <pre><code>(identifier ^attribute value)\n</code></pre> <p>The first position always holds an internal identifier symbol, generated by the Soar architecture as it runs. The attribute and value positions can hold either identifiers or constants. The term identifier is used to refer both to the first position of a WME, as well as to the symbols that occupy that position. If a WME\u2019s attribute or value is an identifier, there is at least one WME that has that identifier symbol in its first position.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#symbols","title":"Symbols","text":"<p>Soar distinguishes between two types of working memory symbols: identifiers and constants.</p> <ul> <li>Identifiers: An identifier is a unique symbol, created at runtime when a   new object is added to working memory. The names of identifiers are created by   Soar, and consist of a single uppercase letter followed by a string of digits,   such as <code>G37</code> or <code>O22</code>.</li> </ul> <p>(The Soar user interface will also allow users to specify identifiers using lowercase letters in a case-insensitive manner, for example, when using the <code>print</code> command. But internally, they are actually uppercase letters.)</p> <ul> <li>Constants: There are three types of constants: integers, floating-point, and symbolic constants: - \u0088Integer constants (numbers). The range of values depends on the machine   and implementation you\u2019re using, but it is at least [-2 billion...+2   billion]. - \u0088Floating-point constants (numbers). The range depends on the machine and   implementation you\u2019re using. - \u0088Symbolic constants. These are symbols with arbitrary names. A constant can use   any combination of letters, digits, or <code>$%&amp;*+-/:&lt;=&gt;?_</code>. Other characters (such as blank   spaces) can be included by surrounding the complete constant name with vertical   bars: <code>|This is a constant|</code>. (The vertical bars aren\u2019t part of the name; they\u2019re   just notation.) A vertical bar can be included by prefacing it with a backslash inside   surrounding vertical bars: <code>|Odd-symbol\\|name|</code></li> </ul> <p>Identifiers should not be confused with constants, although they may \"look the same\"; identifiers are generated (by the Soar architecture) at runtime and will not necessarily be the same for repeated runs of the same program. Constants are specified in the Soar program and will be the same for repeated runs.</p> <p>Even when a constant \"looks like\" an identifier, it will not act like an identifier in terms of matching. A constant is printed surrounded by vertical bars whenever there is a possibility of confusing it with an identifier: <code>|G37|</code> is a constant while <code>G37</code> is an identifier. To avoid possible confusion, you should not use letter-number combinations as constants or for production names.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#objects","title":"Objects","text":"<p>Recall from Section Working Memory: The current situation that all WME\u2019s that share an identifier are collectively called an object in working memory. The individual working memory elements that make up an object are often called augmentations, because they augment the object. A template for an object in working memory is:</p> <pre><code>(identifier ^attribute-1 value-1 ^attribute-2 value-2\n            ^attribute-3 value-3... ^attribute-n value-n)\n</code></pre> <p>For example, if you run Soar with the supplementary blocks-world program provided online, after one elaboration cycle, you can look at the top-level state object by using the print command:</p> <pre><code>soar&gt; print s1\n(S1 ^io I1 ^ontop O2 ^ontop O3 ^ontop O1 ^problem-space blocks\n    ^superstate nil ^thing B3 ^thing T1 ^thing B1 ^thing B2\n    ^type state)\n</code></pre> <p>The attributes of an object are printed in alphabetical order to make it easier to find a specific attribute.</p> <p>Working memory is a set, so that at any time, there are never duplicate versions of working memory elements. However, it is possible for several working memory elements to share the same identifier and attribute but have different values. Such attributes are called multi- valued attributes or multi-attributes. For example, state <code>S1</code>, above, has two attributes that are multi-valued: <code>thing</code> and <code>ontop</code>.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#timetags","title":"Timetags","text":"<p>When a working memory element is created, Soar assigns it a unique integer timetag. The timetag is a part of the working memory element, and therefore, WME\u2019s are actually quadruples, rather than triples. However, the timetags are not represented in working memory and cannot be matched by productions. The timetags are used to distinguish between multiple occurrences of the same WME. As preferences change and elements are added and deleted from working memory, it is possible for a WME to be created, removed, and created again. The second creation of the WME \u2014 which bears the same identifier, attribute, and value as the first WME \u2014 is different, and therefore is assigned a different timetag. This is important because a production will fire only once for a given instantiation, and the instantiation is determined by the timetags that match the production and not by the identifier-attribute-value triples.</p> <p>To look at the timetags of WMEs, the <code>print --internal</code> command can be used:</p> <pre><code>soar&gt; print --internal S1\n(3: S1 ^io I1)\n(10: S1 ^ontop O2)\n(9: S1 ^ontop O3)\n(11: S1 ^ontop O1)\n(4: S1 ^problem-space blocks)\n(2: S1 ^superstate nil)\n(6: S1 ^thing B3)\n(5: S1 ^thing T1)\n(8: S1 ^thing B1)\n(7: S1 ^thing B2)\n(1: S1 ^type state)\n</code></pre> <p>This shows all the individual augmentations ofS1, each is preceded by an integer timetag.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#acceptable-preferences-in-working-memory","title":"Acceptable preferences in working memory","text":"<p>The <code>acceptable</code> preferences for operators appear in working memory as identifier-attribute- value-preference quadruples. No other preferences appear in working memory. A template for an <code>acceptable</code> preference in working memory is:</p> <pre><code>(identifier ^operator value +)\n</code></pre> <p>For example, if you run Soar with the example blocks-world program linked above, after the first operator has been selected, you can again look at the top-level state using the <code>print --internal</code> command:</p> <pre><code>soar&gt; print --internal s1\n(3: S1 ^io I1)\n(9: S1 ^ontop O3)\n(10: S1 ^ontop O2)\n(11: S1 ^ontop O1)\n(48: S1 ^operator O4 +)\n(49: S1 ^operator O5 +)\n(50: S1 ^operator O6 +)\n(51: S1 ^operator O7 +)\n(54: S1 ^operator O7)\n(52: S1 ^operator O8 +)\n(53: S1 ^operator O9 +)\n(4: S1 ^problem-space blocks)\n(2: S1 ^superstate nil)\n(5: S1 ^thing T1)\n(8: S1 ^thing B1)\n(6: S1 ^thing B3)\n(7: S1 ^thing B2)\n(1: S1 ^type state)\n</code></pre> <p>The state S1 has six augmentations of <code>acceptable</code> preferences for different operators (O4 throughO9). These have plus signs following the value to denote that they are acceptable preferences. The state has exactly one operator,O7. This state corresponds to the illustration of working memory in Figure 2.4.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#working-memory-as-a-graph","title":"Working Memory as a Graph","text":"<p>Not only is working memory a set, it is also a graph structure where the identifiers are nodes, attributes are links, and constants are terminal nodes. Working memory is not an arbitrary graph, but a graph rooted in the states (e.g. S1). Therefore, all WMEs are linked either directly or indirectly to a state. The impact of this constraint is that all WMEs created by actions are linked to WMEs tested in the conditions. The link is one-way, from the identifier to the value. Less commonly, the attribute of a WME may be an identifier.</p> A semantic net illustration of four objects in working memory. <p>This figure illustrates four objects in working memory; the object with identifier <code>X44</code> has been linked to the object with identifier <code>O43</code>, using the attribute as the link, rather than the value. The objects in working memory illustrated by this figure are:</p> <pre><code>(O43 ^isa apple ^color red ^inside O53 ^size small ^X44 200)\n(O87 ^isa ball ^color red ^inside O53 ^size big)\n(O53 ^isa box ^size large ^color orange ^contains O43 O87)\n(X44 ^unit grams ^property mass)\n</code></pre> <p>In this example, object <code>O43</code> and object <code>O87</code> are both linked to object <code>O53</code> through <code>(O53 ^contains O43)</code> and <code>(O53 ^contains O87)</code>, respectively (the contains attribute is a multi-valued attribute). Likewise, object <code>O53</code> is linked to object <code>O43</code> through <code>(O43 ^inside O53)</code> and linked to object <code>O87</code> through <code>(O87 ^inside O53)</code>. Object <code>X44</code> is linked to object <code>O43</code> through <code>(O43 ^X44 200)</code>.</p> <p>Links are transitive so that <code>O53</code>is linked to <code>X44</code>(because <code>O53</code> is linked to<code>O43</code> and <code>O43</code> is linked to <code>X44</code>). However, since links are not symmetric, <code>X44</code>is not linked to <code>O53</code>.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#working-memory-activation","title":"Working Memory Activation","text":"<p>WMEs have a form of base level activation associated with them that is not accessible to the agent, but that is used by the architecture. Working Memory Activation (WMA) is sub-symbolic metadata associated with a given element and represents its usage. A WME has been used if it has been matched in a rule that fired. WMA is not recorded or maintained when disabled, which is the default. See wm command for working memory settings and options for enabling WMA.</p> <p>Simply enabling WMA has no impact on any agent\u2019s behavior outside of a small additional computational cost. However, working memory activation is used for other features. Primarily, it is necessary for allowing the forgetting of memory elements from working memory. When working memory forgetting is turned on, those working memory elements with activation below a given threshold are removed from working memory. This allows agents to maintain a bounded working memory size without explicit memory size management. It also has a role in determining spreading activation values, discussed in section activation.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#preference-memory","title":"Preference Memory","text":"<p>Preferences are created by production firings and express the relative or absolute merits for selecting an operator for a state. When preferences express an absolute rating, they are identifier-attribute-value-preference quadruples; when preferences express relative ratings, they are identifier-attribute-value-preference-value quintuples</p> <p>For example,</p> <pre><code>(S1 ^operator O3 +)\n</code></pre> <p>is a preference that asserts that operator O3 is an <code>acceptable</code> operator for state S1, while</p> <pre><code>(S1 ^operator O3 &gt; O4)\n</code></pre> <p>is a preference that asserts that operator O3 is a better choice for the operator of state S1 than operator O4.</p> <p>The semantics of preferences and how they are processed were described in Section Preference Memory: Selection Knowledge, which also described each of the eleven different types of preferences. Multiple production instantiations may create identical preferences. Unlike working memory, preference memory is not a set: Duplicate preferences are allowed in preference memory.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#production-memory","title":"Production Memory","text":"<p>Production memory contains productions, which can be entered in by a user (typed in while Soar is running or loaded from a file) or generated by chunking while Soar is running. Productions (both user-defined productions and chunks) may be examined using the <code>print</code> command, described in the print command.</p> <pre><code>sp {blocks-world*propose*move-block\n   (state &lt;s&gt; ^problem-space blocks\n      ^thing &lt;thing1&gt; {&lt;&gt; &lt;thing1&gt; &lt;thing2&gt;}\n      ^ontop &lt;ontop&gt;)\n   (&lt;thing1&gt; ^type block ^clear yes)\n   (&lt;thing2&gt; ^clear yes)\n   (&lt;ontop&gt; ^top-block &lt;thing1&gt;\n   ^bottom-block &lt;&gt; &lt;thing2&gt;)\n--&gt;\n   (&lt;s&gt; ^operator &lt;o&gt; +)\n   (&lt;o&gt; ^name move-block\n   ^moving-block &lt;thing1&gt;\n   ^destination &lt;thing2&gt;)\n}\n</code></pre> <p>Each production has three required components: a name, a set of conditions (also called the left-hand side, or LHS), and a set of actions (also called the right-hand side, or RHS). There are also two optional components: a documentation string and a type.</p> <p>Syntactically, each production consists of the symbol <code>sp</code>, followed by: an opening curly brace, <code>{</code>; the production\u2019s name; the documentation string (optional); the production type (optional); comments (optional); the production\u2019s conditions; the symbol<code>--&gt;</code>(literally: <code>dash-dash-greater than</code>); the production\u2019s actions; and a closing curly brace,<code>}</code>. Each element of a production is separated by white space. Indentation and line feeds are used by convention, but are not necessary.</p> <p>An example production, named <code>blocks-world*propose*move-block</code>, is shown in the following code block. This production proposes operators named move-block that move blocks from one location to another. The details of this production will be described in the following sections.</p> <pre><code>sp {production-name\n   \"Documentation string\"\n   :type\n   CONDITIONS\n   --&gt;\n   ACTIONS\n   }\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#conventions-for-indenting-productions","title":"Conventions for indenting productions","text":"<p>Productions in this manual are formatted using conventions designed to improve their readability. These conventions are not part of the required syntax. First, the name of the production immediately follows the first curly bracket after the <code>sp</code>. All conditions are aligned with the first letter after the first curly brace, and attributes of an object are all aligned The arrow is indented to align with the conditions and actions and the closing curly brace follows the last action.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#production-names","title":"Production Names","text":"<p>The name of the production is an almost arbitrary constant. (See Section Symbols for a description of constants.) By convention, the name describes the role of the production, but functionally, the name is just a label primarily for the use of the programmer.</p> <p>A production name should never be a single letter followed by numbers, which is the format of identifiers.</p> <p>The convention for naming productions is to separate important elements with asterisks; the important elements that tend to appear in the name are:</p> <ol> <li>The name of the task or goal (e.g.,blocks-world).</li> <li>The name of the architectural function (e.g.,propose).</li> <li>The name of the operator (or other object) at issue. (e.g.,move-block)</li> <li>Any other relevant details.</li> </ol> <p>This name convention enables one to have a good idea of the function of a production just by examining its name. This can help, for example, when you are watching Soar run and looking at the specific productions that are firing and retracting. Since Soar uses white space to delimit components of a production, if whitespace inadvertently occurs in the production name, Soar will complain that an open parenthesis was expected to start the first condition.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#documentation-string-optional","title":"Documentation string (optional)","text":"<p>A production may contain an optional documentation string. The syntax for a documentation string is that it is enclosed in double quotes and appears after the name of the production and before the first condition (and may carry over to multiple lines). The documentation string allows the inclusion of internal documentation about the production; it will be printed out when the production is printed using the <code>print</code> command.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#production-type-optional","title":"Production type (optional)","text":"<p>A production may also include an optional production type, which may specify that the production should be considered a default production (<code>`:default</code>) or a chunk (<code>:chunk</code>), or may specify that a production should be given o-support (<code>:o-support</code>) or i-support (<code>:i-support</code>). Users are discouraged from using these types.</p> <p>Another flag (<code>:template</code>) can be used to specify that a production should be used to generate new reinforcement learning rules. See Section Rule Templates for details. There is one additional flag (<code>:interrupt</code>) which can be placed at this location in a production. However this flag does not specify a production type, but is a signal that the production should be marked for special debugging capabilities. For more information, see <code>sp</code> command.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#comments-optional","title":"Comments (optional)","text":"<p>Productions may contain comments, which are not stored in Soar when the production is loaded, and are therefore not printed out by the print command. A comment is begun with a pound sign character <code>#</code> and ends at the end of the line. Thus, everything following the <code>#</code> is not considered part of the production, and comments that run across multiple lines must each begin with a <code>#</code>.</p> <p>For example:</p> <pre><code>sp {blocks-world*propose*move-block\n   (state &lt;s&gt; ^problem-space blocks\n      ^thing &lt;thing1&gt; {&lt;&gt; &lt;thing1&gt; &lt;thing2&gt;}\n      ^ontop &lt;ontop&gt;)\n   (&lt;thing1&gt; ^type block ^clear yes)\n   (&lt;thing2&gt; ^clear yes)\n#     (&lt;ontop&gt; ^top-block &lt;thing1&gt;\n#        ^bottom-block &lt;&gt; &lt;thing2&gt;)\n--&gt;\n   (&lt;s&gt; ^operator &lt;o&gt; +)\n   (&lt;o&gt; ^name move-block # you can also use in-line comments\n      ^moving-block &lt;thing1&gt;\n      ^destination &lt;thing2&gt;)}\n</code></pre> <p>When commenting out conditions or actions, be sure that all parentheses remain balanced outside the comment.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#external-comments","title":"External comments","text":"<p>Comments may also appear in a file with Soar productions, outside the curly braces of the sp command. Comments must either start a new line with a <code>#</code> or start with <code>;#</code>. In both cases, the comment runs to the end of the line.</p> <pre><code># imagine that this is part of a \"Soar program\" that contains\n# Soar productions as well as some other code.\n\nload file blocks.soar   ;# this is also a comment\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#the-condition-side-of-productions-or-lhs","title":"The condition side of productions (or LHS)","text":"<p>The condition side of a production, also called the left-hand side (or LHS) of the production, is a pattern for matching one or more WMEs. When all of the conditions of a production match elements in working memory, the production is said to be instantiated, and is ready to perform its action. (Each instance binds the rule to specific WMEs.)</p> <p>The following subsections describe the condition side of a production, including predicates, disjunctions, conjunctions, negations, <code>acceptable</code> preferences for operators, and a few advanced topics.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#conditions","title":"Conditions","text":"<p>The condition side of a production consists of a set of conditions. Each condition tests for the existence or absence (explained later in Section Negated Conditions) of working memory elements. Each condition consists of a open parenthesis, followed by a test for the identifier, and the tests for augmentations of that identifier, in terms of attributes and values. The condition is terminated with a close parenthesis. A single condition might test properties of a single working memory element, or properties of multiple working memory elements that constitute an object.</p> <pre><code>(identifier-test ^attribute1-test value1-test\n   ^attribute2-test value2-test\n   ^attribute3-test value3-test\n   ...)\n</code></pre> <p>The first condition in a production must match against a state in working memory. Thus, the first condition must begin with the additional symbol \"state\". All other conditions and actions must be linked directly or indirectly to this condition. This linkage may be direct to the state, or it may be indirect, through objects specified in the conditions. If the identifiers of the actions are not linked to the state, a warning is printed when the production is parsed, and the production is not stored in production memory. In the actions of the example production shown in Figure 3.2, the operator preference is directly linked to the state and the remaining actions are linked indirectly via the operator preference.</p> <p>Although all of the attribute tests in the example condition above are followed by value tests, it is possible to test for only the existence of an attribute and not test any specific value by just including the attribute and no value. Another exception to the above template is operator preferences, which have the following structure where a plus sign follows the value test.</p> <pre><code>(state-identifier-test ^operator value1-test +\n   ...)\n</code></pre> <p>In the remainder of this section, we describe the different tests that can be used for identifiers, attributes, and values. The simplest of these is a constant, where the constant specified in the attribute or value must match the same constant in a working memory element.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#variables-in-productions","title":"Variables in productions","text":"<p>Variables match against symbols in WMEs in the identifier, attribute, or value positions. Variables can be further constrained by additional tests (described in later sections) or by multiple occurrences in conditions. If a variable occurs more than once in the condition of a production, the production will match only if the variables match the same identifier or constant. However, there is no restriction that prevents different variables from binding to the same identifier or constant.</p> <p>Because identifiers are generated by Soar at run time, it impossible to include tests for specific identifiers in conditions. Therefore, variables are used in conditions whenever an identifier is to be matched.</p> <p>Variables also provide a mechanism for passing identifiers and constants which match in conditions to the action side of a rule.</p> <p>Syntactically, a variable is a symbol that begins with a left angle-bracket (i.e.,&lt;), ends with a right angle-bracket (i.e.,&gt;), and contains at least one non-pipe (|) character in between.</p> <p>In the example production in Figure 3.2, there are seven variables: <code>&lt;s&gt;</code>, <code>&lt;clear1&gt;</code>, <code>&lt;clear2&gt;</code>, <code>&lt;ontop&gt;,&lt;block1&gt;,&lt;block2&gt;</code>, and <code>&lt;o&gt;</code>.</p> <p>The following table gives examples of legal and illegal variable names.</p> Legal variables Illegal variables <code>&lt;s&gt;</code> &lt;&gt; &lt;1&gt; &lt;1 <code>&lt;variable1&gt;</code> variable&gt; <code>&lt;abc1&gt;</code> <code>&lt;a b&gt;</code>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#predicates-for-values","title":"Predicates for values","text":"<p>A test for an identifier, attribute, or value in a condition (whether constant or variable) can be modified by a preceding predicate. There are six general predicates that can be used: <code>&lt;&gt;</code>, <code>&lt;=&gt;</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;=</code>, <code>&gt;</code>.</p> Predicate Semantics of Predicate &lt;&gt; Not equal. Matches anything except the value immediately following it. &lt;=&gt; Same type. Matches any symbol that is the same type (identifier, integer, floating-point, non-numeric constant) as the value immediately following it. &lt; Numerically less than the value immediately following it. &lt;= Numerically less than or equal to the value immediately following it. &gt;= Numerically greater than or equal to the value immediately following it. &gt; Numerically greater than the value immediately following it. <p>The following table shows examples of legal and illegal predicates:</p> Legal predicates Illegal predicates <code>&gt; &lt;valuex&gt;</code> <code>&gt; &gt; &lt;valuey&gt;</code> <code>&lt; 1</code> <code>1 &gt;</code> <code>&lt;=&gt; &lt;y&gt;</code> <code>= 10</code> <p>There are also four special predicates that can be used to test Long-Term Identifier (LTI) links held by working memory identifiers: <code>@</code>, <code>!@</code>, <code>@+</code>, <code>@-</code></p> Predicate Semantics of Predicate <code>@</code> Same LTI. Matches when the two values are working memory identifiers linked to the same LTI. <code>!@</code> Different LTI. Matches when the values are not both identifiers linked to the same LTI. <code>@+</code> Matches if the value is an identifier linked to some LTI. <code>@-</code> Matches if the value is not an identifier linked to some LTI. <p>See Knowledge Representation for more information on long-term semantic memory and LTIs.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#example-productions","title":"Example Productions","text":"<pre><code>sp {propose-operator*to-show-example-predicate\n   (state &lt;s&gt; ^car &lt;c&gt;)\n   (&lt;c&gt; ^style convertible ^color &lt;&gt; rust)\n   --&gt;\n   (&lt;s&gt; ^operator &lt;o&gt; +)\n   (&lt;o&gt; ^name drive-car ^car &lt;c&gt;) }\n</code></pre> <p>In this production, there must be a \"color\" attribute for the working memory object that matches <code>&lt;c&gt;</code>, and the value of that attribute must not be \"rust\".</p> <pre><code>sp {example*lti*predicates\n   (state &lt;s&gt; ^existing-item { @+ &lt;orig-sti&gt; }\n      ^smem.result.retrieved { @ &lt;orig-sti&gt; &lt;result-sti&gt; })\n   --&gt;\n... }\n</code></pre> <p>In this production,<code>&lt;orig-sti&gt;</code>, is tested for whether it is linked to some LTI. It is also compared against <code>&lt;result-sti&gt;</code>(a working memory element retrieved from long-term mem- ory and known to be linked to an LTI) to see if the two elements point to the same long-term memory. Note the the <code>@+</code> in this example is actually unnecessary, since the <code>{ @ &lt;orig-sti&gt; &lt;result-sti&gt; }</code> test will fail to match if either value tested is not linked to an LTI.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#disjunctions-of-values","title":"Disjunctions of values","text":"<p>A test for an identifier, attribute, or value may also be for a disjunction of constants. With a disjunction, there will be a match if any one of the constants is found in a working memory element (and the other parts of the working memory element matches). Variables and predicates may not be used within disjunctive tests.</p> <p>Syntactically, a disjunctive test is specified with double angle brackets (i.e., <code>&lt;&lt; and &gt;&gt;</code>). There must be spaces separating the brackets from the constants.</p> <p>The following table provides examples of legal and illegal disjunctions:</p> Legal disjunctions Illegal disjunctions <code>&lt;&lt; A B C 45 I17 &gt;&gt;</code> <code>&lt;&lt; &lt;var&gt; A &gt;&gt;</code> <code>&lt;&lt; 5 10 &gt;&gt;</code> <code>&lt;&lt; &lt; 5 &gt; 10 &gt;&gt;</code> <code>&lt;&lt; good-morning good-evening &gt;&gt;</code> <code>&lt;&lt;A B C &gt;&gt;</code>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#example-production","title":"Example Production","text":"<p>For example, the third condition of the following production contains a disjunction that restricts the color of the table to red or blue:</p> <pre><code>sp {blocks*example-production-conditions\n   (state ^operator &lt;o&gt; + ^table &lt;t&gt;)\n   (&lt;o&gt; ^name move-block)\n   (&lt;t&gt; ^type table ^color &lt;&lt; red blue &gt;&gt; )\n   --&gt;\n   ... }\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#note","title":"Note","text":"<p>Disjunctions of complete conditions are not allowed in Soar. Multiple (similar) productions fulfill this role.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#conjunctions-of-values","title":"Conjunctions of values","text":"<p>A test for an identifier, attribute, or value in a condition may include a conjunction of tests, all of which must hold for there to be a match.</p> <p>Syntactically, conjuncts are contained within curly braces (i.e., <code>{ and }</code>). The following table shows some examples of legal and illegal conjunctive tests:</p> Legal conjunctions Illegal conjunctions { <code>&lt;= &lt;a&gt; &gt;= &lt;b&gt;</code> } { <code>&lt;x&gt; &lt; &lt;a&gt; + &lt;b&gt;</code> } { <code>&lt;x&gt; &gt; &lt;y&gt;</code> } { <code>&gt; &gt; &lt;b&gt;</code>} { <code>&lt;&gt; &lt;x&gt; &lt;y&gt;</code>} { <code>&lt;a&gt; &lt;b&gt;</code> } { <code>&lt;y&gt; &lt;&gt; &lt;x&gt;</code>} { <code>&lt;&lt; A B C &gt;&gt; &lt;x&gt;</code> } { <code>&lt;=&gt; &lt;x&gt; &gt; &lt;y&gt; &lt;&lt; 1 2 3 4 &gt;&gt; &lt;z&gt;</code>} <p>Because those examples are a bit difficult to interpret, let\u2019s go over the legal examples one by one to understand what each is doing.</p> <p>In the first example, the value must be less than or equal to the value bound to variable <code>&lt;a&gt;</code> and greater than or equal to the value bound to variable <code>&lt;b&gt;</code>.</p> <p>In the second example, the value is bound to the variable <code>&lt;x&gt;</code>, which must also be greater than the value bound to variable <code>&lt;y&gt;</code>.</p> <p>The third and fourth examples are equivalent. They state that the value must not be equal to the value bound to variable <code>&lt;x&gt;</code> and should be bound to variable <code>&lt;y&gt;</code>. Note the importance of order when using conjunctions with predicates: in the second example, the predicate modifies <code>&lt;y&gt;</code>, but in the third example, the predicate modifies <code>&lt;x&gt;</code>.</p> <p>In the fifth example, the value must be one of A, B, or C, and the second conjunctive test binds the value to variable <code>&lt;x&gt;</code>.</p> <p>In the sixth example, there are four conjunctive tests. First, the value must be the same type as the value bound to variable <code>&lt;x&gt;</code>. Second, the value must be greater than the value bound to variable <code>&lt;y&gt;</code>. Third, the value must be equal to 1 , 2 , 3 , or 4. Finally, the value should be bound to variable <code>&lt;z&gt;</code>.</p> <p>In Figure 3.2, a conjunctive test is used for the thing attribute in the first condition.</p> <p>Note that it is illegal syntax for a condition to test the equality of two variables, as demonstrated in the last illegal conjunction above. Any such test can instead be coded in simpler terms by only using one variable in the places where either would be referenced throughout the rule.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#negated-conditions","title":"Negated conditions","text":"<p>In addition to the positive tests for elements in working memory, conditions can also test for the absence of patterns. A negated condition will be matched only if there does not exist a working memory element consistent with its tests and variable bindings. Thus, it is a test for the absence of a working memory element.</p> <p>Syntactically, a negated condition is specified by preceding a condition with a dash (i.e., \"-\").</p> <p>For example, the following condition tests the absence of a working memory element of the object bound to <code>&lt;p1&gt; ^type father</code>.</p> <pre><code>-(&lt;p1&gt; ^type father)\n</code></pre> <p>A negation can be used within an object with many attribute-value pairs by having it precede a specific attribute:</p> <pre><code>(&lt;p1&gt; ^name john -^type father ^spouse &lt;p2&gt;)\n</code></pre> <p>In that example, the condition would match if there is a working memory element that matches <code>(&lt;p1&gt; ^name john)</code> and another that matches <code>(&lt;p1&gt; ^spouse &lt;p2&gt;)</code>, but is no working memory element that matches <code>(&lt;p1&gt; ^type father)</code> (when <code>p1</code> is bound to the same identifier).</p> <p>On the other hand, the condition:</p> <pre><code>-(&lt;p1&gt; ^name john ^type father ^spouse &lt;p2&gt;)\n</code></pre> <p>would match only if there is no object in working memory that matches all three attribute- value tests.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#example-production_1","title":"Example Production","text":"<pre><code>sp {default*evaluate-object\n   (state &lt;ss&gt; ^operator &lt;so&gt;)\n   (&lt;so&gt; ^type evaluation\n      ^superproblem-space &lt;p&gt;)\n   -(&lt;p&gt; ^default-state-copy no)\n   --&gt;\n   (&lt;so&gt; ^default-state-copy yes) }\n</code></pre> <p>For negated conditions in combination with attribute-path notation consult the section negated multi-valued attributes and attribute-path notation.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#notes","title":"Notes","text":"<p>One use of negated conditions to avoid is testing for the absence of the working memory element that a production creates with i-support; this would lead to an \"infinite loop\" in your Soar program, as Soar would repeatedly fire and retract the production. For example, the following rule\u2019s actions will cause it to no longer match, which will cause the action to retract, which will cause the rule to match, and so on:</p> <pre><code>sp {example*infinite-loop\n   (state &lt;s&gt; ^car &lt;c&gt;\n      -^road )\n   --&gt;\n   (&lt;s&gt; ^road |route-66|) }\n</code></pre> <p>Also note that syntactically it is invalid for the first condition of a rule to be a negated condition. For example, the following production would fail to load:</p> <pre><code>sp {example*invalid-negated-first-condition\n   (state &lt;s&gt; -^road &lt;r&gt;\n      ^car &lt;c&gt;)\n   --&gt;\n... }\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#negated-conjunctions-of-conditions","title":"Negated conjunctions of conditions","text":"<p>Conditions can be grouped into conjunctive sets by surrounding the set of conditions with <code>{ and }</code>. The production compiler groups the test in these conditions together. This grouping allows for negated tests of more than one working memory element at a time. In the example below, the state is tested to ensure that it does not have an object on the table.</p> <pre><code>sp {blocks*negated-conjunction-example\n   (state &lt;s&gt; ^name top-state)\n  -{(&lt;s&gt; ^ontop &lt;on&gt;)\n    (&lt;on&gt; ^bottom-object &lt;bo&gt;)\n    (&lt;bo&gt; ^type table)}\n   --&gt;\n   (&lt;s&gt; ^nothing-ontop-table true)}\n</code></pre> <p>When using negated conjunctions of conditions, the production has nested curly braces. One set of curly braces delimits the production, while the other set delimits the conditions to be conjunctively negated.</p> <p>If only the last condition, <code>(&lt;bo&gt; ^type table)</code> were negated, the production would match only if the state had an ontop relation, and the ontop relation had a bottom-object, but the bottom object wasn\u2019t a table. Using the negated conjunction, the production will also match when the state has no ontop augmentation or when it has an ontop augmentation that doesn\u2019t have a bottom-object augmentation.</p> <p>The semantics of negated conjunctions can be thought of in terms of mathematical logic, where the negation of \\((A \\wedge B \\wedge C)\\):</p> \\[\\neg (A \\wedge B \\wedge C)\\] <p>can be rewritten as:</p> \\[(\\neg A) \\vee (\\neg B) \\vee (\\neg C)\\] <p>That is, \"not (A and B and C)\" becomes \"(not A) or (not B) or (not C)\".</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#multi-valued-attributes","title":"Multi-valued attributes","text":"<p>An object in working memory may have multiple augmentations that specify the same at- tribute with different values; these are called multi-valued attributes, or multi-attributes for short. To shorten the specification of a condition, tests for multi-valued attributes can be shortened so that the value tests are together.</p> <p>For example, the condition:</p> <pre><code>(&lt;p1&gt; ^type father ^child sally ^child sue)\n</code></pre> <p>could also be written as:</p> <pre><code>(&lt;p1&gt; ^type father ^child sally sue)\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#multi-valued-attributes-and-variables","title":"Multi-valued attributes and variables","text":"<p>When variables are used with multi-valued attributes, remember that variable bindings are not unique unless explicitly forced to be so. For example, to test that an object has two values for attribute child, the variables in the following condition can match to the same value.</p> <pre><code>(&lt;p1&gt; ^type father ^child &lt;c1&gt; &lt;c2&gt;)\n</code></pre> <p>To do tests for multi-valued attributes with variables correctly, conjunctive tests must be used, as in:</p> <pre><code>(&lt;p1&gt; ^type father ^child &lt;c1&gt; {&lt;&gt; &lt;c1&gt; &lt;c2&gt;})\n</code></pre> <p>The conjunctive test <code>{&lt;&gt; &lt;c1&gt; &lt;c2&gt;}</code> ensures that <code>&lt;c2&gt;</code> will bind to a different value than <code>&lt;c1&gt;</code> binds to.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#negated-conditions-and-multi-valued-attributes","title":"Negated conditions and multi-valued attributes","text":"<p>A negation can also precede an attribute with multiple values. In this case it tests for the absence of the conjunction of the values. For example</p> <pre><code>(&lt;p1&gt; ^name john -^child oprah uma)\n</code></pre> <p>is the same as</p> <pre><code>(&lt;p1&gt; ^name john)\n-{(&lt;p1&gt; ^child oprah)\n(&lt;p1&gt; ^child uma)}\n</code></pre> <p>and the match is possible if either <code>(&lt;p1&gt; ^child oprah)</code> or <code>(&lt;p1&gt; ^child uma)</code> cannot be found in working memory with the binding for <code>&lt;p1&gt;</code> (but not if both are present).</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#acceptable-preferences-for-operators","title":"Acceptable preferences for operators","text":"<p>The only preferences that can appear in working memory are acceptable preferences for operators, and therefore, the only preferences that may appear in the conditions of a production are <code>acceptable</code> preferences for operators.</p> <p>Acceptable preferences for operators can be matched in a condition by testing for a \"+\" following the value. This allows a production to test the existence of a candidate operator and its properties, and possibly create a preference for it, before it is selected.</p> <p>In the example below, <code>^operator &lt;o&gt; +</code> matches the <code>acceptable</code> preference for the operator augmentation of the state. This does not test that operator <code>&lt;o&gt;</code> has been selected as the current operator.</p> <pre><code>sp {blocks*example-production-conditions\n   (state ^operator &lt;o&gt; + ^table &lt;t&gt;)\n   (&lt;o&gt; ^name move-block)\n   --&gt;\n   ... }\n</code></pre> <p>In the example below, the production tests the state for <code>acceptable</code> preferences for two different operators (and also tests that these operators move different blocks):</p> <pre><code>sp {blocks*example-production-conditions\n   (state ^operator &lt;o1&gt; + &lt;o2&gt; + ^table &lt;t&gt;)\n   (&lt;o1&gt; ^name move-block ^moving-block &lt;m1&gt; ^destination &lt;d1&gt;)\n   (&lt;o2&gt; ^name move-block ^moving-block {&lt;m2&gt; &lt;&gt; &lt;m1&gt;}\n      ^destination &lt;d2&gt;)\n   --&gt;\n   ... }\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#attribute-tests","title":"Attribute tests","text":"<p>The previous examples applied all of the different tests to the values of working memory elements. All of the tests that can be used for values can also be used for attributes and identifiers (except those including constants).</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#variables-in-attributes","title":"Variables in attributes","text":"<p>Variables may be used with attributes, as in:</p> <pre><code>sp {blocks*example-production-conditions\n   (state &lt;s&gt; ^operator &lt;o&gt; +\n      ^thing &lt;t&gt; {&lt;&gt; &lt;t&gt; &lt;t2&gt;} )\n   (operator &lt;o&gt; ^name group\n      ^by-attribute &lt;a&gt;\n      ^moving-block &lt;t&gt;\n      ^destination &lt;t2&gt;)\n   (&lt;t&gt; ^type block ^&lt;a&gt; &lt;x&gt;)\n   (&lt;t2&gt; ^type block ^&lt;a&gt; &lt;x&gt;)\n   --&gt;\n   (&lt;s&gt; ^operator &lt;o&gt; &gt;) }\n</code></pre> <p>This production tests that there is <code>acceptable</code> operator that is trying to group blocks according to some attribute, <code>&lt;a&gt;</code>, and that block <code>&lt;t&gt;</code> and <code>&lt;t2&gt;</code> both have this attribute (whatever it is), and have the same value for the attribute.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#predicates-in-attributes","title":"Predicates in attributes","text":"<p>Predicates may be used with attributes, as in:</p> <pre><code>sp {blocks*example-production-conditions\n   (state ^operator &lt;o&gt; + ^table &lt;t&gt;)\n   (&lt;t&gt; ^&lt;&gt; type table)\n   --&gt;\n... }\n</code></pre> <p>which tests that the object with its identifier bound to <code>&lt;t&gt;</code> must have an attribute whose value is <code>table</code>, but the name of this attribute is not <code>type</code>.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#disjunctions-of-attributes","title":"Disjunctions of attributes","text":"<p>Disjunctions may also be used with attributes, as in:</p> <pre><code>sp {blocks*example-production-conditions\n   (state ^operator &lt;o&gt; + ^table &lt;t&gt;)\n   (&lt;t&gt; ^&lt;&lt; type name&gt;&gt; table)\n   --&gt;\n... }\n</code></pre> <p>which tests that the object with its identifier bound to  must have either an attribute <code>type</code> whose value is <code>table</code> or an attribute <code>name</code> whose value is <code>table</code>."},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#conjunctive-tests-for-attributes","title":"Conjunctive tests for attributes","text":"<p>Section Conjunction of Values illustrated the use of conjunctions for the values in conditions. Conjunctive tests may also be used with attributes, as in:</p> <pre><code>sp {blocks*example-production-conditions\n   (state ^operator &lt;o&gt; + ^table &lt;t&gt;)\n   (&lt;t&gt; ^{&lt;ta&gt; &lt;&gt; name} table)\n   --&gt;\n   ... }\n</code></pre> <p>which tests that the object with its identifier bound to <code>&lt;t&gt;</code> must have an attribute whose value is <code>table</code>, and the name of this attribute is not <code>name</code>, and the name of this attribute (whatever it is) is bound to the variable <code>&lt;ta&gt;</code>.</p> <p>When attribute predicates or attribute disjunctions are used with multi-valued attributes, the production is rewritten internally to use a conjunctive test for the attribute; the conjunctive test includes a variable used to bind to the attribute name. Thus,</p> <pre><code>(&lt;p1&gt; ^type father ^ &lt;&gt; name sue sally)\n</code></pre> <p>is interpreted to mean:</p> <pre><code>(&lt;p1&gt; ^type father\n   ^{&lt;&gt; name &lt;a*1&gt;} sue\n   ^&lt;a*1&gt; sally)\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#attribute-path-notation","title":"Attribute-path notation","text":"<p>Often, variables appear in the conditions of productions only to link the value of one attribute with the identifier of another attribute. Attribute-path notation provides a shorthand so that these intermediate variables do not need to be included.</p> <p>Syntactically, path notation lists a sequence of attributes separated by dots (.), after the <code>^</code> in a condition.</p> <p>For example, using attribute path notation, the production:</p> <pre><code>sp {blocks-world*monitor*move-block\n   (state &lt;s&gt; ^operator &lt;o&gt;)\n   (&lt;o&gt; ^name move-block\n      ^moving-block &lt;block1&gt;\n      ^destination &lt;block2&gt;)\n   (&lt;block1&gt; ^name &lt;block1-name&gt;)\n   (&lt;block2&gt; ^name &lt;block2-name&gt;)\n   --&gt;\n   (write (crlf) |Moving Block: | &lt;block1-name&gt;\n      | to: | &lt;block2-name&gt; ) }\n</code></pre> <p>could be written as:</p> <pre><code>sp {blocks-world*monitor*move-block\n   (state &lt;s&gt; ^operator &lt;o&gt;)\n   (&lt;o&gt; ^name move-block\n      ^moving-block.name &lt;block1-name&gt;\n      ^destination.name &lt;block2-name&gt;)\n   --&gt;\n   (write (crlf) |Moving Block: | &lt;block1-name&gt;\n      | to: | &lt;block2-name&gt; ) }\n</code></pre> <p>Attribute-path notation yields shorter productions that are easier to write, less prone to errors, and easier to understand.</p> <p>When attribute-path notation is used, Soar internally expands the conditions into the multiple Soar objects, creating its own variables as needed. Therefore, when you print a production (using the <code>print</code> command), the production will not be represented using attribute-path notation.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#negations-and-attribute-path-notation","title":"Negations and attribute path notation","text":"<p>A negation may be used with attribute path notation, in which case it amounts to a negated conjunction. For example, the production:</p> <pre><code>sp {blocks*negated-conjunction-example\n   (state &lt;s&gt; ^name top-state)\n   -{(&lt;s&gt; ^ontop &lt;on&gt;)\n   (&lt;on&gt; ^bottom-object &lt;bo&gt;)\n   (&lt;bo&gt; ^type table)}\n   --&gt;\n   (&lt;s&gt; ^nothing-ontop-table true) }\n</code></pre> <p>could be rewritten as:</p> <pre><code>sp {blocks*negated-conjunction-example\n   (state &lt;s&gt; ^name top-state -^ontop.bottom-object.type table)\n   --&gt;\n   (&lt;s&gt; ^nothing-ontop-table true) }\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#multi-valued-attributes-and-attribute-path-notation","title":"Multi-valued attributes and attribute path notation","text":"<p>Attribute path notation may also be used with multi-valued attributes, such as:</p> <pre><code>sp {blocks-world*propose*move-block\n   (state &lt;s&gt; ^problem-space blocks\n      ^clear.block &lt;block1&gt; { &lt;&gt; &lt;block1&gt; &lt;block2&gt; }\n      ^ontop &lt;ontop&gt;)\n   (&lt;block1&gt; ^type block)\n   (&lt;ontop&gt; ^top-block &lt;block1&gt;\n      ^bottom-block &lt;&gt; &lt;block2&gt;)\n   --&gt;\n   (&lt;s&gt; ^operator &lt;o&gt; +)\n   (&lt;o&gt; ^name move-block +\n      ^moving-block &lt;block1&gt; +\n      ^destination &lt;block2&gt; +) }\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#multi-attributes-and-attribute-path-notation","title":"Multi-attributes and attribute-path notation","text":"<p>Note: It would not be advisable to write the production in Figure 3.2 using attribute-path notation as follows:</p> <pre><code>sp {blocks-world*propose*move-block*dont-do-this\n   (state &lt;s&gt; ^problem-space blocks\n      ^clear.block &lt;block1&gt;\n      ^clear.block { &lt;&gt; &lt;block1&gt; &lt;block2&gt; }\n      ^ontop.top-block &lt;block1&gt;\n      ^ontop.bottom-block &lt;&gt; &lt;block2&gt;)\n   (&lt;block1&gt; ^type block)\n   --&gt;\n   ...}\n</code></pre> <p>This is not advisable because it corresponds to a different set of conditions than those in the original production (the <code>top-block</code> and <code>bottom-block</code> need not correspond to the same <code>ontop</code> relation). To check this, we could print the original production at the Soar prompt:</p> <pre><code>soar&gt; print blocks-world*propose*move-block*dont-do-this\nsp {blocks-world*propose*move-block*dont-do-this\n   (state &lt;s&gt; ^problem-space blocks ^thing &lt;thing2&gt;\n      ^thing { &lt;&gt; &lt;thing2&gt; &lt;thing1&gt; } ^ontop &lt;o*1&gt; ^ontop &lt;o*2&gt;)\n   (&lt;thing2&gt; ^clear yes)\n   (&lt;thing1&gt; ^clear yes ^type block)\n   (&lt;o*1&gt; ^top-block &lt;thing1&gt;)\n   (&lt;o*2&gt; ^bottom-block { &lt;&gt; &lt;thing2&gt; &lt;b*1&gt; })\n   --&gt;\n   (&lt;s&gt; ^operator &lt;o&gt; +)\n   (&lt;o&gt; ^name move-block\n      ^moving-block &lt;thing1&gt;\n      ^destination &lt;thing2&gt;) }\n</code></pre> <p>Soar has expanded the production into the longer form, and created two distinctive variables, <code>&lt;o*1&gt;</code> and <code>&lt;o*2&gt;</code> to represent the on top attribute. These two variables will not necessarily bind to the same identifiers in working memory.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#negated-multi-valued-attributes-and-attribute-path-notation","title":"Negated multi-valued attributes and attribute-path notation","text":"<p>Negations of multi-valued attributes can be combined with attribute-path notation. However; it is very easy to make mistakes when using negated multi-valued attributes with attribute-path notation. Although it is possible to do it correctly, we strongly discourage its use.</p> <p>For example,</p> <pre><code>sp {blocks*negated-conjunction-example\n   (state &lt;s&gt; ^name top-state -^ontop.bottom-object.name table A)\n   --&gt;\n   (&lt;s&gt; ^nothing-ontop-A-or-table true) }\n</code></pre> <p>gets expanded to:</p> <pre><code>sp {blocks*negated-conjunction-example\n   (state &lt;s&gt; ^name top-state)\n   -{(&lt;s&gt; ^ontop &lt;o*1&gt;)\n   (&lt;o*1&gt; ^bottom-object &lt;b*1&gt;)\n   (&lt;b*1&gt; ^name A)\n   (&lt;b*1&gt; ^name table)}\n   --&gt;\n   (&lt;s&gt; ^nothing-ontop-A-or-table true) }\n</code></pre> <p>This example does not refer to two different blocks with different names. It tests that there is not a non top relation with a <code>bottom-block</code> that is named <code>A</code> and named <code>table</code>. Thus, this production probably should have been written as:</p> <pre><code>sp {blocks*negated-conjunction-example\n   (state &lt;s&gt; ^name top-state\n   -^ontop.bottom-object.name table\n   -^ontop.bottom-object.name A)\n   --&gt;\n   (&lt;s&gt; ^nothing-ontop-A-or-table true) }\n</code></pre> <p>which expands to:</p> <pre><code>sp {blocks*negated-conjunction-example\n   (state &lt;s&gt; ^name top-state)\n   -{(&lt;s&gt; ^ontop &lt;o*2&gt;)\n     (&lt;o*2&gt; ^bottom-object &lt;b*2&gt;)\n     (&lt;b*2&gt; ^name a)}\n   -{(&lt;s&gt; ^ontop &lt;o*1&gt;)\n     (&lt;o*1&gt; ^bottom-object &lt;b*1&gt;)\n     (&lt;b*1&gt; ^name table)}\n   --&gt;\n   (&lt;s&gt; ^nothing-ontop-a-or-table true +) }\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#notes-on-attribute-path-notation","title":"Notes on attribute-path notation","text":"<ul> <li>Attributes specified in attribute-path notation may not start with a digit. For   example, if you type <code>^foo.3.bar</code>, Soar thinks the <code>.3</code> is a floating-point number.   (Attributes that don\u2019t appear in path notation can begin with a number.)</li> <li>Attribute-path notation may be used to any depth.</li> <li>Attribute-path notation may be combined with structured values, described in Section   Structured Value Notation.</li> </ul>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#structured-value-notation","title":"Structured-value notation","text":"<p>Another convenience that eliminates the use of intermediate variables is structured-value notation. Syntactically, the attributes and values of a condition may be written where a variable would normally be written. The attribute-value structure is delimited by parentheses.</p> <p>Using structured-value notation, the production in Figure 3.2 may also be written as:</p> <pre><code>sp {blocks-world*propose*move-block\n   (state &lt;s&gt; ^problem-space blocks\n      ^thing &lt;thing1&gt;\n      ^thing {&lt;&gt; &lt;thing1&gt; &lt;thing2&gt;}\n      ^ontop (^top-block &lt;thing1&gt;\n      ^bottom-block &lt;&gt; &lt;thing2&gt;))\n   (&lt;thing1&gt; ^type block ^clear yes)\n   (&lt;thing2&gt; ^clear yes)\n   --&gt;\n   (&lt;s&gt; ^operator &lt;o&gt; +)\n   (&lt;o&gt; ^name move-block\n      ^moving-block &lt;thing1&gt;\n      ^destination &lt;thing2&gt;) }\n</code></pre> <p>Thus, several conditions may be \"collapsed\" into a single condition.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#using-variables-within-structured-value-notation","title":"Using variables within structured-value notation","text":"<p>Variables are allowed within the parentheses of structured-value notation to specify an identifier to be matched elsewhere in the production. For example, the variable <code>&lt;ontop&gt;</code> could be added to the conditions (although it is not referenced again, so this is not helpful in this instance):</p> <pre><code>sp {blocks-world*propose*move-block\n   (state &lt;s&gt; ^problem-space blocks\n      ^thing &lt;thing1&gt;\n      ^thing {&lt;&gt; &lt;thing1&gt; &lt;thing2&gt;}\n      ^ontop (&lt;ontop&gt;\n      ^top-block &lt;thing1&gt;\n      ^bottom-block &lt;&gt; &lt;thing2&gt;))\n   (&lt;thing1&gt; ^type block ^clear yes)\n   (&lt;thing2&gt; ^clear yes)\n   --&gt;\n   (&lt;s&gt; ^operator &lt;o&gt; +)\n   (&lt;o&gt; ^name move-block\n      ^moving-block &lt;thing1&gt;\n      ^destination &lt;thing2&gt;) }\n</code></pre> <p>Structured values may be nested to any depth. Thus, it is possible to write our example production using a single condition with multiple structured values:</p> <pre><code>sp {blocks-world*propose*move-block\n   (state &lt;s&gt; ^problem-space blocks\n      ^thing &lt;thing1&gt;\n   ({&lt;&gt; &lt;thing1&gt; &lt;thing2&gt;}\n      ^clear yes)\n      ^ontop (^top-block\n   (&lt;thing1&gt;\n      ^type block\n      ^clear yes)\n      ^bottom-block &lt;&gt; &lt;thing2&gt;) )\n   --&gt;\n   (&lt;s&gt; ^operator &lt;o&gt; +)\n   (&lt;o&gt; ^name move-block\n      ^moving-block &lt;thing1&gt;\n      ^destination &lt;thing2&gt;) }\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#notes-on-structured-value-notation","title":"Notes on structured-value notation","text":"<ul> <li>Attribute-path notation and structured-value notation are orthogonal and can   be combined in any way. A structured value can contain an attribute path, or a   structure can be given as the value for an attribute path.</li> <li>Structured-value notation can be combined with negations and with multi-attributes.</li> <li>Structured-value notation can not be used in the actions of productions.</li> </ul>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#the-action-side-of-productions-or-rhs","title":"The action side of productions (or RHS)","text":"<p>The action side of a production, also called the right-hand side (or RHS) of the production, consists of individual actions that can:</p> <ul> <li>Add new elements to working memory.</li> <li>Remove elements from working memory.</li> <li>Create preferences.</li> <li>Perform other actions</li> </ul> <p>When the conditions of a production match working memory, the production is said to be instantiated, and the production will fire during the next elaboration cycle. Firing the production involves performing the actions using the same variable bindings that formed the instantiation.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#variables-in-actions","title":"Variables in Actions","text":"<p>Variables can be used in actions. A variable that appeared in the condition side will be replaced with the value that is was bound to in the condition. A variable that appears only in the action side will be bound to a new identifier that begins with the first letter of that variable (e.g., <code>&lt;o&gt;</code> might be bound to <code>o234</code>). This symbol is guaranteed to be unique and it will be used for all occurrences of the variable in the action side, appearing in all working memory elements and preferences that are created by the production action.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#creating-working-memory-elements","title":"Creating Working Memory Elements","text":"<p>An element is created in working memory by specifying it as an action. Multiple augmentations of an object can be combined into a single action, using the same syntax as in conditions, including path notation and multi-valued attributes.</p> <pre><code>--&gt;\n(&lt;s&gt; ^block.color red\n   ^thing &lt;t1&gt; &lt;t2&gt;) }\n</code></pre> <p>The action above is expanded to be:</p> <pre><code>--&gt;\n(&lt;s&gt; ^block &lt;*b&gt;)\n(&lt;*b&gt; ^color red)\n(&lt;s&gt; ^thing &lt;t1&gt;)\n(&lt;s&gt; ^thing &lt;t2&gt;) }\n</code></pre> <p>This will add four elements to working memory with the variables replaced with whatever values they were bound to on the condition side.</p> <p>Since Soar is case sensitive, different combinations of upper- and lowercase letters represent different constants. For example, <code>\"red\"</code>, <code>\"Red\"</code>, and <code>\"RED\"</code> are all distinct symbols in Soar. In many cases, it is prudent to choose one of uppercase or lowercase and write all constants in that case to avoid confusion (and bugs).</p> <p>The constants that are used for attributes and values have a few restrictions on them:</p> <ol> <li>There are a number of architecturally created augmentations for state and    impasse objects; see Section Impass in Working Memory and in Productions for a listing of    these special augmentations. User-defined productions can not create or remove    augmentations of states that use these attribute names.</li> <li>Attribute names should not begin with a number if these attributes will be used in    attribute-path notation.</li> </ol>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#removing-working-memory-elements","title":"Removing Working Memory Elements","text":"<p>A element is explicitly removed from working memory by following the value with a dash:</p> <p><code>-</code> , also called a reject.</p> <pre><code>--&gt;\n(&lt;s&gt; ^block &lt;b&gt; -)}\n</code></pre> <p>If the removal of a working memory element removes the only link between the state and working memory elements that had the value of the removed element as an identifier, those working memory elements will be removed. This is applied recursively, so that all item that become unlinked are removed.</p> <p>The removal should be used with an action that will be o-supported. If removal is attempted with i-support, the working memory element will reappear if the removal loses i-support and the element still has support.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#the-syntax-of-preferences","title":"The syntax of preferences","text":"<p>Below are the eleven types of preferences as they can appear in the actions of a production for the selection of operators:</p> RHS preferences Semantics (id ^operator value) acceptable (id ^operator value +) acceptable (id ^operator value !) require (id ^operator value ~) prohibit (id ^operator value -) reject (id ^operator value &gt; value2) better (id ^operator value &lt; value2) worse (id ^operator value &gt;) best (id ^operator value &lt;) worst (id ^operator value =) unary indifferent (id ^operator value = value2) binary indifferent (id ^operator value = number) numeric indifferent <p>The identifier and value will always be variables, such as <code>(&lt;s1&gt; ^operator &lt;o1&gt; &gt; &lt;o2&gt;)</code>.</p> <p>The preference notation appears similar to the predicate tests that appear on the left-hand side of productions, but has very different meaning. Predicates cannot be used on the right- hand side of a production and you cannot restrict the bindings of variables on the right-hand side of a production. (Such restrictions can happen only in the conditions.)</p> <p>Also notice that the + symbol is optional when specifying <code>acceptable</code> preferences in the actions of a production, although using this symbol will make the semantics of your productions clearer in many instances. The <code>+</code> symbol will always appear when you inspect preference memory (with the <code>preferences</code> command).</p> <p>Productions are never needed to delete preferences because preferences will be retracted when the production no longer matches. Preferences should never be created by operator application rules, and they should always be created by rules that will give only i-support to their actions.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#shorthand-notations-for-preference-creation","title":"Shorthand notations for preference creation","text":"<p>There are a few shorthand notations allowed for the creation of operator preferences on the right-hand side of productions.</p> <p>Acceptable preferences do not need to be specified with a+symbol.<code>(&lt;s&gt; ^operator &lt;op1&gt;)</code> is assumed to mean <code>(&lt;s&gt; ^operator &lt;op1&gt; +)</code>.</p> <p>Note however that the+is only implicit if no other preferences are specified for that operator. Specifying a preference that is not the <code>acceptable</code> preference does not also imply an acceptable preference. For example, <code>(&lt;s&gt; ^operator &lt;op1&gt; &gt; )</code> by itself cannot lead to <code>&lt;op1&gt;</code> being selected, since it does not have an <code>acceptable</code> preference.</p> <p>Ambiguity can easily arise when using a preference that can be either binary or unary: <code>&gt; &lt; =</code>. The default assumption is that if a value follows the preference, then the preference is binary. It will be unary if a carat (up-arrow), a closing parenthesis, another preference, or a comma follows it.</p> <p>Below are four examples of legal, although unrealistic, actions that have the same effect.</p> <pre><code>(&lt;s&gt; ^operator &lt;o1&gt; &lt;o2&gt; + &lt;o2&gt; &lt; &lt;o1&gt; &lt;o3&gt; =, &lt;o4&gt;)\n(&lt;s&gt; ^operator &lt;o1&gt; + &lt;o2&gt; +\n   &lt;o2&gt; &lt; &lt;o1&gt; &lt;o3&gt; =, &lt;o4&gt; +)\n(&lt;s&gt; ^operator &lt;o1&gt; &lt;o2&gt; &lt;o2&gt; &lt; &lt;o1&gt; &lt;o4&gt; &lt;o3&gt; =)\n(&lt;s&gt; ^operator &lt;o1&gt; ^operator &lt;o2&gt;\n   ^operator &lt;o2&gt; &lt; &lt;o1&gt; ^operator &lt;o4&gt; &lt;o3&gt; =)\n</code></pre> <p>Any one of those actions could be expanded to the following list of preferences:</p> <pre><code>(&lt;s&gt; ^operator &lt;o1&gt; +)\n(&lt;s&gt; ^operator &lt;o2&gt; +)\n(&lt;s&gt; ^operator &lt;o2&gt; &lt; &lt;o1&gt;)\n(&lt;s&gt; ^operator &lt;o3&gt; =)\n(&lt;s&gt; ^operator &lt;o4&gt; +)\n</code></pre> <p>Note that structured-value notation may not be used in the actions of productions.</p> <p>Commas are only allowed in rule syntax for this sort of use, in the RHS. They can be used to separate actions, and if used when no disambiguation is needed will have no effect other than syntactic sugar.</p> <p>As another example, <code>(&lt;s&gt; ^operator &lt;o1&gt; &lt;o2&gt; &gt; &lt;o3&gt;)</code> would be interpreted as</p> <pre><code>(&lt;s&gt; ^operator &lt;o1&gt; +\n^operator &lt;o2&gt; &gt; &lt;o3&gt;)\n</code></pre> <p>But <code>(&lt;s&gt; ^operator &lt;o1&gt; &lt;o2&gt; &gt;, &lt;o3&gt;)</code> would be interpreted as</p> <pre><code>(&lt;s&gt; ^operator &lt;o1&gt; +\n   ^operator &lt;o2&gt; &gt;\n   ^operator &lt;o3&gt; +)\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#right-hand-side-functions","title":"Right-hand side Functions","text":"<p>The fourth type of action that can occur in productions is called a right-hand side function. Right-hand side functions allow productions to create side effects other than changing work- ing memory. The RHS functions are described below, organized by the type of side effect they have.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#stopping-and-pausing-soar","title":"Stopping and pausing Soar","text":"<p>halt \u2014 Terminates Soar\u2019s execution and returns to the user prompt. A <code>halt</code> action irreversibly terminates the running of a Soar program. It should not be used if the agent is to be restarted (see the <code>interrupt</code> RHS action below.)</p> <pre><code>sp {\n   ...\n   --&gt;\n   (halt) }\n</code></pre> <p>interrupt \u2014 Executing this function causes Soar to stop at the end of the current phase, and return to the user prompt. This is similar to halt, but does not terminate the run. The run may be continued by issuing a run command from the user interface. The interrupt RHS function has the same effect as typing stop-soar at the prompt, except that there is more control because it takes effect exactly at the end of the phase that fires the production.</p> <pre><code>sp {\n   ...\n   --&gt;\n   (interrupt) }\n</code></pre> <p>Soar execution may also be stopped immediately before a production fires, using the <code>:interrupt</code> directive. This functionality is called a matchtime interrupt and is very useful for debugging. See 'sp' command for more information.</p> <pre><code>sp {production*name\n   :interrupt\n   ...\n   --&gt;\n   ...}\n</code></pre> <p>wait \u2014 Executing this function causes the current Soar thread to sleep for the given integer number of milliseconds.</p> <pre><code>sp {\n   ...\n   --&gt;\n   (wait 1000) }\n</code></pre> <p>Note that use of this function is discouraged.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#text-input-and-output","title":"Text input and output","text":"<p>These functions are provided as production actions to do simple output of text in Soar. Soar applications that do extensive input and output of text should use Soar Markup Language (SML). To learn about SML, read the \"SML Quick Start Guide\" which should be located in the \"Documentation\" folder of your Soar install.</p> <p>write \u2014 This function writes its arguments to the standard output. It does not automatically insert blanks, line feeds, or carriage returns. For example, if <code>&lt;o&gt;</code> is bound to 4, then</p> <pre><code>sp {\n   ...\n   --&gt;\n   (write &lt;o&gt; &lt;o&gt; &lt;o&gt; | x| &lt;o&gt; | | &lt;o&gt;) }\n</code></pre> <p>prints</p> <pre><code>444 x4 4\n</code></pre> <p>crlf \u2014 Short for \"carriage return, line feed\", this function can be called only within <code>write</code>. It forces a new line at its position in the write action.</p> <pre><code>sp {\n   ...\n   --&gt;\n   (write &lt;x&gt; (crlf) &lt;y&gt;) }\n</code></pre> <p>log \u2014 This function is equivalent to the <code>write</code> function, except that it specifies a \"log channel\" for output. The output will only show if that channel is active. The function takes two arguments. First is an integer corresponding to the channel level for output, second is the message to print. See the 'output` command for information about agent log channels.</p> <pre><code>sp {\n   ...\n   --&gt;\n   (log 3 |This only prints when agent-logs channel 3 is enabled.|) }\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#mathematical-functions","title":"Mathematical functions","text":"<p>The expressions described in this section can be nested to any depth. For all of the functions in this section, missing or non-numeric arguments result in an error.</p> <p>+, -, *, / \u2014 These symbols provide prefix notation mathematical functions. These symbols work similarly to C functions. They will take either integer or real-number arguments. The first three functions return an integer when all arguments are integers and otherwise return a real number, and the last two functions always return a real number. These functions can each take any number of arguments, and will return the result of sequentially operating on each argument. The <code>-</code> symbol is also a unary function which, given a single argument, returns the product of the argument and -1. The <code>/</code> symbol is also a unary function which, given a single argument, returns the reciprocal of the argument <code>(1/x)</code>.</p> <pre><code>sp {\n   ...\n   --&gt;\n   (&lt;s&gt; ^sum (+ &lt;x&gt; &lt;y&gt;)\n      ^product-sum (* (+ &lt;v&gt; &lt;w&gt;) (+ &lt;x&gt; &lt;y&gt;))\n      ^big-sum (+ &lt;x&gt; &lt;y&gt; &lt;z&gt; 402)\n      ^negative-x (- &lt;x&gt;))}\n</code></pre> <p>div, mod \u2014 These symbols provide prefix notation binary mathematical functions (they each take two arguments). These symbols work similarly to C functions: They will take only integer arguments (using reals results in an error) and return an integer: div takes two integers and returns their integer quotient; mod returns their remainder.</p> <pre><code>sp {\n   ...\n   --&gt;\n   (&lt;s&gt; ^quotient (div &lt;x&gt; &lt;y&gt;)\n   ^remainder (mod &lt;x&gt; &lt;y&gt;)) }\n</code></pre> <p>abs, atan2, sqrt, sin, cos \u2014 These provide prefix notation unary mathematical functions (they each take one argument). These symbols work similarly to C functions:</p> <p>They will take either integer or real-number arguments. The first function (<code>abs</code>) returns an integer when its argument is an integer and otherwise returns a real number, and the last four functions always return a real number. <code>atan2</code> returns as a float in radians, the arctangent of (first_arg / second_arg).sin and cos take as arguments the angle in radians.</p> <pre><code>sp {\n   ...\n   --&gt;\n   (&lt;s&gt; ^abs-value (abs &lt;x&gt;)\n      ^sqrt (sqrt &lt;x&gt;)) }\n</code></pre> <p>min, max \u2014 These symbols provide n-ary mathematical functions (they each take a list of symbols as arguments). These symbols work similarly to C functions. They take either integer or real-number arguments, and return a real-number value if any of their arguments are real-numbers. Otherwise they return integers.</p> <pre><code>sp {\n   ...\n   --&gt;\n   (&lt;s&gt; ^max (max &lt;x&gt; 3.14 &lt;z&gt;)\n      ^min (min &lt;a&gt; &lt;b&gt; 42 &lt;c&gt;)) }\n</code></pre> <p>int \u2014 Converts a single symbol to an integer constant. This function expects either an integer constant, symbolic constant, or floating point constant. The symbolic constant must be a string which can be interpreted as a single integer. The floating point constant is truncated to only the integer portion. This function essentially operates as a type casting function. For example, the expression \\(2 + \\sqrt(6)\\) could be printed as an integer using the following:</p> <pre><code>sp {\n   ...\n   --&gt;\n   (write (+ 2 (int sqrt(6))) ) }\n</code></pre> <p>float \u2014 Converts a single symbol to a floating point constant. This function expects either an integer constant, symbolic constant, or floating point constant. The symbolic constant must be a string which can be interpreted as a single floating point number. This function essentially operates as a type casting function. For example, if you wanted to print out an integer expression as a floating-point num- ber, you could do the following:</p> <pre><code>sp {\n   ...\n   --&gt;\n   (write (float (+ 2 3))) }\n</code></pre> <p>ifeq \u2014 Conditionally return a symbol. This function takes four arguments. It returns the third argument if the first two are equal and the fourth argument otherwise. Note that symbols of different types will always be considered unequal. For example, 1.0 and 1 will be unequal because the first is a float and the second is an integer.</p> <pre><code>sp {example-rule\n   (state &lt;s&gt; ^a &lt;a&gt; ^b &lt;b&gt;)\n   ...\n   --&gt;\n   (write (ifeq &lt;a&gt; &lt;b&gt; equal not-equal)) }\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#generating-and-manipulating-symbols","title":"Generating and manipulating symbols","text":"<p>A new symbol (an identifier) is generated on the right-hand side of a production whenever a previously unbound variable is used. This section describes other ways of generating and manipulating symbols on the right-hand side.</p> <p>capitalize-symbol \u2014 Given a symbol, this function returns a new symbol with the first character capitalized. This function is provided primarily for text output, for example, to allow the first word in a sentence to be capitalized.</p> <pre><code>(capitalize-symbol foo)\n</code></pre> <p>compute-heading \u2014 This function takes four real-valued arguments of the form \\((x_1, y_1, x_2, y_2)\\), and returns the direction (in degrees) from \\((x_1, y_1)\\) to \\((x_2, y_2)\\), rounded to the nearest integer.</p> <p>For example:</p> <pre><code>sp {\n   ...\n   --&gt;\n   (&lt;s&gt; ^heading (compute-heading 0 0.5 32.5 28)) }\n</code></pre> <p>After this rule fires, working memory would look like:</p> <pre><code>(S1 ^heading 48).\n</code></pre> <p>compute-range \u2014 This function takes four real-valued arguments of the form \\((x_1, y_1, x_2, y_2)\\), and returns the distance from \\((x_1, y_1)\\) to \\((x_2, y_2)\\), rounded to the nearest integer.</p> <p>For example:</p> <pre><code>sp {\n   ...\n   --&gt;\n   (&lt;s&gt; ^distance (compute-range 0 0.5 32.5 28)) }\n</code></pre> <p>After this rule fires, working memory would look like:</p> <pre><code>(S1 ^distance 42).\n</code></pre> <p>concat \u2014 Given an arbitrary number of symbols, this function concatenates them to- gether into a single constant symbol. For example:</p> <pre><code>sp {example\n   (state &lt;s&gt; ^type state)\n   --&gt;\n   (&lt;s&gt; ^name (concat foo bar (+ 2 4))) }\n</code></pre> <p>After this rule fires, the WME <code>(S1 ^name foobar6)</code> will be added.</p> <p>deep-copy \u2014 This function returns a copy of the given symbol along with linked copies of all descendant symbols. In other terms, a full copy is made of the working mem- ory subgraph that can be reached when starting from the given symbol. All copied identifiers are created as new IDs, and all copied values remain the same. For example:</p> <pre><code>sp {\n   (state &lt;s&gt; ^tree &lt;t&gt;)\n   (&lt;t&gt; ^branch1 foo ^branch2 &lt;b&gt;)\n   (&lt;b&gt; ^branch3 &lt;t&gt;)\n   --&gt;\n   (&lt;s&gt; ^tree-copy (deep-copy &lt;t&gt;)) }\n</code></pre> <pre><code>After this rule fires, the following structure would exist:\n</code></pre> <pre><code>(S1 ^tree T1 ^tree-copy D1)\n   (T1 ^branch1 foo ^branch2 B1)\n      (B1 ^branch3 T1)\n(D1 ^branch1 foo ^branch2 B2)\n   (B2 ^branch3 D1)\n</code></pre> <p>dc \u2014 This function takes no arguments, and returns the integer number of the current decision cycle. For example:</p> <pre><code>sp {example\n   (state &lt;s&gt; ^type state)\n   --&gt;\n   (&lt;s&gt; ^dc-count (dc) }\n</code></pre> <p>@ (get) \u2014 This function returns the LTI number of the given ID. If the given ID is not linked to an LTI, it does nothing. For example:</p> <pre><code>sp {example\n   (state &lt;s&gt; ^stm &lt;l1&gt;)\n   --&gt;\n   (&lt;s&gt; ^lti-num (@ &lt;l1&gt;) }\n</code></pre> <pre><code>After this rule fires, the(S1 ^lti-num)WME will have an integer value such as 42.\n</code></pre> <p>link-stm-to-ltm \u2014 This function takes two arguments. It links the first given symbol to the LTI indicated by the second integer value.</p> <p>For example:</p> <pre><code>sp {example\n   (state &lt;s&gt; ^stm &lt;l1&gt;)\n   --&gt;\n   (link-stm-to-ltm &lt;l1&gt; 42) }\n</code></pre> <p>After this rule fires, the WME <code>(S1 ^stm &lt;l1&gt;)</code> will be linked to <code>@42</code>.</p> <p>make-constant-symbol \u2014 This function returns a new constant symbol guaranteed to be different from all symbols currently present in the system. With no arguments, it returns a symbol whose name starts with <code>\"constant\"</code>. With one or more arguments, it takes those argument symbols, concatenates them, and uses that as the prefix for the new symbol. (It may also append a number to the resulting symbol, if a symbol with that prefix as its name already exists.)</p> <pre><code>sp {\n   ...\n   --&gt;\n   (&lt;s&gt; ^new-symbol (make-constant-symbol)) }\n</code></pre> <p>When this production fires, it will create an augmentation in working memory such as:</p> <pre><code>(S1 ^new-symbol constant5)\n</code></pre> <p>The production:</p> <pre><code>sp {\n   ...\n   --&gt;\n   (&lt;s&gt; ^new-symbol (make-constant-symbol &lt;s&gt; )) }\n</code></pre> <p>will create an augmentation in working memory such as:</p> <pre><code>(S1 ^new-symbol |S14|)\n</code></pre> <p>when it fires. The vertical bars denote that the symbol is a constant, rather than an identifier; in this example, the number 4 has been appended to the symbol S1. This can be particularly useful when used in conjunction with the <code>timestamp</code> function; by using <code>timestamp</code> as an argument to <code>make-constant-symbol</code>, you can get a new symbol that is guaranteed to be unique. For example:</p> <pre><code>sp {\n   ...\n   --&gt;\n   (&lt;s&gt; ^new-symbol (make-constant-symbol (timestamp))) }\n</code></pre> <p>When this production fires, it will create an augmentation in working memory such as:</p> <pre><code>(S1 ^new-symbol 8/1/96-15:22:49)\n</code></pre> <p>rand-float \u2014 This function takes an optional positive real-valued argument. If no argument (or a negative argument) is given, it returns a random real-valued number in the range \\([0. 0 , 1 .0]\\). Otherwise, given a value n, it returns a number in the range \\([0. 0 ,n]\\).</p> <p>For example:</p> <pre><code>sp {\n   ...\n   --&gt;\n   (&lt;s&gt; ^fate (rand-float 1000)) }\n</code></pre> <p>After this rule fires, working memory might look like: <code>(S1 ^fate 275.481802)</code>.</p> <p>rand-int \u2014 This function takes an optional positive integer argument. If no argument (or a negative argument) is given, it returns a random integer number in the range \\([-2^{31} , 2^{31}]\\). Otherwise, given a value n, it returns a number in the range \\([0,n]\\). For example:</p> <pre><code>sp {\n   ...\n   --&gt;\n   (&lt;s&gt; ^fate (rand-int 1000)) }\n</code></pre> <p>After this rule fires, working memory might look like: <code>(S1 ^fate 13)</code>.</p> <p>round-off \u2014 This function returns the first given value rounded to the nearest multiple of the second given value. Values must be integers or real-numbers.</p> <p>For example:</p> <pre><code>sp {\n   (state &lt;s&gt; ^pi &lt;pi&gt;\n   --&gt;\n   (&lt;s&gt; ^pie (round-off &lt;pi&gt; 0.1)) }\n</code></pre> <p>After this rule fires, working memory might look like: <code>(S1 ^pi 3.14159 ^pie 3.1)</code>.</p> <p>round-off-heading \u2014 This function is the same as round-off, but additionally shifts the returned value by multiples of 360 such that \\(-360 \\le value \\le 360\\). For example:</p> <pre><code>sp {\n   (state &lt;s&gt; ^heading &lt;dir&gt;\n   --&gt;\n   (&lt;s&gt; ^true-heading (round-off-heading &lt;dir&gt; 0.5)) }\n</code></pre> <p>After this rule fires, working memory might look like: <code>(S1 ^heading 526.432 ^true-heading 166.5)</code>.</p> <p>size \u2014 This function returns an integer symbol whose value is the count of WME aug- mentations on a given ID argument. Providing a non-ID argument results in an error. For example:</p> <pre><code>sp {\n   (state &lt;s&gt; ^numbers &lt;n&gt;)\n   (&lt;n&gt; ^1 1 ^10 10 ^100 100)\n   --&gt;\n   (&lt;s&gt; ^augs (size &lt;n&gt;)) }\n</code></pre> <p>After this rule fires, the value of <code>S1 ^augs</code> would be 3. Note that some architecturally-maintained IDs such as <code>(&lt;s&gt; ^epmem)</code> and <code>(&lt;s&gt; ^io)</code> are not counted by the <code>size</code> function.</p> <p>strlen \u2014 This function returns an integer symbol whose value is the size of the given string symbol. For example:</p> <pre><code>sp {\n   (state &lt;s&gt; ^io.input-link.message &lt;m&gt;)\n   ...\n   --&gt;\n   (&lt;s&gt; ^message-len (strlen &lt;m&gt;)) }\n</code></pre> <p>timestamp \u2014 This function returns a symbol whose print name is a representation of the current date and time. For example:</p> <pre><code>sp {\n   ...\n   --&gt;\n   (write (timestamp)) }\n</code></pre> <p>When this production fires, it will print out a representation of the current date and time, such as:</p> <pre><code>soar&gt; run 1 e\n2018-09-26 14:36:39.375\n</code></pre> <p>trim \u2014 This function takes a single string symbol argument and returns the same string with leading and trailing whitespace removed. For example:</p> <pre><code>sp {\n   (state &lt;s&gt; ^message &lt;m&gt;)\n   --&gt;\n   (&lt;s&gt; ^trimmed (trim &lt;m&gt;)) }\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#user-defined-functions-and-interface-commands-as-rhs-actions","title":"User-defined functions and interface commands as RHS actions","text":"<p>Any function with a certain signature may be registered with the Kernel (e.g. using SML) and called as an RHS function. RHS functions receive a single string argument and return a single string which is assigned to a symbol in Soar.</p> <p>RHS functions are most complex in C/C++ due to the requirements of memory management. An RHS function must adhere to the signature of <code>RHSEventHandler</code>:</p> <pre><code>char const _(smlRhsEventId id, void_ pUserData, Agent* pAgent,\nchar const* pFunctionName, char const* pArgument,\nint *buffSize, char *buff)\n</code></pre> <p>The function must fill <code>*buff</code> with the string to be returned and then return <code>*buff</code>, but only if <code>*buffSize</code> indicates there is enough room to hold the string. If <code>*buffSize</code> is not large enough, the function must return <code>NULL</code> and set <code>*buffSize</code> to the required size. Soar will then allocate a buffer of the required size and call the function again. If calling the function twice would have an undesirable effect, the following code can be used to cache the result in between calls by Soar:</p> <pre><code>// at beginning of function:\nstatic std::string prevResult;\nif ( !prevResult.empty() )\n{\nstrncpy( buf, prevResult.c_str(), *bufSize );\nprevResult = \"\";\nreturn buf;\n}\n// ...\n// at end of function:\nif ( resultString.length() + 1 &gt; *bufSize )\n{\n*bufSize = resultString.length() + 1;\nprevResult = resultString;\nreturn NULL;\n}\nstrcpy( buf, resultString.c_str() );\nreturn buf;\n</code></pre> <p>RHS function interfaces in other languages are much simpler. For example, in Java the signature is:</p> <pre><code>String rhsFunctionHandler(int eventID, Object data, String agentName,\nString functionName, String argument)\n}\n</code></pre> <p>Any arguments passed to the function on the RHS of a production are concatenated (without spaces) and passed to the function in the pArgument argument.</p> <p>Such a function can be registered with the kernel via the client interface by calling:</p> <pre><code>Kernel::AddRhsFunction(char const* pRhsFunctionName, RhsEventHandler handler, void* pUserData);\n</code></pre> <pre><code>Kernel.AddRhsFunction(String functionName, RhsFunctionInterface handlerObject, Object callbackData);\n</code></pre> <p>The <code>exec</code> and <code>cmd</code> functions are used to call user-defined functions and interface commands on the RHS of a production.</p> <p>exec \u2014 Used to call user-defined registered functions. Any arguments are concatenated without spaces. For example, if <code>&lt;o&gt;</code> is bound to <code>x</code>, then</p> <pre><code>sp {\n   ...\n   --&gt;\n   (exec MakeANote &lt;o&gt; 1) }\n</code></pre> <p>will call the user-defined <code>MakeANote</code> function with the argument \"x1\". The return value of the function, if any, may be placed in working memory or passed to another RHS function. For example, the log of a number <code>&lt;x&gt;</code> could be printed this way:</p> <pre><code>sp {\n   ...\n   --&gt;\n   (write |The log of | &lt;x&gt; | is: | (exec log(&lt;x&gt;))|) }\n</code></pre> <p>where \"log\" is a registered user-defined function.</p> <p>cmd \u2014 Used to call built-in Soar commands. Spaces are inserted between concatenated arguments. For example, the production</p> <pre><code>sp {\n   ...\n   --&gt;\n   (write (cmd print --depth 2 &lt;s&gt;)) }\n</code></pre> <p>will have the effect of printing the object bound to <code>&lt;s&gt;</code> to depth 2.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#controlling-chunking","title":"Controlling chunking","text":"<p>Chunking is described in Chapter 4.</p> <p>The following two functions are provided as RHS actions to assist in development of Soar programs; they are not intended to correspond to any theory of learning in Soar. This functionality is provided as a development tool, so that learning may be turned off in specific problem spaces, preventing otherwise buggy behavior.</p> <p>The <code>dont-learn</code> and <code>force-learn</code> RHS actions are to be used with specific settings for the <code>chunk</code> command. Using the <code>chunk</code> command, learning may be set to one of <code>always</code>, <code>never</code>, <code>flagged</code>, or <code>unflagged</code>; chunking must be set to <code>flagged</code> for the <code>force-learn</code> RHS action to have any effect and chunking must be set to <code>unflagged</code> for the <code>dont-learn</code> RHS action to have any effect.</p> <p>dont-learn \u2014 When chunking is set to <code>unflagged</code>, by default chunks can be formed in all states; the <code>dont-learn</code> RHS action will cause chunking to be turned off for the specified state.</p> <pre><code>sp {turn-learning-off\n   (state &lt;s&gt; ^feature 1 ^feature 2 -^feature 3)\n   --&gt;\n   (dont-learn &lt;s&gt;) }\n</code></pre> <p>The <code>dont-learn</code> RHS action applies when <code>chunk</code> is set to <code>unflagged</code>, and has no effect when other settings for <code>chunk</code> are used.</p> <p>force-learn \u2014 When learning is set to <code>flagged</code>, by default chunks are not formed in any state; the <code>force-learn</code> RHS action will cause chunking to be turned on for the specified state.</p> <pre><code>sp {turn-learning-on\n   (state &lt;s&gt; ^feature 1 ^feature 2 -^feature 3)\n   --&gt;\n   (force-learn &lt;s&gt;) }\n</code></pre> <p>The <code>force-learn</code> RHS action applies when <code>chunk</code> is set to flagged, and has no effect when other settings for <code>chunk</code> are used.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#grammars-for-production-syntax","title":"Grammars for production syntax","text":"<p>This subsection contains the BNF grammars for the conditions and actions of productions. (BNF stands for Backus-Naur form or Backus normal form; consult a computer science book on theory, programming languages, or compilers for more information. However, if you don\u2019t already know what a BNF grammar is, it\u2019s unlikely that you have any need for this subsection.)</p> <p>This information is provided for advanced Soar users, for example, those who need to write their own parsers. Note that some terms (e.g.<code>&lt;symconstant&gt;</code>) are undefined; as such, this grammar should only be used as a starting point.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#grammar-of-soar-productions","title":"Grammar of Soar productions","text":"<p>A grammar for Soar productions is:</p> <pre><code>&lt;soar-production&gt;  ::= sp \"{\" &lt;production-name&gt; [&lt;documentation&gt;] [&lt;flags&gt;]\n&lt;condition-side&gt; --&gt; &lt;action-side&gt; \"}\"\n&lt;documentation&gt;    ::= \"\"\" [&lt;string&gt;] \"\"\"\n&lt;flags&gt;            ::= \":\" (o-support | i-support | chunk | default)\n</code></pre> <p>Grammar for Condition Side: Below is a grammar for the condition sides of productions:</p> <pre><code>&lt;condition-side&gt;   ::= &lt;state-imp-cond&gt; &lt;cond&gt;*\n&lt;state-imp-cond&gt;   ::= \"(\" (state | impasse) [&lt;id_test&gt;]\n&lt;attr_value_tests&gt;+ \")\"\n&lt;cond&gt;             ::= &lt;positive_cond&gt; | \"-\" &lt;positive_cond&gt;\n&lt;positive_cond&gt;    ::= &lt;conds_for_one_id&gt; | \"{\" &lt;cond&gt;+ \"}\"\n&lt;conds_for_one_id&gt; ::= \"(\" [(state|impasse)] &lt;id_test&gt;\n&lt;attr_value_tests&gt;+ \")\"\n&lt;id_test&gt;          ::= &lt;test&gt;\n&lt;attr_value_tests&gt; ::= [\"-\"] \"^\" &lt;attr_test&gt; (\".\" &lt;attr_test&gt;)*\n&lt;value_test&gt;*\n&lt;attr_test&gt;        ::= &lt;test&gt;\n&lt;value_test&gt;       ::= &lt;test&gt; [\"+\"] | &lt;conds_for_one_id&gt; [\"+\"]\n\n&lt;test&gt;             ::= &lt;conjunctive_test&gt; | &lt;simple_test&gt;\n&lt;conjunctive_test&gt; ::= \"{\" &lt;simple_test&gt;+ \"}\"\n&lt;simple_test&gt;      ::= &lt;disjunction_test&gt; | &lt;relational_test&gt;\n&lt;disjunction_test&gt; ::= \"&lt;&lt;\" &lt;constant&gt;+ \"&gt;&gt;\"\n&lt;relational_test&gt;  ::= [&lt;relation&gt;] &lt;single_test&gt;\n&lt;relation&gt;         ::= \"&lt;&gt;\" | \"&lt;\" | \"&gt;\" | \"&lt;=\" | \"&gt;=\" | \"=\" | \"&lt;=&gt;\"\n&lt;single_test&gt;      ::= &lt;variable&gt; | &lt;constant&gt;\n&lt;variable&gt;         ::= \"&lt;\" &lt;sym_constant&gt; \"&gt;\"\n&lt;constant&gt;         ::= &lt;sym_constant&gt; | &lt;int_constant&gt; | &lt;float_constant&gt;\n</code></pre> <p>Notes on the Condition Side</p> <ul> <li>In an <code>&lt;idtest&gt;</code>, only a <code>&lt;variable&gt;</code> may be used in a <code>&lt;singletest&gt;</code>.</li> </ul> <p>Grammar for Action Side: Below is a grammar for the action sides of productions:</p> <pre><code>&lt;rhs&gt;                      ::= &lt;rhs_action&gt;*\n&lt;rhs_action&gt;               ::= \"(\" &lt;variable&gt; &lt;attr_value_make&gt;+ \")\"\n| &lt;func_call&gt;\n&lt;func_call&gt;                ::= \"(\" &lt;func_name&gt; &lt;rhs_value&gt;* \")\"\n&lt;func_name&gt;                ::= &lt;sym_constant&gt; | \"+\" | \"-\" | \"*\" | \"/\"\n&lt;rhs_value&gt;                ::= &lt;constant&gt; | &lt;func_call&gt; | &lt;variable&gt;\n&lt;attr_value_make&gt;          ::= \"^\" &lt;variable_or_sym_constant&gt;\n(\".\" &lt;variable_or_sym_constant&gt;)* &lt;value_make&gt;+\n&lt;variable_or_sym_constant&gt; ::= &lt;variable&gt; | &lt;sym_constant&gt;\n&lt;value_make&gt;               ::= &lt;rhs_value&gt; &lt;preference_specifier&gt;*\n\n&lt;preference-specifier&gt;     ::= &lt;unary-preference&gt; [\",\"]\n| &lt;unary-or-binary-preference&gt; [\",\"]\n| &lt;unary-or-binary-preference&gt; &lt;rhs_value&gt; [\",\"]\n&lt;unary-pref&gt;               ::= \"+\" | \"-\" | \"!\" | \"~\"\n&lt;unary-or-binary-pref&gt;     ::= \"&gt;\" | \"=\" | \"&lt;\"\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#impasses-in-working-memory-and-in-productions","title":"Impasses in Working Memory and in Productions","text":"<p>When the preferences in preference memory cannot be resolved unambiguously, Soar reaches an impasse, as described in Section the Soar architecture:</p> <ul> <li>When Soar is unable to select a new operator (in the decision cycle), it is said   to reach an operator impasse.</li> </ul> <p>All impasses lead to the creation of a new substate in working memory, and appear as objects within that substate. These objects can be tested by productions. This section describes the structure of state objects in working memory.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#impasses-in-working-memory","title":"Impasses in working memory","text":"<p>There are four types of impasses.</p> <p>Below is a short description of the four types of impasses. (This was described in more detail in Section impasses and substates)</p> <ol> <li>tie: when there is a collection of equally eligible operators competing for the value of    a particular attribute;</li> <li>conflict: when two or more objects are better than each other, and they are not    dominated by a third operator;</li> <li>constraint-failure: when there are conflicting necessity preferences;</li> <li>no-change: when the proposal phase runs to quiescence without suggesting a new    operator.</li> </ol> <p>The list below gives the seven augmentations that the architecture creates on the substate generated when an impasse is reached, and the values that each augmentation can contain:</p> <ul> <li><code>^type state</code></li> <li> <p><code>^impasse</code> Contains the impasse type: <code>tie</code>, <code>conflict</code>, <code>constraint-failure</code>, or <code>no-change</code>.</p> </li> <li> <p><code>^choices</code> Either <code>multiple</code> (for tie and conflict impasses), <code>constraint-failure</code>   (for constraint-failure impasses), or <code>none</code> (for constraint-failure or   no-change impasses).</p> </li> <li> <p><code>^superstate</code> Contains the identifier of the state in which the impasse arose.</p> </li> <li> <p><code>^attribute</code> For multi-choice and constraint-failure impasses, this contains   <code>operator</code>. For no-change impasses, this contains the attribute of the last decision   with a value (<code>state</code> or <code>operator</code>).</p> </li> <li> <p><code>^item</code> For multi-choice and constraint-failure impasses, this contains all   values involved in the tie, conflict, or constraint-failure. If the set of items   that tie or conflict changes during the impasse, the architecture removes or   adds the appropriate item augmentations without terminating the existing   impasse.</p> </li> <li> <p><code>^item-count</code> For multi-choice and constraint-failure impasses, this contains   the number of values listed under the item augmentation above.</p> </li> <li> <p><code>^non-numeric</code> For tie impasses, this contains all operators that do not have   numeric indifferent preferences associated with them. If the set of items that   tie changes during the impasse, the architecture removes or adds the appropriate   non-numeric augmentations without terminating the existing impasse.</p> </li> <li> <p><code>^non-numeric-count</code> For tie impasses, this contains the number of operators   listed under the non-numeric augmentation above.</p> </li> <li> <p><code>^quiescence</code> States are the only objects with <code>quiescence t</code>, which is an   explicit statement that quiescence (exhaustion of the elaboration cycle) was   reached in the superstate. If problem solving in the subgoal is contingent on   quiescence having been reached, the substate should test this flag. The   side-effect is that no chunk will be built if it depended on that test. See   Problem Solving that does not test Superstate for details. This attribute can be ignored when learning is turned off.</p> </li> </ul> <p>Knowing the names of these architecturally defined attributes and their possible values will help you to write productions that test for the presence of specific types of impasses so that you can attempt to resolve the impasse in a manner appropriate to your program. Many of the default productions in the demos/defaults directory of the Soar distribution provide means for resolving certain types of impasses. You may wish to make use of some of all of these productions or merely use them as guides for writing your own set of productions to respond to impasses.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#examples","title":"Examples","text":"<p>The following is an example of a substate that is created for a tie among three operators:</p> <pre><code>(S12 ^type state ^impasse tie ^choices multiple ^attribute operator\n   ^superstate S3 ^item O9 O10 O11 ^quiescence t)\n</code></pre> <p>The following is an example of a substate that is created for a no-change impasse to apply an operator:</p> <pre><code>(S12 ^type state ^impasse no-change ^choices none ^attribute operator\n   ^superstate S3 ^quiescence t)\n(S3 ^operator O2)\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#testing-for-impasses-in-productions","title":"Testing for impasses in productions","text":"<p>Since states appear in working memory, they may also be tested for in the conditions of productions.</p> <p>For example, the following production tests for a constraint-failure impasse on the top-level state.</p> <pre><code>sp {default*top-goal*halt*operator*failure\n   \"Halt if no operator can be selected for the top goal.\"\n   :default\n   (state &lt;ss&gt; ^impasse constraint-failure ^superstate &lt;s&gt;)\n   (&lt;s&gt; ^superstate nil)\n   --&gt;\n   (write (crlf) |No operator can be selected for top goal.| )\n   (write (crlf) |Soar will halt now. Goodnight.| )\n   (halt)\n   }\n</code></pre>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#soar-io-input-and-output-in-soar","title":"Soar I/O: Input and Output in Soar","text":"<p>Many Soar users will want their programs to interact with a real or simulated environment. For example, Soar programs could control a robot, receiving sensory inputs and sending command outputs. Soar programs might also interact with simulated environments, such as a flight simulator. The mechanisms by which Soar receives inputs and sends outputs to an external process is called Soar I/O.</p> <p>This section describes how input and output are represented in working memory and in productions. Interfacing with a Soar agent through input and output can be done using the Soar Markup Language (SML). The details of designing an external process that uses SML to create the input and respond to output from Soar are beyond the scope of this manual, but they are described online on the Soar website. This section is provided for the sake of Soar users who will be making use of a program that has already been implemented, or for those who would simply like to understand how I/O works in Soar.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#overview-of-soar-io","title":"Overview of Soar I/O","text":"<p>When Soar interacts with an external environment, it must make use of mechanisms that allow it to receive input from that environment and to effect changes in that environment. An external environment may be the real world or a simulation; input is usually viewed as Soar\u2019s perception and output is viewed as Soar\u2019s motor abilities.</p> <p>Soar I/O is accomplished via input functions and output functions. Input functions are called at the start of every execution cycle, and add elements directly to specific input structures in working memory. These changes to working memory may change the set of productions that will fire or retract. Output functions are called at the end of every execution cycle and are processed in response to changes to specific output structures in working memory. An output function is called only if changes have been made to the output-link structures in working memory.</p> <p>The structures for manipulating input and output in Soar are linked to a predefined attribute of the top-level state, called the io attribute. The io attribute has substructure to represent sensor inputs from the environment called input links; because these are represented in working memory, Soar productions can match against input links to respond to an external situation. Likewise, the io attribute has substructure to represent motor commands, called output links. Functions that execute motor commands in the environment use the values on the output links to determine when and how they should execute an action. Generally, input functions create and remove elements on the input link to update Soar\u2019s perception of the environment. Output functions respond to values of working memory elements that appear on Soar\u2019s output link structure.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#input-and-output-in-working-memory","title":"Input and output in working memory","text":"<p>All input and output is represented in working memory as substructure of the io attribute of the top-level state. By default, the architecture creates an <code>input-link</code> attribute of the io object and an <code>output-link</code> attribute of the io object. The values of the <code>input-link</code> and <code>output-link</code> attributes are identifiers whose augmentations are the complete set of input and output working memory elements, respectively. Some Soar systems may benefit from having multiple input and output links, or that use names which are more descriptive of the input or output function, such as <code>vision-input-link</code>, <code>text-input-link</code>, or <code>motor-output-link</code>. In addition to providing the default io substructure, the architecture allows users to create multiple input and output links via productions and I/O functions. Any identifiers for io substructure created by the user will be assigned at run time and are not guaranteed to be the same from run to run. Therefore users should always employ variables when referring to input and output links in productions.</p> <p>Suppose a blocks-world task is implemented using a robot to move actual blocks around, with a camera creating input to Soar and a robotic arm executing command outputs.</p> <p>The camera image might be analyzed by a separate vision program; this program could have as its output the locations of blocks on an xy plane. The Soar input function could take the output from the vision program and create the following working memory elements on the input link (all identifiers are assigned at runtime; this is just an example of possible bindings):</p> <pre><code>(S1 ^io I1)          [A]\n(I1 ^input-link I2)  [A]\n(I2 ^block B1)\n(I2 ^block B2)\n(I2 ^block B3)\n(B1 ^x-location 1)\n(B1 ^y-location 0)\n(B1 ^color red)\n(B2 ^x-location 2)\n(B2 ^y-location 0)\n(B2 ^color blue)\n(B3 ^x-location 3)\n(B3 ^y-location 0)\n(B3 ^color yellow)\n</code></pre> An example portion of the input link for the blocks-world task. <p>The \u2019[A]\u2019 notation in the example is used to indicate the working memory elements that are created by the architecture and not by the input function. This configuration of blocks corresponds to all blocks on the table, as illustrated in the initial state in Figure 2.2.</p> <p>Then, during the Apply Phase of the execution cycle, Soar productions could respond to an operator, such as \"move the red block ontop of the blue block\" by creating a structure on the output link, such as:</p> <pre><code>(S1 ^io I1)          [A]\n(I1 ^output-link I3) [A]\n(I3 ^name move-block)\n(I3 ^moving-block B1)\n(I3 ^x-destination 2)\n(I3 ^y-destination 1)\n(B1 ^x-location 1)\n(B1 ^y-location 0)\n(B1 ^color red)\n</code></pre> An example portion of the output link for the blocks-world task. <p>An output function would look for specific structure in this output link and translate this into the format required by the external program that controls the robotic arm. Movement by the robotic arm would lead to changes in the vision system, which would later be reported on the input-link.</p> <p>Input and output are viewed from Soar\u2019s perspective. An input function adds or deletes augmentations of the <code>input-link</code> providing Soar with information about some occurrence external to Soar. An output function responds to substructure of the <code>output-link</code> produced by production firings, and causes some occurrence external to Soar. Input and output occur through the io attribute of the top-level state exclusively.</p> <p>Structures placed on the input-link by an input function remain there until removed by an input function. During this time, the structure continues to provide support for any production that has matched against it. The structure does not cause the production to rematch and fire again on each cycle as long as it remains in working memory; to get the production to refire, the structure must be removed and added again.</p>"},{"location":"soar_manual/03_SyntaxOfSoarPrograms/#input-and-output-in-production-memory","title":"Input and output in production memory","text":"<p>Productions involved in input will test for specific attributes and values on the input-link, while productions involved in output will create preferences for specific attributes and values on the output link. For example, a simplified production that responds to the vision input for the blocks task might look like this:</p> <pre><code>sp {blocks-world*elaborate*input\n   (state &lt;s&gt; ^io.input-link &lt;in&gt;)\n   (&lt;in&gt; ^block &lt;ib1&gt;)\n   (&lt;ib1&gt; ^x-location &lt;x1&gt; ^y-location &lt;y1&gt;)\n   (&lt;in&gt; ^block {&lt;ib2&gt; &lt;&gt; &lt;ib1&gt;})\n   (&lt;ib2&gt; ^x-location &lt;x1&gt; ^y-location {&lt;y2&gt; &gt; &lt;y1&gt;})\n   --&gt;\n   (&lt;s&gt; ^block &lt;b1&gt;)\n   (&lt;s&gt; ^block &lt;b2&gt;)\n   (&lt;b1&gt; ^x-location &lt;x1&gt; ^y-location &lt;y1&gt; ^clear no)\n   (&lt;b2&gt; ^x-location &lt;x1&gt; ^y-location &lt;y2&gt; ^above &lt;b1&gt;)\n}\n</code></pre> <p>This production \"copies\" two blocks and their locations directly to the top-level state. It also adds information about the relationship between the two blocks. The variables used for the blocks on the RHS of the production are deliberately different from the variable name used for the block on the input-link in the LHS of the production. If the variable were the same, the production would create a link into the structure of the input-link, rather than copy the information. The attributes <code>x-location</code> and <code>y-location</code> are assumed to be values and not identifiers, so the same variable names may be used to do the copying.</p> <p>A production that creates WMEs on the output-link for the blocks task might look like this:</p> <pre><code>sp {blocks-world*apply*move-block*send-output-command\n   (state &lt;s&gt; ^operator &lt;o&gt; ^io.output-link &lt;out&gt;)\n   (&lt;o&gt; ^name move-block ^moving-block &lt;b1&gt; ^destination &lt;b2&gt;)\n   (&lt;b1&gt; ^x-location &lt;x1&gt; ^y-location &lt;y1&gt;)\n   (&lt;b2&gt; ^x-location &lt;x2&gt; ^y-location &lt;y2&gt;)\n   --&gt;\n   (&lt;out&gt; ^move-block &lt;b1&gt;\n      ^x-destination &lt;x2&gt; ^y-destination (+ &lt;y2&gt; 1))\n   }\n</code></pre> <p>This production would create substructure on the output-link that the output function could interpret as being a command to move the block to a new location.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/","title":"Procedural Knowledge Learning","text":""},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#chunking","title":"Chunking","text":"<p>Chunking is Soar\u2019s experience-based mechanism for learning new procedural knowledge.  Chunking utilizes Soar\u2019s impasse-driven model of problem decomposition into sub-goals to create new productions dynamically during task execution. These new productions, called chunks, summarize the substate problem-solving that occurred which led to new knowledge in a superstate. Whenever a rule fires and creates such new superstate knowledge, which are called results, Soar learns a new rule and immediately adds it to production memory.  In future similar situations, the new chunk will fire and create the appropriate results in a single step, which eliminates the need to spawn another subgoal to perform similar problem- solving. In other words, rather than contemplating and figuring out what to do, the agent immediately knows what to do.</p> <p>Chunking can effect both speed-up and transfer learning. A chunk can effect speed-up learning because it compresses all of the problem-solving needed to produce a result into a single step. For some real-world agents, hundreds of rule firings can be compressed into a single rule firing. A chunk can effect transfer learning because it generalizes the problem-solving in such a way that it can apply to other situations that are similar but have not yet been experienced by the agent.</p> <p>Chunks are created whenever one subgoal creates a result in a superstate; since most Soar programs are continuously sub-goaling and returning results to higher-level states, chunks are typically created continuously as Soar runs. Note that Soar builds the chunk as soon as the result is created, rather than waiting until the impasse is resolved.</p> <p>While chunking is a core capability of Soar, procedural learning is disabled by default. See section usage for more information about enabling and using chunking.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#explanation-based-chunking","title":"Explanation-based Chunking","text":"<p>Explanation-based chunking improves on previous versions of chunking by learning rules that are qualitatively more general and expressive. In fact, any element of a learned rule can now be variablized, and learned rules now have the full expressive power of hand-written rules.</p> <p>Figure 4.1 shows an example of an explanation-based chunk and how it differs from a chunk learned from the original algorithm. It is interesting to note that in Soar 9.4, the arithmetic agent learns 1263 rules like the one on the left-side of the figure. In Soar 9.6, the same agent only learns 8 rules like the one on the right because they are so much more general.</p> A Soar 9.4.0 chunk (left) vs. an explanation-based chunk (right) in the arithmetic demo agent <p>To achieve this generality, chunking needs information about why rules matched in a sub-state and how those rules interacted. This allows it to determine what is generalizable and what limits there are on those generalizations. Unfortunately, the information necessary to determine this information was not readily available in prior versions of Soar which only recorded a trace of all WMEs that were tested in the substate. This trace, which we call the working memory trace possesses limited explanatory information, which limited chunking to learning very specific rules in which only Soar identifiers were variablized and all other elements tested the exact values found in the working memory trace.</p> <p>To remedy this limitation and produce more general chunks, EBC instead analyzes two traces simultaneously: the working memory trace and a corresponding trace of the hand-written rules that matched in the substate. This new network of rule matches is called the explanation trace:</p> A close-up of a trace showing differences between a working memory trace (left) and an explanation trace (right). The working memory trace only contains the literal values of the WMEs that matched. The explanation trace, on the other hand, contains variables and various constraints on the values those variables can hold. <p>Note that this trace is generated dynamically as rules match. Whenever a rule matches during agent execution, Soar creates an internal record of the rule that fired, which is called a rule instantiation. (Each box in the explanation traces of this chapter represents an instantiation that was created during task execution within a particular substate.) The instantiation contains both instance information about what matched (the working memory elements) and explanatory information about why they matched (the rules and actions in the original rules that contains variables, constraint tests, RHS actions, etc.).</p> <p>Note that WMEs that were automatically created by the architecture have special instantiations that explain why they were created. For example, an architectural instantiation is created for each <code>^item</code> attribute automatically created in operator tie impasse substates; the explanation causes the <code>^item</code> augmentation to be dependent on the operator in the super-state that led to it, which means that chunks learned which tested that <code>^item</code> augmentation will cause the chunk to also be dependent on the operator in the superstate.</p> <p>Similarly, architectural instantiations are created for structures recalled by semantic and episodic memory in the substate.</p> <p>All of the instantiations that were created in a substate form the instantiation graph of that substate. As chunking backtraces through the instantiation graph, it determines the subset of instantiations that contributed to a result. This set of instantiations and the connections between them composes the explanation trace for a learning episode. (So, the explanation trace is a subgraph of the instantiation graph.)</p> A visualization of the explanation trace of a chunk learned by the arithmetic agent. Each box represents a rule that fired in the substate. Arrows show dependencies between rules that create working memory elements and conditions that test those working memory elements. <p>EBC uses the explanation trace to determine (1) how variables were used during a problem-solving episode and (2) what constraints on those variables had to be met in order for the substate rules to match. EBC then uses the results of this analysis to create more expressive and general rules, which can contain the full gamut of tests that hand-written rules can and can have any element variablized.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#overview-of-the-ebc-algorithm","title":"Overview of the EBC Algorithm","text":"<p>Basic concepts:</p> <ul> <li>Every condition and action in the explanation trace has three elements:<ul> <li>For conditions, the three elements refer to the symbol in the positive   equality test for the identifier, attribute and value of the condition. For   example, the last condition of rule 2 in Figure 4.4 has <code>&lt;s&gt;</code> as the   identifier element, number as the attribute element, and <code>&lt;y&gt;</code> as the value   element.</li> <li>For actions, the three elements refer to the identifier, attribute and   value of the WME being created.</li> </ul> </li> <li>\u0088An element is either a variable, like <code>&lt;s&gt;</code> or a literal constant, like <code>23</code>,   <code>3.3</code>, or <code>someString</code></li> </ul>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#identity","title":"Identity","text":"<p>Before we can discuss the algorithm, we must first define one of its central concepts: identity.</p> <ul> <li>\u0088An identity is the set of all variables in a trace that refer to the same underlying object.<ul> <li>So we can say that two variables are said to share an identity if they   both refer to the same underlying object.</li> </ul> </li> <li>The NULL identity is a special identity that indicates an element which cannot be generalized and must contain a specific value.<ul> <li>All elements in the original rule that reference specific constant values   are trivially assigned the NULL identity.</li> <li>A variable\u2019s identity can also be mapped to the NULL identity. When this hap-   pens, we say the identity has been literalized.</li> </ul> </li> </ul> <p>EBC traverses an explanation trace of the problem-solving that occurred in the substate to determine which variables in different rule instances refer to the same underlying object. There are two ways that an explanation trace can show a shared identity:</p> <ol> <li>Variables that have the same name and are in the same rule firing will share    an identity This is the trivial case. The basic semantics of rules implies that    the same variable in a rule references the same underlying object.</li> <li>If a RHS action of one rule creates a WME and a LHS condition of another    rules tests that same WME, then all variables in the condition and actions will    possess the same identity as their counterpart\u2019s corresponding element.  The    interaction between the two rules indicates a shared identity between their    corresponding variables.</li> </ol> An explanation trace of two simple rules that matched in a substate. <p>To get a better picture of what a shared identity is, consider the two simple rules and the explanation trace of how they matched in a substate as shown in Figure 4.4. The connection between rule 2 and rule 1 will unify the identities of <code>&lt;s&gt;</code> ,<code>&lt;x&gt;</code> an <code>&lt;y&gt;</code> in rule 1 with the identities of <code>&lt;s&gt;</code> ,<code>&lt;x&gt;</code> an <code>&lt;y2&gt;</code> in rule 2. So, the <code>&lt;x&gt;</code> in rule 2 shares the same identity as the <code>&lt;x&gt;</code> in rule 1. Similarly, the <code>&lt;y2&gt;</code> in rule 2 shares the same identity as <code>&lt;y&gt;</code> in rule 1. In contrast, the <code>&lt;y&gt;</code> in rule 2 does NOT share the same identity as the <code>&lt;y&gt;</code> in rule 1.</p> <p>It doesn\u2019t matter that the <code>&lt;y&gt;</code> in rule 1 uses the same variable name as the<code>&lt;y&gt;</code> in rule 2.  It also doesn\u2019t matter that both conditions with <code>&lt;y&gt;</code> happen to match the same working memory element, <code>(S1 ^number 3)</code>. In terms of sharing an identity, the only thing that matters is how the rules interact, namely whether there\u2019s a connection between elements in the condition of one rule and elements in the actions of another rule.</p> <p>All literal values, for example all of the attribute in Figure 4.4 (superstate, number, intermediate1, etc.) are considered members of the <code>NULL</code> identity.</p> <p>Variable identities can also be mapped to the NULL identity, which means that any elements in the final rule that share that identity will not be variablized. When this happens, we say that the identity has been literalized. There are two ways that a rule interaction can effect an identity literalization:</p> <ol> <li>If a RHS action of one rule creates a WME element using a constant, literal    value in an element and a LHS condition tests that element, then the identity of    the condition\u2019s variables is literalized and mapped to the NULL identity.    Because the variable in the condition matched a rule that will always create the    same constant, literal value, the condition\u2019s variable must have that same    value. Otherwise, it would not have matched.</li> <li>If a RHS action of one rule creates a WME element using a variable and a LHS    condition tests that that element is a specific value, then the identity of the    action\u2019s variables is literalized and mapped to the NULL identity.  Because the    condition requires that the rule that created the matched WME to have a specific    constant, literal value, the action\u2019s variable must have that same value.    Otherwise, it would not have created something that matched the condition.</li> </ol> <p>Identities are the basis of nearly every mechanism in explanation-based chunking. EBC\u2019s identity analysis algorithm, which is a fairly complicated process, determines all shared identities in an explanation trace. Figure 4.5 shows an explanation trace after identity analysis has been performed. Elements that share an identity in the figure are colored the same.</p> An explanation trace after identity analysis. <p>While it\u2019s not readable in this figure, note that each identity is assigned a numeric ID. Both the explainer and the visualizer annotate elements of an explanation with the identity ID in square brackets. These numbers are simply syntactic sugar to ease debugging and make traces easier to understand. Underneath the hood, every test in a condition has a pointer to more complicated identity data structure that will be discussed in more detail in Section  Identity Assignment and Propagation on the identity graph.</p> Note that the two rows on the bottom indicate when each component occurs during Soar\u2019s processing."},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#the-five-main-components-of-explanation-based-chunking","title":"The Five Main Components of Explanation-Based Chunking","text":"<ol> <li>Identity analysis    This component determines which variables in an explanation trace share the same    identity. It also determines which identities are ineligible for variablization because    they were tested against literal values in some rules.    Note that this component has two distinct mechanisms that occur at very different    times. The first mechanism, identity propagation, occurs constantly while problem-    solving in the substate. The second mechanism, identity graph manipulation, occurs    during the learning episode.</li> <li>Relevant operator selection knowledge tracking    This component also occurs before the learning episode. Whenever an operator is se-    lected, it analyzes what rule firings contributed necessary operator selection preferences    and caches them in all rule instances that tests that operator.</li> <li>Constraint tracking    This component keeps track of every value or relational constraint (e.g. <code>&lt;&gt;    &lt;x&gt;,&gt;= 3.14,&lt;&lt; disjunction of constants &gt;&gt;</code>) placed on the various variables    that share an identity. It is used by the rule formation component to make    sure that the learned rule only fires when all constraints required are met.</li> <li>Operationality analysis     This component determines which conditions in an    explanation trace tested working memory elements in a superstate. The rule    formation component will use these conditions as a basis for the left-hand side    of the chunk. While it does have a few key new differences, this is the one step    that is similar to previous versions of chunking.</li> <li>Rule Formation    The above four components performed the analysis that EBC needs to form a    general but correct rule. This final component uses the results of that    analysis to actually build the new rule. This is a complex component that has    seven different stages. If a valid rule is created, Soar immediately adds the    rule to production memory.</li> </ol> <p>The following sections will describe each component in more detail.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#what-ebc-does-prior-to-the-learning-episode","title":"What EBC Does Prior to the Learning Episode","text":"<p>While most of the work that explanation-based chunking performs occurs during the learning episode, i.e. after a rule in a substate fires and Soar detects that a result will be created, some critical aspects of the analysis it performs also occur prior to the learning episode, during problem-solving in the substate. The two points when that happens is when a rule fires in a substate and when an operator is selected in a substate.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#identity-assignment-and-propagation","title":"Identity Assignment and Propagation","text":"<p>Each instantiation describes the working memory elements that matched each condition and the working memory elements and preferences that are created by each action. With the introduction of EBC, all instantiations now also store the underlying explanation behind each condition and action as defined by the original rule: which elements in conditions are variables and which ones are literal constants, which variables are the same variables, what constraints must be met on the values of each variable and any relationships between variables.</p> <p>EBC uses this underlying logic to determine the identities of objects used during the problem- solving. Identities are not simply IDs. Each identity is a declarative object that describes a set of variables across multiple rule firings and the various properties they hold.</p> <p>When an instantiation is created, EBC assigns all elements of every condition and action to an identity, creating new identities as necessary. Identities are created and propagated using the following rules:</p> <ol> <li>If the same variable appears in multiple places in the same rule, it must be    assigned the same identity.</li> <li>The NULL Identity is assigned to any element with a literal value in the    original rule.</li> <li>A new identity is created and assigned for:<ul> <li>All right-hand side action elements that produce a new Soar identifier in   the substate These are also known as unbound RHS variables.</li> <li>All variable elements of conditions that matched superstate WMEs It is   important to note that if two conditions both match the same superstate WME,   each condition is considered independent. This means that each condition is   assigned new identities for each of its elements and will produce its own   condition in the final learned rule. This is a key way that EBC differs   from previous versions of chunking.</li> </ul> </li> <li>An existing identity is propagated for:<ul> <li>Any condition element that matched a substate WME with existing identities   Each element is assigned the identity found in the corresponding element of   the action of the rule that created that WME. This propagates identities   forward through the explanation trace, which allows us to represent that the   variable in the condition refers to the same object as the variable in the   action of the other rule.</li> <li>Any element that matches special working memory elements called singletons   are assigned the same identity. Singletons are working memory elements that   are guaranteed to only have a single possible value in a state. The most   important singleton is the local <code>^superstate</code> singleton, which is an   architecturally created WME that links the substate to the superstate, for   example <code>(S2 ^superstate S1)</code>. Since we know that it\u2019s impossible for there to   be two superstate features in a state, all conditions that test that   singleton WME will be assigned the same identities.  While there are a   variety of built-in singletons for architecturally-created WMEs, users can   also specify their own domain-specific singletons to eliminate unnecessary   generality when learning. See section    Using Singletons to Simplify a Rule's Conditions.   The full list of architecturally-created singletons can be found   in the <code>chunk</code> command\u2019s help entry.</li> </ul> </li> </ol> <p>Note that rule 1 may conflict with other rules. For example, if a variable appears in two different conditions, then two different identities may propagate into each one of them. In such cases, rule 1 is always enforced and propagation is ignored. During the second phase of identity analysis, which occurs during the actual learning episode, EBC will re-examine all of the condition-action pairs as it performs a backward traversal of the explanation trace and fix the missing propagations. It does this by creating and manipulating an identity graph that can correctly incorporate all identity relationships.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#relevant-operator-selection-knowledge-tracking","title":"Relevant Operator Selection Knowledge Tracking","text":"<p>As described in the beginning of this chapter, chunking summarizes the processing required to produce the results of subgoals. Traditionally, the philosophy behind how an agent should be designed was that the path of operator selections and applications from an initial state in a substate to a result would always have all necessary tests in the operator proposal conditions and any goal test, so only those items would need to be summarized. The idea was that in a properly designed agent, a substate\u2019s operator evaluation preferences lead to a more efficient search of the space but do not influence the correctness of the result. As a result, the knowledge used by rules that produce such evaluation preferences should not be included in any chunks produced from that substate.</p> <p>In practice, however, it may make sense to design an agent so that search control does affect the correctness of search. Here are just two examples:</p> <ol> <li>Some of the tests for correctness of a result are included in productions that prefer operators that will produce correct results. The system will work correctly only when those productions are loaded.</li> <li>An operator is given a worst preference, indicating that it should be used only when all other options have been exhausted. Because of the semantics of worst, this operator will be selected after all other operators; however, if this operator then produces a result that is dependent on the operator occurring after all others, this fact will not be captured in the conditions of the chunk.</li> </ol> <p>In both of these cases, part of the test for producing a result is implicit in search control productions. This move allows the explicit state test to be simpler because any state to which the test is applied is guaranteed to satisfy some of the requirements for success. However, chunks created in such a problem space will not be correct because important parts of the superstate that were tested by operator evaluation rules do not appear as conditions. The chunks would not accurately summarize the processing in that problem state. The tracking of Relevant Operator Selection Knowledge (ROSK) is a way to address this issue.</p> <p>Relevant operator selection knowledge is the set of necessary operator evaluation preferences that led to the selection of an operator in a subgoal. As previously described, whenever Soar learns a rule, it recursively backtraces through rule instances to determine which conditions to include in the final chunk or justification. With the ROSK, not only does Soar backtrace through each rule instance that created a matched working memory element, but it also backtraces through every rule instance that created preferences in the ROSK for any operator that gave those matched WMEs o-support. By backtracing through that additional set of preferences at each step of the backtrace, an agent will create more specific chunks that incorporate the goal-attainment knowledge encoded in the operator evaluation rules.</p> <p>Specifically, this component does two things:</p> <ol> <li>When an operator is selected, it analyzes the operator preferences that led to the decision, and caches any operator selection knowledge that played a necessary role in the selection. All necessity preferences, i.e. prohibit and require preferences, are always included in the ROSK since they inherently encode the correctness of whether an operator is applicable in a problem space. In contrast, some desirability preferences (rejects, betters, worses, bests, worsts and indifferents) are included in the ROSK depending on the role they play in the selection of the operator.  How Soar determines which of those preferences to include in the ROSK is determined by the preference semantics it uses to choose an operator. During the decision phase, operator preferences are evaluated in a sequence of seven steps or filters, in an effort to select a single operator, as described in Section 2.4.2. Each step, or filter, handles a specific type of preference. As the preference semantics are applied at each step to incrementally filter the candidate operators to a potential selected operator, EBC incrementally adds operator preferences to the ROSK based on the preferences that were instrumental in applying each filter. A more detailed explanation of the logic used at each step can be found in Section 4.6.15.</li> <li>When an o-supported rule matches, EBC caches the operator\u2019s ROSK in the instantiation of that rule.  Since that selection knowledge was necessary to select the operator needed for the rule to match, chunking must backtrace through that knowledge. The operationality analysis component uses the cached ROSK to do this and incorporate the necessary operator selection reasoning knowledge into the learned rule. For some types of agent designs, including operator selection knowledge is needed to ensure correctness.</li> </ol>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#what-ebc-does-during-the-learning-episode","title":"What EBC Does During the Learning Episode","text":"<p>All of the previously discussed steps occurred during problem-solving in the substate as rules matched and operators were selected. It is worth noting that the analysis performed prior to the learning episode is persistent and can be shared across learning episodes. In other words, EBC can repeatedly re-use that analysis if it learns multiple chunks in the same substate.</p> <p>Every time a rule fires in a substate, Soar checks to see if any of the working memory elements created by the rule qualify as results. This is when the actual learning episode begins.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#calculating-the-complete-set-of-results","title":"Calculating the Complete Set of Results","text":"<p>A chunk\u2019s actions are built from the results of a subgoal. Aresultis any working memory element created in the substate that is linked to a superstate. A working memory element is linked if its identifier is either the value of a superstate WME, or the value of an augmentation for an object that is linked to a superstate.</p> <p>The results produced by a single production firing are the basis for creating the actions of a chunk. A new result can lead to other results by linking a superstate to a WME in the substate. This WME may in turn link other WMEs in the substate to the superstate, making them results. Therefore, the creation of a single WME that is linked to a superstate can lead to the creation of a large number of results. All of the newly created results become the basis of the chunk\u2019s actions.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#backtracing-and-the-three-types-of-analysis-performed","title":"Backtracing and the Three Types of Analysis Performed","text":"<p>When learning a new rule, EBC performs a dependency analysis of the productions that fired in a substate \u2013 a process called backtracing. Backtracing works as follows. For each instantiated production that creates a subgoal result, backtracing examines the explanation trace to determine which working memory elements matched each condition. If the working memory element is local to the substate, then backtracing recursively examines the instantiation that created that condition\u2019s matched working memory element. Thus, backtracing traces backwards through all rules that fired and created working memory elements that were used to produce a result.</p> <p>If an instantiation being backtraced through tested a selected operator, EBC will backtrace through each instantiation that created a preference in that operator\u2019s relevant operator selection knowledge set. This behavior is off by default and can be enabled with chunk add-osk on(See Section 9.4.1.5.)</p> <p>Multiple components of EBC perform their work during backtracing: operationality analysis, identity analysis and constraint tracking. The following sections will discuss what aspects of the agent\u2019s problem-solving are analyzed during backtracing.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#operationality-analysis","title":"Operationality Analysis","text":"<p>The traditional core function of chunking\u2019s backtracing is to determine which conditions in the working memory trace tested working memory elements accessible to the superstate.  These conditions will form the left-hand side of the rule.</p> <p>The determination of which conditions to include is analogous to the concept of operationality in explanation-based techniques. In classic EBL literature, operationality is typically defined as nodes in the explanation trace that are \"efficiently calculatable\". In terms of Soar\u2019s problem-state computational model, operationality can be defined as any condition that tests knowledge linked to a superstate.</p> <p>As EBC is backtracing through rules that fired in a substate, it collects all of these operational conditions. Once the entire explanation trace is traversed, the operationality analysis will have determined exactly what superstate knowledge was tested during the process of creating a result, which it then uses as the basis for the left-hand side of the newly learned rule.</p> <p>Note: Soar 9.6.0\u2019s explanation-based approach has led to one key change to Soar\u2019s operationality analysis. In previous versions of chunking, chunking would never add two conditions to a chunk that matched the same superstate working memory element. This made sense because chunking was based on a generalization of the working memory trace. More than one condition that tested the same WME would be redundant. Explanation-based chunk- ing, though, learns based on the reasoning within the original hand-written rules. Since the reasoning behind each of the two conditions may be different even if they matched the same WME, EBC must always add both conditions. (Note that there are some exceptions. See Section 4.7.3.2 on superstate singletons and user singletons.)</p> <p>Negated conditions are included in a trace in the following way: when a production fires, its negated conditions are fully instantiated with its variables\u2019 appropriate values. This instantiation is based on the working memory elements that matched the production\u2019s positive conditions. If the variable is not used in any positive conditions, such as in a conjunctive negation, a dummy variable is used that will later become a variable in a chunk. If the identifier used to instantiate a negated condition\u2019s identifier field is linked to the super-state, then the instantiated negated condition is added to the trace as a negated condition. In all other cases, the negated condition is ignored because the system cannot determine why a working memory element was not produced in the subgoal and thus allowed the production to fire.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#identity-analysis","title":"Identity Analysis","text":"<p>The first phase of identity analysis, forward identity propagation, occurred as rules fired and instantiations were recorded. Unfortunately, forward propagation alone will not produce correct identities. We previously gave one reason why this is the case \u2013 conditions may have conflicting identities propagated forward \u2013 but there are other, more complicated reasons as well that are beyond the scope of this document. What is important to know is that a second phase of identity analysis will be performed during backtracing that will refine and correct the limitations of the initial forward propagation of identity. This second phase achieves these corrections by building an identity graph, which represent the identities involved during problem-solving, and manipulating it as it backtraces through the explanation trace.</p> <p>The Identity Graph</p> <p>The identity graph initially contains a node for each identity used in the explanation trace.  Each node can have multiple edges that point to children identities and a single directed join edge that initially points back to itself. As the agent backtraces through the explanation trace, EBC will manipulate the identity graph based on the condition-action pairs it encounters.</p> <ol> <li>Joining identities    If a condition matches an action with a conflicting identity, EBC performs a    join operation between the two identities. This chooses one identity as    the joined identity and points the join edges of the other identity and any    previously joined identities to the new joined identity.  Note that any time    EBC uses an element\u2019s identity, it is actually using the joined identity.</li> <li>Literalizing identities    If a condition/action with a variable element matches    an action/condition with a literal element, EBC marks the identity    as literalized. This means that any conditions in the final chunk that have    elements with that identity will be considered to have the NULL identity, just    like constants, and will not be variablized. Instead, the matched value will be    used for that element.</li> </ol>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#constraint-tracking","title":"Constraint Tracking","text":"<p>Our definition of operationality is very clear and allows us to almost trivially determine which conditions we should include in a learned rule, but it does have one shortcoming: non-operational conditions, which are ones that don\u2019t test working memory elements in the superstate, can transitively place constraints on the values of variables in operational conditions that will appear in a chunk. If our learning algorithm does not include these constraints, the learned rule can apply to situations where the previous substate reasoning could not have occurred, which means that the learned rule is over-general.</p> <p>To handle this limitation,EBC keeps track of all constraints found in non-operational conditions that it encounters while backtracing in the following manner:</p> <ul> <li>\u0088It stores constraints on the value a single identity, for example&gt;= 0,&lt; 23.</li> <li>\u0088It stores relational constraints between two identities, for example&gt; <code>&lt;min&gt;</code>, <code>&lt; &lt;max&gt;</code> or <code>&lt;&gt; &lt;other&gt;</code>.</li> <li>\u0088EBC stores all of these constraints based on the underlying identities, not the variables used. For example, if a variablehad the constraint&lt;&gt; , EBC would record that the variables that share the identity ofcannot have the same value as variables that share the identity of."},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#rule-formation","title":"Rule Formation","text":"<p>There are seven distinct, sequential stages to rule formation. The following sections will give a brief overview of each one.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#condition-and-action-creation","title":"Condition and Action Creation","text":"<p>This stage creates the basis for the left-hand and right-hand side of the rule. To create the initial conditions of the chunk, it copies all conditions in the explanation trace that were flagged as operational during backtracing. These initial conditions contain literal values for each element. To form the actions of the chunk, it creates copies of the actions that produced each of the result and all children of those results that came along for the ride.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#enforcement-of-constraints","title":"Enforcement of Constraints","text":"<p>This stage adds all constraints on non-operational conditions that were collected during backtracing. As previously described, each constraint is indexed in terms of the identity it constrains. So,if the identity being constrained exists in one of the conditions of the learned rule, EBC will enforce the constraint by adding a new test to that condition.</p> <p>One situation in which attaching a constraint can be tricky occurs when the constrained identity has been literalized but the constraint itself refers to an identity that has not been literalized, for example{ &gt;  3 }. While that constraint references a condition element that can only match a value of 3 , the relationship between 3 and the identity o <code>&lt;x&gt;</code> must still hold (assuming <code>&lt;x&gt;</code> appears in a different element somewhere else in the rule.) Since these constraints still need to be enforced to ensure a correct rule, EBC will invert the constraint and attach it to a variable in another condition. In this example, it would add a&lt; 3to some other condition with an element that ha <code>&lt;x&gt;</code> \u2019s identity."},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#identity-based-variablization","title":"Identity-Based Variablization","text":"<p>To achieve any useful generality in chunks, identifiers of actual objects must be replaced by variables when the chunk is created; otherwise chunks will only ever fire when the exact same objects are matched. At this point in the algorithm, all of the real work needed to determine the most general but correct variablization has already been performed by the identity analysis component.</p> <p>So, this step simply needs to replace all elements with non-NULL identities with variables, making sure that elements with the same joined identity are assigned the same variable.  This step also makes sure to skip and elements with identities that have been flagged as literalized.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#merging-redundant-conditions","title":"Merging Redundant Conditions","text":"<p>Any two conditions in the learned rule that share the same identities in all three elements can be combined. In such cases, it is logically impossible for those two conditions to match two different WMEs and cause the same rules to match in the substate. (If the two conditions were to match two different WMEs, at least one of the other rules in the explanation trace that had unified the two conditions would not have matched.) As a result, EBC can safely merge those two conditions without losing generality.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#polishing-conditions","title":"Polishing Conditions","text":"<p>EBC polishes the conditions of the learned rule by pruning unnecessary constraints on literalized elements and replacing multiple disjunction constraints with a single simplified dis- junction.</p> <ol> <li>Merging disjunctions: If an element in a condition has two disjunction tests, the    constraints will be merged into a single disjunction that contains only the shared val-    ues. <code>{ &lt;&lt; a b c &gt;&gt; &lt;&lt; b c d &gt;&gt; &lt;x&gt;}</code> becomes <code>{ &lt;&lt;b c &gt;&gt; &lt;x&gt; }</code>, because it is    impossible fo <code>&lt;x&gt;</code> to be either a or b. This will also eliminate any duplicate disjunctions.</li> <li>Throwing out unnecessary constraints: If an element in a condition has been literalized but also has a literal constraint on its value, then the constraint is unnecessary and will be thrown out. For example, <code>&lt;s&gt; ^value{ &lt; 33 23 }</code> becomes <code>&lt;s&gt; ^value 23</code>.</li> </ol>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#validating-rule-and-repairing-unconnected-conditions","title":"Validating Rule and Repairing Unconnected Conditions","text":"<p>At this point, the rule is essentially formed. Chunking must now make sure that the learned rule is fully operational and can be legally added to production memory. A fully operational rule does not have any conditions or actions that are not linked to a goal state specified in the rule.</p> <p>If an unconnected action or condition is found, EBC will attempt to repair the rule by adding new conditions that provide a link from a state that is already tested somewhere else in the rule to the unconnected condition or action.</p> <p>To repair the rule, EBC performs a search through working memory to find the shortest path of working memory elements that lead from a state identifier in the rule to a WME with the identifier in the unconnected condition or action. A new condition is then added for every WME in that found path, which is then variablized.</p> <p>Note that there may be multiple paths from a state to the unconnected identifier. EBC does a breadth-first search, so it will find one with the shortest distance.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#re-ordering-conditions","title":"Re-ordering Conditions","text":"<p>Since the efficiency of the Rete matcher depends heavily upon the order of a production\u2019s conditions, the chunking mechanism attempts to sort the chunk\u2019s conditions into the most favorable order. At each stage, the condition-ordering algorithm tries to determine which eligible condition, if placed next, will lead to the fewest number of partial instantiations when the chunk is matched. A condition that matches an object with a multi-valued attribute will lead to multiple partial instantiations, so it is generally more efficient to place these conditions later in the ordering. This is the same process that internally reorders the conditions in user- defined productions, as mentioned briefly in Section 2.3.1.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#subtleties-of-ebc","title":"Subtleties of EBC","text":""},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#relationship-between-chunks-and-justifications","title":"Relationship Between Chunks and Justifications","text":"<p>Chunks are closely related to another type of rule called a justification. Justifications are also created when a substate creates a result for a superstate, the difference being that justifications are only built when learning is off. These justifications are needed to decide whether the working memory elements in the result should get i-support or o-support in the superstate. To do that, Soar needs to determine whether any rules involved in the creation of the result tested the selected operator in the superstate, which is exactly the same type of analysis that chunking does.</p> <p>As a result, Soar uses a limited version of the chunking algorithm to do that. It analyzes the substate problem-solving and learns a new, temporary rule, a \"justification\", which is added to production memory. If this temporary rule tests an operator in the superstate, it gives the result o-support. (Note that when learning is on, a justification is not needed since the chunk will provide the correct support.)</p> <p>Justifications use all the components described in the following sections and are even affected by the current chunk settings.<sup>1</sup> You can even print justifications out like other rules. The only differences between chunks and justifications are:</p> <ol> <li>Every condition and action in a justification contain the literal values that matched.    Justifications contain no variables.<sup>2</sup></li> <li>Justifications don\u2019t contain any of the value constraints that a chunk would have.</li> <li>Justifications get removed from production memory as soon as their conditions no    longer match.</li> </ol>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#chunk-inhibition","title":"Chunk Inhibition","text":"<p>If a newly learned chunk was immediately added to production memory, it would immediately match with the same working memory elements that participated in its creation. This can be problematic if the production\u2019s actions create new working memory elements. Consider the case where a substate proposes a new operator, which causes a chunk to be learned that also proposes a new operator. The chunk would immediately fire and create a preference for another new operator, which duplicates the operator preference that was the original result of the subgoal.</p> <p>To prevent this, Soar uses inhibition. This means that each production that is built during chunking is considered to have already fired with an instantiation based on the exact set of working memory elements used to create it.</p> <p>Note that inhibition does not prevent a newly learned chunk from immediately matching other working memory elements that are present and creating a new instantiation.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#chunks-based-on-chunks","title":"Chunks Based on Chunks","text":"<p>When a problem has been decomposed into more than one substate, a single result can produce multiple chunks. This process is called bottom-up chunking. The first chunk is produced in the substate where the problem-solving that produced the result occurred. The next chunk is based on the implicit match of the first chunk in one of the higher level problem- spaces. If that match is lower than the state that the result is being returned to, Soar will backtrace through the chunk match and learn a second chunk (relative to the substate that the chunk matched in). This process continues until it learns a chunk that only creates working memory elements in the same state that it matched in.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#mixing-chunks-and-justifications","title":"Mixing Chunks and Justifications","text":"<p>If an agent is using the only or except setting, then justifications will be built in states where learning is disabled and chunks will be built in states where learning is enabled. In these situations, justifications also serve another purpose: they provide an explanation of the results for future learning episodes in states that do have learning on. EBC does this by retaining all of the extra information that chunks have but justifications do not, namely those extra tests and how things would have been variablized. This allows EBC to learn chunks from justifications as readily as it can from hand-written rules and other chunks.</p> <p>When mixing justifications and chunks, users may want to set the explainer to record the learning episodes behind justifications. This allows one to examine the reasoning behind a justification just like you would a chunk, which may be important if that justification later participates in the formation a chunk. See Section 9.6.3 for more information about the explainer\u2019s settings.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#generality-and-correctness-of-learned-rules","title":"Generality and Correctness of Learned Rules","text":"<p>Chunking is intended to produce the most general rule that is also correct.</p> <p>Generality is a measure of the space of similar situations that a rule can apply to. A more general rule can be applied to a larger space of similar situations. A rule is considered over- general if it can apply to situations in which the original problem-solving would have never occurred.</p> <p>Correctness is a requirement that the learned rule produces the exact same results that the original problem-solving would have produced. In other words, if we inhibited a correct chunk so that it did not fire, the agent should subgoal, execute the same substate reasoning that it previously performed when learning the chunk, and produce the same results that the learned chunk produces.</p> <p>Note that an over-general rule is an incorrect rule, but not all incorrect rules are over-general.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#over-specialization-and-over-generalization","title":"Over-specialization and Over-generalization","text":"<p>Explanation-based chunking was pursued to address the main limitation of traditional chunk- ing:over-specialized rules that were very specific and could not be applied to many other situations. Specifically, EBC\u2019s identity-based variablization and constraint tracking/enforcement has eliminated the core source of this issue.</p> <p>The nature of EBC\u2019s algorithm does add two new situations in which rules may become over- specialized. Section 4.6.16 discusses how variables used in certain RHS functions need to be literalized to maintain correctness, which can cause overspecialization. Section 4.6.7 discusses how testing or augmenting a previous result creates non-operational rules that require repair, a process which may sometimes over-specialize a rule. Note that this situation can easily be avoided and, even when it does occur, may not add much unnecessary specificity to learned rules.</p> <p>While over-specialization may no longer be a common problem, it is still possible to get over-general rules. Several of the sources of correctness issues listed in the next section can produce over-general rules in certain situations.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#previous-results-and-rule-repair","title":"Previous Results and Rule Repair","text":"<p>An agent may learn a slightly over-specialized rule when EBC repairs a rule that has unconnected conditions, which are conditions that have an identifier that is not linked to one of the states referenced in the rule. Such rules are illegal and cannot be added to Soar\u2019s production memory.</p> <p>Rules that require repair are caused by substate problem-solving that tests or augments a previous result. A previous result is a working memory element that was originally created locally in the substate but then later became a result when a rule fired and connected it to the superstate. (At which point a chunk must have been learned.). If another substate rules later matches or augments such a previous result WMEusing a path relative to the local substate, then EBC will have problems. It will know that the WME is in the superstate so conditions that test the WME are considered operational and augmentations on that identifier are considered results \u2013 but it won\u2019t know where in the superstate that working memory is located is and how it should be referenced in the learned rule, because the problem solving referenced the result relative to the local substate.</p> <p>As described in Section 4.5.3.6, EBC repairs the rule by adding new grounding conditions that provide a link from a state, which is tested somewhere else in the rule, to the unconnected condition or action. It does this by searching through working memory to find the shortest path from a state to the identifier behind the unconnected element. It then variablizes those conditions appropriately.</p> <p>Since the conditions are based purely on what happened to be in working memory at that point and nothing in the explanation dictated that particular path found during the search, the learned rule may be over-specialized. The chunk will only match future situations where the previous result can be found on that same path. Fortunately, new chunks can be learned to ameliorate this. If a similar situation is encountered in the future, but with a different path to the unconnected element, the chunk won\u2019t fire, because the added grounding conditions won\u2019t match, which should cause the agent to subgoal and learn a similar chunk with a different set of grounding conditions.</p> <p>Note that if an agent designer expects that the path to the previous result found by the search will always exist, a repaired rule should match just as generally as an unrepaired rule.</p> <p>But if this is not the case, an agent designer can avoid this situation by modifying the rules that test or augment the substructure of a previous result. If those rules are modified so that they match the previous results by referencing them relative to the superstate than the the local substate, EBC will be able create a valid rule without any repair.</p> <p>To detect when this is happening, use the chunk stats command. (See section 9.4.1.2 It will tell you if any of an agent\u2019s learned rules that required repair. If you instruct the explainer to record the chunk, you can also see whether a specific chunk was repaired by looking at the chunk\u2019s individual stats</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#missing-operator-selection-knowledge","title":"Missing Operator Selection Knowledge","text":"<p>If an agent uses rules that create operator preferences to choose amongst multiple operators in the substate, it is possible that the reasoning behind those rules needs to be incorporated in any rule learned. This topic is discussed in greater detail in Section 4.4.2.</p> <p>EBC will incorporate relevant operator selection knowledge if you enable the chunk setting add-osk, which is off by default. (See Section 9.4.1.5.)</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#generalizing-over-operators-selected-probabilistically","title":"Generalizing Over Operators Selected Probabilistically","text":"<p>If the problem-solving in a substate involves operators that were selected probabilistically, chunking will not be able to summarize the agent\u2019s reasoning into a correct rule. For a rule to be correct, it must always produce the same result that the substate would have produced if the learned rule was not in production memory. Since a different operator could have been selected which could have resulted in different problem-solving, the substate could easily produce different results than any chunk learned in that substate.</p> <p>Future versions of chunking will provide an option to prevent rules from forming when a probabilistically-selected operator was chosen during problem-solving. Until then, agent engineers can disable learning in states that involve such reasoning.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#collapsed-negative-reasoning","title":"Collapsed Negative Reasoning","text":"<p>Over-general chunks can be created when conditions in the explanation trace test for the absence of a working memory elements in the substate. Since there is no clear way for chunking to generate a set of conditions that describe when a given working memory element would not exist in a substate, chunking can\u2019t represent that aspect of the problem-solving.</p> <p>Chunking can include negated tests if they test for the absence of working memory elements in the superstate, though. So, the agent engineer can avoid using negated conditions for local substate data by either (1) designing the problem-solving so that the data that is being tested in the negation is already in the superstate or (2) making the data a result by attaching it to the superstate. This increases the number of chunks learned, but a negated condition of knowledge in the superstate can be incorporated correctly into learned rules.</p> <p>Note that there are agent design patterns where local negations are perfectly safe to ignore, so Soar allows local negations by default. In some agents, they are common enough that turning the filter on prevents any rules from being learned.</p> <p>If you suspect that a rule may be over-general because of locally negated condition, you can verify whether such a condition was encountered during backtracing by using the  chunk stats command and explain stats command. See Sections 9.4.1.2 and 9.6.3.8 for more information.</p> <p>If such chunks are problematic, turning off chunking\u2019s correctness filter allow-local-negations will force Soar to reject chunks whose problem-solving involved a local negation.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#problem-solving-that-doesnt-test-the-superstate","title":"Problem-Solving That Doesn\u2019t Test The Superstate","text":"<p>Over-general chunks can be created if a result of a subgoal is dependent on the creation of an impasse within the substate. For example, processing in a subgoal may consist of exhaustively applying all the operators in the problem space. If so, then a convenient way to recognize that all operators have applied and processing is complete is to wait for a state no-change impasse to occur. When the impasse occurs, a production can test for the resulting substate and create a result for the original subgoal. This form of state test builds over- general chunks because no pre-existing structure is relevant to the result that terminates the subgoal. The result is dependent only on the existence of the substate within a substate.</p> <p>In these cases, EBC will learn a chunk with no conditions, which it will reject. But the superstate result is still created by the substate rule that matched. If a new rule is learned that uses that result, it will be over-general since the rule does not summarize the reasoning that led to the result, namely that all operators were exhaustively applied.</p> <p>The current solution to this problem is a bit of a hack. Soar allows an agent to signal to the architecture that a test for a substate is being made by testing for the^quiescence t augmentation of the subgoal. If this special test is found in the explanation trace, EBC will not build a chunk. The history of this test is maintained, so that if the result of the substate is then used to produce further results for a superstate, no higher chunks will be built.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#disjunctive-context-conflation","title":"Disjunctive Context Conflation","text":"<p>An incorrect rule can be learned when multiple rules fire in a substate that test different structures in the superstate but create the same WME in the substate. For example, there may be a rule that can match the superstate in several different ways, each time elaborating the local state with a WME indicating that at least one of these qualifying superstate WMEs existed. In such a situation, the rule would fire multiple times, but the result of the rule firings will be collapsed into creating a single WME in the substate.</p> <p>If this WME is then tested to create a result on the superstate, the chunk that is subsequently created can produce different behavior than the substate would have. In the original subgoal processing, multiple matches produced one substate WME, but that one substate WME only created a single result in the superstate. The chunk on the other hand will match multiple times for each of the items that previously created the substate WME. And then, each one of those matches will create its own distinct result in the superstate. Since this is different behavior than the original substate, this rule would be considered incorrect.</p> <p>If it were possible, EBC should learn a disjunctive conjunctive condition, with each dis- junction being the superstate conditions tested by each substate rule that had previously created the substate WME that was repeatedly asserted. This is why this potential source of incorrect rules is called disjunctive context conflation.</p> <p>If this type of reasoning is needed, agents can move the conflating WME to the superstate.  The rule learned would then produce only one result regardless of the number of rules that repeatedly created that WME.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#generalizing-knowledge-retrieved-from-semantic-or-episodic-memory","title":"Generalizing knowledge retrieved from semantic or episodic memory","text":"<p>Generalizing problem-solving based on knowledge recalled from an external memory system can be problematic for three main reasons.</p> <ol> <li>Knowledge can change after the learning episode    Semantic knowledge can be modified by the agent. Different semantic knowledge can    effect different problem-solving, in which case a rule based on the original problem-    solving would be incorrect.</li> <li>Justification for a memory recall is opaque to agent     EBC does not have access    to the reasoning behind why a piece of knowledge was recalled from a memory    system. For example, consider the case of a semantic memory that is recalled    because it has the highest level of activation at a particular time. In a future    situation, the same semantic memory may not be the most active, in which case    something else would be recalled and different problem-solving could occur.    Because of that possibility, the original rule is not guaranteed to produce the    same result and hence has the potential to be incorrect. (Note that this can    also occur with episodic memory queries.)</li> <li>Knowledge from semantic or episodic memory recalled directly into the    substate is considered local    To understand why this is a problem, remember that a chunk\u2019s conditions are    based on the conditions in the explanation trace that tested knowledge linked    to a superstate.  (See section 4.5.2.1 for more information.) If semantic or    episodic memory is recalled directly into the substate, then any conditions    that test that recalled knowledge is considered local to the substate and    will not be included as a condition in the chunk.  So, even though the    substate reasoning required some piece of semantic knowledge to exist, the    chunk will not require it. And, since the learned rule is not incorporating    some of the reasoning and constraints that involved the recalled knowledge,    the rule may be over-general.  To avoid this situation, an agent can retrieve    the knowledge in a higher-level state rather than the substate in which the    rule is learned.</li> </ol>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#learning-from-instruction","title":"Learning from Instruction","text":"<p>Note that some agent designs, for example an agent that learns by instruction, can take advantage of the fact that knowledge recalled from semantic or episodic memory directly into the substate is considered local. For such agents, a rule that is directly dependent on the instructions being in working memory would be useless. The agent would need to get the instruction every time it wanted to perform the task again, defeating the purpose of learning by instruction.</p> <p>One technique that can be used to produce a more general rule which is not directly dependent on the instruction being in working memory is to first store the instructions in semantic or episodic memory. When the agent is in a substate that it wants to learn a rule based on the instructions, it recalls the instructions from semantic or episodic memory directly into the substate. Because that knowledge is not linked to the superstate, any rules learned in that substate will not be directly dependent on the existence of the instructions.</p> <p>Since conditions that test the recalled knowledge are not incorporated into the learned rule, it is very easy to learn over-general chunks. To avoid this, any substate rules which test recalled knowledge must also test superstate structures that correspond to the recalled knowledge.  Doing so removes the need for the instructions to exist while avoiding over-generality by ensuring that structures in the superstate corresponding to those instructions are still being tested. Those conditions that test superstate WMEs will be generalized and included in the chunk, but the undesired portion of the reason that they matched will not be, namely the fact that the superstate knowledge corresponded to recalled instructions.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#determining-which-osk-preferences-are-relevant","title":"Determining Which OSK Preferences are Relevant","text":"<p>The following outline describes the logic that happens at each step. For a more detailed description of the various filters (but not the ROSK) see Section 2.4.2 on page 21. Note that depending on the set of preferences being processed, impasses may occur at some of these stages, in which case, no operator is selected and the ROSK is emptied. Moreover, if the candidate set is reduced to zero or one, the decision process will exit with a finalized ROSK.  For simplicity\u2019s sake, this explanation assumes that there are no impasses and the decision process continues.</p> <p>Require Filter If an operator is selected based on a require preference, that preference is added to the ROSK. The logic behind this step is straightforward, the require preference directly resulted in the selection of the operator.</p> <p>Prohibit/Reject Filters If there exists at least one prohibit or reject preference, all prohibit and reject preferences for the eliminated candidates are added to the ROSK. The logic behind this stage is that the conditions that led to the exclusion of the prohibited and rejected candidates is what allowed the final operator to be selected from among that particular set of surviving candidates.</p> <p>Better/Worse Filter For every candidate that is not worse than some other candidate, add all better/worse preferences involving the candidate.</p> <p>Best FilterAdd any best preferences for remaining candidates to the ROSK.</p> <p>Worst Filter If any remaining candidate has a worst preference which leads to that candidate being removed from consideration, that worst preference is added to the ROSK.  Again, the logic is that the conditions that led to that candidate not being selected allowed the final operator to be chosen.</p> <p>Indifferent Filter This is the final stage, so the operator is now selected based on the agent\u2019s exploration policy. How indifferent preferences are added to the ROSK depends on whether any numeric indifferent preferences exist.</p> <ol> <li>If there exists at least one numeric indifferent preference, then every numeric    preference for the winning candidate is added to the ROSK. There can be multi-    ple such preferences. Moreover, all binary indifferent preferences be- tween that    winning candidate and candidates without a numeric preference are added.</li> <li>If all indifferent preferences are non-numeric, then any unary indifferent preferences for the winning candidate are added to the ROSK. Moreover, all binary    indifferent preferences between that winning candidate and other candidates are    added.</li> </ol> <p>The logic behind adding binary indifferent preferences between the selected operator and the other final candidates is that those binary indifferent preferences prevented a tie impasse and allowed the final candidate to be chosen by the exploration policy from among those mutually indifferent preferences.</p> <p>Note that there may be cases where two or more rules create the same type of preference for a particular candidate. In those cases, only the first preference encountered is added to the ROSK. Adding all of them can produce over-specific chunks. It may still be possible to learn similar chunks with those other preferences if the agent subgoals again in a similar context.</p> <p>Note also that operator selection knowledge is not tracked and incorporated into chunks by default. The setting must be turned on via the chunk command\u2019s add-osk setting. See Section 9.4.1 on page 233 for more information.</p> <p>The ROSK also affects the conditions of justifications, so the <code>add-desirability-prefs</code> setting does have an effect on the agent even if learning is turned off.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#generalizing-knowledge-from-math","title":"Generalizing Knowledge From Math","text":"<p>and Other Right-Hand Side Functions</p> <p>Explanation-based chunking introduces the ability to learn more expressive rules whose actions perform arbitrary right-hand side functions with variablized arguments.</p> <p>It is important to note that this ability is limited. EBC can only learn rules with generalized RHS functions in its actions when the rule that created the result contained a RHS function.  In many cases, RHS functions will be used in the intermediate rule firings in the explanation trace. Not only will these intermediate RHS function not appear in the chunk, but any chunk learned based on their output will become more specific. This is one of the sources of over-specialization referenced in section 4.6.6 on over-specialization.</p> <p>RHS function calls in intermediate rule firings are a challenge for EBC to deal with because the problem-solving may have placed constraints on the intermediate results that cannot be represented in a single Soar rule.</p> <p>For example, consider the case of one rule that used a RHS function to add two numbers.  Now consider another rule that matched the output of the RHS function, but only if it was less than 5. If the second rule matched, it would return the total as a result. How could we encode the reasoning of those two rules into one rule? Since Soar\u2019s production syntax does not allow using RHS function as constraints in conditions, there is no way to insure that the two numbers add up to something less than 5 in a single rule. This is why RHS functions in intermediate rule firings can cause over-specialization.</p> <p>Because the chunk\u2019s conditions can\u2019t represent constraints on the output of intermediate RHS functions, EBC must literalize both the identities of the variables that appear as arguments to the intermediate RHS function, as well as the identities in any conditions that test the output of the RHS function. That fixes the value of the RHS function and guarantees that any constraints in conditions that test the output of that RHS function will be met. While this will make the learned rule more specific, it will also ensure that the rule is correct.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#situations-in-which-a-chunk-is-not-learned","title":"Situations in which a Chunk is Not Learned","text":"<p>Soar learns a chunk every time a subgoal produces a result, unless one of the following conditions is true:</p> <ol> <li>Chunking is off    This corresponds to the command chunk never. See Section 9.4.1 on page 233 for    details of chunk and how to turn chunking on or off.</li> <li>Chunking was only enabled for some states, and the subgoal in question is not    one of them When chunking is enabled via the only or except command, the agent    must specify which states learning either occurs in or doesn\u2019t occur in,    respectively. For the except setting, Soar will learn rules in all states in    which a dont-learnRHS production action was not executed. Similarly, for the    only setting, Soar will learn rules in all states where a force-learn RHS    production action was executed. See Section 3.3.6.7 on page 82 for more    information.  This capability is provided for debugging and practical system    development, but it is not part of the theory of Soar.</li> <li>The chunk learned is a duplicate of another production or chunk already in    production memory In some rare cases, a duplicate production will not be    detected because the order of the conditions or actions is not the same as an    existing production.</li> <li>The problem-solving in the substate violated one of the enabled correctness    guarantee filters During the development of explanation-based chunking, we have    developed a list of possible causes of incorrect chunks. EBC\u2019s correctness    guarantee filters detect when those situations occur and prevents a chunk from    being learned.  For example, the allow-local-negations filter will prevent a rule    from being formed if the problem-solving that led to the result was dependent on    a condition that tested whether a subgoal WME doesn\u2019t exist. Since there is no    practical way to determine why a piece of knowledge doesn\u2019t exist, testing a    local negation can result in an over- general and incorrect chunk. See Section    4.7.3.1 on page 121 for more information.  Note that correctness filters have    not yet been implemented for all the identified potential sources of    correctness issues.</li> <li>The chunking option bottom-only is on and a chunk was already built in the    bottom subgoal that generated the results With bottom-only chunking, chunks are    learned only in states in which no subgoal has yet generated a chunk. In this    mode, chunks are learned only for the \"bottom\" of the subgoal hierarchy and not    the intermediate levels. With experience, the subgoals at the bottom will be    replaced by the chunks, allowing higher level subgoals to be chunked.  See    Section 9.4.1 on page 233 for details of chunk used with the bottom-only    setting.</li> <li>The problem-solving that led to the result contained a condition that tested    the architecturally-created <code>&lt;state&gt; ^quiescence t</code> augmentation This mechanism    is motivated by the chunking from exhaustion problem, where the results of a    subgoal are dependent on the exhaustion of alternatives (see Section 4.6.11 on    page 114). If this substate augmentation is encountered when determining the    conditions of a chunk, then no chunk will be built for the currently considered    action.  This is recursive, so that if an un-chunked result is relevant to a    second result, no chunk will be built for the second result. This does not    prevent the creation of a chunk that would include^quiescence tas a condition.</li> <li>The problem-solving in the substate did not test any knowledge in the    superstate In these cases, the chunk learned does not have any conditions and is    not a legal production. Note that this creates an unusual persistence issue for    any results that came out of the substate. Since a justification or chunk was    not learned, there is no rule in the superstate that can provide either    i-support or o-support for the result that came out of the substate.    Consequently, those result WMEs will be completely dependent on the rules that    fired within the substate. So, when the substate is removed, those results will    also be removed.</li> </ol>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#usage","title":"Usage","text":""},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#overview-of-the-chunk-command","title":"Overview of the chunk command","text":"<pre><code>===================================================\nChunk Commands and Settings\n===================================================\n? | help Print this help listing\ntimers [ on | OFF ] Timing statistics (no args to print stats)\nstats Print stats on learning that has occurred\n------------------- Settings ----------------------\nALWAYS | never | only | except When Soar will learn new rules\nbottom-only [ on | OFF ] Learn only from bottom substate\nnaming-style [ numbered | RULE] Simple names or rule-based name\nmax-chunks 50 Max chunks that can be learned (per phase)\nmax-dupes 3 Max duplicate chunks (per rule, per phase)\n------------------- Debugging ---------------------\ninterrupt [ on | OFF ] Stop Soar after learning from any rule\nexplain-interrupt [ on | OFF ] Stop Soar after learning explained rule\nwarning-interrupt [ on | OFF ] Stop Soar after detecting learning issue\n------------------- Fine Tune ---------------------\nsingleton Print all WME singletons\nsingleton &lt;type&gt; &lt;attribute&gt; &lt;type&gt; Add a WME singleton pattern\nsingleton -r &lt;type&gt; &lt;attribute&gt; &lt;type&gt; Remove a WME singleton pattern\n----------------- EBC Mechanisms ------------------\nadd-ltm-links [ on | OFF ] Recreate LTM links in original results\nadd-osk [ on | OFF ] Incorporate operator selection knowledge\nmerge [ ON | off ] Merge redundant conditions\nlhs-repair [ ON | off ] Add grounding conds for unconnected LHS\nrhs-repair [ ON | off ] Add grounding conds for unconnected RHS\nuser-singletons [ ON | off ] Use domain-specific singletons\n---------- Correctness Guarantee Filters ---------- Allow rules to form that...\nallow-local-negations [ ON | off ] ...used local negative reasoning\nallow-opaque\\* [ ON | off ] ...used knowledge from a LTM recall\nallow-missing-osk* [ ON | off ] ...tested operators selected using OSK\nallow-uncertain-operators* [ ON | off ] ...tested probabilistic operators\n\n- disabled\n</code></pre> <p>See Section 9.4.1 for more detailed information about the chunk command\u2019s settings.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#enabling-procedural-learning","title":"Enabling Procedural Learning","text":"<p>By default, explanation-based chunking is off.</p> <ul> <li>\u0088To turn on chunking: <code>chunk always</code></li> <li>\u0088To turn off chunking: <code>chunk never</code></li> </ul> <p>In real world agents, there may be certain problem spaces in which you don\u2019t want your agent to learn rules. Chunking has a mechanism to allow agents to dynamically specify the states in which rules are learned.</p> <ul> <li>\u0088To turn off chunking in all states except ones manually flagged on:</li> <li>Use chunk only setting.</li> <li>Design an agent rule that executes the RHS action force-learn, which only    matches in states in which you want to learn rules. -\u0088To turn on chunking in all states except ones manually flagged off:</li> <li>Use chunk except setting.</li> <li>Design an agent rule that executes the RHS action dont-learn, which only    matches in states in which you don\u2019t want to learn rules.</li> </ul> <p>Depending on your agent design, you may want to consider enabling the add-osk option.  As of Soar 9.6.0, EBC does not incorporate operator selection knowledge into learned rules by default, since there is a performance cost and not all agents designs require its inclusion.  You may want to enable this option if your agent has rules that test knowledge in the superstate to create operator preferences in the substate. See section 4.4.2 on page 103 for more information about learning and operator selection knowledge.</p> <p>See Section 9.4.1 on page 233 for more information about using the chunk command to enable and disable procedural learning.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#fine-tuning-what-your-agent-learns","title":"Fine-tuning What Your Agent Learns","text":""},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#prohibiting-known-sources-of-correctness-issues","title":"Prohibiting known sources of correctness issues","text":"<p>It is theoretically possible to detect nearly all of the sources of correctness issues and prevent rules from forming when those situations are detected. In Soar 9.6.0, though, only one filter is available,allow-local-negations. Future versions of Soar will include more correctness filters.</p> <p>Note that it is still possible to detect that your agent may have encountered a known source of a correctness issue by looking at the output of the chunk stats command. It has specific statistics for some of the sources, while others can be gleaned indirectly. For example, if the stats show that some rules required repair, you know that your agent testing or augmenting a previous result in a substate.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#using-singletons-to-simplify-a-rules-conditions","title":"Using Singletons to Simplify a Rule\u2019s Conditions","text":"<p>Unlike previous versions of chunking, EBC adds all conditions that tested superstate knowledge to a chunk, regardless of whether another condition already tested that working memory element. This means that EBC can sometimes produce learned rules with seemingly duplicate conditions. While these conditions are logically correct, they may be redundant because the nature of the domain may make it impossible for the two conditions to match different working memory elements. For example, in the blocks-world domain, the fact that there can be only one gripper in the world means that having multiple conditions testing for a gripper would be redundant.</p> <p>Soar allows agents to specify such known domain characteristics, which EBC will then use to create better rules that don\u2019t have such unnecessary conditions. We call any working memory element that is guaranteed to only have a single possible value at any given time, a singleton. If EBC encounters two different conditions in the backtrace that both test the same superstate WME that matches a user singleton pattern, it will merge the two conditions. As described in Section 4b, there are several architectural singleton\u2019s that EBC already knows about. To specify patterns for domain-specific singletons, the chunk singleton command can be used.</p> <p>See Section 9.4.1 for more information about the chunk singleton command.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#examining-what-was-learned","title":"Examining What Was Learned","text":""},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#printing-and-traces","title":"Printing and Traces","text":"<p>Printing Rules</p> <p>\u0088To print all chunks learned:  <code>print --chunks</code> or <code>print -c</code></p> <p>\u0088To print all justifications learned (and still matching):  <code>print --justifications</code> or <code>print -j</code></p> <p>\u0088To print a rule or justification: <code>print &lt;rule-name&gt;</code></p> <p>For more information on print, see section 9.3.1 on page 217.</p> <p>Trace Messages</p> <p>\u0088To print when new rules are learned (just the name): <code>trace --learning 1</code> or <code>trace -l 1</code></p> <p>\u0088To print when new rules are learned (the full rule): <code>trace --learning 2</code> or <code>trace -l 2</code></p> <p>\u0088To print a trace of the conditions as they are collected during backtracing: <code>trace --backtracing</code> or <code>trace -b</code></p> <p>\u0088To print warnings about chunking issues detected while learning: <code>trace --chunk-warnings</code> or <code>trace -C</code></p> <p>\u0088To print when learned chunks match and fire: <code>trace --backtracing</code> or <code>trace -b</code></p> <p>For more information on trace, see section 9.6.1 on page 259.</p> <p>Note that the most detailed information about why a particular rule was learned can be acquired using the explain mechanism as described in section 9.6.3 on page 269. That is highly recommended over printing the backtracing trace messages.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#chunking-statistics","title":"Chunking Statistics","text":"<p>Chunking automatically compiles various statistics about the procedural rule learning that an agent performs. To access these stats, use the command <code>chunk</code>, <code>stats</code> or <code>stats -l</code>.</p> <pre><code>===========================================================================\nExplanation-Based Chunking Statistics\n===========================================================================\nSubstates analyzed 0\nRules learned 0\nJustifications learned 0\n\n---\n\nWork Performed\n\nNumber of rules fired 0\nNumber of rule firings analyzed during backtracing 0\nNumber of OSK rule firings analyzed during backtracing 0\nNumber of rule firings re-visited during backtracing 0\n\nConditions merged 0\nDisjunction tests merged 0\n\n- Redundant values 0\n\n- Impossible values eliminated 0\n\nOperational constraints 0\nNon-operational constraints detected 0\nNon-operational constraints enforced 0\n\n---\n\nIdentity Analysis\n\nIdentities created 0\nDistinct identities in learned rules 0\nIdentity propagations 0\nIdentity propagations blocked 0\nIdentity propagations from local singleton 0\nIdentities joined 0\n\n- To unify two identities propagated into same variable 0\n- To unify two conditions that tested a superstate singleton 0\n- To connect an child result (result in rule had children WMEs) 0\n  Identities literalized 0\n- Condition with variable matched a literal RHS element 0\n- Condition with variable matched a RHS function 0\n- Condition with literal value matched a RHS variable 0\n- Variable used in a RHS function 0\n\n---\n\nPotential Generality Issues Detected\n\nRules repaired that had unconnected conditions or actions 0\nExtra conditions added during repair 0\n\n---\n\nPotential Correctness Issues Detected\n\nChunk used negated reasoning about substate 0\nChunk tested knowledge retrieved from long-term memory 0\nJustification used negated reasoning about substate 0\nJustification tested knowledge retrieved from long-term memory 0\n\n---\n\nLearning Skipped or Unsuccessful\n\nIgnored duplicate of existing rule 0\nSkipped because problem-solving tested ^quiescence true 0\nSkipped because no superstate knowledge tested 0\nSkipped because MAX-CHUNKS exceeded in a decision cycle 0\nSkipped because MAX-DUPES exceeded for rule this decision cycle 0\n</code></pre> <p>Note that similar statistics for a specific learned rule can be acquired using the explain mechanism as described in section 9.6.3 on page 269.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#interrupting-execution-to-examine-learning","title":"Interrupting Execution To Examine Learning","text":"<p>\u0088To stop Soar after each successful learning episode: <pre><code>chunk interrupt on\n</code></pre></p> <p>\u0088To stop Soar after detecting any learning issue: <pre><code>chunk warning-interrupt on\n</code></pre></p> <p>\u0088To stop Soar after learning a rule that the explainer recorded: <pre><code>chunk explain-interrupt on\n</code></pre></p> <p>For more information about how to record when a specific rule is learned, see section on page 269 that describes the explain mechanism.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#explaining-learned-procedural-knowledge","title":"Explaining Learned Procedural Knowledge","text":"<p>While explanation-based chunking makes it easier for people to now incorporate learning into their agents, the complexity of the analysis it performs makes it far more difficult to understand how the learned rules were formed. The explainer is a new module that has been developed to help ameliorate this problem. The explainer allows you to interactively explore how rules were learned.</p> <p>When requested, the explainer will make a very detailed record of everything that happened during a learning episode. Once a user specifies a recorded chunk to \"discuss\", they can browse all of the rule firings that contributed to the learned rule, one at a time. The explainer will present each of these rules with detailed information about the identity of the variables, whether it tested knowledge relevant to the the superstate, and how it is connected to other rule firings in the substate. Rule firings are assigned IDs so that user can quickly choose a new rule to examine.</p> <p>The explainer can also present several different screens that show more verbose analyses of how the chunk was created. Specifically, the user can ask for a description of (1) the chunk\u2019s initial formation, (2) the identities of variables and how they map to identity sets, (3) the constraints that the problem-solving placed on values that a particular identity can have, and (4) specific statistics about that chunk, such as whether correctness issues were detected or whether it required repair to make it fully operational.</p> <p>Finally, the explainer will also create the data necessary to visualize all of the processing described in an image using the new \u2019visualize\u2019 command. These visualization are the easiest way to quickly understand how a rule was formed.</p> <p>Note that, despite recording so much information, a lot of effort has been put into minimizing the cost of the explainer. When debugging, we often let it record all chunks and justifications formed because it is efficient enough to do so.</p> <p>Use the explain command without any arguments to display a summary of which rule firings the explainer is watching. It also shows which chunk or justification the user has specified is the current focus of its output, i.e. the chunk being discussed.</p> <p>Tip: This is a good way to get a chunk id so that you don\u2019t have to type or paste in a chunk name.</p> <p>This command starts the explanation process by specifying which chunk\u2019s explanation trace you want to explore.</p> <p>Tip: Use the alias to quickly start discussing a chunk, for example:</p> <p>Once you specify a rule to explain, this will be one of the first commands you issue.explain formation provides an explanation of the initial rule that fired which created a result. This is what is called the \u2018base instantiation\u2019 and is what led to the chunk being learned. Other rules may also be base instantiations if they previously created children of the base instantiation\u2019s results. They also will be listed in the initial formation output.  soar % explain formation</p> <pre><code>The formation of chunk \u2019chunk*apply*move-gripper-above*pass*top-state*OpNoChange*t6-1\u2019 (c 1)\n\nInitial base instantiation (i 31) that fired when apply*move-gripper-above*pass*top-state matched at level 3 at time 6:\nExplanation trace of instantiation # 31 (match of rule apply*move-gripper-above*pass*top-state at level 3)\n(produced chunk result)\nIdentities instead of variables Operational Creator\n1: (&lt;s&gt; ^operator &lt;op&gt;) ([159] ^operator [160]) No i 30 (pick-up*propose*move-gripper-above)\n2: (&lt;op&gt; ^name move-gripper-above) ([160] ^name move-gripper-above) No i 30 (pick-up*propose*move-gripper-above)\n3: (&lt;op&gt; ^destination &lt;des&gt;) ([160] ^destination [161]) No i 30 (pick-up*propose*move-gripper-above)\n4: (&lt;s&gt; ^top-state &lt;t*1&gt;) ([159] ^top-state [162]) No i 27 (elaborate*state*top-state)\n5: (&lt;t*1&gt; ^io &lt;i*1&gt;) ([162] ^io [163]) Yes Higher-level Problem Space\n6: (&lt;i*1&gt; ^output-link &lt;o*1&gt;) ([163] ^output-link [164]) Yes Higher-level Problem Space\n7: (&lt;o*1&gt; ^gripper &lt;gripper&gt;) ([164] ^gripper [165]) Yes Higher-level Problem Space\n--&gt;\n1: (&lt;gripper&gt; ^command move-gripper-above +) ([165] ^command move-gripper-above +)\n2: (&lt;gripper&gt; ^destination &lt;des&gt; +) ([165] ^destination [161] +)\n\n---\n\nThis chunk summarizes the problem-solving involved in the following 5\nrule firings:\ni 27 (elaborate*state*top-state)\ni 28 (elaborate*state*operator*name)\ni 29 (pick-up*elaborate*desired)\ni 30 (pick-up*propose*move-gripper-above)i 31 (apply*move-gripper-above*pass*top-state)\n\nexplain instantiation &lt;instantiation id&gt;\n</code></pre> <p>This command prints a specific instantiation in the explanation trace. This lets you browse the instantiation graph one rule at a time. This is probably one of the most common things you will do while using the explainer.</p> <p>Tip: Use the alias <code>i &lt;instantiation id&gt;</code> to quickly view an instantiation, for example:</p> <pre><code>soar % i 30\nExplanation trace of instantiation # 30 (match of rule pick-up*propose*move-gripper-above at level 3)\n\n- Shortest path to a result: i 30 -&gt; i 31\n  Identities instead of variables Operational Creator\n  1: (&lt;s&gt; ^name pick-up) ([152] ^name pick-up) No i 28 (elaborate*state*operator*name)\n  2: (&lt;s&gt; ^desired &lt;d*1&gt;) ([152] ^desired [153]) No i 29 (pick-up*elaborate*desired)\n  3: (&lt;d*1&gt; ^moving-block &lt;mblock&gt;) ([153] ^moving-block [154]) No i 29 (pick-up*elaborate*desired)\n  4: (&lt;s&gt; ^top-state &lt;ts&gt;) ([152] ^top-state [155]) No i 27 (elaborate*state*top-state)\n  5: (&lt;ts&gt; ^clear &lt;mblock&gt;) ([155] ^clear [154]) Yes Higher-level Problem Space\n  6: (&lt;ts&gt; ^gripper &lt;g&gt;) ([155] ^gripper [156]) Yes Higher-level Problem Space\n  7: (&lt;g&gt; ^position up) ([156] ^position up) Yes Higher-level Problem Space\n  8: (&lt;g&gt; ^holding nothing) ([156] ^holding nothing) Yes Higher-level Problem Space\n  9: (&lt;g&gt; ^above { &lt;&gt; &lt;mblock&gt; &lt;a*1&gt; }) ([156] ^above { &lt;&gt;[154] [157] }) Yes Higher-level Problem Space\n  --&gt;\n  1: (&lt;s&gt; ^operator &lt;op1&gt; +) ([152] ^operator [158] +)\n  2: (&lt;op1&gt; ^name move-gripper-above +) ([158] ^name move-gripper-above +)\n  3: (&lt;op1&gt; ^destination &lt;mblock&gt; +) ([158] ^destination [154] +)\n\nexplain [explanation-trace | wm-trace]\n</code></pre> <p>In most cases, users spend most of their time browsing the explanation trace. This is where chunking learns most of the subtle relationships that you are likely to be debugging. But users will also need to examine the working memory trace to see the specific values matched.</p> <p>To switch between traces, you can use the <code>explain e</code> and the <code>explain w</code> commands.</p> <p>Tip: Use <code>et</code> and <code>wt</code>, which are aliases to the above two commands, to quickly switch between traces.</p> <pre><code>soar % explain w\nWorking memory trace of instantiation # 30 (match of rule pick-up*propose*move-gripper-above at level 3)\n1: (S9 ^name pick-up) No i 28 (elaborate*state*operator*name)\n2: (S9 ^desired D6) No i 29 (pick-up*elaborate*desired)\n3: (D6 ^moving-block B3) No i 29 (pick-up*elaborate*desired)\n4: (S9 ^top-state S1) No i 27 (elaborate*state\\*top-state)\n5: (S1 ^clear B3) Yes Higher-level Problem Space\n6: (S1 ^gripper G2) Yes Higher-level Problem Space\n7: (G2 ^position up) Yes Higher-level Problem Space\n8: (G2 ^holding nothing) Yes Higher-level Problem Space\n9: (G2 ^above { &lt;&gt; B3 T1 }) Yes Higher-level Problem Space\n--&gt;\n1: (S9 ^operator O9) +\n2: (O9 ^name move-gripper-above) +\n3: (O9 ^destination B3) +\n\nexplain constraints\n</code></pre> <p>This feature lists all constraints found in non-operational constraints of the explanation trace. If these constraints were not met, the problem-solving would not have occurred.</p> <p>This feature is not yet implemented. You can use explain stats to see if any transitive constraints were added to a particular chunk.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#explain-identity","title":"explain identity","text":"<p>explain identity will show the mappings from variable identities to identity sets. If avail- able, the variable in a chunk that an identity set maps to will also be displayed.</p> <p>By default, only identity sets that appear in the chunk will be displayed in the identity analysis. To see the identity set mappings for other sets, change the only-chunk-identities setting to <code>off</code>.</p> <pre><code># soar % explain identity\n\n- # Variablization Identity to Identity Set Mappings -\n\n-== NULL Identity Set ==-\n\nThe following variable identities map to the null identity set and will\nnot be generalized: 282 301 138 291 355 336 227 309 328 318 128 218 345\n\n-== How variable identities map to identity sets ==-\n\nVariablization IDs Identity CVar Mapping Type\n\nInstantiation 36:\n125 -&gt; 482 | IdSet 12 | &lt;s&gt; | New identity set\n126 -&gt; 493 | IdSet 11 | &lt;o&gt; | New identity set\nInstantiation 38:\nInstantiation 41:\n146 -&gt; 482 | IdSet 12 | &lt;s&gt; | New identity set\n147 -&gt; 493 | IdSet 11 | &lt;o&gt; | New identity set\nInstantiation 42:\n151 -&gt; 180 | IdSet 1 | &lt;ss&gt; | New identity set\n149 -&gt; 482 | IdSet 12 | &lt;s&gt; | New identity set\n150 -&gt; 493 | IdSet 11 | &lt;o&gt; | New identity set\n307 -&gt; 180 | IdSet 1 | &lt;ss&gt; | Added to identity set\n187 -&gt; 180 | IdSet 1 | &lt;ss&gt; | Added to identity set\n334 -&gt; 180 | IdSet 1 | &lt;ss&gt; | Added to identity set\n173 -&gt; 180 | IdSet 1 | &lt;ss&gt; | Added to identity set\n280 -&gt; 180 | IdSet 1 | &lt;ss&gt; | Added to identity set\nInstantiation 53:\n219 -&gt; 489 | IdSet 15 | &lt;b&gt; | New identity set\nInstantiation 61:\nInstantiation 65:\n319 -&gt; 492 | IdSet 20 | &lt;t&gt; | New identity set\n\nexplain stats\n</code></pre> <p>Explain\u2019s <code>stat</code> command prints statistics about the specific chunk being discussed. This is a good way to see whether any generality or correctness issues were detected while learning that rule.</p> <pre><code>===========================================================\nStatistics for \u2019chunk*apply*move-gripper-above*pass*top-state*OpNoChange*t6-1\u2019 (c 1):\n===========================================================\nNumber of conditions 14\nNumber of actions 2\nBase instantiation i 31 (apply*move-gripper-above*pass\\*top-state)\n\n===========================================================\nGenerality and Correctness\n===========================================================\n\nTested negation in local substate No\nLHS required repair No\nRHS required repair No\nWas unrepairable chunk No\n\n===========================================================\nWork Performed\n===========================================================\nInstantiations backtraced through 5\nInstantiations skipped 6\nConstraints collected 1\nConstraints attached 0\nDuplicates chunks later created 0\nConditions merged 2\n</code></pre> <p>After-Action Reports The explainer has an option to create text files that contain statistics about the rules learned by an agent during a particular run. When enabled, the explainer will write out a file with the statistics when either Soar exits or a <code>soar init</code> is executed.  This option is still considered experimental and in beta.</p> A colored visualization of an explanation trace"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#visualizing-the-explanation","title":"Visualizing the Explanation","text":"<p>The <code>visualize</code> command can generate two graphical representations of the analysis that chunking performed to learn a rule. While the explainer provides more date, these images are the easiest and most effective ways to quickly understand how a chunk was formed, especially for particularly complex chunks. The visualizer can create two types of chunking- related images:</p> <ol> <li>An image that shows the entire instantiation graph at once and how it    contributed to the learned rule.  Use the command visualize ebc analysis to    create a very informative graph that shows all rules that fired in a substate    with arrows that indicate dependencies between actions in one rule and    conditions in others. In addition to all of the dependencies between the rules    that fired, this visualization also shows which conditions in the instantiations    tested knowledge in the superstate and hence became the basis for a condition in    the final learned rule. Finally, the individual elements in the explanation are    color-coded to show which variables share the same identity.</li> <li>An image that shows the graph of how variable identities were combined.  Use    the visualize identity graph to create a graph that shows how identities were    used to determine the variablization of a learned rule. This shows all    identities found in the chunk and how the identity analysis joined them based on    the problem-solving that occurred. This can be useful in determining why two    elements were assigned the same variable.</li> </ol> <p>Note that Soar will automatically attempt to launch a viewer to see the image generated. If you have an editor that can open Graphviz files, you can have Soar launch that automatically as well. (Such editors allow you to move things around and lay out the components of the image exactly as you want them.) Your operating system chooses which program to launch based on the file type.</p> <p>For the visualizer to work, you must have Graphviz and DOT installed, which are free third-party tools, and both must be available on your path. To date, the visualizer has only been tested on Mac and Linux. It is possible that certain systems may not allow Soar to launch an external program.</p>"},{"location":"soar_manual/04_ProceduralKnowledgeLearning/#footnotes","title":"Footnotes","text":"<ul> <li>[1]: Even though they don\u2019t contain variables,    justifications can be over-general because they don\u2019t incorporate enough    knowledge, for example, operator selection knowledge.</li> <li>[2]: Justifications can have variables in the negated    conditions and negated conjunctions of conditions. They just don\u2019t have any    variables in its positive conditions. </li> </ul>"},{"location":"soar_manual/05_ReinforcementLearning/","title":"Reinforcement Learning","text":"<p>Soar has a reinforcement learning (RL) mechanism that tunes operator selection knowledge based on a given reward function. This chapter describes the RL mechanism and how it is integrated with production memory, the decision cycle, and the state stack. We assume that the reader is familiar with basic reinforcement learning concepts and notation. If not, we recommend first reading Reinforcement Learning: An Introduction (1998) by Richard S. Sutton and Andrew G. Barto. The detailed behavior of the RL mechanism is determined by numerous parameters that can be controlled and configured via the <code>rl</code> command. Please refer to the documentation for that command in section 9.4.2 on page 238.</p>"},{"location":"soar_manual/05_ReinforcementLearning/#rl-rules","title":"RL Rules","text":"<p>Soar\u2019s RL mechanism learns Q-values for state-operator<sup>1</sup> pairs. Q-values are stored as numeric-indifferent preferences created by specially formulated productions called RL rules.  RL rules are identified by syntax. A production is a RL rule if and only if its left hand side tests for a proposed operator, its right hand side creates a single numeric-indifferent preference, and it is not a template rule (see Section 5.4.2 for template rules). These constraints ease the technical requirements of identifying/ updating RL rules and makes it easy for the agent programmer to add/ maintain RL capabilities within an agent. We define an RL operator as an operator with numeric-indifferent preferences created by RL rules.</p> <p>The following is an RL rule:</p> <pre><code>sp {rl*3*12*left\n  (state &lt;s&gt; ^name task-name\n    ^x 3\n    ^y 12\n    ^operator &lt;o&gt; +)\n  (&lt;o&gt; ^name move\n    ^direction left)\n--&gt;\n(&lt;s&gt; ^operator &lt;o&gt; = 1.5)\n}\n</code></pre> <p>Note that the LHS of the rule can test for anything as long as it contains a test for a proposed operator. The RHS is constrained to exactly one action: creating a numeric-indifferent preference for the proposed operator.</p> <p>The following are not RL rules:</p> <pre><code>sp {multiple*preferences\n(state &lt;s&gt; ^operator &lt;o&gt; +)\n--&gt;\n(&lt;s&gt; ^operator &lt;o&gt; = 5, &gt;)\n}\n\nsp {variable*binding\n(state &lt;s&gt; ^operator &lt;o&gt; +\n^value &lt;v&gt;)\n--&gt;\n(&lt;s&gt; ^operator &lt;o&gt; = &lt;v&gt;)\n}\n\nsp {invalid*actions\n(state &lt;s&gt; ^operator &lt;o&gt; +)\n--&gt;\n(&lt;s&gt; ^operator &lt;o&gt; = 5)\n(write (crlf) |This is not an RL rule.|)\n}\n</code></pre> <p>The first rule proposes multiple preferences for the proposed operator and thus does not comply with the rule format. The second rule does not comply because it does not provide a constant for the numeric-indifferent preference value. The third rule does not comply because it includes a RHS function action in addition to the numeric-indifferent preference action.</p> <p>In the typical RL use case, the user intends for the agent to learn the best operator in each possible state of the environment. The most straightforward way to achieve this is to give the agent a set of RL rules, each matching exactly one possible state-operator pair.  This approach is equivalent to a table-based RL algorithm, where the Q-value of each state- operator pair corresponds to the numeric-indifferent preference created by exactly one RL rule.</p> <p>In the more general case, multiple RL rules can match a single state-operator pair, and a single RL rule can match multiple state-operator pairs. That is, in Soar, a state-operator pair corresponds to an operator in a specific working memory context, and multiple rules can modify the preferences for a single operator, and a single rule can be instantiated multiple ways to modify preferences for multiple operators. For RL in Soar, all numeric-indifferent preferences for an operator are summed when calculating the operator\u2019s Q-value<sup>2</sup>. In this context, RL rules can be interpreted more generally as binary features in a linear approximator of each state-operator pair\u2019s Q-value, and their numeric-indifferent preference values their weights. In other words,</p> \\[Q(s, a) = w_1 \\phi_2 (s, a) + w_2 \\phi_2 (s, a) + \\ldots + w_n \\phi_n (s, a)\\] <p>where all RL rules in production memory are numbered \\(1 \\dots n\\), \\(Q(s, a)\\) is the Q-value of the state-operator pair \\((s, a)\\), \\(w_i\\) is the numeric-indifferent preference value of RL rule \\(i\\), \\(\\phi_i (s, a) = 0\\) if RL rule \\(i\\) does not match \\((s, a)\\), and \\(\\phi_i (s, a) = 1\\) if it does.  This interpretation allows RL rules to simulate a number of popular function approximation schemes used in RL such as tile coding and sparse coding.</p>"},{"location":"soar_manual/05_ReinforcementLearning/#reward-representation","title":"Reward Representation","text":"<p>RL updates are driven by reward signals. In Soar, these reward signals are given to the RL mechanism through a working memory link called the reward-link. Each state in Soar\u2019s state stack is automatically populated with a reward-link structure upon creation. Soar will check each structure for a numeric reward signal for the last operator executed in the associated state at the beginning of every decision phase. Reward is also collected when the agent is halted or a state is retracted.</p> <p>In order to be recognized, the reward signal must follow this pattern:</p> <pre><code>(&lt;r1&gt; ^reward &lt;r2&gt;)\n(&lt;r2&gt; ^value [val])\n</code></pre> <p>where <code>&lt;r1&gt;</code> is the reward-link identifier, <code>&lt;r2&gt;</code> is some intermediate identifier, and <code>[val]</code> is any constant numeric value. Any structure that does not match this pattern is ignored. If there are multiple valid reward signals, their values are summed into a single reward signal.  As an example, consider the following state:</p> <pre><code>(S1 ^reward-link R1)\n(R1 ^reward R2)\n(R2 ^value 1.0)\n(R1 ^reward R3)\n(R3 ^value -0.2)\n</code></pre> <p>In this state, there are two reward signals with values 1.0 and -0.2. They will be summed together for a total reward of 0.8 and this will be the value given to the RL update algorithm.</p> <p>There are two reasons for requiring the intermediate identifier. The first is so that multiple reward signals with the same value can exist simultaneously. Since working memory is a set, multiple WMEs with identical values in all three positions (identifier, attribute, value) cannot exist simultaneously. Without an intermediate identifier, specifying two rewards with the same value would require a WME structure such as</p> <pre><code>(S1 ^reward-link R1)\n(R1 ^reward 1.0)\n(R1 ^reward 1.0)\n</code></pre> <p>which is invalid. With the intermediate identifier, the rewards would be specified as</p> <pre><code>(S1 ^reward-link R1)\n(R1 ^reward R2)\n(R2 ^value 1.0)\n(R1 ^reward R3)\n(R3 ^value 1.0)\n</code></pre> <p>which is valid. The second reason for requiring an intermediate identifier in the reward signal is so that the rewards can be augmented with additional information, such as their source or how long they have existed. Although this information will be ignored by the RL mechanism, it can be useful to the agent or programmer. For example:</p> <pre><code>(S1 ^reward-link R1)\n(R1 ^reward R2)\n(R2 ^value 1.0)\n(R2 ^source environment)\n(R1 ^reward R3)\n(R3 ^value -0.2)\n(R3 ^source intrinsic)\n(R3 ^duration 5)\n</code></pre> <p>The <code>(R2 ^source environment)</code>,<code>(R3 ^source intrinsic)</code>, and <code>(R3 ^duration 5)</code> WMEs are arbitrary and ignored by RL, but were added by the agent to keep track of where the rewards came from and for how long.</p> <p>Note that the reward-link is not part of the io structure and is not modified directly by the environment. Reward information from the environment should be copied, via rules, from the input-link to the reward-link. Also note that when collecting rewards, Soar simply scans the reward-link and sums the values of all valid reward WMEs. The WMEs are not modified and no bookkeeping is done to keep track of previously seen WMEs. This means that reward WMEs that exist for multiple decision cycles will be collected multiple times if not removed or retracted.</p>"},{"location":"soar_manual/05_ReinforcementLearning/#updating-rl-rule-values","title":"Updating RL Rule Values","text":"<p>Soar\u2019s RL mechanism is integrated naturally with the decision cycle and performs online updates of RL rules. Whenever an RL operator is selected, the values of the corresponding RL rules will be updated. The update can be on-policy (Sarsa) or off-policy (Q-Learning), as controlled by the learning-policy parameter of the rl command. (See page 238.) Let \\(\\delta_t\\) be the amount of change for the Q-value of an RL operator in a single update. For Sarsa, we have</p> \\[ \\delta_t = \\alpha \\left[ r_{t+1} + \\gamma Q(s_{t+1}, a_{t+1}) - Q(s_t, a_t) \\right] \\] <p>where</p> <ul> <li>\\(Q(s_t, a_t)\\) is the Q-value of the state and chosen operator in decision cycle \\(t\\).</li> <li>\\(Q(s_{t+1}, a_{t+1})\\) is the Q-value of the state and chosen RL operator in the next decision cycle.</li> <li>\\(r_{t+1}\\) is the total reward collected in the next decision cycle.</li> <li>\\(\\alpha\\) and \\(\\gamma\\) are the settings of the learning-rate and discount-rate parameters of the <code>rl</code> command, respectively.</li> </ul> <p>Note that since \\(\\delta_t\\) depends on \\(Q(s_{t+1}, a_{t+1})\\), the update for the operator selected in decision cycle \\(t\\) is not applied until the next RL operator is chosen.  For Q-Learning, we have  where \\(A_{t+1}\\) is the set of RL operators proposed in the next decision cycle.</p> <p>Finally, \\(\\delta_t\\) is divided by the number of RL rules comprising the Q-value for the operator and the numeric-indifferent values for each RL rule is updated by that amount.</p> <p>An example walkthrough of a Sarsa update with \\(\\alpha = 0.3\\) and \\(\\gamma = 0.9\\) (the default settings in Soar) follows.</p> <ol> <li> <p>In decision cycle \\(t\\), an operator <code>O1</code> is proposed, and RL rules rl-1   and rl-2 create the following numeric-indifferent preferences for it:   <pre><code>rl-1: (S1 ^operator O1 = 2.3)\nrl-2: (S1 ^operator O1 = -1)\n</code></pre>   The Q-value for <code>O1</code> is \\(Q(s_t, \\textbf{O1}) = 2.3 - 1 = 1.3\\).</p> </li> <li> <p><code>O1</code> is selected and executed, so  \\(Q(s_t, a_t) = Q(s_t, \\textbf{O1}) = 1.3\\).</p> </li> <li> <p>In decision cycle \\(t+1\\), a total reward of 1.0 is collected on the   reward-link, an operator O2is proposed, and another RL rule rl-3 creates the   following numeric-indifferent preference for it:   <pre><code>rl-3: (S1 ^operator O2 = 0.5)\n</code></pre></p> </li> </ol> <p>So \\(Q(s_{t+1}, \\textbf{O2}) = 0.5\\).</p> <ol> <li><code>O2</code> is selected, so  \\(Q(s_{t+1}, a_{t+1}) = Q(s_{t+1}, \\textbf{O2}) = 0.5\\) Therefore,</li> </ol> \\[\\delta_t = \\alpha \\left[r_{t+1} + \\gamma Q(s_{t+1}, a_{t+1}) - Q(s_t, a_t) \\right] = 0.3 \\times [ 1.0 + 0.9 \\times 0.5 - 1.3 ] = 0.045\\] <p>Since rl-1 and rl-2 both contributed to the Q-value of O1, \\(\\delta_t\\) is evenly divided amongst them, resulting in updated values of</p> <pre><code>rl-1: (&lt;s&gt; ^operator &lt;o&gt; = 2.3225)\nrl-2: (&lt;s&gt; ^operator &lt;o&gt; = -0.9775)\n</code></pre> <ol> <li>rl-3 will be updated when the next RL operator is selected.</li> </ol>"},{"location":"soar_manual/05_ReinforcementLearning/#gaps-in-rule-coverage","title":"Gaps in Rule Coverage","text":"<p>The previous description had assumed that RL operators were selected in both decision cyclestandt+ 1. If the operator selected int+ 1 is not an RL operator, thenQ(st+1,at+1) would not be defined, and an update for the RL operator selected at timetwill be undefined. We will call a sequence of one or more decision cycles in which RL operators are not selected between two decision cycles in which RL operators are selected agap. Conceptually, it is desirable to use the temporal difference information from the RL operator after the gap to update the Q-value of the RL operator before the gap. There are no intermediate storage locations for these updates. Requiring that RL rules support operators at every decision can be difficult for agent programmers, particularly for operators that do not represent steps in a task, but instead perform generic maintenance functions, such as cleaning processed output-link structures.</p> <p>To address this issue, Soar's RL mechanism supports automatic propagation of updates over gaps. For a gap of length \\(n\\), the Sarsa update is \\(\\(\\delta_t = \\alpha \\left[ \\sum_{i=t}^{t+n}{\\gamma^{i-t} r_i} + \\gamma^{n+1} Q(s_{t+n+1}, a_{t+n+1}) - Q(s_t, a_t) \\right]\\)\\) and the Q-Learning update is \\(\\(\\delta_t = \\alpha \\left[ \\sum_{i=t}^{t+n}{\\gamma^{i-t} r_i} + \\gamma^{n+1} \\underset{a \\in A_{t+n+1}}{\\max} Q(s_{t+n+1}, a) - Q(s_t, a_t) \\right]\\)\\)</p> <p>Note that rewards will still be collected during the gap, but they are discounted based on the number of decisions they are removed from the initial RL operator.</p> <p>Gap propagation can be disabled by setting the temporal-extension parameter of the rl command to off. When gap propagation is disabled, the RL rules preceding a gap are updated usingQ(st+1,at+1) = 0. The rl setting of the watch command (see Section 9.6.1 on page 259) is useful in identifying gaps.</p> Example Soar substate operator trace."},{"location":"soar_manual/05_ReinforcementLearning/#rl-and-substates","title":"RL and Substates","text":"<p>When an agent has multiple states in its state stack, the RL mechanism will treat each substate independently. As mentioned previously, each state has its own reward-link. When an RL operator is selected in a stateS, the RL updates for that operator are only affected by the rewards collected on the reward-link for Sand the Q-values of subsequent RL operators selected inS.</p> <p>The only exception to this independence is when a selected RL operator forces an operator- no-change impasse. When this occurs, the number of decision cycles the RL operator at the superstate remains selected is dependent upon the processing in the impasse state. Consider the operator trace in Figure 5.1.</p> <p>\u0088At decision cycle 1, RL operatorO1is selected inS1and causes an operator-no-change impass for three decision cycles.  \u0088In the substateS2, operatorsO2,O3, andO4are selected and applied sequentially.  \u0088Meanwhile inS1, rewardsr 2 ,r 3 , andr 4 are put on thereward-linksequentially.  \u0088Finally, the impasse is resolved by O4, the proposal for O1 is retracted, and RL operatorO5is selected inS1.</p> <p>In this scenario, only the RL update forQ(s 1 ,O1) will be different from the ordinary case.  Its value depends on the setting of the hrl-discount parameter of the rlcommand.  When this parameter is set to the default valueon, the rewards onS1and the Q-value of O5are discounted by the number of decision cycles they are removed from the selection of O1. In this case the update for  \\(Q(s_1, \\textbf{O1})\\) is</p> \\[\\delta_1 = \\alpha \\left[ r_2 + \\gamma r_3 + \\gamma^2 r_4 + \\gamma^3 Q(s_5, \\textbf{O5}) - Q(s_1, \\textbf{O1}) \\right]\\] <p>which is equivalent to having a three decision gap separating <code>O1</code> and <code>O5</code>.</p> <p>When hrl-discount is set to off, the number of cycles O1has been impassed will be ignored. Thus the update would be</p> \\[\\delta_1 = \\alpha \\left[ r_2 + r_3 + r_4 + \\gamma Q(s_5, \\textbf{O5}) - Q(s_1, \\textbf{O1}) \\right]\\] <p>For impasses other than operator no-change, RL acts as if the impasse hadn\u2019t occurred. If O1is the last RL operator selected before the impasse,r 2 the reward received in the decision cycle immediately following, and On, the first operator selected after the impasse, thenO1 is updated with </p> \\[\\delta_1 = \\alpha \\left[ r_2 + \\gamma Q(s_n, \\textbf{O}_\\textbf{n}) - Q(s_1, \\textbf{O1}) \\right]\\] <p>If an RL operator is selected in a substate immediately prior to the state\u2019s retraction, the RL rules will be updated based only on the reward signals present and not on the Q-values of future operators. This point is not covered in traditional RL theory. The retraction of a substate corresponds to a suspension of the RL task in that state rather than its termination, so the last update assumes the lack of information about future rewards rather than the discontinuation of future rewards. To handle this case, the numeric-indifferent preference value of each RL rule is stored as two separate values, the expected current reward(ECR) and expected future reward (EFR). The ECR is an estimate of the expected immediate reward signal for executing the corresponding RL operator. The EFR is an estimate of the time discounted Q-value of the next RL operator. Normal updates correspond to traditional RL theory (showing the Sarsa case for simplicity):</p> \\[ \\delta_{ECR} = \\alpha \\left[ r_t - ECR(s_t, a_t) \\right] \\] \\[ \\delta_{EFR} = \\alpha \\left[ \\gamma Q(s_{t+1}, a_{t+1}) - EFR(s_t, a_t) \\right] \\] \\[ \\delta_t = \\delta_{ECR} + \\delta_{EFR} \\] \\[ = \\alpha \\left[ r_t + \\gamma Q(s_{t+1}, a_{t+1}) - \\left( ECR(s_t, a_t) + EFR(s_t, a_t) \\right) \\right] \\] \\[ = \\alpha \\left[ r_t + \\gamma Q(s_{t+1}, a_{t+1}) - Q(s_t, a_t) \\right] \\] <p>During substate retraction, only the ECR is updated based on the reward signals present at the time of retraction, and the EFR is unchanged.</p> <p>Soar\u2019s automatic subgoaling and RL mechanisms can be combined to naturally implement hierarchical reinforcement learning algorithms such as MAXQ and options.</p>"},{"location":"soar_manual/05_ReinforcementLearning/#eligibility-traces","title":"Eligibility Traces","text":"<p>The RL mechanism supports eligibility traces, which can improve the speed of learning by updating RL rules across multiple sequential steps. The eligibility-trace-decay-rate and eligibility-trace-tolerance parameters control this mechanism. By setting eligibility-trace-decay-rate to 0 (de- fault), eligibility traces are in effect disabled. When eligibility traces are enabled, the particular algorithm used is dependent upon the learning policy. For Sarsa, the eligibility trace implementation isSarsa(\\(\\lambda\\)). For Q-Learning, the eligibility trace implementation is Watkin's Q(\\(\\lambda\\))*.</p>"},{"location":"soar_manual/05_ReinforcementLearning/#exploration","title":"Exploration","text":"<p>The decide indifferent-selection command (page 198) determines how operators are selected based on their numeric-indifferent preferences. Although all the indifferent selection settings are valid regardless of how the numeric-indifferent preferences were arrived at, the epsilon-greedy and boltzmann settings are specifically designed for use with RL and cor- respond to the two most common exploration strategies. In an effort to maintain backwards compatibility, the default exploration policy is soft max. As a result, one should change to epsilon-greedy or boltzmann when the reinforcement learning mechanism is enabled.</p>"},{"location":"soar_manual/05_ReinforcementLearning/#gqlambda","title":"GQ(\\(\\lambda\\))","text":"<p>Sarsa(\\(\\lambda\\)) and Watkin\u2019s Q(\\(\\lambda\\)) help agents to solve the temporal credit assignment problem more quickly. However, if you wish to implement something akin to CMACs to generalize from experience, convergence is not guaranteed by these algorithms. GQ(\\(\\lambda\\)) is a gradient descent algorithm designed to ensure convergence when learning off-policy. Soar\u2019s learning-policy can be set to on-policy-gq-lambda or off-policy-gq-lambda to increase the likelihood of convergence when learning under these conditions. If you should choose to use one of these algorithms, we recommend setting the rl step-size-parameter to something small, such as 0.01 in order to ensure that the secondary set of weights used by GQ(\\(\\lambda\\))change slowly enough for efficient convergence.</p>"},{"location":"soar_manual/05_ReinforcementLearning/#automatic-generation-of-rl-rules","title":"Automatic Generation of RL Rules","text":"<p>The number of RL rules required for an agent to accurately approximate operator Q-values is usually unfeasibly large to write by hand, even for small domains. Therefore, several methods exist to automate this.</p>"},{"location":"soar_manual/05_ReinforcementLearning/#the-gp-command","title":"The gp Command","text":"<p>The gp command can be used to generate productions based on simple patterns. This is useful if the states and operators of the environment can be distinguished by a fixed number of dimensions with finite domains. An example is a grid world where the states are described by integer row/column coordinates, and the available operators are to move north, south, east, or west. In this case, a single gp command will generate all necessary RL rules:</p> <pre><code>gp {gen*rl*rules\n(state &lt;s&gt; ^name gridworld\n^operator &lt;o&gt; +\n^row [ 1 2 3 4 ]\n^col [ 1 2 3 4 ])\n(&lt;o&gt; ^name move\n^direction [ north south east west ])\n--&gt;\n(&lt;s&gt; ^operator &lt;o&gt; = 0.0)\n}\n</code></pre> <p>For more information see the documentation for this command on page 205.</p>"},{"location":"soar_manual/05_ReinforcementLearning/#rule-templates","title":"Rule Templates","text":"<p>Rule templates allow Soar to dynamically generate new RL rules based on a predefined pattern as the agent encounters novel states. This is useful when either the domains of environment dimensions are not known ahead of time, or when the enumerable state space of the environment is too large to capture in its entirety using gp, but the agent will only encounter a small fraction of that space during its execution. For example, consider the grid world example with 1000 rows and columns. Attempting to generate RL rules for each grid cell and action a priori will result in \\(1000 \\times 1000 \\times 4 = 4 \\times 10^6\\) productions. However, if most of those cells are unreachable due to walls, then the agent will never fire or update most of those productions. Templates give the programmer the convenience of the gp command without filling production memory with unnecessary rules.</p> <p>Rule templates have variables that are filled in to generate RL rules as the agent encounters novel combinations of variable values. A rule template is valid if and only if it is marked with the :template flag and, in all other respects, adheres to the format of an RL rule.  However, whereas an RL rule may only use constants as the numeric-indifference preference value, a rule template may use a variable. Consider the following rule template:</p> <pre><code>sp {sample*rule*template\n:template\n(state &lt;s&gt; ^operator &lt;o&gt; +\n^value &lt;v&gt;)\n--&gt;\n(&lt;s&gt; ^operator &lt;o&gt; = &lt;v&gt;)\n}\n</code></pre> <p>During agent execution, this rule template will match working memory and create new productions by substituting all variables in the rule template that matched against constant values with the values themselves. Suppose that the LHS of the rule template matched against the state</p> <pre><code>(S1 ^value 3.2)\n(S1 ^operator O1 +)\n</code></pre> <p>Then the following production will be added to production memory:</p> <pre><code>sp {rl*sample*rule*template*1\n(state &lt;s&gt; ^operator &lt;o&gt; +\n^value 3.2)\n--&gt;\n(&lt;s&gt; ^operator &lt;o&gt; = 3.2)\n}\n</code></pre> <p>The variable <code>&lt;v&gt;</code> is replaced by3.2on both the LHS and the RHS, but <code>&lt;s&gt;</code> and <code>&lt;o&gt;</code> are not replaced because they matches against identifiers (S1andO1). As with other RL rules, the value of3.2on the RHS of this rule may be updated later by reinforcement learning, whereas the value of 3.2 on the LHS will remain unchanged.  If <code>&lt;v&gt;</code> had matched against a non-numeric constant, it will be replaced by that constant on the LHS, but the RHS numeric-indifference preference value will be set to zero to make the new rule valid.</p> <p>The new production\u2019s name adheres to the following pattern:rltemplate-nameid, where template-name is the name of the originating rule template and id is monotonically increasing integer that guarantees the uniqueness of the name.</p> <p>If an identical production already exists in production memory, then the newly generated production is discarded. It should be noted that the current process of identifying unique template match instances can become quite expensive in long agent runs. Therefore, it is recommended to generate all necessary RL rules using the gp command or via custom scripting when possible.</p>"},{"location":"soar_manual/05_ReinforcementLearning/#chunking","title":"Chunking","text":"<p>Since RL rules are regular productions, they can be learned by chunking just like any other production. This method is more general than using the gp command or rule templates, and is useful if the environment state consists of arbitrarily complex relational structures that cannot be enumerated.</p>"},{"location":"soar_manual/05_ReinforcementLearning/#footnotes","title":"Footnotes","text":"<ul> <li>[1]: In this context, the term \"state\" refers to the state of the task or environment, not a state identifier.  For the rest of this chapter, bold capital letter names such as S1 will refer to identifiers and italic lowercase names such as \\(s_1\\) will refer to task states.</li> <li>[2]: This is assuming the value of numeric-indifferent-mode is set to sum. In general, the RL mechanism only works correctly when this is the case, and we assume this case in the rest of the chapter. See page 198 for more information about this parameter.</li> </ul>"},{"location":"soar_manual/06_SemanticMemory/","title":"Semantic Memory","text":"<p>Soar\u2019s semantic memory is a repository for long-term declarative knowledge, supplement- ing what is contained in short-term working memory (and production memory). Episodic memory, which contains memories of the agent\u2019s experiences, is described in Chapter 7. The knowledge encoded in episodic memory is organized temporally, and specific information is embedded within the context of when it was experienced, whereas knowledge in semantic memory is independent of any specific context, representing more general facts about the world.</p> <p>This chapter is organized as follows: semantic memory structures in working memory; representation of knowledge in semantic memory; storing semantic knowledge; retrieving semantic knowledge; and a discussion of performance. The detailed behavior of semantic memory is determined by numerous parameters that can be controlled and configured via the smem command. Please refer to the documentation for that command in Section 9.5.1 on page 243.</p>"},{"location":"soar_manual/06_SemanticMemory/#working-memory-structure","title":"Working Memory Structure","text":"<p>Upon creation of a new state in working memory (see Section 2.7.1 on page 28; Section 3.4 on page 85), the architecture creates the following augmentations to facilitate agent interaction with semantic memory:</p> <pre><code>(&lt;s&gt; ^smem &lt;smem&gt;)\n(&lt;smem&gt; ^command &lt;smem-c&gt;)\n(&lt;smem&gt; ^result &lt;smem-r&gt;)\n</code></pre> <p>As rules augment the command structure in order to access/change semantic knowledge (6.3, 6.4), semantic memory augments the result structure in response. Production actions should not remove augmentations of the result structure directly, as semantic memory will maintain these WMEs.</p> <p>Figure 6.1: Example long-term identifier with four augmentations.</p>"},{"location":"soar_manual/06_SemanticMemory/#knowledge-representation","title":"Knowledge Representation","text":"<p>The representation of knowledge in semantic memory is similar to that in working memory (see Section 2.2 on page 14) \u2013 both include graph structures that are composed of symbolic elements consisting of an identifier, an attribute, and a value. It is important to note, however, key differences:</p> <p>Currently semantic memory only supports attributes that are symbolic constants (string, integer, or decimal), but not attributes that are identifiers</p> <p>Whereas working memory is a single, connected, directed graph, semantic memory can be disconnected, consisting of multiple directed, connected sub-graphs</p> <p>From Soar 9.6 onward, Long-termidentifiers (LTIs) are defined as identifiers that exist in semantic memory only. Each LTI is permanently associated with a specific number that labels it (e.g. @5 or @7). Instances of an LTI can be loaded into working memory as regular short-term identifiers (STIs) linked with that specific LTI. For clarity, when printed, a short-term identifier associated with an LTI is followed with the label of that LTI. For example, if the working memory ID L7 is associated with the LTI named <code>@29</code>, printing that STI would appear as <code>L7</code> (<code>@29</code>).</p> <p>When presented in a figure, long-term identifiers will be indicated by a double-circle. For instance, Figure 6.1 depicts the long-term identifier @68, with four augmentations, representing the addition fact of <code>6 + 7 = 13</code> (or, rather, 3, carry 1, in context of multi-column arithmetic).</p>"},{"location":"soar_manual/06_SemanticMemory/#integrating-long-term-identifiers-with-soar","title":"Integrating Long-Term Identifiers with Soar","text":"<p>Integrating long-term identifiers in Soar presents a number of theoretical and implementation challenges. This section discusses the state of integration with each of Soar\u2019s memories/learning mechanisms.</p>"},{"location":"soar_manual/06_SemanticMemory/#working-memory","title":"Working Memory","text":"<p>Long-term identifiers themselves never exist in working memory. Rather, instances of long term memories are loaded into working memory as STIs through queries or retrievals, and manipulated just like any other WMEs. Changes to any STI augmentations do not directly have any effect upon linked LTIs in semantic memory. Changes to LTIs themselves only occur though store commands on the command link or through command-line directives such as <code>smem --add</code> (see below).</p> <p>Each time an agent loads an instance of a certain LTI from semantic memory into working memory using queries or retrievals, the instance created will always be a new unique STI. This means that if same long-term memory is retrieved multiple times in succession, each retrieval will result in a different STI instance, each linked to the same LTI. A benefit of this is that a retrieved long-term memory can be modified without compromising the ability to recall what the actual stored memory is.^1</p> <p>(^1) Before Soar 9.6, LTIs were themselves retrieved into working memory. This meant all augmentations to such IDs, whether from the original retrieval or added after retrieval, would always be merged under the same ID, unless deep-copy was used to make a duplicate short-term memory.</p>"},{"location":"soar_manual/06_SemanticMemory/#procedural-memory","title":"Procedural Memory","text":"<p>Soar productions can use various conditions to test whether an STI is associated with an LTI or whether two STIs are linked to the same LTI (see Section 3.3.5.3 on page 53). LTI names (e.g. <code>@6</code>) may not appear in the action side of productions.</p>"},{"location":"soar_manual/06_SemanticMemory/#episodic-memory","title":"Episodic Memory","text":"<p>Episodic memory (see Section 7 on page 157) faithfully captures LTI-linked STIs, including the episode of transition. Retrieved episodes contain STIs as they existed during the episode, regardless of any changes to linked LTIs that transpired since the episode occurred.</p>"},{"location":"soar_manual/06_SemanticMemory/#storing-semantic-knowledge","title":"Storing Semantic Knowledge","text":""},{"location":"soar_manual/06_SemanticMemory/#store-command","title":"Store command","text":"<p>An agent stores a long-term identifier in semantic memory by creating a ^store command: this is a WME whose identifier is the command link of a state\u2019s smem structure, the attribute is store, and the value is a short-term identifier.</p> <pre><code>&lt;s&gt; ^smem.command.store &lt;identifier&gt;\n</code></pre> <p>Semantic memory will encode and store all WMEs whose identifier is the value of the store command. Storing deeper levels of working memory is achieved through multiple store commands.</p> <p>Multiple store commands can be issued in parallel. Storage commands are processed on every state at the end of every phase of every decision cycle. Storage is guaranteed to succeed and a status WME will be created, where the identifier is the ^result link of the smem structure of that state, the attribute is success, and the value is the value of the store command above.</p> <pre><code>&lt;s&gt; ^smem.result.success &lt;identifier&gt;\n</code></pre> <p>If the identifier used in the store command is not linked to any existing LTIs, a new LTI will be created in smem and the stored STI will be linked to it. If the identifier used in the store command is already linked to an LTI, the store will overwrite that long-term memory. For example, if an existing LTI@5had augmentations^A do ^B re ^C mi, and a storecommand stored short-term identifierL35which was linked to@5but had only the augmentation^D fa, the LTI@5would be changed to only have^D fa.</p>"},{"location":"soar_manual/06_SemanticMemory/#store-new-command","title":"Store-new command","text":"<p>The ^store-new command structure is just like the ^store command, except that smem will always store the given memory as an entirely new structure, regardless of whether the given STI was linked to an existing LTI or not. Any STIs that don\u2019t already have links will get linked to the newly created LTIs. But if a stored STI was already linked to some LTI, Soar will not re-link it to the newly created LTI.</p> <p>If this behavior is not desired, the agent can add a ^link-to-new-LTM yes augmentation to override this behavior. One use for this setting is to allow chunking to backtrace through a stored memory in a manner that will be consistent with a later state of memory when the newly stored LTI is retrieved again.</p>"},{"location":"soar_manual/06_SemanticMemory/#user-initiated-storage","title":"User-Initiated Storage","text":"<p>Semantic memory provides agent designers the ability to store semantic knowledge via the add switch of the smem command (see Section 9.5.1 on page 243). The format of the command is nearly identical to the working memory manipulation components of the RHS of a production (i.e. no RHS-functions; see Section 3.3.6 on page 67). For instance:</p> <pre><code>smem --add {\n(&lt;arithmetic&gt; ^add10-facts &lt;a01&gt; &lt;a02&gt; &lt;a03&gt;)\n(&lt;a01&gt; ^digit1 1 ^digit-10 11)\n(&lt;a02&gt; ^digit1 2 ^digit-10 12)\n(&lt;a03&gt; ^digit1 3 ^digit-10 13)\n}\n</code></pre> <p>Unlike agent storage, declarative storage is automatically recursive. Thus, this command instance will add a new long-term identifier (represented by the temporary \u2019arithmetic\u2019 variable) with three augmentations. The value of each augmentation will each become an LTI with two constant attribute/value pairs. Manual storage can be arbitrarily complex and use standard dot-notation. The add command also supports hardcoded LTI ids such as@1in place of variables.</p>"},{"location":"soar_manual/06_SemanticMemory/#storage-location","title":"Storage Location","text":"<p>Semantic memory uses SQLite to facilitate efficient and standardized storage and querying of knowledge. The semantic store can be maintained in memory or on disk (per the database and path parameters; see Section 9.5.1). If the store is located on disk, users can use any standard SQLite programs/components to access/query its contents. However, using a disk- based semantic store is very costly (performance is discussed in greater detail in Section 6.5 on page 155), and running in memory is recommended for most runs.</p> <p>Note that changes to storage parameters, for example database, path and append will not have an effect until the database is used after an initialization. This happens either shortly after launch (on first use) or after a database initialization command is issued. To switch databases or database storage types while running, set your new parameters and then perform an \u2013init command.</p> <p>The path parameter specifies the file system path the database is stored in. When path is set to a valid file system path and database mode is set to file, then the SQLite database is written to that path.</p> <p>The append parameter will determine whether all existing facts stored in a database on disk will be erased when semantic memory loads. Note that this affects soar init also. In other words, if the append setting is off, all semantic facts stored to disk will be lost when a soar init is performed. For semantic memory,append mode is on by default.</p> <p>Note: As of version 9.3.3, Soar used a new schema for the semantic memory database. This means databases from 9.3.2 and below can no longer be loaded. A conversion utility is available in Soar 9.4 to convert from the old schema to the new one.</p> <p>The lazy-commit parameter is a performance optimization. If set to on(default), disk databases will not reflect semantic memory changes until the Soar kernel shuts down. This improves performance by avoiding disk writes. The optimization parameter (see Section</p>"},{"location":"soar_manual/06_SemanticMemory/#retrieving-semantic-knowledge","title":"Retrieving Semantic Knowledge","text":"<p>An agent retrieves knowledge from semantic memory by creating an appropriate command (we detail the types of commands below) on the command link of a state\u2019s smem structure. At the end of the output of each decision, semantic memory processes each state\u2019s smem <code>^command</code> structure. Results, meta-data, and errors are added to the result structure of that state\u2019s smems tructure.</p> <p>Only one type of retrieval command (which may include optional modifiers) can be issued per state in a single decision cycle. Malformed commands (including attempts at multiple retrieval types) will result in an error:</p> <pre><code>&lt;s&gt; ^smem.result.bad-cmd &lt;smem-c&gt;\n</code></pre> <p>Where the <code>&lt;smem-c&gt;</code> variable refers to the command structure of the state.</p> <p>After a command has been processed, semantic memory will ignore it until some aspect of the command structure changes (via addition/removal of WMEs). When this occurs, the result structure is cleared and the new command (if one exists) is processed.</p>"},{"location":"soar_manual/06_SemanticMemory/#non-cue-based-retrievals","title":"Non-Cue-Based Retrievals","text":"<p>A non-cue-based retrieval is a request by the agent to reflect in working memory the current augmentations of an LTI in semantic memory. The command WME has a retrieve attribute and an LTI-linked identifier value:</p> <pre><code>&lt;s&gt; ^smem.command.retrieve &lt;lti&gt;\n</code></pre> <p>If the value of the command is not an LTI-linked identifier, an error will result:</p> <pre><code>&lt;s&gt; ^smem.result.failure &lt;lti&gt;\n</code></pre> <p>Otherwise, two new WMEs will be placed on the result structure:</p> <pre><code>&lt;s&gt; ^smem.result.success &lt;lti&gt;\n&lt;s&gt; ^smem.result.retrieved &lt;lti&gt;\n</code></pre> <p>All augmentations of the long-term identifier in semantic memory will be created as new WMEs in working memory.</p>"},{"location":"soar_manual/06_SemanticMemory/#cue-based-retrievals","title":"Cue-Based Retrievals","text":"<p>A cue-based retrieval performs a search for a long-term identifier in semantic memory whose augmentations exactly match an agent-supplied cue, as well as optional cue modifiers.</p> <p>A cue is composed of WMEs that describe the augmentations of a long-term identifier. A cue WME with a constant value denotes an exact match of both attribute and value. A cue WME with an LTI-linked identifier as its value denotes an exact match of attribute and linked LTI. A cue WME with a short-term identifier as its value denotes an exact match of attribute, but with any value (constant or identifier).</p> <p>A cue-based retrieval command has a query attribute and an identifier value, the cue:</p> <pre><code>&lt;s&gt; ^smem.command.query &lt;cue&gt;\n</code></pre> <p>For instance, consider the following rule that creates a cue-based retrieval command:</p> <pre><code>sp {smem*sample*query\n(state &lt;s&gt; ^smem.command &lt;scmd&gt;\n^lti &lt;lti&gt;\n^input-link.foo &lt;bar&gt;)\n--&gt;\n(&lt;scmd&gt; ^query &lt;q&gt;)\n(&lt;q&gt; ^name &lt;any-name&gt;\n^foo &lt;bar&gt;\n^associate &lt;lti&gt;\n^age 25)\n}\n</code></pre> <p>In this example, assume that the <code>&lt;lti&gt;</code> variable will match a short-term identifier which is linked to a long-term identifier and that the <code>&lt;bar&gt;</code> variable will match a constant. Thus, the query requests retrieval of a long-term memory with augmentations that satisfy ALL of the following requirements:</p> <ul> <li>Attribute name with ANY value</li> <li>Attribute foo with value equal to that of variable <code>&lt;bar&gt;</code> at the time this rule fires</li> <li>Attribute associate with value that is the same long-term identifier as that linked to by the <code>&lt;lti&gt;</code> STI at the time this rule fires</li> <li>Attribute age with integer value 25</li> </ul> <p>If no long-term identifier satisfies ALL of these requirements, an error is returned:</p> <pre><code>&lt;s&gt; ^smem.result.failure &lt;cue&gt;\n</code></pre> <p>Otherwise, two WMEs are added:</p> <pre><code>&lt;s&gt; ^smem.result.success &lt;cue&gt;\n&lt;s&gt; ^smem.result.retrieved &lt;retrieved-lti&gt;\n</code></pre> <p>The result <code>&lt;retrieved-lti&gt;</code> will be a new short-term identifier linked to the result LTI.</p> <p>As with non-cue-based retrievals, all of the augmentations of the long-term identifier in semantic memory are added as new WMEs to working memory. If these augmentations include other LTIs in smem, they too are instantiated into new short-term identifiers in working memory.</p> <p>It is possible that multiple long-term identifiers match the cue equally well. In this case, se- mantic memory will retrieve the long-term identifier that was most recently stored/retrieved. (More accurately, it will retrieve the LTI with the greatest activation value. See below.)</p> <p>The cue-based retrieval process can be further tempered using optional modifiers:</p> <p>The prohibit command requires that the retrieved long-term identifier is not equal to that linked with the supplied long-term identifier:</p> <pre><code>&lt;s&gt; ^smem.command.prohibit &lt;bad-lti&gt;\n</code></pre> <p>Multiple prohibit command WMEs may be issued as modifiers to a single cue-based retrieval. This method can be used to iterate over all matching long-term identifiers.</p> <p>The neg-query command requires that the retrieved long-term identifier does NOT contain a set of attributes/attribute-value pairs:</p> <pre><code>&lt;s&gt; ^smem.command.neg-query &lt;cue&gt;\n</code></pre> <p>The syntax of this command is identical to that of regular/ positive query command.</p> <p>The math-query command requires that the retrieved long term identifier contains an attribute value pair that meets a specified mathematical condition. This condition can either be a conditional query or a superlative query. Conditional queries are of the format:</p> <pre><code>&lt;s&gt; ^smem.command.math-query.&lt;cue-attribute&gt;.&lt;condition-name&gt; &lt;value&gt;\n</code></pre> <p>Superlative queries do not use a value argument and are of the format:</p> <pre><code>&lt;s&gt; ^smem.command.math-query.&lt;cue-attribute&gt;.&lt;condition-name&gt;\n</code></pre> <p>Values used in math queries must be integer or float type values. Currently supported condition names are:</p> <ul> <li>less A value less than the given argument</li> <li>greater A value greater than the given argument</li> <li>less-or-equal A value less than or equal to the given argument</li> <li>greater-or-equal A value greater than or equal to the given argument</li> <li>max The maximum value for the attribute</li> <li>min The minimum value for the attribute</li> </ul>"},{"location":"soar_manual/06_SemanticMemory/#activation","title":"Activation","text":"<p>When an agent issues a cue-based retrieval and multiple LTIs match the cue, the LTI which semantic memory provides to working memory as the result is the LTI which not only matches the cue, but also has the highest activation value. Semantic memory has several activation methods available for this purpose.</p> <p>The simplest activation methods are recency and frequency activation. Recency activa- tion attaches a time-stamp to each LTI and records the time of last retrieval. Using recency activation, the LTI which matches the cue and was also most-recently retrieved is the one which is returned as the result for a query. Frequency activation attaches a counter to each LTI and records the number of retrievals for that LTI. Using frequency activation, the LTI which matches the cue and also was most frequently used is returned as the result of the query. By default, Soar uses recency activation.</p> <p>Base-level activation can be thought of as a mixture of both recency and frequency. Soar makes use of the following equation (known as the Petrov approximation^2 ) for calculating base-level activation:</p> <p>where n is the number of activation boosts, tnis the time since the first boost, tkis the time of the kth boost, dis the decay factor, and kis the number of recent activation boosts which are stored. (In Soar,kis hard-coded to 10.) To use base-level activation, use the following CLI command when sourcing an agent:</p> <pre><code>smem --set activation-mode base-level\n</code></pre> <p>Spreading activation is new to Soar 9.6.0 and provides a secondary type of activation beyond the previous methods. First, spreading activation requires that base-level activation is also being used. They are considered additive. This value does not represent recency or frequency of use, but rather context-relatedness. Spreading activation increases the activation of LTIs which are linked to by identifiers currently present in working memory.^3 Such LTIs may be thought of as spreading sources.</p> <p>Spreading activation values spread according to network structure. That is, spreading sources will add to the spreading activation values of any of their child LTIs, according to the directed graph structure with in smem(not working memory). The amount of spread is controlled by the spreading-continue-probability parameter. By default this value is set to0.9. This would mean that90%of an LTI\u2019s spreading activation value would be divided among its direct children (without subtracting from its own value). This value is multiplicative with depth. A \"grandchild\" LTI, connected at a distance of two from a source LTI, would receive spreading according to 0. 9 \u00d7 0 .9 = 0.81 of the source spreading activation value.</p> <p>Spreading activation values are updated each decision cycle only as needed for specific smem retrievals. For efficiency, two limits exist for the amount of spread calculated. The spreading-limit parameter limits how many LTIs can receive spread from a given spreading source LTI. By default, this value is ( 300 ). Spread is distributed in a magnitude- first manner to all descendants of a source. (Without edge-weights, this simplifies to breadth- first.) Once the number of LTIs that have been given spread from a given source reaches the max value indicated by spreading-limit, no more is calculated for that source that update cycle, and the next spreading source\u2019s contributions are calculated. The maximum depth of descendants that can receive spread contributions from a source is similarly given by the spreading-depth-limit parameter. By default, this value is ( 10 ).</p> <p>In order to use spreading activation, use the following command:</p> <pre><code>smem --set spreading on\n</code></pre> <p>(^2) Petrov, Alexander A. \"Computationally efficient approximation of the base-level learning equation in ACT-R.\"Proceedings of the seventh international conference on cognitive modeling.2006. (^3) Specifically, linked to by STIs that have augmentations.</p> <p>Also, spreading activation can make use of working memory activation for adjusting edge weights and for providing nonuniform initial magnitude of spreading for sources of spread. This functionality is optional. To enable the updating of edge-weights, use the command:</p> <pre><code>smem --set spreading-edge-updating on\n</code></pre> <p>and to enable working memory activation to modulate the magnitude of spread from sources, use the command:</p> <pre><code>smem --set spreading-wma-source on\n</code></pre> <p>For most use-cases, base-level activation is sufficient to provide an agent with relevant knowl- edge in response to a query. However, to provide an agent with more context-relevant results as opposed to results based only on historical usage, one must use spreading activation.</p>"},{"location":"soar_manual/06_SemanticMemory/#retrieval-with-depth","title":"Retrieval with Depth","text":"<p>For either cue-based or non-cue-based retrieval, it is possible to retrieve a long-term identifier with additional depth. Using the depth parameter allows the agent to retrieve a greater amount of the memory structure than it would have by retrieving not only the long-term identifier\u2019s attributes and values, but also by recursively adding to working memory the attributes and values of that long-term identifier\u2019s children.</p> <p>Depth is an additional command attribute, like query:</p> <pre><code>&lt;s&gt; ^smem.command.query &lt;cue&gt;\n^smem.command.depth &lt;integer&gt;\n</code></pre> <p>For instance, the following rule uses depth with a cue-based retrieval:</p> <pre><code>&lt;s&gt; ^smem.command.query &lt;cue&gt;\nsp {smem*sample*query\n(state &lt;s&gt; ^smem.command &lt;sc&gt;\n^input-link.foo &lt;bar&gt;)\n--&gt;\n(&lt;sc&gt; ^query &lt;q&gt;\n^depth 2)\n(&lt;q&gt; ^name &lt;any-name&gt;\n^foo &lt;bar&gt;\n^associate &lt;lti&gt;\n^age 25)\n}\n</code></pre> <p>In the example above and without using depth, the long-term identifier referenced by</p> <pre><code>^associate &lt;lti&gt;\n</code></pre> <p>would not also have its attributes and values be retrieved. With a depth of 2 or more, that long-term identifier also has its attributes and values added to working memory.</p> <p>Depth can incur a large cost depending on the specified depth and the structures stored in semantic memory.</p>"},{"location":"soar_manual/06_SemanticMemory/#performance","title":"Performance","text":"<p>Initial empirical results with toy agents show that semantic memory queries carry up to a 40% overhead as compared to comparable rete matching. However, the retrieval mechanism implements some basic query optimization: statistics are maintained about all stored knowledge. When a query is issued, semantic memory re-orders the cue such as to minimize expected query time. Because only perfect matches are acceptable, and there is no symbol variablization, semantic memory retrievals do not contend with the same combinatorial search space as the rete. Preliminary empirical study shows that semantic memory maintains sub-millisecond retrieval time for a large class of queries, even in very large stores (millions of nodes/edges).</p> <p>Once the number of long-term identifiers overcomes initial overhead (about 1000 WMEs), initial empirical study shows that semantic storage requires far less than 1KB per stored WME.</p>"},{"location":"soar_manual/06_SemanticMemory/#math-queries","title":"Math queries","text":"<p>There are some additional performance considerations when using math queries during retrieval. Initial testing indicates that conditional queries show the same time growth with respect to the number of memories in comparison to non-math queries, however the actual time for retrieval may be slightly longer. Superlative queries will often show a worse result than similar non-superlative queries, because the current implementation of semantic memory requires them to iterate over any memory that matches all other involved cues.</p>"},{"location":"soar_manual/06_SemanticMemory/#performance-tweaking","title":"Performance Tweaking","text":"<p>When using a database stored to disk, several parameters become crucial to performance. The first is lazy-commit , which controls when database changes are written to disk. The default setting (on) will keep all writes in memory and only commit to disk upon re- initialization (quitting the agent or issuing the init command). The off setting will write each change to disk and thus incurs massive I/O delay.</p> <p>The next parameter is thresh. This has to do with the locality of storing/updating activation information with semantic augmentations. By default, all WME augmentations are incrementally sorted by activation, such that cue-based retrievals need not sort large number of candidate long-term identifiers on demand, and thus retrieval time is independent of cue selectivity. However, each activation update (such as after a retrieval) incurs an update cost linear in the number of augmentations. If the number of augmentations for a long-term identifier is large, this cost can dominate. Thus, the thresh parameter sets the upper bound of augmentations, after which activation is stored with the long-term identifier. This allows the user to establish a balance between cost of updating augmentation activation and the number of long-term identifiers that must be pre-sorted during a cue-based retrieval. As long as the threshold is greater than the number of augmentations of most long-term identifiers, performance should be fine (as it will bound the effects of selectivity).</p> <p>The next two parameters deal with the SQLite cache, which is a memory store used to speed operations like queries by keeping in memory structures like levels of index B+-trees. The first parameter, page-size , indicates the size, in bytes, of each cache page. The second parameter, cache-size , suggests to SQLite how many pages are available for the cache. Total cache size is the product of these two parameter settings. The cache memory is not pre- allocated, so short/small runs will not necessarily make use of this space. Generally speaking, a greater number of cache pages will benefit query time, as SQLite can keep necessary meta- data in memory. However, some documented situations have shown improved performance from decreasing cache pages to increase memory locality. This is of greater concern when dealing with file-based databases, versus in-memory. The size of each page, however, may be important whether databases are disk- or memory-based. This setting can have far-reaching consequences, such as index B+-tree depth. While this setting can be dependent upon a particular situation, a good heuristic is that short, simple runs should use small values of the page size (1k,2k,4k), whereas longer, more complicated runs will benefit from larger values (8k,16k,32k,64k). The episodic memory chapter (see Section 7.4 on page 163) has some further empirical evidence to assist in setting these parameters for very large stores.</p> <p>The next parameter is optimization. The safety parameter setting will use SQLite default settings. If data integrity is of importance, this setting is ideal. The performance setting will make use of lesser data consistency guarantees for significantly greater performance. First, writes are no longer synchronous with the OS (synchronous pragma), thus semantic memory won\u2019t wait for writes to complete before continuing execution. Second, transaction journaling is turned off (journalmode pragma), thus groups of modifications to the semantic store are not atomic (and thus interruptions due to application/os/hardware failure could lead to inconsistent database state). Finally, upon initialization, semantic mem- ory maintains a continuous exclusive lock to the database (locking mode pragma), thus other applications/agents cannot make simultaneous read/write calls to the database (thereby reducing the need for potentially expensive system calls to secure/release file locks).</p> <p>Finally, maintaining accurate operation timers can be relatively expensive in Soar. Thus, these should be enabled with caution and understanding of their limitations. First, they will affect performance, depending on the level (set via the timers parameter). A level of three, for instance, times every modification to long-term identifier recency statistics. Furthermore, because these iterations are relatively cheap (typically a single step in the linked-list of a b+-tree), timer values are typically unreliable (depending upon the system, resolution is 1 microsecond or more).</p>"},{"location":"soar_manual/07_EpisodicMemory/","title":"Episodic Memory","text":"<p>Episodic memory is a record of an agent\u2019s stream of experience. The episodic storage mechanism will automatically record episodes as a Soar agent executes. The agent can later deliberately retrieve episodic knowledge to extract information and regularities that may not have been noticed during the original experience and combine them with current knowledge such as to improve performance on future tasks.</p> <p>This chapter is organized as follows: episodic memory structures in working memory; episodic storage; retrieving episodes; and a discussion of performance.  The detailed behavior of episodic memory is determined by numerous parameters that can be controlled and configured via the <code>epmem</code> command.</p> <p>Please refer to the documentation for the <code>epmem</code> command.</p>"},{"location":"soar_manual/07_EpisodicMemory/#working-memory-structure","title":"Working Memory Structure","text":"<p>Upon creation of a new state in working memory, the architecture creates the following augmentations to facilitate agent interaction with episodic memory:</p> <pre><code>(&lt;s&gt; ^epmem &lt;e&gt;)\n(&lt;e&gt; ^command &lt;e-c&gt;)\n(&lt;e&gt; ^result &lt;e-r&gt;)\n(&lt;e&gt; ^present-id #)\n</code></pre> <p>As rules augment the command structure in order to retrieve episodes, episodic memory augments the result structure in response. Production actions should not remove augmentations of the result structure directly, as episodic memory will maintain these WMEs.</p> <p>The value of the present-id augmentation is an integer and will update to expose to the agent the current episode number. This information is identical to what is available via the time statistic and the present-id retrieval meta-data (7.3.4).</p>"},{"location":"soar_manual/07_EpisodicMemory/#episodic-storage","title":"Episodic Storage","text":"<p>Episodic memory records new episodes without deliberate action/consideration by the agent.  The timing and frequency of recording new episodes is controlled by the phase and trigger parameters. The phase parameter sets the phase in the decision cycle (default: end of each decision cycle) during which episodic memory stores episodes and processes commands. The value of the trigger parameter indicates to the architecture the event that concludes an episode: adding a new augmentation to the output-link (default) or each decision cycle.</p> <p>For debugging purposes, the force parameter allows the user to manually request that an episode be recorded (or not) during the current decision cycle. Behavior is as follows:</p> <p>The value of the force parameter is initialized to off every decision cycle. During the phase of episodic storage, episodic memory tests the value of the force parameter; if it has a value other than of off, episodic memory follows the force d policy irrespective of the value of the trigger parameter.</p>"},{"location":"soar_manual/07_EpisodicMemory/#episode-contents","title":"Episode Contents","text":"<p>When episodic memory stores a new episode, it captures the entire top-state of working memory. There are currently two exceptions to this policy:</p> <p>Episodic memory only supports WMEs whose attribute is a constant. Behavior is currently undefined when attempting to store a WME that has an attribute that is an identifier.</p> <p>The exclusions parameter allows the user to specify a set of attributes for which Soar will not store WMEs. The storage process currently walks the top-state of working memory in a breadth-first manner, and any WME that is not reachable other than via an excluded WME will not be stored. By default, episodic memory excludes the epmem and smem structures, to prevent encoding of potentially large and/or frequently changing memory retrievals.</p>"},{"location":"soar_manual/07_EpisodicMemory/#storage-location","title":"Storage Location","text":"<p>Episodic memory uses SQLite to facilitate efficient and standardized storage and querying of episodes. The episodic store can be maintained in memory or on disk (per the database and path parameters). If the store is located on disk, users can use any standard SQLite programs/components to access/query its contents. See the later discussion on performance for additional parameters dealing with databases on disk.</p> <p>Note that changes to storage parameters, for example database, path and append will not have an effect until the database is used after an initialization. This happens either shortly after launch (on first use) or after a database initialization command is issued. To switch databases or database storage types while running, set your new parameters and then perform an <code>epmem --init</code> command.</p> <p>The path parameter specifies the file system path the database is stored in. When path is set to a valid file system path and database mode is set to file, then the SQLite database is written to that path.</p> <p>The append parameter will determine whether all existing facts stored in a database on disk will be erased when episodic memory loads. Note that this affects init-soar also. In other words, if the append setting is off, all episodes stored will be lost when an init-soar is performed. For episodic memory, append mode is off by default.</p> <p>Note: As of version 9.3.3, Soar now uses a new schema for the episodic memory database. This means databases from 9.3.2 and below can no longer be loaded. A conversion utility will be available in Soar 9.4 to convert from the old schema to the new one.</p>"},{"location":"soar_manual/07_EpisodicMemory/#retrieving-episodes","title":"Retrieving Episodes","text":"<p>An agent retrieves episodes by creating an appropriate command (we detail the types of commands below) on the command link of a state\u2019s epmem structure. At the end of the phase of each decision, after episodic storage, episodic memory processes each state\u2019s epmem command structure. Results, meta-data, and errors are placed on the result structure of that state\u2019s epmem structure.</p> <p>Only one type of retrieval command (which may include optional modifiers) can be issued per state in a single decision cycle. Malformed commands (including attempts at multiple retrieval types) will result in an error:</p> <pre><code>&lt;s&gt; ^epmem.result.status bad-cmd\n</code></pre> <p>After a command has been processed, episodic memory will ignore it until some aspect of the command structure changes (via addition/removal of WMEs). When this occurs, the result structure is cleared and the new command (if one exists) is processed.</p> <p>All retrieved episodes are recreated exactly as stored, except for any operators that have an acceptable preference, which are recreated with the attribute operator*. For example, if the original episode was:</p> <pre><code>(&lt;s&gt; ^operator &lt;o1&gt; +)\n(&lt;o1&gt; ^name move)\n</code></pre> <p>A retrieval of the episode would become:</p> <pre><code>(&lt;s&gt; ^operator* &lt;o1&gt;)\n(&lt;o1&gt; ^name move)\n</code></pre>"},{"location":"soar_manual/07_EpisodicMemory/#cue-based-retrievals","title":"Cue-Based Retrievals","text":"<p>Cue-based retrieval commands are used to search for an episode in the store that best matches an agent-supplied cue, while adhering to optional modifiers. A cue is composed of WMEs that partially describe a top-state of working memory in the retrieved episode. All cue-based retrieval requests must contain a single ^query cue and, optionally, a single ^neg-query cue.</p> <pre><code>&lt;s&gt; ^epmem.command.query &lt;required-cue&gt;\n&lt;s&gt; ^epmem.command.neg-query &lt;optional-negative-cue&gt;\n</code></pre> <p>A ^querycue describes structures desired in the retrieved episode, whereas a ^neg-query cue describes non-desired structures. For example, the following Soar production creates a ^querycue consisting of a particular state name and a copy of a current value on the input-link structure:</p> <pre><code>sp {epmem*sample*query\n(state &lt;s&gt; ^epmem.command &lt;ec&gt;\n^io.input-link.foo &lt;bar&gt;)\n--&gt;\n(&lt;ec&gt; ^query &lt;q&gt;)\n(&lt;q&gt; ^name my-state-name\n^io.input-link.foo &lt;bar&gt;)\n}\n</code></pre> <p>As detailed below, multiple prior episodes may equally match the structure and contents of an agent\u2019s cue. Nuxoll has produced initial evidence that in some tasks, retrieval quality improves when using activation of cue WMEs as a form of feature weighting. Thus, episodic memory supports integration with working memory activation (see Section 9.3.2.1 on page 221). For a theoretical discussion of the Soar implementation of working memory activation, consider readingComprehensive Working Memory Activation in Soar (Nuxoll, A., Laird, J., James, M., ICCM 2004).</p> <p>The cue-based retrieval process can be thought of conceptually as a nearest-neighbor search.  First, all candidate episodes, defined as episodes containing at least one leaf WME (a cue WME with no sub-structure) in at least one cue, are identified. Two quantities are calculated for each candidate episode, with respect to the supplied cue(s): the cardinality of the match (defined as the number of matching leaf WMEs) and the activation of the match (defined as the sum of the activation values of each matching leaf WME). Note that each of these values is negated when applied to a negative query. To compute each candidate episode\u2019s match score, these quantities are combined with respect to the balance parameter as follows:</p> \\[ (balance)\\cdot(cardinality) + (1-balance)\\cdot(activation) \\] <p>Performing a graph match on each candidate episode, with respect to the structure of the cue, could be very computationally expensive, so episodic memory implements a two-stage matching process. An episode with perfect cardinality is considered a perfect surface match and, per the graph-match parameter, is subjected to further structural matching. Whereas surface matching efficiently determines if all paths to leaf WMEs exist in a candidate episode, graph matching indicates whether or not the cue can be structurally unified with the candidate episode (paying special regard to the structural constraints imposed by shared identifiers). Cue-based matching will return the most recent structural match, or the most recent candidate episode with the greatest match score.</p> <p>A special note should be made with respect to how short- vs. long-term identifiers (see Section 6.2 on page 146) are interpreted in a cue. Short-term identifiers are processed much as they are in working memory \u2013 transient structures. Cue matching will try to find any identifier in an episode (with respect to WME path from state) that can apply. Long- term identifiers, however, are treated as constants. Thus, when analyzing the cue, episodic memory will not consider long-term identifier augmentations, and will only match with the same long-term identifier (in the same context) in an episode.</p> <p>The case-based retrieval process can be further controlled using optional modifiers:</p> <p>The before command requires that the retrieved episode come relatively before a supplied time:</p> <pre><code>&lt;s&gt; ^epmem.command.before time\n</code></pre> <p>The after command requires that the retrieved episode come relatively after a sup- plied time:</p> <pre><code>&lt;s&gt; ^epmem.command.after time\n</code></pre> <p>The prohibit command requires that the time of the retrieved episode is not equal to a supplied time:</p> <pre><code>&lt;s&gt; ^epmem.command.prohibit time\n</code></pre> <p>Multiple prohibit command WMEs may be issued as modifiers to a single CB retrieval.</p> <p>If no episode satisfies the cue(s) and optional modifiers an error is returned:</p> <pre><code>&lt;s&gt; ^epmem.result.failure &lt;query&gt; &lt;optional-neg-query&gt;\n</code></pre> <p>If an episode is returned, there is additional meta-data supplied (7.3.4).</p>"},{"location":"soar_manual/07_EpisodicMemory/#absolute-non-cue-based-retrieval","title":"Absolute Non-Cue-Based Retrieval","text":"<p>At time of storage, each episode is attributed a unique time. This is the current value of time statistic and is provided as the memory-id meta-data item of retrieved episodes. An absolute non-cue-based retrieval is one that requests an episode by time. An agent issues an absolute non-cue-based retrieval by creating a WME on the command structure with attribute retrieve and value equal to the desired time:</p> <pre><code>&lt;s&gt; ^epmem.command.retrieve time\n</code></pre> <p>Supplying an invalid value for the retrieve command will result in an error.</p> <p>The time of the first episode in an episodic store will have value 1 and each subsequent episode\u2019s time will increase by 1. Thus the desired time may be the mathematical result of operations performed on a known episode\u2019s time.</p> <p>The current episodic memory implementation does not implement any episodic store dynamics, such as forgetting. Thus any integer time greater than 0 and less than the current value of the time statistic will be valid. However, if forgetting is implemented in future versions, no such guarantee will be made.</p>"},{"location":"soar_manual/07_EpisodicMemory/#relative-non-cue-based-retrieval","title":"Relative Non-Cue-Based Retrieval","text":"<p>Episodic memory supports the ability for an agent to \"play forward\" episodes using relative non-cue-based retrievals.</p> <p>Episodic memory stores the time of the last successful retrieval (non-cue-based or cue-based).  Agents can indirectly make use of this information by issuing next or previous commands.  Episodic memory executes these commands by attempting to retrieve the episode immediately proceeding/preceding the last successful retrieval (respectively). To issue one of these commands, the agent must create a new WME on the command link with the appropriate attribute (next or previous) and value of an arbitrary identifier:</p> <pre><code>&lt;s&gt; ^epmem.command.next &lt;n&gt;\n&lt;s&gt; ^epmem.command.previous &lt;p&gt;\n</code></pre> <p>If no such episode exists then an error is returned.</p> <p>Currently, if the time of the last successfully retrieved episode is known to the agent (as could be the case by accessing result meta-data), these commands are identical to performing an absolute non-cue-based retrieval after adding/subtracting 1 to the last time (respectively).  However, if an episodic store dynamic like forgetting is implemented, these relative commands are guaranteed to return the next/previous valid episode (assuming one exists).</p>"},{"location":"soar_manual/07_EpisodicMemory/#retrieval-meta-data","title":"Retrieval Meta-Data","text":"<p>The following list details the WMEs that episodic memory creates in the result link of the epmem structure wherein a command was issued:</p> <p>retrieved <code>&lt;retrieval-root&gt;</code> If episodic memory retrieves an episode, that memory is placed here. This WME is an identifier that is treated as the root of the state that was used to create the episodic memory. If the retrieve command was issued with an invalid time, the value of this WME will be no-memory.</p> <p>success <code>&lt;query&gt; &lt;optional-neg-query&gt;</code> If the cue-based retrieval was successful, the WME will have the status as the attribute and the value of the identifier of the query (and neg-query, if applicable).</p> <p>match-score This WME is created whenever an episode is successfully retrieved from a cue-based retrieval command. The WME value is a decimal indicating the raw match score for that episode with respect to the cue(s).</p> <p>cue-size This WME is created whenever an episode is successfully retrieved from a cue-based retrieval command. The WME value is an integer indicating the number of leaf WMEs in the cue(s).</p> <p>normalized-match-score This WME is created whenever an episode is success- fully retrieved from a cue-based retrieval command. The WME value is the decimal result of dividing the raw match score by the cue size. It can hypothetically be used as a measure of episodic memory\u2019s relative confidence in the retrieval.</p> <p>match-cardinality This WME is created whenever an episode is successfully retrieved from a cue-based retrieval command. The WME value is an integer indicating the number of leaf WMEs matched in the <code>^querycue</code> minus those matched in the <code>^neg-querycue</code>.</p> <p>memory-id This WME is created whenever an episode is successfully retrieved from a cue-based retrieval command. The WME value is an integer indicating the time of the retrieved episode.</p> <p>present-id This WME is created whenever an episode is successfully retrieved from a cue-based retrieval command. The WME value is an integer indicating the current time, such as to provide a sense of \"now\" in episodic memory terms. By comparing this value to the memory-id value, the agent can gain a sense of the relative time that has passed since the retrieved episode was recorded.</p> <p>graph-match This WME is created whenever an episode is successfully retrieved from a cue-based retrieval command and the graph-match parameter was on. The value is an integer with value 1 if graph matching was executed successfully and 0 otherwise.</p> <p>mapping <code>&lt;mapping-root&gt;</code>  This WME is created whenever an episode is success- fully retrieved from a cue-based retrieval command, the graph-match parameter was on, and structural match was successful on the retrieved episode. This WME provides a mapping between identifiers in the cue and in the retrieved episode. For each identifier in the cue, there is anodeWME as an augmentation to the mapping identifier. The node has a cue augmentation, whose value is an identifier in the cue, and a retrieved augmentation, whose value is an identifier in the retrieved episode. In a graph match it is possible to have multiple identifier mappings \u2013 this map represents the \"first\" unified mapping (with respect to episodic memory algorithms).</p>"},{"location":"soar_manual/07_EpisodicMemory/#performance","title":"Performance","text":"<p>There are currently two sources of \"unbounded\" computation: graph matching and cue- based queries. Graph matching is combinatorial in the worst case. Thus, if an episode presents a perfect surface match, but imperfect structural match (i.e. there is no way to unify the cue with the candidate episode), there is the potential for exhaustive search. Each identifier in the cue can be assigned one of any historically consistent identifiers (with respect to the sequence of attributes that leads to the identifier from the root), termed a literal. If the identifier is a multi-valued attribute, there will be more than one candidate literals and this situation can lead to a very expensive search process. Currently there are no heuristics in place to attempt to combat the expensive backtracking. Worst-case performance will be combinatorial in the total number of literals for each cue identifier (with respect to cue structure).</p> <p>The cue-based query algorithm begins with the most recent candidate episode and will stop search as soon as a match is found (since this episode must be the most recent). Given this procedure, it is trivial to create a two-WME cue that forces a linear search of the episodic store. Episodic memory combats linear scan by only searching candidate episodes, i.e. only those that contain a change in at least one of the cue WMEs. However, a cue that has no match and contains WMEs relevant to all episodes will force inspection of all episodes.  Thus, worst-case performance will be linear in the number of episodes.</p>"},{"location":"soar_manual/07_EpisodicMemory/#performance-tweaking","title":"Performance Tweaking","text":"<p>When using a database stored to disk, several parameters become crucial to performance.  The first is commit , which controls the number of episodes that occur between writes to disk. If the total number of episodes (or a range) is known ahead of time, setting this value to a greater number will result in greatest performance (due to decreased I/O).</p> <p>The next two parameters deal with the SQLite cache, which is a memory store used to speed operations like queries by keeping in memory structures like levels of index B+-trees. The first parameter, page-size , indicates the size, in bytes, of each cache page. The second parameter, cache-size , suggests to SQLite how many pages are available for the cache.  Total cache size is the product of these two parameter settings. The cache memory is not pre- allocated, so short/small runs will not necessarily make use of this space. Generally speaking, a greater number of cache pages will benefit query time, as SQLite can keep necessary meta- data in memory. However, some documented situations have shown improved performance from decreasing cache pages to increase memory locality. This is of greater concern when dealing with file-based databases, versus in-memory. The size of each page, however, may be important whether databases are disk- or memory-based. This setting can have far-reaching consequences, such as index B+-tree depth. While this setting can be dependent upon a particular situation, a good heuristic is that short, simple runs should use small values of the page size (1k, 2k, 4k), whereas longer, more complicated runs will benefit from larger values (8k, 16k, 32k, 64k). One known situation of concern is that as indexed tables accumulate many rows (~millions), insertion time of new rows can suffer an infrequent, but linearly increasing burst of computation. In episodic memory, this situation will typically arise with many episodes and/or many working memory changes. Increasing the page size will reduce the intensity of the spikes at the cost of increasing disk I/O and average/total time for episode storage. Thus, the settings of page size for long, complicated runs establishes the</p> Example episodic memory cache setting data. <p>desired balance of reactivity (i.e. max computation) and average speed. To ground this discussion, the Figure 7.1 depicts maximum and average episodic storage time (the value of the epmem storage timer, converted to milliseconds) with different page sizes after 10 million decisions (1 episode/decision) of a very basic agent (i.e. very few working memory changes per episode) running on a 2.8GHz Core i7 with Mac OS X 10.6.5. While only a single use case, the cross-point of these data forms the basis for the decision to default the parameter at 8192 bytes.</p> <p>The next parameter is optimization , which can be set to either safety or performance.  The safety parameter setting will use SQLite default settings. If data integrity is of importance, this setting is ideal. The performance setting will make use of lesser data consistency guarantees for significantly greater performance. First, writes are no longer synchronous with the OS (synchronous pragma), thus episodic memory won\u2019t wait for writes to complete before continuing execution. Second, transaction journaling is turned off (journalmode pragma), thus groups of modifications to the episodic store are not atomic (and thus interruptions due to application/os/hardware failure could lead to inconsistent database state).  Finally, upon initialization, episodic memory maintains a continuous exclusive lock to the database (locking mode pragma), thus other applications/agents cannot make simultaneous read/write calls to the database (thereby reducing the need for potentially expensive system calls to secure/release file locks).</p> <p>Finally, maintaining accurate operation timers can be relatively expensive in Soar. Thus, these should be enabled with caution and understanding of their limitations. First, they will affect performance, depending on the level (set via the timers parameter). A level of three, for instance, times every step in the cue-based retrieval candidate episode search. Furthermore, because these iterations are relatively cheap (typically a single step in the linked-list of a b+-tree), timer values are typically unreliable (depending upon the system, resolution is 1 microsecond or more).</p>"},{"location":"soar_manual/08_SpatialVisualSystem/","title":"Spatial Visual System","text":"<p>The Spatial Visual System (SVS) allows Soar to effectively represent and reason about continuous, three dimensional environments. SVS maintains an internal representation of the environment as a collection of discrete objects with simple geometric shapes, called the scene graph. The Soar agent can query for spatial relationships between the objects in the scene graph through a working memory interface similar to that of episodic and semantic memory.  Figure 8.1 illustrates the typical use case for SVS by contrasting it with an agent that does not utilize it. The agent that does not use SVS (a. in the figure) relies on the environment to provide a symbolic representation of the continuous state. On the other hand, the agent that uses SVS (b) accepts a continuous representation of the environment state directly, and then performs queries on the scene graph to extract a symbolic representation internally. This allows the agent to build more flexible symbolic representations without requiring modifications to the environment code. Furthermore, it allows the agent to manipulate internal copies of the scene graph and then extract spatial relationships from the modified states, which is useful for look-ahead search and action modeling. This type of imagery operation naturally captures and propagates the relationships implicit in spatial environments, and doesn\u2019t suffer from the frame problem that relational representations have.</p> (a) Typical environment setup without using SVS. (b) Same environment using SVS."},{"location":"soar_manual/08_SpatialVisualSystem/#the-scene-graph","title":"The scene graph","text":"<p>The primary data structure of SVS is the scene graph. The scene graph is a tree in which the nodes represent objects in the scene and the edges represent \"part-of\" relationships between objects. An example scene graph consisting of a car and a pole is shown in Figure 8.2. The scene graph\u2019s leaves are geometry nodes and its interior nodes are group nodes. Geometry nodes represent atomic objects that have intrinsic shape, such as the wheels and chassis in the example. Currently, the shapes supported by SVS are points, lines, convex polyhedrons, and spheres. Group nodes represent objects that are the aggregates of their child nodes, such as the car object in the example. The shape of a group node is the union of the shapes of its children. Structuring complex objects in this way allows Soar to reason about them naturally at different levels of abstraction. The agent can query SVS for relationships between the car as a whole with other objects (e.g. does it intersect the pole?), or the relationships between its parts (e.g. are the wheels pointing left or right with respect to the chassis?). The scene graph always contains at least a root node: the world node.</p> <p>Each node other than the world node has a transform with respect to its parent. A transform consists of three components:</p> <ul> <li>position(x,y,z) Specifies the x, y, and z offsets of the node\u2019s origin with   respect to its parent\u2019s origin.</li> <li>rotation(x,y,z) Specifies the rotation of the node relative to its origin in   Euler angles.  This means that the node is rotated the specified number of   radians along each axis in the order x-y-z. For more information,   see http://en.wikipedia.org/wiki/Euler_angles.</li> <li>scaling(x,y,z) Specifies the factors by which the node is scaled along each axis.</li> </ul> <p>The component transforms are applied in the order scaling, then rotation, then position.  Each node\u2019s transform is applied with respect to its parent\u2019s coordinate system, so the transforms accumulate down the tree. A node\u2019s transform with respect to the world node, or its world transform, is the aggregate of all its ancestor transforms. For example, if the car has a position transform of (1, 0 ,0) and a wheel on the car has a position transform of (0, 1 ,0), then the world position transform of the wheel is (1, 1 ,0).</p> <p>SVS represents the scene graph structure in working memory under the^spatial-scene link. The working memory representation of the car and pole scene graph is</p> (a) A 3D scene. (b) The scene graph representation. <pre><code>(S1 ^svs S3)\n  (S3 ^command C3 ^spatial-scene S4)\n    (S4 ^child C10 ^child C4 ^id world)\n      (C10 ^id pole)\n      (C4 ^child C9 ^child C8 ^child C7 ^child C6 ^child C5 ^id car)\n        (C9 ^id chassis)\n        (C8 ^id wheel3)\n        (C7 ^id wheel2)\n        (C6 ^id wheel1)\n        (C5 ^id wheel0)\n</code></pre> <p>Each state in working memory has its own scene graph. When a new state is created, it will receive an independent copy of its parent\u2019s scene graph. This is useful for performing look-ahead search, as it allows the agent to destructively modify the scene graph in a search state using mental imagery operations.</p>"},{"location":"soar_manual/08_SpatialVisualSystem/#svs_viewer","title":"svs_viewer","text":"<p>A viewer has been provided to show the scene graph visually. Run the program svs viewer -s PORTfrom the soar/out folder to launch the viewer listening on the given port. Once the viewer is running, from within soar use the command svs connect viewer PORTto connect to the viewer and begin drawing the scene graph. Any changes to the scene graph will be reflected in the viewer. The viewer by default draws the top state scene graph, to draw that on a substate first stop drawing the top state with svs S1.scene.draw off and then svs S7.scene.draw on.</p>"},{"location":"soar_manual/08_SpatialVisualSystem/#scene-graph-edit-language","title":"Scene Graph Edit Language","text":"<p>The Scene Graph Edit Language (SGEL) is a simple, plain text, line oriented language that is used by SVS to modify the contents of the scene graph. Typically, the scene graph is used to represent the state of the external environment, and the programmer sends SGEL commands reflecting changes in the environment to SVS via the <code>Agent::SendSVSInput</code> function in the SML API. These commands are buffered by the agent and processed at the beginning of each input phase. Therefore, it is common to send scene changes through SendSVS Input before the input phase. If you send SGEL commands at the end of the input phase, the results won\u2019t be processed until the following decision cycle.</p> <p>Each SGEL command begins with a single word command type and ends with a newline. The four command types are</p> <ul> <li> <p>add ID PARENT_ID [GEOMETRY] [TRANSFORM]   Add a node to the scene graph with the givenID, as a child ofPARENTID, and with   typeTYPE(usually object).TheGEOMETRYandTRANSFORMarguments are optional and   described below.</p> </li> <li> <p>change ID [GEOMETRY] [TRANSFORM]    Change the transform and/or geometry of the node with the givenID.</p> </li> <li> <p>delete ID   Delete the node with the givenID.</p> </li> <li> <p>tag [add|change|delete] ID TAG_NAME TAG_VALUE   Adds, changes, or deletes a tag from an object. A tag consists of a TAG_NAME and   TAG_VALUE pair and is added to the node with the given ID. Both TAG_NAMEand   TAG_VALUE must be strings. Tags can differentiate nodes (e.g. as a type field) and   can be used in conjunction with the tag select filter to choose a subset of the nodes.</p> </li> </ul> <p>The <code>TRANSFORM</code> argument has the <code>form[p X Y Z] [r X Y Z] [s X Y Z]</code>, corresponding to the position, rotation, and scaling components of the transform, respectively. All the components are optional; any combination of them can be excluded, and the included components can appear in any order.</p> <p>The <code>GEOMETRY</code> argument has two forms:</p> <ul> <li> <p>b RADIUS   Make the node a geometry node with sphere shape with radius RADIUS.</p> </li> <li> <p>v X1 Y1 Z1 X2 Y2 Z2   Make the node a geometry node with a convex polyhedron shape with the specified   vertices. Any number of vertices can be listed.</p> </li> </ul>"},{"location":"soar_manual/08_SpatialVisualSystem/#examples","title":"Examples","text":"<p>Creating a sphere called ball4 with radius 5 at location (4, 4, 0). add ball4 world b 5 p 4 4 0</p> <p>Creating a triangle in the xy plane, then rotate it vertically, double its size, and move it to (1, 1, 1).</p> <pre><code>add tri9 world v -1 -1 0 1 -1 0 0 0.5 0 p 1 1 1 r 1.507 0 0 s 2 2 2\n</code></pre> <p>Creating a snowman shape of 3 spheres stacked on each other and located at (2, 2, 0).</p> <pre><code>add snowman world p 2 2 0\nadd bottomball snowman b 3 p 0 0 3\nadd middleball snowman b 2 p 0 0 8\nadd topball snowman b 1 p 0 0 11\n</code></pre> <p>Set the rotation transform on box11 to 180 degrees around the z axis.</p> <pre><code>change box11 r 0 0 3.14159\n</code></pre> <p>Changing the color tag on box7 to green.</p> <pre><code>tag change box7 color green\n</code></pre>"},{"location":"soar_manual/08_SpatialVisualSystem/#commands","title":"Commands","text":"<p>The Soar agent initiates commands in SVS via the ^command link, similar to semantic and episodic memory. These commands allow the agent to modify the scene graph and extract filters. Commands are processed during the output phase and the results are added to working memory during the input phase. SVS supports the following commands:</p> <ul> <li><code>add_node</code> Creates a new node and adds it to the scene graph</li> <li><code>copy_node</code> Creates a copy of an existing node</li> <li><code>delete_node</code> Removes a node from the scene graph and deletes it</li> <li><code>set_transform</code> Changes the position, rotation, and/or scale of a node</li> <li><code>set_tag</code> Adds or changes a tag on a node</li> <li><code>delete_tag</code> Deletes a tag from a node</li> <li><code>extract</code> Compute the truth value of spatial relationships in the current scene graph.</li> <li><code>extract_once</code> Same as extract, except it is only computed once and doesn\u2019t update when the scene changes.</li> </ul>"},{"location":"soar_manual/08_SpatialVisualSystem/#add_node","title":"add_node","text":"<p>This commands adds a new node to the scene graph.</p> <ul> <li><code>^id [string]</code> The id of the node to create</li> <li><code>^parent [string]</code> The id of the node to attach the new node to (default is world)</li> <li><code>^geometry &lt;&lt; group point ball box &gt;&gt;</code> The geometry the node should have</li> <li><code>^position.{ ^x ^y ^z }</code> Position of the node (optional)</li> <li><code>^rotation.{ ^x ^y ^z }</code> Rotation of the node (optional)</li> <li><code>^scale.{ ^x ^y ^z }</code> Scale of the node (optional)</li> </ul> <p>The following example creates a node called box 5 and adds it to the world. The node has a box shape of side length 0.1 and is placed at position (1, 1, 0).</p> <pre><code>(S1 ^svs S3)\n  (S3 ^command C3 ^spatial-scene S4)\n    (C3 ^add_node A1)\n      (A1 ^id box5 ^parent world ^geometry box ^position P1 ^scale S6)\n        (P1 ^x 1.0 ^y 1.0 ^z 0.0)\n        (S6 ^x 0.1 ^y 0.1 ^z 0.1)\n</code></pre>"},{"location":"soar_manual/08_SpatialVisualSystem/#copy_node","title":"copy_node","text":"<p>This command creates a copy of an existing node and adds it to the scene graph. This copy is not recursive, it only copies the node itself, not its children. The position, rotation, and scale transforms are also copied from the source node but they can be changed if desired.</p> <ul> <li>^id [string] The id of the node to create</li> <li>^source [string] The id of the node to copy</li> <li>^parent [string] The id of the node to attach the new node to (default is world)</li> <li>^position.{^x ^y ^z} Position of the node (optional)</li> <li>^rotation.{^x ^y ^z} Rotation of the node (optional)</li> <li>^scale.{^x ^y ^z} Scale of the node (optional)</li> </ul> <p>The following example copies a node called box5 as new node box6 and moves it to position (2, 0, 2).</p> <pre><code>(S1 ^svs S3)\n  (S3 ^command C3 ^spatial-scene S4)\n    (C3 ^copy_node A1)\n      (A1 ^id box6 ^source box5 ^position P1)\n        (P1 ^x 2.0 ^y 0.0 ^z 2.0)\n</code></pre>"},{"location":"soar_manual/08_SpatialVisualSystem/#delete_node","title":"delete_node","text":"<p>This command deletes a node from the scene graph. Any children will also be deleted.</p> <ul> <li>`^id [string] The id of the node to delete</li> </ul> <p>The following example deletes a node called</p> <pre><code>(S1 ^svs S3)\n  (S3 ^command C3 ^spatial-scene S4)\n    (C3 ^delete_node D1)\n      (D1 ^id box5)\n</code></pre>"},{"location":"soar_manual/08_SpatialVisualSystem/#set_transform","title":"set_transform","text":"<p>This command allows you to change the position, rotation, and/ or scale of an existing node. You can specify any combination of the three transforms.</p> <ul> <li><code>^id [string]</code> The id of the node to change</li> <li><code>^postion</code> Position of the node (optional)</li> <li><code>^position.{^x ^y ^z}</code> Rotation of the node (optional)</li> <li><code>^scale{^x ^y ^z}</code> Scale of the node (optional)</li> </ul> <p>The following example moves and rotates a node called <code>box5</code>.</p> <pre><code>(S1 ^svs S3)\n  (S3 ^command C3 ^spatial-scene S4)\n    (C3 ^set_transform S6)\n      (S6 ^id box5 ^position P1 ^rotation R1)\n        (P1 ^x 2.0 ^y 2.0 ^z 0.0)\n        (R1 ^x 0.0 ^y 0.0 ^z 1.57)\n</code></pre>"},{"location":"soar_manual/08_SpatialVisualSystem/#set_tag","title":"set_tag","text":"<p>This command allows you to add or change a tag on a node. If a tag with the same id already exists, the existing value will be replaced with the new value.</p> <ul> <li><code>^id [string]</code> The id of the node to set the tag on</li> <li><code>^tag_name [string]</code> The name of the tag to add</li> <li><code>^tag_value [string]</code> The value of the tag to add</li> </ul> <p>The following example adds a shape tag to the node <code>box5</code>.</p> <pre><code>(S1 ^svs S3)\n  (S3 ^command C3 ^spatial-scene S4)\n    (C3 ^set_tag S6)\n      (S6 ^id box5 ^tag_name shape ^tag_value cube)\n</code></pre>"},{"location":"soar_manual/08_SpatialVisualSystem/#delete_tag","title":"delete_tag","text":"<p>This command allows you to delete a tag from a node.</p> <ul> <li>^id [string] The id of the node to set the tag on</li> <li>^tag_name [string] The name of the tag to add</li> <li>^tag_value [string] The value of the tag to add</li> </ul> <p>The following example deletes the shape tag from the node .</p> <pre><code>(S1 ^svs S3)\n  (S3 ^command C3 ^spatial-scene S4)\n    (C3 ^delete_tag D1)\n      (D1 ^name box5 ^tag_name shape)\n</code></pre>"},{"location":"soar_manual/08_SpatialVisualSystem/#extract-and-extract_once","title":"extract and extract_once","text":"<p>This command is commonly used to compute spatial relationships in the scene graph. More generally, it puts the result of a filter pipeline (described in section svs-filters in working memory. Its syntax is the same as filter pipeline syntax. During the input phase, SVS will evaluate the filter and put a <code>^result</code> attribute on the command\u2019s identifier.  Under the <code>^result</code> attribute is a multi-valued <code>^record</code> attribute. Each record corresponds to an output value from the head of the filter pipeline, along with the parameters that produced the value. With the regular <code>extract</code> command, these records will be updated as the scene graph changes. With the <code>extract_once</code> command, the records will be created once and will not change. Note that you should not change the structure of a filter once it is created (SVS only processes a command once). Instead to extract something different you must create a new command. The following is an example of an extract command which tests whether the car and pole objects are intersecting.  The <code>^status</code> and <code>^result</code> WMEs are added by SVS when the command is finished.</p> <pre><code>(S1 ^svs S3)\n  (S3 ^command C3 ^spatial-scene S4)\n    (C3 ^extract E2)\n      (E2 ^a A1 ^b B1 ^result R7 ^status success ^type intersect)\n        (A1 ^id car ^status success ^type node)\n        (B1 ^id pole ^status success ^type node)\n        (R7 ^record R17)\n          (R17 ^params P1 ^value false)\n            (P1 ^a car ^b pole)\n</code></pre>"},{"location":"soar_manual/08_SpatialVisualSystem/#filters","title":"Filters","text":"<p>Filters are the basic unit of computation in SVS. They transform the continuous information in the scene graph into symbolic information that can be used by the rest of Soar. Each filter accepts a number of labeled parameters as input, and produces a single output. Filters can be arranged into pipelines in which the outputs of some filters are fed into the inputs of other filters. The Soar agent creates filter pipelines by building an analogous structure in working memory as an argument to an \"extract\" command. For example, the following structure defines a set of filters that reports whether the car intersects the pole: <pre><code>(S1 ^svs S3)\n  (S3 ^command C3 ^spatial-scene S4)\n    (C3 ^extract E2)\n      (E2 ^a A1 ^b B1 ^type intersect)\n        (A1 ^id car ^type node)\n        (B1 ^id pole ^type node)\n</code></pre></p> <p>The <code>^type</code> attribute specifies the type of filter to instantiate, and the other attributes specify parameters. This command will create three filters: an <code>intersect</code> filter and two node filters. A node filter takes an <code>id</code> parameter and returns the scene graph node with that ID as its result. Here, the outputs of the <code>car</code> and <code>pole</code> node filters are fed into the <code>^a</code> and <code>^b</code> parameters of the filter. SVS will update each filter\u2019s output once every decision cycle, at the end of the input phase. The output of the intersect filter is a boolean value indicating whether the two objects are intersecting. This is placed into working memory as the result of the extract command:</p> <pre><code>(S1 ^svs S3)\n  (S3 ^command C3 ^spatial-scene S4)\n    (C3 ^extract E2)\n      (E2 ^a A1 ^b B1 ^result R7 ^status success ^type intersect)\n        (A1 ^id car ^status success ^type node)\n        (B1 ^id pole ^status success ^type node)\n        (R7 ^record R17)\n          (R17 ^params P1 ^value false)\n            (P1 ^a car ^b pole)\n</code></pre> <p>Notice that a <code>^status</code> success is placed on each identifier corresponding to a filter. A result WME is placed on the extract command with a single record with value false.</p>"},{"location":"soar_manual/08_SpatialVisualSystem/#result-lists","title":"Result lists","text":"<p>Spatial queries often involve a large number of objects. For example, the agent may want to compute whether an object intersects any others in the scene graph. It would be inconvenient to build the extract command to process this query if the agent had to specify each object involved explicitly. Too many WMEs would be required, which would slow down the production matcher as well as SVS because it must spend more time interpreting the command structure. To handle these cases, all filter parameters and results can be lists of values. For example, the query for whether one object intersects all others can be expressed as</p> <pre><code>(S1 ^svs S3)\n  (S3 ^command C3)\n    (C3 ^extract E2)\n      (E2 ^a A1 ^b B1 ^result R7 ^status success ^type intersect)\n        (A1 ^id car ^status success ^type node)\n        (B1 ^status success ^type all_nodes)\n        (R7 ^record R9 ^record R8)\n          (R9 ^params P2 ^value false)\n            (P2 ^a car ^b pole)\n          (R8 ^params P1 ^value true)\n            (P1 ^a car ^b car)\n</code></pre> <p>The all_nodes filter outputs a list of all nodes in the scene graph, and the intersect filter outputs a list of boolean values indicating whether the car intersects each node, represented by the multi-valued attribute record. Notice that each record contains both the result of the query as well as the parameters that produced that result. Not only is this approach more convenient than creating a separate command for each pair of nodes, but it also allows the intersect filter to answer the query more efficiently using special algorithms that can quickly rule out non-intersecting objects.</p>"},{"location":"soar_manual/08_SpatialVisualSystem/#filter-list","title":"Filter List","text":"<p>The following is a list of all filters that are included in SVS. You can also get this list by using the cli command <code>svs filters</code> and get information about a specific filter using the command <code>svs filters.FILTER_NAME</code>. Many filters have a <code>_select</code> version. The select version returns a subset of the input nodes which pass a test.  For example, the intersect filter returns boolean values for each input (a, b) pair, while the intersect_select filter returns the nodes in set b which intersect the input node a. This is useful for passing the results of one filter into another (e.g.  take the nodes that intersect node a and find the largest of them).</p> <ul> <li>Node: Given an <code>^id</code>, outputs the node with that id.</li> <li>all_nodes: Outputs all the nodes in the scene</li> <li>combine_nodes: Given multiple node inputs as <code>^a</code>, concatenates them into a single output set.</li> <li>remove_nodes: Removes node <code>^a</code> from the input set and outputs the rest.</li> <li>node_position: Outputs the position of each node in input <code>^a</code>.</li> <li>node_rotation: Outputs the rotation of each node in input <code>^a</code>.</li> <li>node_scale: Outputs the scale of each node in input <code>^a</code>.</li> <li>node_bbox: Outputs the bounding box of each node in input <code>^a</code>.</li> <li>distance and distance_select:    Outputs the distance between input nodes <code>^a</code> and <code>^b</code> Distance can be specified   by <code>^distance_type &lt;&lt; centroid hull &gt;&gt;</code>, where is the euclidean distance between the centers, and the hull is the   minimum distance between the node surfaces. <code>distance_select</code> chooses nodes in set b in   which the distance to node a falls within the range <code>^min</code>and <code>^max</code>.</li> <li>closest and farthest   Outputs the node in set <code>^b</code> closest to or farthest from <code>^a</code> (also uses <code>distance_type</code>).</li> <li>axis_distance and axis_distance_select   Outputs the distance from input node <code>^a</code> to <code>^b</code> along a particular axis   (<code>^axis &lt;&lt; x y z &gt;&gt;</code>). This   distance is based on bounding boxes. A value of 0 indicates the nodes   overlap on the given axis, otherwise the result is a signed value   indicating whether node b is greater or less than node a on the given   axis. The <code>axis_distance_select</code> filter also uses <code>^min</code> and <code>^max</code> to select nodes in set b.</li> <li>volume and volume_select   Outputs the bounding box volume of each node in set <code>^a</code>. For volume_select,   it outputs a subset of the nodes whose volumes fall within the range <code>^min</code>   and <code>^max</code>.</li> <li>largest and smallest   Outputs the node in set <code>^a</code>} with the largest or smallest volume.</li> <li>larger and larger_select   Outputs whether input node <code>^a</code> is larger than each input node <code>^b</code>, or selects all nodes in b for which a is larger.</li> <li>smaller and smaller_select   Outputs whether input node <code>^a</code> is smaller than each input node <code>^b</code>, or   selects all nodes in b for which a is smaller.</li> <li>contain and contain_select   Outputs whether the bounding box of each input node <code>^a</code> contains the bounding   box of each input node <code>^b</code>, or selects those nodes in b which are contained   by node a.</li> <li>intersect and intersect_select   Outputs whether each input node <code>^a</code> intersects each input node <code>^b</code>, or   selects those nodes in b which intersect node a. Intersection is specified by   <code>^intersect_type &lt;&lt; hull box &gt;&gt;</code>; either the convex hull of the node or   the axis-aligned bounding box.</li> <li>tag_select   Outputs all the nodes in input set <code>^a</code> which have the tag specified by   <code>^tag_name</code> and <code>^tag_value</code>.</li> </ul>"},{"location":"soar_manual/08_SpatialVisualSystem/#examples_1","title":"Examples","text":"<p>Select all the objects with a volume between 1 and 2.</p> <pre><code>(S1 ^svs S3)\n  (S3 ^command C3)\n    (C3 ^extract E1)\n      (E1 ^type volume_select ^a A1 ^min 1 ^max 2)\n        (A1 ^type all_nodes)\n</code></pre> <p>Find the distance between the centroid of ball3 and all other objects.</p> <pre><code>(S1 ^svs S3)\n(S3 ^command C3)\n    (C3 ^extract E1)\n      (E1 ^type distance ^a A1 ^b B1 ^distance_type centroid)\n        (A1 ^type node ^id ball3)\n        (B1 ^type all_nodes)\n</code></pre> <p>Test where ball2 intersects any red objects.</p> <pre><code>(S1 ^svs S3)\n  (S3 ^command C3)\n    (C3 ^extract E1)\n      (E1 ^type intersect ^a A1 ^b B1 ^intersect_type hull)\n        (A1 ^type node ^id ball2)\n        (B1 ^type tag_select ^a A2 ^tag_name color ^tag_value red)\n          (A2 ^type all_nodes)\n</code></pre> <p>Find all the objects on the table. This is done by selecting nodes where the distance between them and the table along the z axis is a small positive number.</p> <pre><code>(S1 ^svs S3)\n  (S3 ^command C3)\n    (C3 ^extract E1)\n      (E1 ^type axis_distance_select ^a A1 ^b B1 ^axis z ^min .0001 ^max .1)\n        (A1 ^type node ^id table)\n        (B1 ^type all_nodes)\n</code></pre> <p>Find the smallest object that intersects the table (excluding itself).</p> <pre><code>(S1 ^svs S3)\n  (S3 ^command C3)\n    (C3 ^extract E1)\n      (E1 ^type smallest ^a A1)\n        (A1 ^type intersect_select ^a A2 ^b B2 ^intersect_type hull)\n          (A2 ^type node ^id table)\n          (B1 ^type remove_node ^id table ^a A3)\n            (A3 ^type all_nodes)\n</code></pre>"},{"location":"soar_manual/08_SpatialVisualSystem/#writing-new-filters","title":"Writing new filters","text":"<p>SVS contains a small set of generally useful filters, but many users will need additional specialized filters for their application. Writing new filters for SVS is conceptually simple.</p> <ol> <li>Write a C++ class that inherits from the appropriate filter     subclass.</li> <li>Register the new class in a global table of all filters ().</li> <li>Recompile the kernel.</li> </ol>"},{"location":"soar_manual/08_SpatialVisualSystem/#filter-subclasses","title":"Filter subclasses","text":"<p>The fact that filter inputs and outputs are lists rather than single values introduces some complexity to how filters are implemented. Depending on the functionality of the filter, the multiple inputs into multiple parameters must be combined in different ways, and sets of inputs will map in different ways onto the output values. Furthermore, the outputs of filters are cached so that the filter does not repeat computations on sets of inputs that do not change. To shield the user from this complexity, a set of generally useful filter paradigms were implemented as subclasses of the basic <code>filter</code> class. When writing custom filters, try to inherit from one of these classes instead of from <code>filter</code> directly.</p>"},{"location":"soar_manual/08_SpatialVisualSystem/#map-filter","title":"Map filter","text":"<p>This is the most straightforward and useful class of filters. A filter of this class takes the Cartesian product of all input values in all parameters, and performs the same computation on each combination, generating one output. In other words, this class implements a one-to-one mapping from input combinations to output values.</p> <p>To write a new filter of this class, inherit from the <code>map_filter</code> class, and define the <code>compute</code> function. Below is an example template:</p> <pre><code>class new_map_filter : public map_filter&lt;double&gt; // templated with output type\n{\npublic:\nnew_map_filter(Symbol *root, soar_interface *si, filter_input *input, scene *scn)\n: map_filter&lt;double&gt;(root, si, input)   // call superclass constructor\n{}\n/* Compute\n        Do the proper computation based on the input filter_params\n        and set the out parameter to the result\n        Return true if successful, false if an error occured */\nbool compute(const filter_params* p, double&amp; out){\nsgnode* a;\nif(!get_filter_param(this, p, \"a\", a)){\nset_status(\"Need input node a\");\nreturn false;\n}\nout = // Your computation here\n}\n};\n</code></pre>"},{"location":"soar_manual/08_SpatialVisualSystem/#select-filter","title":"Select filter","text":"<p>This is very similar to a map filter, except for each input combination from the Cartesian product the output is optional. This is useful for selecting and returning a subset of the outputs.</p> <p>To write a new filter of this class, inherit from the <code>select_filter</code> class, and define the <code>compute</code> function. Below is an example template:</p> <pre><code>class new_select_filter : public select_filter&lt;double&gt; // templated with output type\n{\npublic:\nnew_select_filter(Symbol *root, soar_interface *si, filter_input *input, scene *scn)\n: select_filter&lt;double&gt;(root, si, input)   // call superclass constructor\n{}\n/* Compute\n        Do the proper computation based on the input filter_params\n        and set the out parameter to the result (if desired)\n        Also set the select bit to true if you want to the result to be output.\n        Return true if successful, false if an error occurred */\nbool compute(const filter_params* p, double&amp; out, bool&amp; select){\nsgnode* a;\nif(!get_filter_param(this, p, \"a\", a)){\nset_status(\"Need input node a\");\nreturn false;\n}\nout = // Your computation here\nselect = // test for when to output the result of the computation\n}\n};\n</code></pre>"},{"location":"soar_manual/08_SpatialVisualSystem/#rank-filter","title":"Rank filter","text":"<p>A filter where a ranking is computed for each combination from the Cartesian product of the input and only the combination which results in the highest (or lowest) value is output. The default behavior is to select the highest, to select the lowest you can call <code>set_select_highest(false)</code> on the filter.</p> <p>To write a new filter of this class, inherit from the <code>rank_filter</code> class, and define the <code>rank</code> function. Below is an example template:</p> <pre><code>class new_rank_filter : public rank_filter\n{\npublic:\nnew_rank_filter(Symbol *root, soar_interface *si, filter_input *input, scene *scn)\n: rank_filter(root, si, input)   // call superclass constructor\n{}\n/* Compute\n        Do the proper computation based on the input filter_params\n        And set r to the ranking result.\n        Return true if successful, false if an error occured */\nbool compute(const filter_params* p, double&amp; r){\nsgnode* a;\nif(!get_filter_param(this, p, \"a\", a)){\nset_status(\"Need input node a\");\nreturn false;\n}\nr = // Ranking computation\n}\n};\n</code></pre>"},{"location":"soar_manual/08_SpatialVisualSystem/#generic-node-filters","title":"Generic Node Filters","text":"<p>There are also a set of generic filters specialized for computations involving nodes. With these you only need to specify a predicate function involving nodes. (Also see filters/base_node_filters.h ).</p> <p>There are three types of these filters:</p>"},{"location":"soar_manual/08_SpatialVisualSystem/#node-test-filters","title":"Node Test Filters","text":"<p>These filters involve a binary test between two nodes (e.g. intersection or larger). You must specify a test function of the following form:</p> <pre><code>bool node_test(sgnode* a, sgnode* b, const filter_params* p)\n</code></pre> <p>For an example of how the following base filters are used, see filters/intersect.cpp.</p> <ul> <li>node_test_filter   For each input pair (a, b) this outputs the boolean result of .</li> <li>node_test_select_filter   For each input pair (a, b) this outputs node b if .   (Can choose to select b if the test is false by calling ).</li> </ul>"},{"location":"soar_manual/08_SpatialVisualSystem/#node-comparison-filters","title":"Node Comparison Filters","text":"<p>These filters involve a numerical comparison between two nodes (e.g. distance). You must specify a comparison function of the following form:</p> <pre><code>double node_comparison(sgnode* a, sgnode* b, const filter_params* p)\n</code></pre> <p>For an example of how the following base filters are used, see filters/distance.cpp.</p> <ul> <li>node_comparison_filter   For each input pair (a, b), outputs the numerical result of <code>node_comparison(a, b)</code>.</li> <li>node_comparison_select_filter   For each input pair (a, b), outputs node b if <code>min &lt;= node_comparison(a, b) &lt;=   max</code>. Min and max can be set through calling <code>set_min(double)</code> and   <code>set_max(double)</code>, or as specified by the user through the filter_params.</li> <li>node_comparison_rank_filter   This outputs the input pair (a, b) for which <code>node_comparison(a, b)</code> produces the highest value.   To instead have the lowest value output call <code>set_select_highest(true)</code>.</li> </ul>"},{"location":"soar_manual/08_SpatialVisualSystem/#node-evaluation-filters","title":"Node Evaluation Filters","text":"<p>These filters involve a numerical evaluation of a single node (e.g. volume). You must specify an evaluation function of the following form:</p> <pre><code>double node_evaluation(sgnode* a, const filter_params* p)\n</code></pre> <p>For an example of how the following base filters are used, see filters/volume.cpp.</p> <ul> <li>node_evaluation_filter   For each input node a, this outputs the numerical result of .</li> <li>node_evaluation_select_filter   or each input node a, this outputs the node if . Min and max can be set   through calling and , or as specified by the user through the   filter_params.</li> <li>node_evaluation_rank_filter   This outputs the input node a for which produces the highest value. To   instead have the lowest value output call .</li> </ul>"},{"location":"soar_manual/08_SpatialVisualSystem/#command-line-interface","title":"Command line interface","text":"<p>The user can query and modify the runtime behavior of SVS using the <code>svs</code> command. The syntax of this command differs from other Soar commands due to the complexity and object-oriented nature of the SVS implementation.  The basic idea is to allow the user to access each object in the SVS implementation (not to be confused with objects in the scene graph) at runtime. Therefore, the command has the form <code>svs PATH [ARGUMENTS]</code>, where <code>PATH</code> uniquely identifies an object or the method of an object. <code>ARGUMENTS</code> is a space separated list of strings that each object or function interprets in its own way. For example, <code>svs S1.scene.world.car</code> identifies the car object in the scene graph of the top state.  As another example, <code>svs connect_viewer 5999</code> calls the method to connect to the SVS visualizer with 5999 being the TCP port to connect on. Every path has two special arguments.</p> <ul> <li><code>svs PATH dir</code> prints all the children of the object at <code>PATH</code>.</li> <li><code>svs PATH help</code> prints text about how to use the object, if available.</li> </ul> <p>See SVS for more details.</p>"},{"location":"soar_manual/09_SoarUserInterface/","title":"The Soar User Interface","text":"<p>This chapter describes the set of user interface commands for Soar. All commands and examples are presented as if they are being entered at the Soar command prompt.</p> <p>This chapter is organized into 7 sections:</p> <ol> <li>Basic Commands for Running Soar</li> <li>Examining Memory</li> <li>Configuring Trace Information and Debugging</li> <li>Configuring Soar\u2019s Run-Time Parameters</li> <li>File System I/O Commands</li> <li>Soar I/O commands</li> <li>Miscellaneous Commands</li> </ol> <p>Each section begins with a summary description of the commands covered in that section, including the role of the command and its importance to the user. Command syntax and usage are then described fully, in alphabetical order.</p> <p>The following pages were automatically generated from the git repository at</p> <p>https://github.com/SoarGroup/Soar/wiki</p> <p>on the date listed on the title page of this manual. Please consult the repository directly for the most accurate and up-to-date information.</p> <p>For a concise overview of the Soar interface functions, see the Function Summary and Index on page . This index is intended to be a quick reference into the commands described in this chapter.</p>"},{"location":"soar_manual/09_SoarUserInterface/#notation","title":"Notation","text":"<p>The notation used to denote the syntax for each user-interface command follows some general conventions:</p> <ul> <li>The command name itself is given in a bold font.</li> <li>Optional command arguments are enclosed within square brackets, <code>[</code> and <code>]</code></li> <li>A vertical bar, <code>|</code>, separates alternatives.</li> <li>Curly braces, <code>{}</code> , are used to group arguments when at least one   argument from the set is required.</li> <li>The commandline prompt that is printed by Soar, is normally the   agent name, followed by \u2019\u2019. In the examples in this manual, we use   \"\".</li> <li>Comments in the examples are preceded by a \u2019#\u2019, and in-line comments   are preceded by \u2019;#\u2019.</li> </ul> <p>For many commands, there is some flexibility in the order in which the arguments may be given. (See the online help for each command for more information.) We have not incorporated this flexible ordering into the syntax specified for each command because doing so complicates the specification of the command. When the order of arguments will affect the output produced by a command, the reader will be alerted.</p> <p>Note that the command list was revamped and simplified in Soar 9.6.0. While we encourage people to learn the new syntax, aliases and some special mechanism have been added to maintain backwards compatibility with old Soar commands. As a result, many of the sub-commands of the newer commands may use different styles of arguments.</p>"},{"location":"soar_manual/09_SoarUserInterface/#basic-commands-for-running-soar","title":"Basic Commands for Running Soar","text":"<p>This section describes the commands used to start, run and stop a Soar program; to invoke on-line help information; and to create and delete Soar productions. It also describes how to configure some general settings for Soar.</p> <p>The specific commands described in this section are:</p> <ul> <li> <p>soar   Commands and settings related to running Soar. Use soar ?   for a summary of sub-commands listed below.</p> <ul> <li> <p>soar init   Reinitialize Soar so a program can be rerun from scratch.</p> </li> <li> <p>soar stop   Interrupt a running Soar program.</p> </li> <li> <p>soar max-chunks   Limit the number of chunks created during a decision cycle.</p> </li> <li> <p>soar max-dc-time   Set a wall-clock time limit such that the agent will be   interrupted when a single decision cycle exceeds this limit.</p> </li> <li> <p>soar max-elaborations   Limit the maximum number of elaboration cycles in a given   phase.</p> </li> <li> <p>soar max-goal-depth   Limit the sub-state stack depth.</p> </li> <li> <p>soar max-memory-usage   Set the number of bytes that when exceeded by an agent,   will trigger the memory usage exceeded event.</p> </li> <li> <p>soar max-nil-output-cycles   Limit the maximum number of decision cycles executed   without producing output.</p> </li> <li> <p>soar max-gp   Set the upper-limit to the number of productions generated   by the gp command.</p> </li> <li> <p>soar stop-phase   Controls the phase where agents stop when running by   decision.</p> </li> <li> <p>soar tcl   Controls whether Soar Tcl mode is enabled.</p> </li> <li> <p>soar timers   Toggle on or off the internal timers used to profile Soar.</p> </li> <li> <p>soar version   Returns version number of Soar kernel.</p> </li> <li> <p>soar waitsnc   Generate a wait state rather than a state-no-change   impasse.</p> </li> </ul> </li> <li> <p>run   Begin Soar\u2019s execution cycle.</p> </li> <li> <p>exit   Shut down the Soar environment. Terminates Soar and exits the kernel. <code>stop exit</code></p> </li> <li> <p>help   Provide formatted, on-line information about Soar commands.</p> </li> <li> <p>decide   Commands and settings related to the selection of operators   during the Soar decision process</p> <ul> <li> <p>decide indifferent-selection   Controls indifferent preference arbitration.</p> </li> <li> <p>decide numeric-indifferent-mode   Select method for combining numeric preferences.</p> </li> <li> <p>decide predict   Predict the next selected operator</p> </li> <li> <p>decide select   Force the next selected operator</p> </li> <li> <p>decide set-random-seed   Seed the random number generator.</p> </li> </ul> </li> <li> <p>alias   Define a new alias, or command, using existing commands and   arguments.</p> </li> </ul> <p>These commands are all frequently used anytime Soar is run.</p>"},{"location":"soar_manual/09_SoarUserInterface/#procedural-memory-commands","title":"Procedural Memory Commands","text":"<p>This section describes the commands used to create and delete Soar productions, to see what productions will match and fire in the next Propose or Apply phase, to watch when specific productions fire and retract, and to configure options for selecting between mutually indifferent operators, along with various other methods for examining the contents and statistics of procedural memory.</p> <p>The specific commands described in this section are:</p> <ul> <li> <p>sp   Create a production and add it to production memory.</p> </li> <li> <p>gp   Define a pattern used to generate and source a set of Soar   productions.</p> </li> <li> <p>production   Commands to manipulate Soar rules and analyze their usage</p> <ul> <li> <p>production break   Set interrupt flag on specific productions.</p> </li> <li> <p>production excise   This command removes productions from Soar\u2019s memory.</p> </li> <li> <p>production find   Find productions that contain a given pattern.</p> </li> <li> <p>production firing-counts   Print the number of times productions have fired.</p> </li> <li> <p>production matches   Print information about the match set and partial matches.</p> </li> <li> <p>production memory-usage   Print memory usage for production matches.</p> </li> <li> <p>production optimize-attribute   Declare an attribute as multi-attributes so as to increase   Rete production matching efficiency.</p> </li> <li> <p>production watch   Trace firings and retractions of specific productions.</p> </li> </ul> </li> </ul> <p>sp is of course used in virtually all Soar programming. Of the remaining commands, soar and production memory-usage are most often used. production find is especially useful when the number of productions loaded is high. production firing-counts is used to see if how many times certain rules fire. production watch is related to wm watch , but applies only to specific, named productions.</p>"},{"location":"soar_manual/09_SoarUserInterface/#short-term-memory-commands","title":"Short-term Memory Commands","text":"<p>This section describes the commands for interacting with working memory and preference memory, seeing what productions will match and fire in the next Propose or Apply phase, and examining the goal dependency set. These commands are particularly useful when running or debugging Soar, as they let users see what Soar is \"thinking.\" Also included in this section is information about using Soar\u2019s Spatial Visual System (SVS), which filters perceptual input into a form usable in symbolic working memory.</p> <p>The specific commands described in this section are:</p> <ul> <li> <p>print   Print items in working, semantic and production memory. Can   also print the print the WMEs in the goal dependency set for each   goal.</p> </li> <li> <p>wm   Commands and settings related to working memory and working memory   activation.</p> <ul> <li> <p>wm activation   Get/Set working memory activation parameters.</p> </li> <li> <p>wm add   Manually add an element to working memory.</p> </li> <li> <p>wm remove   Manually remove an element from working memory.</p> </li> <li> <p>wm watch   Print information about wmes that match a certain pattern   as they are added and removed.</p> </li> </ul> </li> <li> <p>preferences   Examine items in preference memory.</p> </li> <li> <p>svs   Perform spatial visual system commands.</p> </li> </ul> <p>Of these commands, print is the most often used (and the most complex). print \u2013gds is useful for examining the goal dependency set when subgoals seem to be disappearing unexpectedly. preferences is used to examine which candidate operators have been proposed.</p>"},{"location":"soar_manual/09_SoarUserInterface/#learning","title":"Learning","text":"<p>This section describes the commands for enabling and configuring Soar\u2019s mechanisms of chunking and reinforcement learning. The specific commands described in this section are:</p> <ul> <li> <p>chunk   Set the parameters for explanation-based chunking, Soar\u2019s   learning mechanism.</p> </li> <li> <p>rl   Get/Set RL parameters and statistics.</p> </li> </ul>"},{"location":"soar_manual/09_SoarUserInterface/#long-term-declarative-memory","title":"Long-term Declarative Memory","text":"<p>This section describes the commands for enabling and configuring Soar\u2019s long-term semantic memory and episodic memory systems. The specific commands described in this section are:</p> <ul> <li> <p>smem   Get/Set semantic memory parameters and statistics.</p> </li> <li> <p>epmem   Get/Set episodic memory parameters and statistics.</p> </li> </ul>"},{"location":"soar_manual/09_SoarUserInterface/#other-debugging-commands","title":"Other Debugging Commands","text":"<p>This section describes the commands used primarily for debugging or to configure the trace output printed by Soar as it runs. Many of these commands provide options that simplify or restrict runtime behavior to enable easier and more localized debugging. Users may specify the content of the runtime trace output, examine the backtracing information that supports generated justifications and chunks, or request details on Soar\u2019s performance.</p> <p>The specific commands described in this section are:</p> <ul> <li> <p>trace   Control the information printed as Soar runs. (was watch)</p> </li> <li> <p>output   Controls sub-commands and settings related to Soar\u2019s output.</p> <ul> <li> <p>output enabled   Toggles printing at the lowest level.</p> </li> <li> <p>output console   Redirects printing to the the terminal. Most users will not   change this.</p> </li> <li> <p>output callbacks   Toggles standard Soar agent callback-based printing.</p> </li> <li> <p>output log   Record all user-interface input and output to a file.</p> </li> <li> <p>output command-to-file   Dump the printed output and results of a command to a file.</p> </li> <li> <p>output print-depth   Set how many generations of an identifier\u2019s children that   Soar will print</p> </li> <li> <p>output warnings   Toggle whether or not warnings are printed.</p> </li> <li> <p>output verbose   Control detailed information printed as Soar runs.</p> </li> <li> <p>output echo-commands   Set whether or not commands are echoed to other connected   debuggers.</p> </li> </ul> </li> <li> <p>explain   Provides interactive exploration of why a rule was learned.</p> </li> <li> <p>visualize   Creates graph visualizations of Soar\u2019s memory systems or   processing.</p> </li> <li> <p>stats   Print information on Soar\u2019s runtime statistics.</p> </li> <li> <p>debug   Contains commands that provide access to Soar\u2019s internals. Most   users will not need to access these commands</p> <ul> <li> <p>debug allocate   Allocate additional 32 kilobyte blocks of memory for a   specified memory pool without running Soar.</p> </li> <li> <p>debug port   Returns the port the kernel instance is listening on.</p> </li> <li> <p>debug time   Uses a default system clock timer to record the wall time   required while executing a command.</p> </li> <li> <p>debug internal-symbols   Print information about the Soar symbol table.</p> </li> </ul> </li> </ul> <p>Of these commands, trace is the most often used (and the most complex). output print-depth is related to the print command. stats is useful *for understanding how much work Soar is doing.</p>"},{"location":"soar_manual/09_SoarUserInterface/#file-system-io-commands","title":"File System I/O Commands","text":"<p>This section describes commands which interact in one way or another with operating system input and output, or file I/O. Users can save/retrieve information to/from files, redirect the information printed by Soar as it runs, and save and load the binary representation of productions. The specific commands described in this section are:</p> <ul> <li> <p>cd   Change directory.</p> </li> <li> <p>dirs   List the directory stack.</p> </li> <li> <p>load   Loads soar files, rete networks, saved percept streams and   external libraries.</p> <ul> <li> <p>load file   Sources a file containing soar commands and productions.   May also contain Tcl code if Tcl mode is enabled.</p> </li> <li> <p>load library   Loads an external library that extends functionality of   Soar.</p> </li> <li> <p>load rete-network   Loads a rete network that represents rules loaded in   production memory.</p> </li> <li> <p>load library   Loads soar files, rete networks, saved percept streams and   external libraries.</p> </li> </ul> </li> <li> <p>ls   List the contents of the current working directory.</p> </li> <li> <p>popd   Pop the current working directory off the stack and change to   the next directory on the stack.</p> </li> <li> <p>pushd   Push a directory onto the directory stack, changing to it.</p> </li> <li> <p>pwd   Print the current working directory.</p> </li> <li> <p>save   Saves chunks, rete networks and percept streams.</p> <ul> <li> <p>save agent   Saves the agent\u2019s procedural and semantic memories and   settings to a single file.</p> </li> <li> <p>save chunks   Saves chunks into a file.</p> </li> <li> <p>save percepts   Saves future input link structures into a file.</p> </li> <li> <p>save rete-network   Saves the current rete networks that represents rules   loaded in production memory.</p> </li> </ul> </li> <li> <p>echo   Prints a string to the current output device.</p> </li> </ul> <p>(See also the output command.)</p> <p>The load file command, previously known as source, is used for nearly every Soar program. The directory functions are important to understand so that users can navigate directories/folders to load/save the files of interest. Saving and loading percept streams are used mainly when Soar needs to interact with an external environment. Soar applications that include a graphical interface or other simulation environment will often require the use of echo. Users might take advantage of these commands when debugging agents, but care should be used in adding and removing WMEs this way as they do not fall under Soar\u2019s truth maintenance system.</p>"},{"location":"soar_manual/blocksworld/","title":"Blocksworld Soar Rules","text":"<pre><code>###############################################################################\n###\n### File              : blocks.soar\n### Original author(s): John E. Laird &lt;laird@eecs.umich.edu&gt;\n### Organization      : University of Michigan AI Lab\n### Created on        : 15 Mar 1995, 13:53:46\n### Last Modified By  : Clare Bates Congdon &lt;congdon@eecs.umich.edu&gt;\n### Last Modified On  : 17 Jul 1996, 16:35:14\n### Soar Version      : 7\n###\n### Description : A new, simpler implementation of the blocks world\n###               with just three blocks being moved at random.\n###\n### Notes: \n###   CBC, 6/27: Converted to Tcl syntax\n###   CBC, 6/27: Added extensive comments\n###############################################################################\n\n###############################################################################\n# Create the initial state with blocks A, B, and C on the table.\n#\n# This is the first production that will fire; Soar creates the initial state\n#   as an architectural function (in the 'zeroth' decision cycle), which will\n#   match against this production.\n# This production does a lot of work because it is creating (preferences for)\n# all the structure for the initial state:\n# 1. The state has a problem-space named 'blocks'. The problem-space limits\n#    the operators that will be selected for a task. In this simple problem,\n#    it isn't really necessary (there is only one operator), but it's a\n#    programming convention that you should get used to.\n# 2. The state has four 'things' -- three blocks and the table.\n# 3. The state has three 'ontop' relations\n# 4. Each of the things has substructure: their type and their names. Note that\n#    the fourth thing is actually a 'table'.\n# 5. Each of the ontop relations has substructure: the top thing and the\n#    bottom thing.\n# Finally, the production writes a message for the user.\n#\n# Note that this production will fire exactly once and will never retract.\n\nsp {blocks-world*elaborate*initial-state\n   (state &lt;s&gt; ^superstate nil)\n--&gt;\n   (&lt;s&gt; ^problem-space blocks\n        ^thing &lt;block-A&gt; &lt;block-B&gt; &lt;block-C&gt; &lt;table&gt;\n        ^ontop &lt;ontop-A&gt; &lt;ontop-B&gt; &lt;ontop-C&gt;)\n   (&lt;block-A&gt; ^type block ^name A)\n   (&lt;block-B&gt; ^type block ^name B)\n   (&lt;block-C&gt; ^type block ^name C)\n   (&lt;table&gt; ^type table ^name TABLE)\n   (&lt;ontop-A&gt; ^top-block &lt;block-A&gt; ^bottom-block &lt;table&gt;)\n   (&lt;ontop-B&gt; ^top-block &lt;block-B&gt; ^bottom-block &lt;table&gt;)\n   (&lt;ontop-C&gt; ^top-block &lt;block-C&gt; ^bottom-block &lt;table&gt;)\n   (write (crlf) |Initial state has A, B, and C on the table.|)}\n\n###############################################################################\n# State elaborations - keep track of which objects are clear\n# There are two productions - one for blocks and one for the table.\n###############################################################################\n\n###############################################################################\n# Assert table always clear\n#\n# The conditions establish that:\n#  1. The state has a problem-space named 'blocks'.\n#  2. The state has a thing of type table.\n# The action:\n#  1. creates an acceptable preference for an attribute-value pair asserting\n#     the table is clear.\n#\n# This production will also fire once and never retract.\n\nsp {elaborate*table*clear\n   (state &lt;s&gt; ^problem-space blocks\n              ^thing &lt;table&gt;)\n   (&lt;table&gt; ^type table)\n--&gt;\n   (&lt;table&gt; ^clear yes)}\n\n###############################################################################\n# Calculate whether a block is clear\n#\n# The conditions establish that:\n#  1. The state has a problem-space named 'blocks'.\n#  2. The state has a thing of type block.\n#  3. There is no 'ontop' relation having the block as its 'bottom-block'.\n# The action:\n#  1. create an acceptable preference for an attribute-value pair asserting\n#     the block is clear.\n#\n# This production will retract whenever an 'ontop' relation for the given block\n#  is created. Since the (&lt;block&gt; ^clear yes) wme only has i-support, it will\n#  be removed from working memory automatically when the production retracts.\n\nsp {elaborate*block*clear\n   (state &lt;s&gt; ^problem-space blocks\n              ^thing &lt;block&gt;)\n   (&lt;block&gt; ^type block)\n   -(&lt;ontop&gt; ^bottom-block &lt;block&gt;)\n--&gt;\n   (&lt;block&gt; ^clear yes)}\n\n###############################################################################\n# Suggest MOVE-BLOCK operators\n#\n# This production proposes operators that move one block ontop of another block.  \n# The conditions establish that:\n#  1. The state has a problem-space named 'blocks'\n#  2. The block moved and the block moved TO must be both be clear.\n#  3. The block moved is different from the block moved to.\n#  4. The block moved must be type block.\n#  5. The block moved must not already be ontop the block being moved to.\n# The actions:\n#  1. create an acceptable preference for an operator.\n#  2. create acceptable preferences for the substructure of the operator (its\n#     name, its 'moving-block' and the 'destination).\n\nsp {blocks-world*propose*move-block\n   (state &lt;s&gt; ^problem-space blocks\n              ^thing &lt;thing1&gt; {&lt;&gt; &lt;thing1&gt; &lt;thing2&gt;}\n              ^ontop &lt;ontop&gt;)\n   (&lt;thing1&gt; ^type block ^clear yes)\n   (&lt;thing2&gt; ^clear yes)\n   (&lt;ontop&gt; ^top-block &lt;thing1&gt;\n            ^bottom-block &lt;&gt; &lt;thing2&gt;)\n--&gt;\n   (&lt;s&gt; ^operator &lt;o&gt; +)\n   (&lt;o&gt; ^name move-block\n        ^moving-block &lt;thing1&gt;\n        ^destination &lt;thing2&gt;)}\n\n###############################################################################\n# Make all acceptable move-block operators also indifferent\n#\n# The conditions establish that:\n#  1. the state has an acceptable preference for an operator\n#  2. the operator is named move-block\n# The actions:\n#  1. create an indifferent prefererence for the operator\n\nsp {blocks-world*compare*move-block*indifferent\n   (state &lt;s&gt; ^operator &lt;o&gt; +)\n   (&lt;o&gt; ^name move-block)\n--&gt;\n   (&lt;s&gt; ^operator &lt;o&gt; =)}\n\n###############################################################################\n# Apply a MOVE-BLOCK operator\n# \n# There are two productions that are part of applying the operator.\n# Both will fire in parallel.\n###############################################################################\n\n###############################################################################\n# Apply a MOVE-BLOCK operator\n#   (the block is no longer ontop of the thing it used to be ontop of)\n#\n# This production is part of the application of a move-block operator.\n# The conditions establish that:\n#  1. An operator has been selected for the current state\n#     a. the operator is named move-block\n#     b. the operator has a 'moving-block' and a 'destination'\n#  2. The state has an ontop relation\n#     a. the ontop relation has a 'top-block' that is the same as the\n#        'moving-block' of the operator\n#     b. the ontop relation has a 'bottom-block' that is different from the \n#        'destination' of the operator\n# The actions:\n#  1. create a reject preference for the ontop relation\n\nsp {blocks-world*apply*move-block*remove-old-ontop\n   (state &lt;s&gt; ^operator &lt;o&gt;\n              ^ontop &lt;ontop&gt;)\n   (&lt;o&gt; ^name move-block \n        ^moving-block &lt;block1&gt; \n        ^destination &lt;block2&gt;)\n   (&lt;ontop&gt; ^top-block &lt;block1&gt; \n            ^bottom-block { &lt;&gt; &lt;block2&gt; &lt;block3&gt; })\n--&gt;\n   (&lt;s&gt; ^ontop &lt;ontop&gt; -)}\n\n###############################################################################\n# Apply a MOVE-BLOCK operator\n#   (the block is now ontop of the destination)\n#\n# This production is part of the application of a move-block operator.\n# The conditions establish that:\n#  1. An operator has been selected for the current state\n#     a. the operator is named move-block\n#     b. the operator has a 'moving-block' and a 'destination'\n# The actions:\n#  1. create an acceptable preference for a new ontop relation\n#  2. create (acceptable preferences for) the substructure of the ontop\n#     relation: the top block and the bottom block\n\nsp {blocks-world*apply*move-block*add-new-ontop\n   (state &lt;s&gt; ^operator &lt;o&gt;)\n   (&lt;o&gt; ^name move-block\n        ^moving-block &lt;block1&gt;\n        ^destination &lt;block2&gt;)\n--&gt;\n   (&lt;s&gt; ^ontop &lt;ontop&gt;)\n   (&lt;ontop&gt; ^top-block &lt;block1&gt;\n            ^bottom-block &lt;block2&gt;)}\n\n###############################################################################\n###############################################################################\n# Detect that the goal has been achieved \n#\n# The conditions establish that:\n#  1. The state has a problem-space named 'blocks'\n#  2. The state has three ontop relations\n#     a. a block named A is ontop a block named B\n#     b. a block named B is ontop a block named C\n#     c. a block named C is ontop a block named TABLE\n# The actions:\n#  1. print a message for the user that the A,B,C tower has been built\n#  2. halt Soar\n\nsp {blocks-world*detect*goal\n   (state &lt;s&gt; ^problem-space blocks\n              ^ontop &lt;AB&gt; \n               { &lt;&gt; &lt;AB&gt; &lt;BC&gt;}\n               { &lt;&gt; &lt;AB&gt; &lt;&gt; &lt;BC&gt; &lt;CT&gt; } )\n   (&lt;AB&gt; ^top-block &lt;A&gt; ^bottom-block &lt;B&gt;)\n   (&lt;BC&gt; ^top-block &lt;B&gt; ^bottom-block &lt;C&gt;)\n   (&lt;CT&gt; ^top-block &lt;C&gt; ^bottom-block &lt;T&gt;)\n   (&lt;A&gt; ^type block ^name A)\n   (&lt;B&gt; ^type block ^name B)\n   (&lt;C&gt; ^type block ^name C)\n   (&lt;T&gt; ^type table ^name TABLE)\n--&gt;\n   (write (crlf) |Achieved A, B, C|)\n   (halt)}\n\n###############################################################################\n###############################################################################\n# Monitor the state: Print a message every time a block is moved\n#\n# The conditions establish that:\n#  1. An operator has been selected for the current state\n#     a. the operator is named move-block\n#     b. the operator has a 'moving-block' and a 'destination'\n#  2. each block has a name\n# The actions:\n#  1. print a message for the user that the block has been moved to the\n#     destination. \n\nsp {blocks-world*monitor*move-block\n   (state &lt;s&gt; ^operator &lt;o&gt;)\n   (&lt;o&gt; ^name move-block\n        ^moving-block &lt;block1&gt;\n        ^destination &lt;block2&gt;)\n   (&lt;block1&gt; ^name &lt;block1-name&gt;)\n   (&lt;block2&gt; ^name &lt;block2-name&gt;)   \n--&gt;\n   (write (crlf) |Moving Block: | &lt;block1-name&gt;\n                 | to: | &lt;block2-name&gt; ) }\n</code></pre>"},{"location":"tutorials/","title":"Tutorials","text":"<ul> <li>Official Soar Tutorial</li> <li>Introduction to the Soar Debugger</li> <li>Soar Markup Language: Quick Start Guide</li> </ul>"},{"location":"tutorials/IntroSoarDebugger/","title":"Introduction to the Soar Debugger","text":"","tags":["debugger","agent debugging"]},{"location":"tutorials/IntroSoarDebugger/#related","title":"Related","text":"<ul> <li>Command line options</li> <li>Tutorial 1</li> </ul>","tags":["debugger","agent debugging"]},{"location":"tutorials/SMLQuickStartGuide/","title":"SML Quick Start Guide","text":"<p>SML (Soar Markup Language) provides an interface into Soar based around sending and receiving commands packaged as XML packets. The interface is designed to support connecting environments to Soar (where input and output data structures are sent back and forth) and to support debuggers (where commands to print out specific productions or working memory elements are sent back and forth).</p> <p>We refer to these environments and debuggers as \"clients\".</p> <p>The details and motivation behind the development of the SML language are described in the \"Soar XML Interface Specification\" which goes into a lot more depth on the details of the XML dialect. However, for users this guide may be largely sufficient.</p> <p>We provide a series of classes that together hide the details of the XML messaging system while allowing the client full control over Soar. This guide will provide a quick introduction to using those classes.</p> <p>The SML API is natively implemented in C++, but there are Java, Python, and Tcl bindings automatically generated by SWIG. Although all examples used in this document are in C++, it should be fairly intuitive how they translate into other languages. Later in the document is a section containing example environments written in Java.</p> <p>This page explains how to compile SML clients in various languages.</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#simple-sml-example","title":"Simple SML example","text":"<p>This example is something of a \"hello world\" example of how to use the major elements of the SML API. Once you understand this example, you'll be pretty much ready to dive in.</p> <pre><code>// Generally only need this one header file\n#include \"sml_Client.h\"\nusing namespace sml ;\nusing namespace std ;\nvoid main() {\n// Create an instance of the Soar kernel in our process\nKernel* pKernel = Kernel::CreateKernelInNewThread() ;\n// Check that nothing went wrong.  We will always get back a kernel object\n// even if something went wrong and we have to abort.\nif (pKernel-&gt;HadError())\n{\ncout &lt;&lt; pKernel-&gt;GetLastErrorDescription() &lt;&lt; endl ;\nreturn ;\n}\n// Create a Soar agent named \"test\"\n// NOTE: We don't delete the agent pointer.  It's owned by the kernel\nsml::Agent* pAgent = pKernel-&gt;CreateAgent(\"test\") ;\n// Check that nothing went wrong\n// NOTE: No agent gets created if there's a problem, so we have to check for\n// errors through the kernel object.\nif (pKernel-&gt;HadError())\n{\ncout &lt;&lt; pKernel-&gt;GetLastErrorDescription() &lt;&lt; endl ;\nreturn ;\n}\n// Load some productions\npAgent-&gt;LoadProductions(\"testsml.soar\") ;\nif (pAgent-&gt;HadError())\n{\ncout &lt;&lt; pAgent-&gt;GetLastErrorDescription() &lt;&lt; endl ;\nreturn ;\n}\nIdentifier* pInputLink = pAgent-&gt;GetInputLink() ;\n// Create (I3 ^plane P1) (P1 ^type Boeing747 ^speed 200 ^direction 50.5) on\n// the input link.  (We don't own any of the returned objects).\nIdentifier* pID          = pAgent-&gt;CreateIdWME(pInputLink, \"plane\") ;\nStringElement* pWME1 = pAgent-&gt;CreateStringWME(pID, \"type\", \"Boeing747\") ;\nIntElement* pWME2    = pAgent-&gt;CreateIntWME(pID, \"speed\", 200) ;\nFloatElement* pWME3  = pAgent-&gt;CreateFloatWME(pID, \"direction\", 50.5) ;\n// Send the changes to working memory to Soar\n// With 8.6.2 this call is optional as changes are sent automatically.\npAgent-&gt;Commit() ;\n// Run Soar for 2 decisions\npAgent-&gt;RunSelf(2) ;\n// Change (P1 ^speed) to 300 and send that change to Soar\npAgent-&gt;Update(pWME2, 300) ;\npAgent-&gt;Commit() ;\n// Run Soar until it generates output or 15 decision cycles have passed\n// (More normal case is to just run for a decision rather than until output).\npAgent-&gt;RunSelfTilOutput() ;\n// Go through all the commands we've received (if any) since we last ran Soar.\nint numberCommands = pAgent-&gt;GetNumberCommands() ;\nfor (int i = 0 ; i &lt; numberCommands ; i++)\n{\nIdentifier* pCommand = pAgent-&gt;GetCommand(i) ;\nstd::string name  = pCommand-&gt;GetCommandName() ;\nstd::string speed = pCommand-&gt;GetParameterValue(\"speed\") ;\n// Update environment here to reflect agent's command\n// Then mark the command as completed\npCommand-&gt;AddStatusComplete() ;\n// Or could do the same manually like this:\n// pAgent-&gt;CreateStringWME(pCommand, \"status\", \"complete\") ;\n}\n// See if anyone (e.g. a debugger) has sent commands to Soar\n// Without calling this method periodically, remote connections will be ignored if\n// we choose the \"CreateKernelInCurrentThread\" method.\npKernel-&gt;CheckForIncomingCommands() ;\n// Create an example Soar command line\nstd::string cmd = \"excise --all\" ;\n// Execute the command\nchar const* pResult = pKernel-&gt;ExecuteCommandLine(cmd.c_str(),pAgent-&gt;GetAgentName()) ;\n// Shutdown and clean up\npKernel-&gt;Shutdown() ;   // Deletes all agents (unless using a remote connection)\ndelete pKernel ;                // Deletes the kernel itself\n} // end main\n</code></pre>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#simple-example-explained","title":"Simple example explained","text":"","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#creating-the-kernel","title":"Creating the kernel","text":"<pre><code>// Create an instance of the Soar kernel in our process\nKernel* pKernel = Kernel::CreateKernelInNewThread() ;\n</code></pre> <p>The client can either create a local Soar kernel or a remote connection to an existing Soar kernel (where commands are sent over a socket to a separate process on the same or a different machine).</p> <p>The local kernel can either be created in the same thread as the caller or in a new thread.</p> <p>Using the same thread will generally be a bit faster, but it requires the client to periodically call <code>pKernel-&gt;CheckForIncomingCommands()</code> so that the kernel has a chance to check for commands coming in from other remote processes (e.g. from a debugger). So if you want maximum speed choose the current thread option, but your code will be a bit more complicated. If speed is not as critical then choose the new thread option. The speed difference isn't that large, perhaps a factor of two on the cost of making a call - which will often be dwarfed by the cost of matching productions or updating the environment.</p> <p>As you are just reading the \"SML Quick Start Guide\" I would strongly recommend you use <code>CreateKernelInNewThread</code> until you are somewhat familiar with the system. If you find you need higher performance later, switching over to the CurrentThread model later only requires changing this one line of code.</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#creating-input-link-wmes","title":"Creating input link WME's","text":"<pre><code>// Create (I3 ^plane P1) (P1 ^type Boeing747 ^speed 200 ^direction 50.5) on\n// the input link.  (We don't own any of the returned objects).\nIdentifier* pID          = pAgent-&gt;CreateIdWME(pInputLink, \"plane\") ;\nStringElement* pWME1 = pAgent-&gt;CreateStringWME(pID, \"type\", \"Boeing747\") ;\n</code></pre> <p>The client can build up an arbitrarily complex graph of working memory elements (WMEs) attached to the input-link. Each WME consists of a triplet: <code>(identifier ^attribute value)</code>. The first identifier comes from \"getInputLink\" and then new identifiers are created by <code>CreateIdWME()</code> and new simple WMEs are created through <code>CreateStringWME</code>/<code>CreateIntWME</code>/<code>CreateFloatWME</code>.</p> <p>A WME's value can be updated through the <code>pAgent-&gt;Update()</code> method and it can be removed through <code>pAgent-&gt;DestroyWME()</code> which also makes the working memory object invalid.</p> <p>A graph (rather than a simple tree) can be created through <code>pAgent-&gt;CreateSharedIdWME()</code>. This creates a new identifier WME with the same value as an existing identifier. (E.g. given <code>pOrig = (P7 ^object O3)</code> then <code>CreateSharedIdWME(pInputLink, \"same\", pOrig)</code> would create <code>(I1 ^same O3)</code>).</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#committing-changes","title":"Committing changes","text":"<pre><code>// Send the changes to working memory to Soar\npAgent-&gt;Commit() ;\n</code></pre> <p>The client must explicitly request that changes to working memory be sent over to Soar. This explicit command allows the communication layer to be more efficient, by collecting all changes together and sending them as a single command. With 8.6.2 changes are sent over immediately they are made so Commit() is unnecessary. This produces slightly worse performance (as changes are not collected together into a single packet) so to get maximum performance call SetAutoCommit(false) and write the manual commit calls.</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#running-soar","title":"Running Soar","text":"<pre><code>// Run Soar until it generates output or 15 decision cycles have passed\npAgent-&gt;RunSelfTilOutput() ;\n// Run Soar for 2 decisions\npAgent-&gt;RunSelf(2) ;\n</code></pre> <p>In most real environments, Soar should be run with <code>pKernel-&gt;RunAllAgentsForever()</code> and then use a call to <code>pKernel-&gt;StopAllAgents()</code> to interrupt. This allows a user to run the environment from a debugger as well as from the environment.</p> <p>There's more discussion of this in Section 2 of this document.</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#retrieving-output","title":"Retrieving Output","text":"<pre><code>// Go through all the commands we've received (if any) since we last ran Soar.\nint numberCommands = pAgent-&gt;GetNumberCommands() ;\nfor (int i = 0 ; i &lt; numberCommands ; i++)\n{\nIdentifier* pCommand = pAgent-&gt;GetCommand(i) ;\nstd::string name  = pCommand-&gt;GetCommandName() ;\nstd::string speed = pCommand-&gt;GetParameterValue(\"speed\") ;\n// Update environment here to reflect agent's command\n// Then mark the command as completed\npCommand-&gt;AddStatusComplete() ;\n// Or could do the same manually like this:\n// pAgent-&gt;CreateStringWME(pCommand, \"status\", \"complete\") ;\n}\n</code></pre> <p>There is direct support provided for an output model where \"commands\" are represented as distinction identifier's on the output-link. For example, if the output-link identifier is O1 then the agent might add a move command with <code>(O1 ^move M1)</code> <code>(M1 ^speed 20)</code>.</p> <p>If you choose to adopt this model for the agent's actions then it is possible to query the agent for the number of commands added since the last time Soar was run and to retrieve each Command in turn, its name and parameter values. In this example, pCommand would point to M1, the name would be move and the parameter value for speed would be 20.</p> <p>If you wish to adopt a different model for agent actions, that is also supported, but the support is less direct.</p> <p>First, notice that GetCommand() returns a standard Identifier WME, so this can be manipulated in the same manner as any other WME. In particular Identifier's offer GetNumberChildren and GetChild methods, so using these it is possible to start from the output link and examine all of working memory beneath the output link. There are also other methods (such as FindByAttribute) that can make this search more efficient.</p> <p>Secondly, you can use <code>IsJustAdded()</code> and <code>AreChildrenModified()</code> on WMEs on the output-link (and below) to determine what has changed since the last time Soar was run.</p> <p>Third, you can call <code>AddOutputHandler()</code> to register a function that is called whenever a specific attribute is added to the output link.</p> <p>Finally, if that is not sufficient, it is possible to call <code>GetNumberOutputLinkChanges()</code> and <code>GetOutputLinkChange()</code> to get a list of all of the WMEs to have been added or removed since the last time Soar was run.</p> <p>From this collection of methods it should be possible to support just about any manner of output model you wish to adopt, but we would recommend the \"Command\" model shown above.</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#the-command-line","title":"The Command Line","text":"<pre><code>// Create an example Soar command line\nstd::string cmd = \"excise --all\" ;\n// Execute the command\nchar const* pResult = pKernel-&gt;ExecuteCommandLine(cmd.c_str(),pAgent-&gt;GetAgentName()) ;\n</code></pre> <p>To this point the discussion has been purely about environments and supporting I/O. However, the <code>ExecuteCommandLine</code> methods allow a client to send any command to Soar that can be typed at the Soar command prompt. Using this method, productions can be loaded, excised, printed out etc.</p> <p><code>ExecuteCommandLineXML()</code> is also available which returns the output as a structured XML message, making it easier and safer for a client to parse values from the output. See the online documentation for details the format of that XML output for each command.</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#capturing-print-output","title":"Capturing print output","text":"<p>To capture output during a run you need to register for the <code>smlEVENT_PRINT</code> event which will be called periodically during the course of the run. To do this you need to define a handler function which will be called during the run. Here's a simple example:</p> <pre><code>void MyPrintEventHandler(smlPrintEventId id, void* pUserData, Agent* pAgent, char const* pMessage)\n{\n// In this case the user data is a string we're building up\nstd::string* pTrace = (std::string*)pUserData ;\n(*pTrace) += pMessage ;\n}\n</code></pre> <p>The method includes a piece of \"userData\" which is defined by you when you register for the event. In this case we would have:</p> <pre><code>std::string trace ;\nint callbackp = pAgent-&gt;RegisterForPrintEvent(smlEVENT_PRINT, MyPrintEventHandler, &amp;trace) ;\n</code></pre> <p>Note how the string \"trace\" is passed into the registration function. This object is then passed back to the handler, which uses it to build up a complete trace. After this handler has been registered calling:</p> <pre><code>result = pAgent-&gt;Run(4) ;\n</code></pre> <p>would run Soar for 4 decisions and the trace output would be collected in the string \"trace\".</p> <p>There is now also another way to get this output by registering for <code>smlEVENT_XML_TRACE_OUTPUT</code>. This event sends XML objects rather than text strings. Displaying these to the user requires more work by the client, but if the client wishes to parse the text working with XML is much easier. This is the approach taken in the Java debugger.</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#events","title":"Events","text":"<p>There are a lot of events you can register for and the list given here will surely grow over time. Here are the types of the handlers in C++ and Java (the Java ones are a little different from the C++ and are more error prone as they're checked at runtime not at compile time):</p> <p>C++ event handlers (if you're not sure how to convert these types into functions look at the example of the print handler in the previous section):</p> <pre><code>// Handler for Run events.\n// Passed back the event ID, the agent and the phase together with whatever user data we registered with the client\ntypedef void (*RunEventHandler)(smlRunEventId id, void* pUserData, Agent* pAgent, smlPhase phase);\n// Handler for Agent events (such as creation/destruction etc.).\ntypedef void (*AgentEventHandler)(smlAgentEventId id, void* pUserData, Agent* pAgent) ;\n// Handler for Print events.\ntypedef void (*PrintEventHandler)(smlPrintEventId id, void* pUserData, Agent* pAgent, char const* pMessage) ;\n// Handler for Production manager events.\ntypedef void (*ProductionEventHandler)(smlProductionEventId id, void* pUserData, Agent* pAgent, char const* pProdName, char const* pInstantion) ;\n// Handler for System events.\ntypedef void (*SystemEventHandler)(smlSystemEventId id, void* pUserData, Kernel* pKernel) ;\n// Handler for XML events.  The data for the event is passed back in pXML.\n// NOTE: To keep a copy of the ClientXML* you are passed use ClientXML* pMyXML = new ClientXML(pXML) to create\n// a copy of the object.  This is very efficient and just adds a reference to the underlying XML message object.\n// You need to delete ClientXML objects you create and you should not delete the pXML object you are passed.\ntypedef void (*XMLEventHandler)(smlXMLEventId id, void* pUserData, Agent* pAgent, ClientXML* pXML) ;\n// Handler for RHS (right hand side) function firings\n// pFunctionName and pArgument define the RHS function being called (the client may parse pArgument to extract other values)\n// The return value is a string which allows the RHS function to create a symbol: e.g. ^att (exec plus 2 2) producing ^att 4\n// NOTE: This is the one place in clientSML where we use a std::string in an interface.  If you wish to compile with a pure \"C\" interface\n// this can be replaced by a handler that is passed a buffer and a length.  The length is passed within the framework already (from the kernel to here)\n// so this is an easy transition.\ntypedef std::string (*RhsEventHandler)(smlRhsEventId id, void* pUserData, Agent* pAgent, char const* pFunctionName, char const* pArgument) ;\n</code></pre> <p>Java event handlers are based on implementing an interface within an object:</p> <p>From Kernel:</p> <pre><code>public interface SystemEventInterface {\npublic void systemEventHandler(int eventID, Object data, Kernel kernel) ;\n}\npublic interface UpdateEventInterface {\npublic void updateEventHandler(int eventID, Object data, Kernel kernel, int runFlags) ;\n}\npublic interface StringEventInterface {\npublic void stringEventHandler(int eventID, Object userData, Kernel kernel, String callbackData) ;\n}\npublic interface AgentEventInterface {\npublic void agentEventHandler(int eventID, Object data, String agentName) ;\n}\npublic interface RhsFunctionInterface {\npublic String rhsFunctionHandler(int eventID, Object data, String agentName, String functionName, String argument) ;\n}\npublic interface ClientMessageInterface {\npublic String clientMessageHandler(int eventID, Object data, String agentName, String functionName, String argument) ;\n</code></pre> <p>From Agent:</p> <pre><code>public interface RunEventInterface {\npublic void runEventHandler(int eventID, Object data, Agent agent, int phase) ;\n}\npublic interface ProductionEventInterface {\npublic void productionEventHandler(int eventID, Object data, Agent agent, String prodName, String instantiation) ;\n}\npublic interface PrintEventInterface {\npublic void printEventHandler(int eventID, Object data, Agent agent, String message) ;\n}\npublic interface xmlEventInterface {\npublic void xmlEventHandler(int eventID, Object data, Agent agent, ClientXML xml) ;\n}\npublic interface OutputEventInterface {\npublic void outputEventHandler(Object data, String agentName, String attributeName, WMElement pWmeAdded) ;\n}\npublic interface OutputNotificationInterface {\npublic void outputNotificationHandler(Object data, Agent agent) ;\n}\n</code></pre> <p>Examples of implementations:</p> <pre><code>public void runEventHandler(int eventID, Object data, Agent agent, int phase)\n{\nSystem.out.println(\"Received run event in Java\") ;\n}\n// We pass back the agent's name because the Java Agent object may not yet\n// exist for this agent yet.  The underlying C++ object *will* exist by the\n// time this method is called.  So instead we look up the Agent object\n// from the kernel with GetAgent().\npublic void agentEventHandler(int eventID, Object data, String agentName)\n{\nSystem.out.println(\"Received agent event in Java\") ;\n}\npublic void productionEventHandler(int eventID, Object data, Agent agent, String prodName, String instantiation)\n{\nSystem.out.println(\"Received production event in Java\") ;\n}\npublic void systemEventHandler(int eventID, Object data, Kernel kernel)\n{\nSystem.out.println(\"Received system event in Java\") ;\n}\npublic void printEventHandler(int eventID, Object data, Agent agent, String message)\n{\nSystem.out.println(\"Received print event in Java: \" + message) ;\n}\npublic void xmlEventHandler(int eventID, Object data, Agent agent, ClientXML xml)\n{\nString xmlText = xml.GenerateXMLString(true) ;\nSystem.out.println(\"Received xml trace event in Java: \" + xmlText) ;\nString allChildren = \"\" ;\nif (xml.GetNumberChildren() &gt; 0)\n{\nClientXML child = new ClientXML() ;\nxml.GetChild(child, 0) ;\nString childText = child.GenerateXMLString(true) ;\nallChildren += childText ;\nchild.delete() ;\n}\n}\npublic String testRhsHandler(int eventID, Object data, String agentName, String functionName, String argument)\n{\nSystem.out.println(\"Received rhs function event in Java for function: \" + functionName + \"(\" + argument + \")\") ;\nreturn \"My rhs result \" + argument ;\n}\n</code></pre> <p>To see more about events look at the sml_ClientEvents.h header file or the TestSMLEvents test program (currently located in the Tools folder).</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#events-in-tcl","title":"Events in Tcl","text":"<p>Tcl requires that callbacks to a Tcl interpreter happen in the same thread as the interpreter is executing in. By default, this will not always happen for SML events. This is because there is an event thread started up by SML (running in the client) which is used to check for incoming events and make the necessary callback calls.</p> <p>Therefore for Tcl we recommend shutting down this event thread and polling explicitly for incoming events. This can be done in a few lines of code like this:</p> <pre><code># We want to make sure to handle events in the Tcl thread\n# so we turn off the event thread and poll for events instead.\n$_kernel StopEventThread\ncheckForEvents $_kernel\n\n# Explicitly check for incoming commands and events every n milliseconds\nproc checkForEvents {k} {\n   $k CheckForIncomingCommands\n   after 10 checkForEvents $k\n}\n</code></pre> <p>This assumes <code>$_kernel</code> is a variable set to the SML kernel object. Note, the after 10 triggers another call to the <code>checkForEvents()</code> method after a 10ms delay. Making this value larger will make Tcl less responsive to events. Making it smaller will consume more CPU time checking for events.</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#building-an-environment","title":"Building an Environment","text":"<p>If you are converting an existing SGIO environment you should also read the \"Moving from SGIO to SML\" document as well as this section.</p> <p>The Java implementation of Towers of Hanoi (TOH) is a useful reference, showing a simple environment environment. I'll use that to as an example here, so the code snippets will be in Java, but a very similar approach can be taken in other languages (currently Tcl or C++).</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#initialization","title":"Initialization","text":"<p>The first step is to create an instance of the kernel and then create an agent. The name passed to <code>CreateKernelInNewThread</code> is the name of the library to load (DLL on Windows). This is optional in 8.6.2 and defaults to SoarKernelSML.</p> <p>It is important to check for an error using the <code>kernel.HadError()</code> method. CreateKernel will not return an empty kernel object even if initialization fails. This is deliberate design to ensure that meaningful errors can be reported to the user.</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#initialization-code-sample","title":"Initialization Code Sample","text":"<pre><code>// create our Soar kernel\nkernel = Kernel.CreateKernelInNewThread();\nif (kernel.HadError())\n{\n// Better to use a \u0093Message Box\u0094 to display this if your platform/toolkit allows.\nSystem.out.println(\"Error creating kernel: \" + kernel.GetLastErrorDescription()) ;\nSystem.exit(1);\n}\nagent = kernel.CreateAgent(AGENT_NAME);\nboolean load = agent.LoadProductions(\"towers-of-hanoi-SML.soar\");\nif (!load || agent.HadError()) {\nthrow new IllegalStateException(\"Error loading productions: \"\n+ agent.GetLastErrorDescription());\n}\n</code></pre>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#input","title":"Input","text":"<p>Mapping from the environment's state to input values involves calls to create, update and destroy working memory elements using calls like these:</p> <pre><code>agent.Create&lt;type&gt;WME (e.g. agent.CreateIntWME)\nagent.Update()\nagent.DestroyWME\n</code></pre> <p>Working memory elements are linked together to form a tree (actually a graph) with the input link as the root of the tree. To get the input link identifier (the top of the tree) call <code>agent.GetInputLink()</code>.</p> <p>A key step after making multiple calls to modify the input link is to call Commit(). All changes to working memory are buffered (in the environment) until the moment Commit is called, at which point they are all sent over as a single large message to the kernel. This greatly improves performance, but you must remember to call Commit before running the agent or your changes won't actually appear on the agent's input link. This was changed in 8.6.2 so the default now is that Commit() is called automatically each time a wme is modified on the input link. To enable the faster version which then requires manual calls to Commit() call SetAutoCommit(false). Calling Commit multiple times during a single input cycle will not cause problems.</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#output","title":"Output","text":"<p>The most common way to examine output from an agent is to use the \"Commands\" model. With this method the agent places each output command on the output-link using the format:</p> <pre><code>(X ^output-link I3)\n(I3 ^command-name C1)\n(C1 ^param1 value ^param2 value)\n</code></pre> <p>Thus the name of the command appears directly under the output-link and all parameters are added to the command identifier and can only be one level deep. (If you wish to use an alternative model see below).</p> <p>If the agent adopts this format for output commands they can be easily retrieved by the environment using code like this:</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#update-world-code-sample","title":"Update World Code Sample","text":"<p>Procedure:</p> <ol> <li>Get Output</li> <li>Change-World-State</li> <li>Send Input</li> </ol> <pre><code>private void updateWorld()\n// See if any commands were generated on the output link\n// (In general we might want to update the world when the agent\n// takes no action in which case some code would be outside this if statement\n// but for this environment that's not necessary).\nif (agent.Commands())\n{\n// perform the command on the output link\nIdentifier command = agent.GetCommand(0);\nif (!command.GetCommandName().equals(MOVE_DISK)) {\nthrow new IllegalStateException(\"Unknown Command: \"\n+ command.GetCommandName());\n}\nif (command.GetParameterValue(SOURCE_PEG) == null ||\ncommand.GetParameterValue(DESTINATION_PEG) == null) {\nthrow new IllegalStateException(\"Parameter(s) missing for Command \"\n+ MOVE_DISK);\n}\nint srcPeg = command.GetParameterValue(\"source-peg\").charAt(0) - 'A';\nint dstPeg = command.GetParameterValue(\"destination-peg\").charAt(0) - 'A';\n// Change the state of the world and generate new input\nmoveDisk(srcPeg, dstPeg);\n// Tell the agent that this command has executed in the environment.\ncommand.AddStatusComplete();\n// Send the new input link changes to the agent\nagent.Commit();\n// \"agent.GetCommand(n)\" is based on watching for changes to the output link\n// so before we do a run we clear the last set of changes.\n// (You can always read the output link directly and not use the\n//  commands model to determine what has changed between runs).\nagent.ClearOutputLinkChanges() ;\nif (isAtGoalState())\nfireAtGoalState();\n}\n}\n</code></pre> <p>The method <code>GetCommandName</code> and <code>GetParameterValue</code> extract the appropriate attributes and values from the output link and return them to the environment.</p> <p>The method <code>AddStatusComplete()</code> adds <code>(C1 ^status complete)</code> to the command structure, indicating to the agent that this command has executed and can now be removed by the agent.</p> <p>(Note that this is simple form of input that in this case is sent to the output link rather than the input link. This is technically a bit of \"back door\" input, but is simpler than passing a large structure to the input link and having the agent match up the two. This addition is made during the agent's next input cycle as with all input).</p> <p>In order for the Commands method to work, the system has to keep track of changes to working memory as only newly added commands are reported through the GetCommand method. For this process to work, the environment must call <code>ClearOutputLinkChanges()</code> before running the agent again.</p> <p>While this Command model should be sufficient for almost all environments, if there is a need to process other structures, the environment can always choose to ignore this model partially or completely. First, the method <code>GetCommand</code> returns an Identifier object. The environment can use the methods <code>GetNumberChildren</code> and <code>GetChild</code> to walk this Identifier and locate any arbitrary working memory element beneath an Identifier or the environment can use the <code>FindByAttribute</code> method to retrieve the values of working memory elements that have a particular attribute.</p> <p>In fact a environment can abandon the Command model completely and simply call <code>GetOutputLink()</code> to get the Identifier object at the top of the output link and proceed to examine the tree (graph) from there.</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#running-the-agents","title":"Running the agent(s)","text":"<p>There are two main methods for running an agent:</p> <ul> <li><code>RunSelfForever()</code> and it's twin <code>RunAllAgentsForever()</code></li> <li><code>RunSelf(1)</code> and <code>RunAllAgents(1)</code> (to step the environment rather than running it).</li> </ul> <p>The trick here is that the code for running the agents should be separate from the code for updating the world (collecting output; updating world state; sending input). By separating the two we can either issue the run from the environment or from a debugger (or other client) and everything works correctly.</p> <p>Let's assume we have the <code>updateWorld()</code> method from above, which should have the form:</p> <pre><code>void updateWorld()\n{\ncheck-for-output() ;\nupdate-world-state() ;\nsend-new-input() ;\n}\n</code></pre> <p>Then the code samples below show how to connect up the system so that updateWorld() is only called once all agents have completed the output phase (i.e. at the end of a decision cycle).</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#run-sample-code","title":"Run Sample Code","text":"<pre><code>public void run()\n{\nm_StopNow = false ;\n// Start a run\n// (since this is single agent could use agent.RunSelfForever() instead, but this shows how to run multi-agent environments)\nkernel.RunAllAgentsForever() ;\n}\npublic void step()\n{\n// Run one decision\nkernel.RunAllAgents(1) ;\n}\npublic void stop()\n{\n// We'd like to call StopSoar() directly from here but we're in a different\n// thread and right now this waits patiently for the runForever call to finish\n// before it executes...not really the right behavior.  So instead we use a flag and\n// issue StopSoar() in a callback.\nm_StopNow = true ;\n}\n</code></pre>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#event-based-method-for-updating-the-world","title":"Event-based method for updating the world","text":"<pre><code>public void registerForUpdateWorldEvent()\n{\nint updateCallback = kernel.RegisterForUpdateEvent(sml.smlUpdateEventId.smlEVENT_AFTER_ALL_OUTPUT_PHASES, this, \"updateEventHandler\", null) ;\n}\npublic void updateEventHandler(int eventID, Object data, Kernel kernel, int runFlags)\n{\n// Might not call updateWorld() depending on runFlags in a fuller environment.\n// See the section below for more on this.\nupdateWorld() ;\n// We have a problem at the moment with calling Stop() from arbitrary threads\n// so for now we'll make sure to call it within an event callback.\n// Do this test after calling updateWorld() so that method can set m_StopNow if it\n// wishes and trigger an immediate stop.\nif (m_StopNow)\n{\nm_StopNow = false ;\nkernel.StopAllAgents() ;\n}\n}\n</code></pre> <p>The Run code is pretty simple. The only issues to be aware of are:</p> <ul> <li><code>RunAllAgentsForever()</code> is currently (8.6.2) a blocking call, so we usually   spawn a thread and issue this call in that thread.</li> <li><code>StopAllAgents()</code> can currently not be called from an arbitrary thread (or it   blocks waiting for the Run to terminate). This may be fixed in a later version,   but for now calling it from an event callback solves this problem.</li> </ul> <p>The way <code>updateWorld()</code> is called is after the <code>smlEVENT_AFTER_ALL_OUTPUT_PHASES</code> event fires. Why bother to do this rather than writing run as:</p> <pre><code>while (!stopped)\n{\nrun(1) ;\nupdate-world() ;\n}\n</code></pre> <p>There are two basic reasons. First, there are no guarantees that <code>run(1)</code> will run for a decision. If we include breakpoints on productions or phase transitions this call may run for less time, possibly confusing the environment (as the agents have not progressed as far as expected). Second, by making the call to <code>updateWorld()</code> event based, we can issue arbitrary run commands from a debugger and the environment will function correctly. For more on this see the \"Event-Driven Environments Proposal.doc\" file.</p> <p>Also in Tcl please be sure to read about how to poll for events in Tcl (see Section 1.6.1).</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#supporting-running-without-updating-the-environment","title":"Supporting running without updating the environment","text":"<p>For some environments it may make sense to allow the user to run an agent without starting the environment. This can be helpful when debugging one agent or having reached a particular situation in the world, stopping and wanting to step slowly to observe the reasoning.</p> <p>To support this the environment should check the runFlags parameter passed to the updateEventHandler. This is a bit field which currently consists of the values in this enum:</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#run-flags","title":"Run Flags","text":"<pre><code>typedef enum\n{\nsml_NONE                =  0,           // No special flags set\nsml_RUN_SELF            =  1 &lt;&lt; 0,      // User included --self flag when running agent\nsml_RUN_ALL             =  1 &lt;&lt; 1,      // User ran all agents\nsml_UPDATE_WORLD        =  1 &lt;&lt; 2,      // User explicitly requested world to update\nsml_DONT_UPDATE_WORLD   =  1 &lt;&lt; 3,      // User explicitly requested world to not update\n} smlRunFlags ;\n</code></pre> <p>Based on these flags, the environment should decide whether to update or not. We leave this entirely to the discretion of the designer because different combinations may make sense for different situations but this might be a typical set (for a multi-agent environment):</p> <p>if <code>sml_RUN_SELF</code> set and <code>SML_UPDATE_WORLD</code> not set or <code>sml_DONT_UPDATE_WORLD</code> set then don't call <code>updateWorld()</code>.</p> <p>The meaning of this would be that:</p> <ul> <li><code>run --self</code> would cause the agent to run but not the environment</li> <li><code>run --noupdate</code> would cause all agents to run but not the environment</li> <li><code>run --self --update</code> would cause one agent to run and update the environment</li> <li><code>run</code> would cause all agents to run and update the environment.</li> </ul> <p>You are free to make other choices if there's a compelling reason.</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#integrating-with-other-clients-esp-the-debugger","title":"Integrating with other clients (esp. the debugger)","text":"<p>One final issue is updating the controls in the environment correctly if the user runs Soar from the debugger and not the environment (e.g. disabling the run button and enabling stop during a run).</p> <p>There are two approaches to this. First, ignore the problem and don't enable/disable controls. Instead, just handle errors if the user tries to issue a second run while a run is already going ahead. The second option is to register for the <code>smlEVENT_SYSTEM_START</code> and <code>smlEVENT_SYSTEM_STOP</code> events and use these to enable/ disable the UI in the environment in appropriate ways.</p> <p>Here's an example for implementing this support:</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#registering-and-handling-startstop-sample-code","title":"Registering and Handling Start/Stop Sample Code","text":"<pre><code>public void registerForStartStopEvents()\n{\nif (kernel != null)\n{\nint startCallback = kernel.RegisterForSystemEvent(smlSystemEventId.smlEVENT_SYSTEM_START, this, \u0093systemEventHandler\u0094, null) ;\nint stopCallback  = kernel.RegisterForSystemEvent(smlSystemEventId.smlEVENT_SYSTEM_STOP, this, \u0093systemEventHandler\u0094, null) ;\n}\n}\npublic void systemEventHandler(int eventID, Object data, Kernel kernel)\n{\nif (eventID == sml.smlSystemEventId.smlEVENT_SYSTEM_START.swigValue())\n{\n// The callback comes in on Soar's thread and we have to update the buttons\n// on the UI thread, so switch threads.\ndpy.asyncExec(new Runnable() { public void run() { updateButtons(true) ; } } ) ;\n}\nif (eventID == sml.smlSystemEventId.smlEVENT_SYSTEM_STOP.swigValue())\n{\n// The callback comes in on Soar's thread and we have to update the buttons\n// on the UI thread, so switch threads.\ndpy.asyncExec(new Runnable() { public void run() { updateButtons(false) ; } } ) ;\n}\n}\npublic void updateButtons(boolean running)\n{\nboolean done = game.isAtGoalState() ;\nstartButton.setEnabled(!running &amp;&amp; !done) ;\nstopButton.setEnabled(running) ;\nresetButton.setEnabled(!running &amp;&amp; !done) ;\nstepButton.setEnabled(!running &amp;&amp; !done) ;\n}\n</code></pre>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#further-details","title":"Further details","text":"<p>To learn more about ClientSML and SML in general, the best documentation is the header files for the methods in ClientSML. In particular, <code>sml_ClientKernel.h</code>, <code>sml_ClientAgent.h</code> and <code>sml_ClientIdentifier.h</code> contain a lot of useful methods and explanations.</p> <p>Beyond that check the Soar XML Interface Spec and any other documentation in its vicinity.</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#using-other-languages","title":"Using other languages","text":"<p>The Tcl and Java interfaces were generated by SWIG. We have provided some custom code to help SWIG out in a few places, mostly with callbacks. If you're interested in creating interfaces for other languages that SWIG supports, check out the SWIG documentation and try to follow our existing solutions.</p> <p>A Tcl package, called Tcl_sml_ClientInterface is available. On Windows it is located in the soar-library directory. This can be used by including the following line in your Tcl code:</p> <pre><code>package require tcl_sml_clientinterface\n</code></pre> <p>Note that the directory where the package resides must be added to Tcl's auto_path variable. The available functions are direct translations of their C++ counterparts. See TOHtest.tcl in soar-library for examples showing how to use the Tcl interface. The Tcl package includes Tcl_sml_ClientInterface.dll (or the equivalent for other platforms), which is required.</p>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#example-environments-in-java","title":"Example Environments in Java","text":"<p>Here are two example clients written in Java, intended to explain the basics of using SML in that language. Thorough explanatory comments are inlined.</p> <ol> <li>A very simple Soar environment.</li> <li>HelloWorld.java</li> <li>helloworld.soar</li> <li>A more complex interactive asynchronous environment.</li> <li>SimpleAsyncEnv.java</li> <li>simpleasyncenv.soar</li> </ol>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#helpful-tips","title":"Helpful Tips","text":"","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#memory-management","title":"Memory Management","text":"<p>Memory management is actually really easy. Generally, the only objects you should explicitly delete are the kernel object and any objects you directly allocated through a call to new. In Java and Tcl, this generally means you can just let things go out of scope when you're done with them. There are a couple special cases you should be aware of, though:</p> <ul> <li>Agent objects are automatically deleted when the owning Kernel object is   deleted (actually, when the call to Kernel::Shutdown is made, which you should   always make before deleting the kernel). If you want to destroy an agent   earlier, you can by making a call to <code>Kernel::destroyAgent</code>. Under no circumstances   should you delete (in the C++ sense) an Agent object.</li> <li>In Java if you create a ClientXML object through <code>xml = new ClientXML()</code> you   should call <code>xml.delete()</code> on it when you're done. This isn't strictly required   (the garbage collector will get it eventually) but is good practice and will   avoid messages about leaked memory when the application shuts down. As per the   general rule, in C++ if you create it with new you're responsible for destroying   it with delete.</li> <li>Since there can be multiple clients interacting with the same kernel and   agents, your application needs to be listening for the appropriate events so if   some other client deletes/destroys a kernel or agent your application is using,   you don't crash. Specifically, listen for the <code>BEFORE_AGENT_DESTROYED</code> and   <code>BEFORE_SHUTDOWN</code> events so you can clean things up as needed in your application.</li> </ul>","tags":["sml"]},{"location":"tutorials/SMLQuickStartGuide/#boosting-performance","title":"Boosting Performance","text":"<p>It is often desirable to maximize the performance of your SML application. This section assumes that you just want to make things as fast as possible after you have finished debugging your application. Debugging is an inherently slow process, so these tips will be less helpful while you're still debugging.</p> <ul> <li>Compile with optimizations turned on. In Visual Studio this means doing a   release build. On Linux and OS X, the default settings are probably sufficient,   but you can experiment with new settings if you want (let us know if you find   better settings).</li> <li>Put primary application and Soar in the same process. That is, use   <code>CreateInNewThread</code> or <code>CreateInCurrentThread</code>, not <code>CreateRemoteConnection</code>. Using a   remote kernel means socket communications are used, which is slow.</li> <li>Don't register for unnecessary events. Every event that is registered for   causes extra work to be done. Try to find an appropriate event to register for   so you don't end up getting more event calls than you actually need - that is,   try to avoid registering for events which occur more frequently than you need   and then filtering them on the application side.</li> <li>Don't connect the debugger. Connecting the debugger creates a remote   connection and also registers for several events.</li> <li>Set watch level 0. Even if you don't have a client registered for any of the   print or XML events, work is still done internally to generate some of the   information that would have been sent out. Setting watch level 0 avoids this   work.</li> <li>Disable monitor productions. Again, even if no client is registered to print   out the text of monitor productions, work is still done internally to prepare   the text. Monitor productions can be disabled by excising them or commenting   them out, but an easier method is to have each monitor production test a debug   flag in working memory which is set by some initialization production or   operator. Thus all of the monitor productions can be turned on or off by   changing one line of code.</li> <li>Disable timers. Soar uses timers internally to generate the output of the   stats command. If you don't need this information, you can use the timers - off   command to disable this bookkeeping. This can make a significant difference in   the watch 0 case.</li> <li>Avoid running agents separately. Instead of calling <code>RunSelf</code> or   <code>RunSelfTilOutput</code> on each agent, just call <code>RunAllAgents</code> on the kernel itself.   This runs all agents together and avoids the overhead of running them   separately. The absolute best you can do is to call <code>RunAllAgentsForever</code> as   described in section 2.4 - this avoids repeatedly calling the run functions at   all and will make it easier to stop and restart your application from the   debugger (or other clients).</li> <li>In the case where the absolute best performance under SML is desired, use   <code>CreateKernelInCurrentThread</code> instead of <code>CreateKernelInNewThread</code> and set the   \"optimized\" flag to true in the parameters passed to   <code>CreateKernelInCurrentThread</code>. This means Soar will execute in the same thread as   your application. Without this each call to and from the Soar kernel requires a   context switch (assuming a single processor machine). This method also   eliminates the thread which polls for new events. This means you must poll for   the events yourself by periodically calling <code>CheckForIncomingCommands</code>, which is   a little more work for the programmer.</li> </ul>","tags":["sml"]},{"location":"tutorials/soar_tutorial/","title":"Soar Tutorial","text":"<ul> <li>Tank Eaters Config</li> </ul>"},{"location":"tutorials/soar_tutorial/TankEatersConfigFile/","title":"Tank Eaters Configuration File","text":"<p>Soar2D is a general framework that includes both Eaters and TankSoar. This document describes how to modify these environments using the configuration settings files.</p>","tags":["eaters"]},{"location":"tutorials/soar_tutorial/TankEatersConfigFile/#configuration-files","title":"Configuration Files","text":"<p>Soar2D configuration files are stored in the Soar2D folder. When running the soar2d jar, you may specify the configuration file to use on the command line, or run without specifying any and a dialog window will pop-up.</p> <pre><code>java -jar soar2d.jar configs/tanksoar.cnf\njava -jar soar2d.jar configs/eaters.cnf\njava -jar soar2d.jar configs/room.cnf\njava -jar soar2d.jar\n</code></pre> <p>Configuration entries are of the format:</p> <pre><code>''key'' = ''value''; # Note the trailing semicolon.\n</code></pre> <p>Use the pound sign for comments. Start them anywhere on a line.</p> <pre><code># Comments go here\nConfiguration keys are simple identifiers. Stick to alphanumeric characters and underscores.\n</code></pre> <pre><code>exampleKey = ''value'';\nexample_key = ''value'';\n</code></pre> <p>Configuration keys have an optional hierarchy separated by dots or braces. These are equivalent:</p> <pre><code>path.to.key = ''value'';\npath.to.another = ''value'';\n\npath\n{\n   to\n   {\n      key = ''value'';\n      another = ''value'';\n   }\n}\n\npath\n{\n   to\n   {\n      key = ''value'';\n   }\n}\npath.to.another = ''value'';\n</code></pre> <p>Configuration values are strings or an array of strings using the following notation:</p> <pre><code>single = data;\nsingle_element_array = [ data ];\ntrailing_comma_ok = [ data, ];\ntwo_element_array = [ data, banks ];\ntwo_element_array_with_trailer = [ data, banks, ];\n</code></pre> <p>Most whitespace is stripped out of the configuration file. These lines are all equivalent:</p> <pre><code>path.to.key = databanks;        # Value is \"databanks\"\npath.to.key = data banks;       # Value is \"databanks\"\npath . to.key = databanks;      # Value is \"databanks\"\npath.t o.key = d a t a banks;   # Value is \"databanks\"\npa th. to. k ey = \"databanks\";  # Value is \"databanks\"\npa th. to. k ey\n= \"databanks\";                  # Value is \"databanks\"\n</code></pre> <p>Preserve spaces using quotes:</p> <pre><code>path.to.key = \"data banks\";     # Value is \"data banks\" with a space.\narrays_too = [ \"data banks\", \"another value\" ]; # Values are \"data banks\" and \"another value\"\n</code></pre> <p>Don't split keys or values across lines:</p> <pre><code>crazy.                 # Syntax error\nspacing = \"databanks\"; #\ncrazy.spacing = \"data  # Value truncated\nbanks\";                # Syntax error\nOK to split other things along lines (or not). These are all legal entires:\n</code></pre> <pre><code>key1 = value1;\nkey2 =\n       value2;\nkey3 = [ value3.1, value3.2, value3.3 ];\nkey4\n=\n[ value4.1, value4.2 ];\nkey5 = [\n     value5.1,\n     value5.2,\n];\nkey6 { subkey6.1 = value6.1; subkey6.2 = value6.2; }\n</code></pre> <p>Backslash doesn't escape anything (this is a change from the original behavior).</p> <p>Code exists to easily pull out types boolean, string, int, double, or arrays of these types:</p> <pre><code>parameter = 5.434; # config.requireDouble(\"parameter\");\nswitch = false;    # config.requireBoolean(\"switch\");\ncount = 4;         # config.requireInt(\"count\");\nplayers = [7, 8]   # config.requireInts(\"players\"); // returns int [] length 2\n</code></pre> <p>Defaults can be enforced in code:</p> <pre><code>config.getInt(\"some.value.not.in.config.file\", 4); // returns 4\n</code></pre>","tags":["eaters"]},{"location":"tutorials/soar_tutorial/TankEatersConfigFile/#clients","title":"Clients","text":"<p>Clients are encoded in a clients block using their names for their sub block. Additionally, their names must be enumerated in an <code>active_clients</code> array. For example:</p> <pre><code>clients\n{\n   active_clients = [ \"watchdog\", \"timer\" ];\n   watchdog\n   {\n      command = \"run-watchdog.bat\";\n   }\n   timer\n   {\n      command = \"run-timer.bat\";\n   }\n   disabled # not enumerated, so it is ignored.\n   {\n      command = \"run-something-someothertime.bat\";\n   }\n}\n</code></pre> <p>Note that there is a default, hidden client named \"java-debugger\". Don't use this name or put it in the active_clients list.</p> Path Type Values Default Comment clients.active_clients string array Each active client. Clients not listed in this array but defined in this block are ignored. clients.''name''.command string Command to run from cwd clients.''name''.timeout int 0 Seconds to wait for client to report in clients.''name''.after boolean true true: spawn after all agents are created, false: spawn before all agents are created","tags":["eaters"]},{"location":"tutorials/soar_tutorial/TankEatersConfigFile/#eaters","title":"eaters","text":"Path Type Values Default Comment eaters.vision int number of cells 2 How far can the eater see? eaters.wall_penalty int points (negative) -5 Penalty for running in to walls eaters.jump_penalty int points (negative) -5 Penalty for executing a jump eaters.low_probability double probability 0.25 Used during random map generation eaters.high_probability double probability 0.75 Used during random map generation","tags":["eaters"]},{"location":"tutorials/soar_tutorial/TankEatersConfigFile/#general","title":"general","text":"Path Type Values Default Comment general.cycle_time_slice double 50 How much simulation time passes per tick (ms) general.default_points int 0 Starting points general.game string tanksoar, eaters, room, kitchen, taxi What game general.map string path Path to map file general.headless boolean false Run headless general.preferences_file string \"preferences\" Path to preferences file (used for common settings to preserve across runs such as last productions, window location). general.runs int 1 How many back-to-back runs to execute general.seed int null (random default) Seed Java and SML general.force_human boolean false Force human input, overrides agent input. Great for debugging input link.","tags":["eaters"]},{"location":"tutorials/soar_tutorial/TankEatersConfigFile/#soar","title":"soar","text":"Path Type Values Default Comment soar.max_memory_usage int bytes kernel default Call command max-memory-usage soar.port int valid TCP ports 12121 Connect/listen on this port soar.remote string IP address null Connect to a remote kernel at this IP soar.spawn_debuggers boolean true Spawn debuggers on agent creation soar.soar_print boolean false Log print events to file","tags":["eaters"]},{"location":"tutorials/soar_tutorial/TankEatersConfigFile/#players","title":"players","text":"<p>Players are encoded in a players block using arbitrary identifiers for their sub blocks. Active player IDs must be enumerated in an <code>active_players</code> array. For example, the following configuration file defines 3 players but only uses two of them for the run:</p> <pre><code>players\n{\n   active_players = [ \"obscure\", \"simple\" ];\n   obscure\n   {\n      productions = \"agents/tanksoar/obscure-bot.soar\";\n   }\n   simple\n   {\n      productions = \"agents/tanksoar/tutorial/simple-bot.soar\";\n   }\n   mapping\n   {\n      productions = \"agents/tanksoar/tutorial/mapping-bot.soar\";\n      shutdown_commands = [ \"echo shutting down\", \"print\" ];\n   }\n}\n</code></pre> <p>Do not id players with the prefix \"gui\" or \"clone\", the players created at runtime use those.</p> Path Type Values Default Comment players.''id''.name string color Agent name players.''id''.productions string null (human) Productions players.''id''.script string null (human) Do not use (yet), for testing players.''id''.color string red, blue, yellow, purple, orange, green, black random desired color players.''id''.pos int array random Starting x,y coordinate (int array, length 2) players.''id''.facing string north, south, east, west random Starting facing direction, cardinal players.''id''.points int 0 Starting points players.''id''.energy int game default Starting energy (tanksoar) players.''id''.health int game default Starting health (tanksoar) players.''id''.missiles int game default Starting missiles (tanksoar) players.''id''.shutdown_commands string array valid Soar commands null Commands to run before destroying agent","tags":["eaters"]},{"location":"tutorials/soar_tutorial/TankEatersConfigFile/#room","title":"room","text":"<p>There are currently no configuration options for the Room environment.</p>","tags":["eaters"]},{"location":"tutorials/soar_tutorial/TankEatersConfigFile/#taxi","title":"taxi","text":"Path Type Values Default Comment taxi.disable_fuel boolean false If disabled, ignore effects of fuel taxi.fuel_starting_minimum int 5 Fuel starts between this and maximum taxi.fuel_starting_maximum int 12 Fuel starts between this and minimum taxi.fuel_maximum int 14 Fuel goes to here when refueled","tags":["eaters"]},{"location":"tutorials/soar_tutorial/TankEatersConfigFile/#tanksoar","title":"tanksoar","text":"Path Type Values Default Comment tanksoar.max_missiles 15 Maximum missile count tanksoar.max_energy 1000 Maximum energy count tanksoar.max_health 1000 Maximum health count tanksoar.collision_penalty -100 Penalty for colliding with another tank or wall tanksoar.max_missile_packs 3 Maximum number of missile packs to spawn at a time tanksoar.missile_pack_respawn_chance 5 Chance per turn that a missile pack spawns when below max tanksoar.shield_energy_usage -20 Energy usage per turn that shields are on tanksoar.missile_hit_award 2 Points awarded when your missile connects with a tank tanksoar.missile_hit_penalty -1 Points lost when hit by a missile tanksoar.frag_award 3 Points awarded when your missile frags a tank tanksoar.frag_penalty -2 Points lost when fragged by a missile tanksoar.max_sound_distance 7 Maximum distance for the sound sensor tanksoar.missile_reset_threshold 100 Max amount of updates that can pass without a missile firing before resetting the map","tags":["eaters"]},{"location":"tutorials/soar_tutorial/TankEatersConfigFile/#terminals","title":"terminals","text":"Path Type Values Default Comment terminals.max_updates int 0 World cycle count limit terminals.agent_command boolean false Agent issues stop command (input-link, not stop-soar) terminals.points_remaining boolean false No more points available on map terminals.winning_score int 0 At least one agent has at least this many points terminals.food_remaining boolean false There is no more food on the map (eaters) terminals.unopened_boxes boolean false There are no unopened boxes on the map (eaters) terminals.fuel_remaining boolean false Run out of fuel (taxi) terminals.passenger_delivered boolean false Passenger successfully delivered (taxi) terminals.passenger_pick_up boolean false Passenger removed from map (taxi)","tags":["eaters"]},{"location":"tutorials/soar_tutorial/TankEatersConfigFile/#logging","title":"Logging","text":"<p>http://logging.apache.org/log4j/1.2/index.html</p>","tags":["eaters"]},{"location":"tutorials/soar_tutorial/TankEatersConfigFile/#map-files","title":"Map Files","text":"<p>Maps are now stored in the config/maps/game folder where game is the game type, such as eaters.</p>","tags":["eaters"]},{"location":"tutorials/soar_tutorial/TankEatersConfigFile/#map-file","title":"Map file","text":"<ul> <li><code>objects_file (string)</code><ul> <li>This file defines objects in the world, see Object File below. The path is     relative to the map file.</li> </ul> </li> <li><code>objects (string array)</code><ul> <li>This is an array of objects ids that are available for use on the map. Often     time these ids are one character so the map is easily human-readable.</li> </ul> </li> <li><code>cells (block)</code><ul> <li>This sub-block defines the cells in the map, or properties about the cells     that will be randomly generated.</li> </ul> </li> <li><code>cells.size (int)</code><ul> <li>Width and height of map.</li> </ul> </li> <li><code>cells.random_walls (boolean)</code><ul> <li>Randomly generate the walls on this map.</li> </ul> </li> <li><code>cells.random_food (boolean)</code><ul> <li>Randomly place food on the map.</li> </ul> </li> <li><code>cells.rows (block)</code><ul> <li>Cell instances</li> </ul> </li> <li><code>cells.rows.INTEGER (string array)</code><ul> <li>The rows the map, from 0 to size - 1, represented as an array of strings.     The strings maps to object ids. Separate multiple objects with dashes. Use a     single dash for an empty cell.</li> </ul> </li> </ul>","tags":["eaters"]},{"location":"tutorials/soar_tutorial/TankEatersConfigFile/#objects-file","title":"Objects File","text":"<p>Objects are under an objects sub-block, and then an id block where the name of the block is their id used in the human-readable map file. Objects need a name property, which is how they are referred to in the code and logs. The rest of the properties are mostly domain specific.</p> <pre><code># &lt;ignored&gt; means that the value is ignored, key presence is used for \"true\"\n# objects {\n#    +&lt;id&gt; {\n#       name = &lt;name&gt;;\n#       *&lt;p1&gt; = &lt;value&gt;;                     # user property\n#       *&lt;p1&gt; = [&lt;value1&gt;, &lt;value2&gt;];        # user property\n#       ?apply.points = &lt;int&gt;;               # number of points to apply\n#       ?apply.energy = &lt;int&gt;;               # amount of energy to apply\n#       ?apply.energy.shields = &lt;boolean&gt;;   # condition for energy apply\n#       ?apply.health = &lt;int&gt;;               # amount of health to apply\n#       ?apply.health.shields-down = &lt;boolean&gt;; # condition for health apply\n#       ?apply.missiles = &lt;int&gt;;             # number of missiles to apply\n#       ?apply.remove = &lt;boolean&gt;;           # remove on apply\n#       ?box-id = &lt;int&gt;;                     # this box's id number (set after load)\n#       ?apply.reward-info = &lt;boolean&gt;;      # contains reward information\n#       ?apply.reward-info.positive-id = &lt;int&gt;; # correct box id (set after load)\n#       ?apply.reward = &lt;boolean&gt;;           # is reward box\n#       ?apply.reward.correct = &lt;boolean&gt;;   # is the correct box (set randomly after load)\n#       ?apply.reward.positive = &lt;int&gt;;      # reward if correct\n#       ?apply.reward.negative = &lt;int&gt;;      # \"reward\" if incorrect, different from wrong box\n#       ?apply.reset = &lt;boolean&gt;;            # reset sim on apply\n#       ?apply.properties {                  # these get moved to top level on applyProperties call\n#          ?&lt;p1&gt; = &lt;value&gt;;                  # user apply property\n#          ?&lt;p1&gt; = [&lt;value1&gt;, &lt;value2&gt;];     # user apply property\n#       }\n#       ?update.decay = &lt;int&gt;;               # decay apply.points by this amount on update\n#       ?update.fly-missile = &lt;int&gt;;         # increment update.fly-missile phase on update\n#       ?update.linger = &lt;int&gt;;              # decrement update.linger on update, remove at 0\n#    }\n#}\n</code></pre>","tags":["eaters"]},{"location":"soar/tags/","title":"Tags","text":"<p>Following is a list of relevant tags:</p>"},{"location":"soar/tags/#ros","title":"ROS","text":"<ul> <li>Building Soar and ROS1</li> </ul>"},{"location":"soar/tags/#agent-debugging","title":"agent debugging","text":"<ul> <li>Design Dogma</li> <li>Java Soar Debugger Intro</li> </ul>"},{"location":"soar/tags/#compile","title":"compile","text":"<ul> <li>Building Soar and ROS1</li> <li>How to compile SML Clients</li> </ul>"},{"location":"soar/tags/#debugger","title":"debugger","text":"<ul> <li>Command-Line Options for the Java Debugger and CLI</li> <li>Java Soar Debugger Intro</li> </ul>"},{"location":"soar/tags/#eaters","title":"eaters","text":"<ul> <li>Tank and Eaters Configuration</li> </ul>"},{"location":"soar/tags/#event","title":"event","text":"<ul> <li>SML Output Link Guide</li> </ul>"},{"location":"soar/tags/#institutions","title":"institutions","text":"<ul> <li>Academic Institutions</li> </ul>"},{"location":"soar/tags/#io","title":"io","text":"<ul> <li>SML Output Link Guide</li> </ul>"},{"location":"soar/tags/#kernel-programming","title":"kernel programming","text":"<ul> <li>Basic Kernel Terminology</li> <li>Timers</li> <li>Waterfall</li> <li>CLI Parsing Code</li> <li>IO and Reward Links</li> <li>Memory Leak Debugging with Visual Studio</li> </ul>"},{"location":"soar/tags/#organizations","title":"organizations","text":"<ul> <li>Commercial Soar Organizations</li> </ul>"},{"location":"soar/tags/#research","title":"research","text":"<ul> <li>Publications</li> <li>Research Groups</li> </ul>"},{"location":"soar/tags/#sml","title":"sml","text":"<ul> <li>Threads in SML</li> <li>SML Output Link Guide</li> <li>Soar Technical FAQ</li> <li>Soar Markup Language</li> </ul>"},{"location":"soar/tags/#substate","title":"substate","text":"<ul> <li>Waterfall</li> </ul>"},{"location":"soar/tags/#threads","title":"threads","text":"<ul> <li>Threads in SML</li> </ul>"}]}